{"id": "2512.13860", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13860", "abs": "https://arxiv.org/abs/2512.13860", "authors": ["Henger Li", "Shuangjie You", "Flavio Di Palo", "Yiyue Qian", "Ayush Jain"], "title": "Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors", "comment": "Accepted by AAAI 2026 Workshop on Agentic AI Benchmarks and Applications for Enterprise Tasks", "summary": "Tool calling enables large language models (LLMs) to interact with external environments through tool invocation, providing a practical way to overcome the limitations of pretraining. However, the effectiveness of tool use depends heavily on the quality of the associated documentation and knowledge base context. These materials are usually written for human users and are often misaligned with how LLMs interpret information. This problem is even more pronounced in industrial settings, where hundreds of tools with overlapping functionality create challenges in scalability, variability, and ambiguity. We propose Verification-Guided Context Optimization (VGCO), a framework that uses LLMs as editors to automatically refine tool-related documentation and knowledge base context. VGCO works in two stages. First, Evaluation collects real-world failure cases and identifies mismatches between tools and their context. Second, Optimization performs hierarchical editing through offline learning with structure-aware, in-context optimization. The novelty of our LLM editors has three main aspects. First, they use a hierarchical structure that naturally integrates into the tool-calling workflow. Second, they are state-aware, action-specific, and verification-guided, which constrains the search space and enables efficient, targeted improvements. Third, they enable cost-efficient sub-task specialization, either by prompt engineering large editor models or by post-training smaller editor models. Unlike prior work that emphasizes multi-turn reasoning, VGCO focuses on the single-turn, large-scale tool-calling problem and achieves significant improvements in accuracy, robustness, and generalization across LLMs.", "AI": {"tldr": "VGCO\u6846\u67b6\u4f7f\u7528LLM\u4f5c\u4e3a\u7f16\u8f91\u5668\u81ea\u52a8\u4f18\u5316\u5de5\u5177\u6587\u6863\u548c\u77e5\u8bc6\u5e93\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7\u8bc4\u4f30\u548c\u4f18\u5316\u4e24\u9636\u6bb5\u89e3\u51b3\u5de5\u5177\u8c03\u7528\u4e2d\u7684\u6587\u6863\u4e0eLLM\u7406\u89e3\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u5de5\u5177\u8c03\u7528\u4f9d\u8d56\u7684\u6587\u6863\u548c\u77e5\u8bc6\u5e93\u4e0a\u4e0b\u6587\u901a\u5e38\u4e3a\u4eba\u7c7b\u7528\u6237\u8bbe\u8ba1\uff0c\u4e0eLLM\u7684\u4fe1\u606f\u5904\u7406\u65b9\u5f0f\u4e0d\u5339\u914d\uff0c\u7279\u522b\u662f\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u5b58\u5728\u5927\u91cf\u529f\u80fd\u91cd\u53e0\u7684\u5de5\u5177\uff0c\u5bfc\u81f4\u53ef\u6269\u5c55\u6027\u3001\u53ef\u53d8\u6027\u548c\u6a21\u7cca\u6027\u6311\u6218\u3002", "method": "\u63d0\u51fa\u9a8c\u8bc1\u5f15\u5bfc\u7684\u4e0a\u4e0b\u6587\u4f18\u5316\u6846\u67b6VGCO\uff0c\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u8bc4\u4f30\u9636\u6bb5\u6536\u96c6\u771f\u5b9e\u5931\u8d25\u6848\u4f8b\u5e76\u8bc6\u522b\u5de5\u5177\u4e0e\u4e0a\u4e0b\u6587\u7684\u4e0d\u5339\u914d\uff1b\u4f18\u5316\u9636\u6bb5\u901a\u8fc7\u79bb\u7ebf\u5b66\u4e60\u8fdb\u884c\u5206\u5c42\u7f16\u8f91\uff0c\u91c7\u7528\u7ed3\u6784\u611f\u77e5\u7684\u4e0a\u4e0b\u6587\u5185\u4f18\u5316\u3002LLM\u7f16\u8f91\u5668\u5177\u6709\u5206\u5c42\u7ed3\u6784\u3001\u72b6\u6001\u611f\u77e5\u3001\u52a8\u4f5c\u7279\u5b9a\u548c\u9a8c\u8bc1\u5f15\u5bfc\u7684\u7279\u70b9\u3002", "result": "VGCO\u5728\u5355\u8f6e\u5927\u89c4\u6a21\u5de5\u5177\u8c03\u7528\u95ee\u9898\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u76f8\u6bd4\u4e4b\u524d\u5f3a\u8c03\u591a\u8f6e\u63a8\u7406\u7684\u5de5\u4f5c\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "VGCO\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u4f18\u5316\u5de5\u5177\u76f8\u5173\u6587\u6863\u548c\u77e5\u8bc6\u5e93\u4e0a\u4e0b\u6587\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u5de5\u5177\u8c03\u7528\u4e2d\u7684\u6587\u6863\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e3a\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5927\u89c4\u6a21\u5de5\u5177\u8c03\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "topic": "code agent"}}
{"id": "2512.13914", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.13914", "abs": "https://arxiv.org/abs/2512.13914", "authors": ["Bhargav Chickmagalur Nanjundappa", "Spandan Maaheshwari"], "title": "Context Branching for LLM Conversations: A Version Control Approach to Exploratory Programming", "comment": "11 pages, 4 figures, 2 tables, 1 code snippet, 4 algorithms", "summary": "Large Language Models (LLMs) have become integral to software engineering workflows, yet their effectiveness degrades significantly in multi-turn conversations. Recent studies demonstrate an average 39% performance drop when instructions are delivered across multiple turns, with models making premature assumptions and failing to course correct (Laban et al., 2025). This degradation is particularly problematic in exploratory programming tasks where developers need to investigate alternative approaches without committing to a single path. Current solutions force users into a false dichotomy: continue in a context-polluted conversation where the LLM becomes increasingly confused, or start fresh and lose all accumulated context.\n  We present ContextBranch, a conversation management system that applies version control semantics to LLM interactions. ContextBranch provides four core primitives--checkpoint, branch, switch, and inject--enabling users to capture conversation state, explore alternatives in isolation, and selectively merge insights. We evaluate ContextBranch through a controlled experiment with 30 software engineering scenarios featuring intentionally polluting explorations. Branched conversations achieved higher response quality compared to linear conversations, with large improvements in focus and context awareness. Benefits were concentrated in complex scenarios involving conceptually distant explorations. Branching reduced context size by 58.1% (31.0 to 13.0 messages), eliminating irrelevant exploratory content. Our work establishes conversation branching as a fundamental primitive for AI-assisted exploratory work, demonstrating that isolation prevents context pollution when exploring alternatives.", "AI": {"tldr": "ContextBranch\u662f\u4e00\u4e2a\u5bf9\u8bdd\u7ba1\u7406\u7cfb\u7edf\uff0c\u5c06\u7248\u672c\u63a7\u5236\u8bed\u4e49\u5e94\u7528\u4e8eLLM\u4ea4\u4e92\uff0c\u901a\u8fc7\u68c0\u67e5\u70b9\u3001\u5206\u652f\u3001\u5207\u6362\u548c\u6ce8\u5165\u56db\u4e2a\u6838\u5fc3\u539f\u8bed\uff0c\u89e3\u51b3\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u6027\u80fd\u4e0b\u964d\u548c\u4e0a\u4e0b\u6587\u6c61\u67d3\u95ee\u9898\u3002", "motivation": "LLM\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff08\u5e73\u5747\u4e0b\u964d39%\uff09\uff0c\u7279\u522b\u662f\u5728\u63a2\u7d22\u6027\u7f16\u7a0b\u4efb\u52a1\u4e2d\uff0c\u7528\u6237\u9700\u8981\u5728\u4e0d\u540c\u65b9\u6cd5\u95f4\u5207\u6362\u800c\u4e0d\u4e22\u5931\u4e0a\u4e0b\u6587\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u7ee7\u7eed\u88ab\u6c61\u67d3\u7684\u5bf9\u8bdd\uff0c\u8981\u4e48\u91cd\u65b0\u5f00\u59cb\u4e22\u5931\u6240\u6709\u79ef\u7d2f\u7684\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51faContextBranch\u7cfb\u7edf\uff0c\u5f15\u5165\u56db\u4e2a\u6838\u5fc3\u539f\u8bed\uff1acheckpoint\uff08\u68c0\u67e5\u70b9\uff09\u6355\u83b7\u5bf9\u8bdd\u72b6\u6001\uff0cbranch\uff08\u5206\u652f\uff09\u5728\u9694\u79bb\u73af\u5883\u4e2d\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848\uff0cswitch\uff08\u5207\u6362\uff09\u5728\u4e0d\u540c\u5206\u652f\u95f4\u79fb\u52a8\uff0cinject\uff08\u6ce8\u5165\uff09\u9009\u62e9\u6027\u5408\u5e76\u89c1\u89e3\u3002", "result": "\u572830\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u573a\u666f\u7684\u5b9e\u9a8c\u4e2d\uff0c\u5206\u652f\u5bf9\u8bdd\u76f8\u6bd4\u7ebf\u6027\u5bf9\u8bdd\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u54cd\u5e94\uff0c\u5728\u6d89\u53ca\u6982\u5ff5\u4e0a\u9065\u8fdc\u63a2\u7d22\u7684\u590d\u6742\u573a\u666f\u4e2d\u6539\u8fdb\u6700\u5927\u3002\u5206\u652f\u5c06\u4e0a\u4e0b\u6587\u5927\u5c0f\u51cf\u5c1158.1%\uff08\u4ece31.0\u6761\u6d88\u606f\u51cf\u5c11\u523013.0\u6761\uff09\uff0c\u6d88\u9664\u4e86\u4e0d\u76f8\u5173\u7684\u63a2\u7d22\u5185\u5bb9\u3002", "conclusion": "\u5bf9\u8bdd\u5206\u652f\u662fAI\u8f85\u52a9\u63a2\u7d22\u6027\u5de5\u4f5c\u7684\u57fa\u672c\u539f\u8bed\uff0c\u9694\u79bb\u673a\u5236\u5728\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848\u65f6\u80fd\u6709\u6548\u9632\u6b62\u4e0a\u4e0b\u6587\u6c61\u67d3\u3002", "topic": "code agent"}}
{"id": "2512.14012", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.14012", "abs": "https://arxiv.org/abs/2512.14012", "authors": ["Ruanqianqian Huang", "Avery Reyna", "Sorin Lerner", "Haijun Xia", "Brian Hempel"], "title": "Professional Software Developers Don't Vibe, They Control: AI Agent Use for Coding in 2025", "comment": null, "summary": "The rise of AI agents is transforming how software can be built. The promise of agents is that developers might write code quicker, delegate multiple tasks to different agents, and even write a full piece of software purely out of natural language. In reality, what roles agents play in professional software development remains in question. This paper investigates how experienced developers use agents in building software, including their motivations, strategies, task suitability, and sentiments. Through field observations (N=13) and qualitative surveys (N=99), we find that while experienced developers value agents as a productivity boost, they retain their agency in software design and implementation out of insistence on fundamental software quality attributes, employing strategies for controlling agent behavior leveraging their expertise. In addition, experienced developers feel overall positive about incorporating agents into software development given their confidence in complementing the agents' limitations. Our results shed light on the value of software development best practices in effective use of agents, suggest the kinds of tasks for which agents may be suitable, and point towards future opportunities for better agentic interfaces and agentic use guidelines.", "AI": {"tldr": "\u7ecf\u9a8c\u5f00\u53d1\u8005\u5c06AI\u4ee3\u7406\u89c6\u4e3a\u751f\u4ea7\u529b\u5de5\u5177\uff0c\u4f46\u4fdd\u6301\u5bf9\u8f6f\u4ef6\u8bbe\u8ba1\u548c\u5b9e\u73b0\u7684\u63a7\u5236\u6743\uff0c\u901a\u8fc7\u4e13\u4e1a\u77e5\u8bc6\u6307\u5bfc\u4ee3\u7406\u884c\u4e3a\uff0c\u6574\u4f53\u5bf9\u4ee3\u7406\u6301\u79ef\u6781\u6001\u5ea6\u3002", "motivation": "\u7814\u7a76AI\u4ee3\u7406\u5728\u4e13\u4e1a\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u9645\u89d2\u8272\uff0c\u4e86\u89e3\u7ecf\u9a8c\u5f00\u53d1\u8005\u5982\u4f55\u4f7f\u7528\u4ee3\u7406\u3001\u4ed6\u4eec\u7684\u52a8\u673a\u3001\u7b56\u7565\u3001\u4efb\u52a1\u9002\u7528\u6027\u548c\u60c5\u611f\u6001\u5ea6\u3002", "method": "\u901a\u8fc7\u5b9e\u5730\u89c2\u5bdf\uff08N=13\uff09\u548c\u5b9a\u6027\u8c03\u67e5\uff08N=99\uff09\u6536\u96c6\u6570\u636e\uff0c\u5206\u6790\u7ecf\u9a8c\u5f00\u53d1\u8005\u4f7f\u7528AI\u4ee3\u7406\u7684\u6a21\u5f0f\u548c\u7b56\u7565\u3002", "result": "\u7ecf\u9a8c\u5f00\u53d1\u8005\u91cd\u89c6\u4ee3\u7406\u4f5c\u4e3a\u751f\u4ea7\u529b\u63d0\u5347\u5de5\u5177\uff0c\u4f46\u575a\u6301\u5bf9\u8f6f\u4ef6\u8bbe\u8ba1\u548c\u5b9e\u73b0\u7684\u63a7\u5236\uff0c\u4ee5\u786e\u4fdd\u8f6f\u4ef6\u8d28\u91cf\uff1b\u4ed6\u4eec\u5229\u7528\u4e13\u4e1a\u77e5\u8bc6\u6307\u5bfc\u4ee3\u7406\u884c\u4e3a\uff0c\u5bf9\u4ee3\u7406\u878d\u5165\u8f6f\u4ef6\u5f00\u53d1\u6301\u79ef\u6781\u6001\u5ea6\u3002", "conclusion": "\u8f6f\u4ef6\u5f00\u53d1\u6700\u4f73\u5b9e\u8df5\u5bf9\u6709\u6548\u4f7f\u7528\u4ee3\u7406\u81f3\u5173\u91cd\u8981\uff0c\u7814\u7a76\u6307\u51fa\u4e86\u4ee3\u7406\u9002\u7528\u7684\u4efb\u52a1\u7c7b\u578b\uff0c\u5e76\u5efa\u8bae\u672a\u6765\u6539\u8fdb\u4ee3\u7406\u754c\u9762\u548c\u4f7f\u7528\u6307\u5357\u3002", "topic": "agent analysis"}}
{"id": "2512.14018", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14018", "abs": "https://arxiv.org/abs/2512.14018", "authors": ["Jiuding Yang", "Shengyao Lu", "Hongxuan Liu", "Shayan Shirahmad Gale Bagi", "Zahra Fazel", "Tomasz Czajkowski", "Di Niu"], "title": "PerfCoder: Large Language Models for Interpretable Code Performance Optimization", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in automatic code generation, yet their ability to produce high-performance code remains limited--a critical requirement in real-world software systems. We argue that current LLMs struggle not only due to data scarcity but, more importantly, because they lack supervision that guides interpretable and effective performance improvements. In this work, we introduce PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code from source code via interpretable, customized optimizations. PerfCoder is fine-tuned on a curated collection of real-world optimization trajectories with human-readable annotations, and preference-aligned by reinforcement fine-tuning using runtime measurements, enabling it to propose input-specific improvement strategies and apply them directly without relying on iterative refinement. On the PIE code performance benchmark, PerfCoder surpasses all existing models in both runtime speedup and effective optimization rate, demonstrating that performance optimization cannot be achieved by scale alone but requires optimization stratetgy awareness. In addition, PerfCoder can generate interpretable feedback about the source code, which, when provided as input to a larger LLM in a planner-and-optimizer cooperative workflow, can further improve outcomes. Specifically, we elevate the performance of 32B models and GPT-5 to new levels on code optimization, substantially surpassing their original performance.", "AI": {"tldr": "PerfCoder\u662f\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u751f\u6210\u9ad8\u6027\u80fd\u4ee3\u7801\u7684LLM\u5bb6\u65cf\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u5b9a\u5236\u5316\u4f18\u5316\u6765\u63d0\u5347\u4ee3\u7801\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u8fd0\u884c\u65f6\u52a0\u901f\u548c\u4f18\u5316\u7387\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524dLLM\u5728\u81ea\u52a8\u4ee3\u7801\u751f\u6210\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u751f\u6210\u9ad8\u6027\u80fd\u4ee3\u7801\u65b9\u9762\u4ecd\u6709\u5c40\u9650\u3002\u8fd9\u4e0d\u4ec5\u662f\u7531\u4e8e\u6570\u636e\u7a00\u7f3a\uff0c\u66f4\u91cd\u8981\u7684\u662f\u7f3a\u4e4f\u6307\u5bfc\u53ef\u89e3\u91ca\u548c\u6709\u6548\u6027\u80fd\u6539\u8fdb\u7684\u76d1\u7763\u3002", "method": "PerfCoder\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u6784\u5efa\uff1a1\uff09\u5728\u5e26\u6709\u4eba\u7c7b\u53ef\u8bfb\u6ce8\u91ca\u7684\u771f\u5b9e\u4e16\u754c\u4f18\u5316\u8f68\u8ff9\u4e0a\u8fdb\u884c\u5fae\u8c03\uff1b2\uff09\u4f7f\u7528\u8fd0\u884c\u65f6\u6d4b\u91cf\u8fdb\u884c\u5f3a\u5316\u5fae\u8c03\u4ee5\u5b9e\u73b0\u504f\u597d\u5bf9\u9f50\uff1b3\uff09\u80fd\u591f\u63d0\u51fa\u8f93\u5165\u7279\u5b9a\u7684\u6539\u8fdb\u7b56\u7565\u5e76\u76f4\u63a5\u5e94\u7528\uff0c\u65e0\u9700\u4f9d\u8d56\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728PIE\u4ee3\u7801\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPerfCoder\u5728\u8fd0\u884c\u65f6\u52a0\u901f\u548c\u6709\u6548\u4f18\u5316\u7387\u65b9\u9762\u8d85\u8d8a\u4e86\u6240\u6709\u73b0\u6709\u6a21\u578b\u3002\u6b64\u5916\uff0c\u5f53PerfCoder\u7684\u53ef\u89e3\u91ca\u53cd\u9988\u4f5c\u4e3a\u8f93\u5165\u63d0\u4f9b\u7ed9\u66f4\u5927LLM\u65f6\uff0c\u5728\u89c4\u5212\u8005-\u4f18\u5316\u5668\u534f\u4f5c\u5de5\u4f5c\u6d41\u4e2d\uff0c\u80fd\u591f\u5c0632B\u6a21\u578b\u548cGPT-5\u7684\u6027\u80fd\u63d0\u5347\u5230\u65b0\u6c34\u5e73\u3002", "conclusion": "\u6027\u80fd\u4f18\u5316\u4e0d\u80fd\u4ec5\u901a\u8fc7\u89c4\u6a21\u6269\u5c55\u5b9e\u73b0\uff0c\u800c\u9700\u8981\u4f18\u5316\u7b56\u7565\u610f\u8bc6\u3002PerfCoder\u5c55\u793a\u4e86\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u76d1\u7763\u548c\u5f3a\u5316\u5fae\u8c03\uff0cLLM\u80fd\u591f\u751f\u6210\u9ad8\u6027\u80fd\u4ee3\u7801\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u53cd\u9988\u3002", "topic": "code agent"}}
{"id": "2512.14064", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14064", "abs": "https://arxiv.org/abs/2512.14064", "authors": ["Yi Hu", "Cai Zhou", "Muhan Zhang"], "title": "What Affects the Effective Depth of Large Language Models?", "comment": null, "summary": "The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of \"effective depth\", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model scale, training type, and task difficulty. First, we analyze the model behavior of Qwen-2.5 family (1.5B-32B) and find that while the number of effective layers grows with model size, the effective depth ratio remains stable. Besides, comparisons between base and corresponding long-CoT models show no increase in effective depth, suggesting that improved reasoning stems from longer context rather than deeper per-token computation. Furthermore, evaluations across tasks of varying difficulty indicate that models do not dynamically use more layers for harder problems. Our results suggest that current LLMs underuse available depth across scales, training paradigms and tasks of varying difficulties, pointing out research opportunities on increasing the layer utilization rate of LLMs, model pruning, and early exiting. Our code is released at https://github.com/AheadOFpotato/what_affects_effective_depth.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u89c4\u6a21\u3001\u8bad\u7ec3\u8303\u5f0f\u548c\u4efb\u52a1\u96be\u5ea6\u4e0b\u90fd\u5b58\u5728\u5c42\u5229\u7528\u7387\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u6709\u6548\u6df1\u5ea6\u6bd4\u4f8b\u4fdd\u6301\u7a33\u5b9a\u800c\u975e\u968f\u96be\u5ea6\u589e\u52a0\uff0c\u63a8\u7406\u80fd\u529b\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u4e0a\u4e0b\u6587\u957f\u5ea6\u800c\u975e\u66f4\u6df1\u5c42\u8ba1\u7b97\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5411\u66f4\u6df1\u5c42\u53d1\u5c55\uff0c\u6027\u80fd\u589e\u76ca\u5374\u9010\u6e10\u51cf\u5c11\u3002\u5148\u524d\u7814\u7a76\u63d0\u51fa\"\u6709\u6548\u6df1\u5ea6\"\u6982\u5ff5\uff0c\u8ba4\u4e3a\u6df1\u5c42\u6a21\u578b\u672a\u80fd\u5145\u5206\u5229\u7528\u6240\u6709\u5c42\u8fdb\u884c\u6709\u610f\u4e49\u7684\u8ba1\u7b97\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u63a2\u7d22\u6709\u6548\u6df1\u5ea6\u5982\u4f55\u968f\u6a21\u578b\u89c4\u6a21\u3001\u8bad\u7ec3\u7c7b\u578b\u548c\u4efb\u52a1\u96be\u5ea6\u53d8\u5316\u3002", "method": "\u7cfb\u7edf\u5206\u6790Qwen-2.5\u7cfb\u5217\u6a21\u578b\uff081.5B-32B\uff09\uff0c\u7814\u7a76\u6709\u6548\u5c42\u6570\u968f\u6a21\u578b\u89c4\u6a21\u7684\u53d8\u5316\uff1b\u6bd4\u8f83\u57fa\u7840\u6a21\u578b\u4e0e\u5bf9\u5e94\u957f\u601d\u7ef4\u94fe\u6a21\u578b\u7684\u6709\u6548\u6df1\u5ea6\uff1b\u8bc4\u4f30\u4e0d\u540c\u96be\u5ea6\u4efb\u52a1\u4e0b\u6a21\u578b\u662f\u5426\u52a8\u6001\u4f7f\u7528\u66f4\u591a\u5c42\u3002", "result": "\u6709\u6548\u5c42\u6570\u968f\u6a21\u578b\u89c4\u6a21\u589e\u957f\uff0c\u4f46\u6709\u6548\u6df1\u5ea6\u6bd4\u4f8b\u4fdd\u6301\u7a33\u5b9a\uff1b\u957f\u601d\u7ef4\u94fe\u6a21\u578b\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u5e76\u672a\u589e\u52a0\u6709\u6548\u6df1\u5ea6\uff0c\u63a8\u7406\u80fd\u529b\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u66f4\u957f\u4e0a\u4e0b\u6587\u800c\u975e\u66f4\u6df1\u5c42\u8ba1\u7b97\uff1b\u6a21\u578b\u4e0d\u4f1a\u4e3a\u66f4\u96be\u95ee\u9898\u52a8\u6001\u4f7f\u7528\u66f4\u591a\u5c42\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u4e0d\u540c\u89c4\u6a21\u3001\u8bad\u7ec3\u8303\u5f0f\u548c\u4efb\u52a1\u96be\u5ea6\u4e0b\u90fd\u5b58\u5728\u5c42\u5229\u7528\u7387\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u8fd9\u4e3a\u63d0\u5347LLM\u5c42\u5229\u7528\u7387\u3001\u6a21\u578b\u526a\u679d\u548c\u65e9\u671f\u9000\u51fa\u7b49\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "topic": "agent analysis"}}
{"id": "2512.13713", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.13713", "abs": "https://arxiv.org/abs/2512.13713", "authors": ["Ali Parsaee", "Yashar Talebirad", "Csongor Szepesv\u00e1ri", "Vishwajeet Ohal", "Eden Redman"], "title": "LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms", "comment": "11 pages, 3 figures, submitted to ANTS 2026", "summary": "Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \\textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infinite loops. A strategy passing mechanism is implemented as a form of consistent memory. We show that while standard LLMs and classical heuristics struggle, advanced reasoning models (e.g., O3) devise strategies to escape deadlocks. LoopBench allows the study of emergent distributed algorithms based on language-based reasoning, offering a testbed for collective intelligence.", "AI": {"tldr": "LoopBench\u662f\u4e00\u4e2a\u8bc4\u4f30LLM\u5728\u5206\u5e03\u5f0f\u5bf9\u79f0\u6027\u6253\u7834\u548c\u5143\u8ba4\u77e5\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u5947\u6570\u73af\u56fe\u7740\u8272\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u80fd\u591f\u8bbe\u8ba1\u7b56\u7565\u907f\u514d\u6b7b\u9501\u3002", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u88ab\u7528\u4f5c\u81ea\u4e3b\u4ee3\u7406\uff0c\u4f46\u5b83\u4eec\u5728\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u534f\u8c03\u80fd\u529b\u4ecd\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u9700\u8981\u8bc4\u4f30LLM\u5728\u5206\u5e03\u5f0f\u5bf9\u79f0\u6027\u6253\u7834\u548c\u5143\u8ba4\u77e5\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165LoopBench\u57fa\u51c6\uff0c\u4e13\u6ce8\u4e8e\u5947\u6570\u73af\u56fe\uff08C3\u3001C5\u3001C11\uff09\u7684\u7740\u8272\u95ee\u9898\uff0c\u4f7f\u7528\u6709\u9650\u989c\u8272\u3002\u5b9e\u73b0\u7b56\u7565\u4f20\u9012\u673a\u5236\u4f5c\u4e3a\u4e00\u81f4\u5185\u5b58\u5f62\u5f0f\uff0c\u8bc4\u4f30LLM\u5728\u975e\u901a\u4fe1\u4ee3\u7406\u73af\u5883\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u6807\u51c6LLM\u548c\u7ecf\u5178\u542f\u53d1\u5f0f\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u800c\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\uff08\u5982O3\uff09\u80fd\u591f\u8bbe\u8ba1\u7b56\u7565\u6765\u907f\u514d\u6b7b\u9501\u548c\u65e0\u9650\u5faa\u73af\u3002", "conclusion": "LoopBench\u4e3a\u7814\u7a76\u57fa\u4e8e\u8bed\u8a00\u63a8\u7406\u7684\u5206\u5e03\u5f0f\u7b97\u6cd5\u63d0\u4f9b\u4e86\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6709\u52a9\u4e8e\u63a2\u7d22\u96c6\u4f53\u667a\u80fd\u7684\u6d8c\u73b0\u884c\u4e3a\u3002", "topic": "agent analysis"}}
{"id": "2512.13714", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13714", "abs": "https://arxiv.org/abs/2512.13714", "authors": ["Gangesh Pathak", "Prasanna Kumar"], "title": "AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach", "comment": "16 Pages", "summary": "LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior (Aiyappa et al., 2023). The current methods of stabilization, such as, reinforcement learning with human feedback (RLHF) and supervised fine-tuning, offer quantifiable improvements but are expensive and based on the intensive annotation of humans, thus being not easily scaled in a sustainable way (Dong et al., 2023; Retzlaff et al., 2024). This paper presents an AI-based annotation pipeline that systematically identifies, labels, and fixes for instability patterns on LLM output. Our human-AI synergy method combines the models of automated weak supervision and confidence-based annotation with the target human validation to guarantee the reliability and moral uprightness of feedback information (Cabitza et al., 2023; Jiang et al., 2023). The semantic consistency, factual correctness, and logical coherence categories of stability-specific annotation are introduced into our framework, allowing the continuous calibration of models and the enhancement of their robustness based on the feedback loops (Honovich et al., 2021; Nan et al., 2021).", "AI": {"tldr": "\u63d0\u51faAI\u8f85\u52a9\u6807\u6ce8\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u540c\u65b9\u6cd5\u8bc6\u522b\u3001\u6807\u6ce8\u548c\u4fee\u590dLLM\u8f93\u51fa\u7684\u4e0d\u7a33\u5b9a\u6027\u6a21\u5f0f\uff0c\u4ee5\u63d0\u5347LLM\u5728\u9ad8\u5ea6\u76d1\u7ba1\u884c\u4e1a\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "LLM\u5728\u9ad8\u5ea6\u76d1\u7ba1\u884c\u4e1a\u5e94\u7528\u53d7\u9650\uff0c\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u3001\u4e0d\u4e00\u81f4\u63a8\u7406\u3001\u5e7b\u89c9\u548c\u6027\u80fd\u6ce2\u52a8\u7b49\u95ee\u9898\uff0c\u73b0\u6709\u7a33\u5b9a\u5316\u65b9\u6cd5\uff08\u5982RLHF\u548c\u76d1\u7763\u5fae\u8c03\uff09\u6210\u672c\u9ad8\u3001\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\uff0c\u96be\u4ee5\u89c4\u6a21\u5316\u3002", "method": "\u5f00\u53d1AI\u8f85\u52a9\u6807\u6ce8\u6d41\u6c34\u7ebf\uff0c\u7ed3\u5408\u81ea\u52a8\u5f31\u76d1\u7763\u548c\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u6807\u6ce8\uff0c\u8f85\u4ee5\u4eba\u5de5\u9a8c\u8bc1\uff0c\u5f15\u5165\u8bed\u4e49\u4e00\u81f4\u6027\u3001\u4e8b\u5b9e\u6b63\u786e\u6027\u548c\u903b\u8f91\u8fde\u8d2f\u6027\u7b49\u7a33\u5b9a\u6027\u7279\u5b9a\u6807\u6ce8\u7c7b\u522b\uff0c\u901a\u8fc7\u53cd\u9988\u5faa\u73af\u6301\u7eed\u6821\u51c6\u6a21\u578b\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u7684\u4eba\u673a\u534f\u540c\u65b9\u6cd5\u80fd\u591f\u7cfb\u7edf\u8bc6\u522b\u548c\u4fee\u590dLLM\u4e0d\u7a33\u5b9a\u6027\u6a21\u5f0f\uff0c\u786e\u4fdd\u53cd\u9988\u4fe1\u606f\u7684\u53ef\u9760\u6027\u548c\u9053\u5fb7\u5b8c\u6574\u6027\uff0c\u589e\u5f3a\u6a21\u578b\u9c81\u68d2\u6027\u3002", "conclusion": "AI\u8f85\u52a9\u6807\u6ce8\u6d41\u6c34\u7ebf\u4e3aLLM\u7a33\u5b9a\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4eba\u673a\u534f\u540c\u5b9e\u73b0\u6301\u7eed\u6a21\u578b\u6821\u51c6\uff0c\u6709\u671b\u63a8\u52a8LLM\u5728\u9ad8\u5ea6\u76d1\u7ba1\u884c\u4e1a\u7684\u53ef\u9760\u5e94\u7528\u3002", "topic": "agent analysis"}}
{"id": "2512.14673", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.14673", "abs": "https://arxiv.org/abs/2512.14673", "authors": ["Ronnie de Souza Santos", "Cleyton Magalh\u00e3es", "Italo Santos"], "title": "Reconsidering Conversational Norms in LLM Chatbots for Sustainable AI", "comment": null, "summary": "LLM based chatbots have become central interfaces in technical, educational, and analytical domains, supporting tasks such as code reasoning, problem solving, and information exploration. As these systems scale, sustainability concerns have intensified, with most assessments focusing on model architecture, hardware efficiency, and deployment infrastructure. However, existing mitigation efforts largely overlook how user interaction practices themselves shape the energy profile of LLM based systems. In this vision paper, we argue that interaction level behavior appears to be an underexamined factor shaping the environmental impact of LLM based systems, and we present this issue across four dimensions. First, extended conversational patterns increase token production and raise the computational cost of inference. Second, expectations of instant responses limit opportunities for energy aware scheduling and workload consolidation. Third, everyday user habits contribute to cumulative operational demand in ways that are rarely quantified. Fourth, the accumulation of context affects memory requirements and reduces the efficiency of long running dialogues. Addressing these challenges requires rethinking how chatbot interactions are designed and conceptualized, and adopting perspectives that recognize sustainability as partly dependent on the conversational norms through which users engage with LLM based systems.", "AI": {"tldr": "\u672c\u6587\u6307\u51faLLM\u804a\u5929\u673a\u5668\u4eba\u7684\u7528\u6237\u4ea4\u4e92\u884c\u4e3a\u662f\u5f71\u54cd\u7cfb\u7edf\u73af\u5883\u53ef\u6301\u7eed\u6027\u7684\u5173\u952e\u4f46\u88ab\u5ffd\u89c6\u7684\u56e0\u7d20\uff0c\u63d0\u51fa\u4e86\u56db\u4e2a\u7ef4\u5ea6\uff1a\u6269\u5c55\u5bf9\u8bdd\u6a21\u5f0f\u589e\u52a0\u8ba1\u7b97\u6210\u672c\u3001\u5373\u65f6\u54cd\u5e94\u671f\u671b\u9650\u5236\u8282\u80fd\u8c03\u5ea6\u3001\u7528\u6237\u4e60\u60ef\u7d2f\u79ef\u9700\u6c42\u3001\u4e0a\u4e0b\u6587\u79ef\u7d2f\u964d\u4f4e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5173\u4e8eLLM\u7cfb\u7edf\u53ef\u6301\u7eed\u6027\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u67b6\u6784\u3001\u786c\u4ef6\u6548\u7387\u548c\u90e8\u7f72\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u5ffd\u89c6\u4e86\u7528\u6237\u4ea4\u4e92\u5b9e\u8df5\u672c\u8eab\u5982\u4f55\u5851\u9020\u7cfb\u7edf\u7684\u80fd\u6e90\u6d88\u8017\u7279\u5f81\u3002\u672c\u6587\u8ba4\u4e3a\u4ea4\u4e92\u5c42\u9762\u7684\u884c\u4e3a\u662f\u5f71\u54cdLLM\u7cfb\u7edf\u73af\u5883\u5f71\u54cd\u7684\u4e00\u4e2a\u672a\u88ab\u5145\u5206\u7814\u7a76\u7684\u56e0\u7d20\u3002", "method": "\u8fd9\u662f\u4e00\u7bc7\u613f\u666f\u8bba\u6587\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6982\u5ff5\u6846\u67b6\uff0c\u4ece\u56db\u4e2a\u7ef4\u5ea6\u63a2\u8ba8\u7528\u6237\u4ea4\u4e92\u884c\u4e3a\u5982\u4f55\u5f71\u54cdLLM\u7cfb\u7edf\u7684\u73af\u5883\u53ef\u6301\u7eed\u6027\uff1a1) \u6269\u5c55\u5bf9\u8bdd\u6a21\u5f0f\u589e\u52a0token\u751f\u6210\u548c\u63a8\u7406\u8ba1\u7b97\u6210\u672c\uff1b2) \u5373\u65f6\u54cd\u5e94\u671f\u671b\u9650\u5236\u80fd\u6e90\u611f\u77e5\u8c03\u5ea6\u548c\u5de5\u4f5c\u8d1f\u8f7d\u6574\u5408\u673a\u4f1a\uff1b3) \u65e5\u5e38\u7528\u6237\u4e60\u60ef\u7d2f\u79ef\u64cd\u4f5c\u9700\u6c42\uff1b4) \u4e0a\u4e0b\u6587\u79ef\u7d2f\u5f71\u54cd\u5185\u5b58\u9700\u6c42\u548c\u957f\u5bf9\u8bdd\u6548\u7387\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u7528\u6237\u4ea4\u4e92\u884c\u4e3a\u662fLLM\u7cfb\u7edf\u73af\u5883\u53ef\u6301\u7eed\u6027\u7684\u91cd\u8981\u4f46\u88ab\u5ffd\u89c6\u7684\u5f71\u54cd\u56e0\u7d20\uff0c\u5e76\u7cfb\u7edf\u6027\u5730\u8bc6\u522b\u4e86\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\u3002\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\u9700\u8981\u91cd\u65b0\u601d\u8003\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\u7684\u8bbe\u8ba1\u548c\u6982\u5ff5\u5316\u65b9\u5f0f\u3002", "conclusion": "\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\uff0c\u5e76\u91c7\u7528\u65b0\u7684\u89c6\u89d2\uff0c\u8ba4\u8bc6\u5230\u53ef\u6301\u7eed\u6027\u90e8\u5206\u53d6\u51b3\u4e8e\u7528\u6237\u4e0eLLM\u7cfb\u7edf\u4ea4\u4e92\u7684\u5bf9\u8bdd\u89c4\u8303\u3002\u9700\u8981\u5c06\u53ef\u6301\u7eed\u6027\u8003\u8651\u7eb3\u5165\u4ea4\u4e92\u8bbe\u8ba1\u5c42\u9762\u3002", "topic": "agent analysis"}}
{"id": "2512.13716", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13716", "abs": "https://arxiv.org/abs/2512.13716", "authors": ["Yitong Luo", "Ziang Chen", "Hou Hei Lam", "Jiayu zhan", "Junqi Wang", "Zhenliang Zhang", "Xue Feng"], "title": "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making", "comment": "Accepted at LAW Workshop, NeurIPS 2025", "summary": "Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical challenge. We address this by proposing a value-driven approach to personalized decision-making. Human values serve as stable, transferable signals that support consistent and generalizable behavior across contexts. Compared to task-oriented paradigms driven by external rewards and incentives, value-driven decision-making enhances interpretability and enables agents to act appropriately even in novel scenarios. We introduce ValuePilot, a two-phase framework consisting of a dataset generation toolkit (DGT) and a decision-making module (DMM). DGT constructs diverse, value-annotated scenarios from a human-LLM collaborative pipeline. DMM learns to evaluate actions based on personal value preferences, enabling context-sensitive, individualized decisions. When evaluated on previously unseen scenarios, DMM outperforms strong LLM baselines, including GPT-5, Claude-Sonnet-4, Gemini-2-flash, and Llama-3.1-70b, in aligning with human action choices. Our results demonstrate that value-driven decision-making is an effective and extensible engineering pathway toward building interpretable, personalized AI agents.", "AI": {"tldr": "ValuePilot\uff1a\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u4ef7\u503c\u9a71\u52a8\u7684\u51b3\u7b56\u65b9\u6cd5\u5b9e\u73b0\u4e2a\u6027\u5316AI\u4ee3\u7406\uff0c\u5305\u542b\u6570\u636e\u96c6\u751f\u6210\u5de5\u5177\u5305\u548c\u51b3\u7b56\u6a21\u5757\uff0c\u5728\u672a\u89c1\u573a\u666f\u4e2d\u4f18\u4e8e\u4e3b\u6d41LLM\u57fa\u7ebf\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u6269\u5c55\u5230\u73b0\u5b9e\u4e16\u754c\u5e94\u7528\uff0c\u9002\u5e94\u8d85\u8d8a\u4efb\u52a1\u5b8c\u6210\u6216\u96c6\u4f53\u5bf9\u9f50\u7684\u4e2a\u6027\u5316\u4ef7\u503c\u504f\u597d\u6210\u4e3a\u5173\u952e\u6311\u6218\u3002\u4e2a\u6027\u5316\u51b3\u7b56\u5bf9\u4e8e\u4eba\u673a\u4ea4\u4e92\u81f3\u5173\u91cd\u8981\uff0c\u4f7fAI\u4ee3\u7406\u80fd\u591f\u4e0e\u4e2a\u4f53\u7528\u6237\u7684\u4ef7\u503c\u504f\u597d\u4fdd\u6301\u4e00\u81f4\u3002", "method": "\u63d0\u51faValuePilot\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) \u6570\u636e\u96c6\u751f\u6210\u5de5\u5177\u5305(DGT)\uff1a\u901a\u8fc7\u4eba-LLM\u534f\u4f5c\u6d41\u7a0b\u6784\u5efa\u591a\u6837\u5316\u7684\u4ef7\u503c\u6807\u6ce8\u573a\u666f\uff1b2) \u51b3\u7b56\u6a21\u5757(DMM)\uff1a\u5b66\u4e60\u57fa\u4e8e\u4e2a\u4eba\u4ef7\u503c\u504f\u597d\u8bc4\u4f30\u884c\u52a8\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u4e2a\u6027\u5316\u51b3\u7b56\u3002", "result": "\u5728\u672a\u89c1\u573a\u666f\u8bc4\u4f30\u4e2d\uff0cDMM\u5728\u7b26\u5408\u4eba\u7c7b\u884c\u52a8\u9009\u62e9\u65b9\u9762\u4f18\u4e8eGPT-5\u3001Claude-Sonnet-4\u3001Gemini-2-flash\u548cLlama-3.1-70b\u7b49\u5f3aLLM\u57fa\u7ebf\u3002", "conclusion": "\u4ef7\u503c\u9a71\u52a8\u7684\u51b3\u7b56\u662f\u6784\u5efa\u53ef\u89e3\u91ca\u3001\u4e2a\u6027\u5316AI\u4ee3\u7406\u7684\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u5de5\u7a0b\u8def\u5f84\uff0c\u4eba\u7c7b\u4ef7\u503c\u4f5c\u4e3a\u7a33\u5b9a\u3001\u53ef\u8f6c\u79fb\u7684\u4fe1\u53f7\u652f\u6301\u8de8\u4e0a\u4e0b\u6587\u7684\u4e00\u81f4\u548c\u53ef\u6cdb\u5316\u884c\u4e3a\u3002", "topic": "agent analysis"}}
{"id": "2512.14429", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.14429", "abs": "https://arxiv.org/abs/2512.14429", "authors": ["Yukun Ren", "Siwei Yu", "Kai Chen", "Jianwei Ma"], "title": "Seismology modeling agent: A smart assistant for geophysical researchers", "comment": "26 pages, 15 figures. Code available at https://github.com/RenYukun1563/specfem-mcp", "summary": "To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4ea4\u4e92\u5de5\u4f5c\u6d41\uff0c\u7528\u4e8e\u7b80\u5316SPECFEM\u5730\u9707\u6ce2\u6a21\u62df\u8f6f\u4ef6\u7684\u4f7f\u7528\uff0c\u901a\u8fc7MCP\u670d\u52a1\u5668\u5c06\u590d\u6742\u64cd\u4f5c\u5206\u89e3\u4e3a\u53ef\u6267\u884c\u7684\u5de5\u5177\uff0c\u5b9e\u73b0\u4ece\u6587\u4ef6\u9a71\u52a8\u5230\u610f\u56fe\u9a71\u52a8\u7684\u8f6c\u53d8\u3002", "motivation": "\u4f20\u7edfSPECFEM\u8f6f\u4ef6\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\uff0c\u4f9d\u8d56\u590d\u6742\u7684\u624b\u52a8\u6587\u4ef6\u7f16\u8f91\u548c\u547d\u4ee4\u884c\u64cd\u4f5c\uff0c\u9700\u8981\u7b80\u5316\u5de5\u4f5c\u6d41\u7a0b\u5e76\u964d\u4f4e\u4f7f\u7528\u95e8\u69db\u3002", "method": "\u5f00\u53d1\u9996\u4e2aSPECFEM\u7684MCP\u670d\u52a1\u5668\u5957\u4ef6\uff0c\u5c06\u6a21\u62df\u8fc7\u7a0b\u5206\u89e3\u4e3a\u79bb\u6563\u7684\u3001\u53ef\u7531\u667a\u80fd\u4f53\u6267\u884c\u7684\u5de5\u5177\uff08\u53c2\u6570\u751f\u6210\u3001\u7f51\u683c\u5212\u5206\u3001\u6c42\u89e3\u5668\u6267\u884c\u3001\u53ef\u89c6\u5316\u7b49\uff09\uff0c\u652f\u6301\u5168\u81ea\u52a8\u6267\u884c\u548c\u4eba\u673a\u534f\u4f5c\u4e24\u79cd\u6a21\u5f0f\u3002", "result": "\u901a\u8fc7\u591a\u4e2a\u6848\u4f8b\u9a8c\u8bc1\uff0c\u5de5\u4f5c\u6d41\u5728\u81ea\u4e3b\u548c\u4ea4\u4e92\u6a21\u5f0f\u4e0b\u90fd\u80fd\u65e0\u7f1d\u8fd0\u884c\uff0c\u4ea7\u751f\u4e0e\u6807\u51c6\u57fa\u51c6\u4e00\u81f4\u7684\u9ad8\u4fdd\u771f\u7ed3\u679c\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5165\u95e8\u95e8\u69db\u5e76\u589e\u5f3a\u4e86\u53ef\u91cd\u590d\u6027\u3002", "conclusion": "\u8fd9\u662fMCP\u6280\u672f\u5728\u8ba1\u7b97\u5730\u9707\u5b66\u4e2d\u7684\u9996\u6b21\u5e94\u7528\uff0c\u4e3a\u8ba1\u7b97\u5730\u7403\u7269\u7406\u5b66\u5411AI\u8f85\u52a9\u548c\u81ea\u52a8\u5316\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u9014\u5f84\u3002", "topic": "code agent"}}
{"id": "2512.14118", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14118", "abs": "https://arxiv.org/abs/2512.14118", "authors": ["Yiran Zhang", "Jincheng Hu", "Mark Dras", "Usman Naseem"], "title": "CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models", "comment": "underreview", "summary": "Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.", "AI": {"tldr": "CogMem\u662f\u4e00\u4e2a\u53d7\u8ba4\u77e5\u542f\u53d1\u7684\u8bb0\u5fc6\u589e\u5f3aLLM\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6301\u4e45\u8bb0\u5fc6\u652f\u6301\u6301\u7eed\u8fed\u4ee3\u63a8\u7406\uff0c\u89e3\u51b3LLM\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u51c6\u786e\u6027\u548c\u8fde\u8d2f\u6027\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5355\u8f6e\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5bb9\u6613\u5931\u53bb\u51c6\u786e\u6027\u548c\u8fde\u8d2f\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9644\u52a0\u5b8c\u6574\u5bf9\u8bdd\u5386\u53f2\uff0c\u5bfc\u81f4\u4e0a\u4e0b\u6587\u65e0\u9650\u589e\u957f\u3001\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u548c\u63a8\u7406\u6548\u7387\u964d\u4f4e\u3002", "method": "CogMem\u91c7\u7528\u4e09\u5c42\u67b6\u6784\uff1a\u957f\u671f\u8bb0\u5fc6\u5c42\uff08LTM\uff09\u6574\u5408\u8de8\u4f1a\u8bdd\u63a8\u7406\u7b56\u7565\uff1b\u76f4\u63a5\u8bbf\u95ee\u8bb0\u5fc6\u5c42\uff08DA\uff09\u7ef4\u62a4\u4f1a\u8bdd\u7ea7\u7b14\u8bb0\u5e76\u68c0\u7d22\u76f8\u5173\u957f\u671f\u8bb0\u5fc6\uff1b\u6ce8\u610f\u529b\u7126\u70b9\u673a\u5236\uff08FoA\uff09\u52a8\u6001\u91cd\u5efa\u7b80\u6d01\u7684\u4efb\u52a1\u76f8\u5173\u4e0a\u4e0b\u6587\u3002", "result": "\u5728TurnBench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u5206\u5c42\u8bbe\u8ba1\u80fd\u591f\u7f13\u89e3\u63a8\u7406\u5931\u8d25\u3001\u63a7\u5236\u4e0a\u4e0b\u6587\u589e\u957f\uff0c\u5e76\u63d0\u9ad8\u6269\u5c55\u63a8\u7406\u94fe\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "CogMem\u901a\u8fc7\u7ed3\u6784\u5316\u8bb0\u5fc6\u67b6\u6784\u4f7fLLM\u80fd\u591f\u8fdb\u884c\u66f4\u53ef\u9760\u3001\u66f4\u7c7b\u4eba\u7684\u63a8\u7406\uff0c\u671d\u7740\u53ef\u6301\u7eed\u8fed\u4ee3\u63a8\u7406\u7684\u65b9\u5411\u53d1\u5c55\u3002", "topic": "agent analysis"}}
{"id": "2512.14142", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14142", "abs": "https://arxiv.org/abs/2512.14142", "authors": ["Hongqiu Ni", "Jiabao Zhang", "Guopeng Li", "Zilong Wang", "Ruiqi Wu", "Chi Zhang", "Haisheng Tan"], "title": "Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents", "comment": "12 pages, 8 figures", "summary": "Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.", "AI": {"tldr": "Astraea\u662f\u4e00\u4e2a\u4e3aLLM\u667a\u80fd\u4ee3\u7406\u8bbe\u8ba1\u7684\u670d\u52a1\u5f15\u64ce\uff0c\u901a\u8fc7\u5168\u5c40\u8bf7\u6c42\u751f\u547d\u5468\u671f\u4f18\u5316\u548c\u5206\u5c42\u8c03\u5ea6\u7b97\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709\u7cfb\u7edf\u5c06\u5e73\u5747\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u964d\u4f4e\u8fbe25.5%\u3002", "motivation": "LLM\u667a\u80fd\u4ee3\u7406\u7684\u591a\u9636\u6bb5\u5de5\u4f5c\u6d41\uff08\u672c\u5730\u8ba1\u7b97\u4e0e\u5916\u90e8API\u8c03\u7528\u4ea4\u66ff\uff09\u4e0e\u73b0\u6709\u63a8\u7406\u7cfb\u7edf\uff08\u5982vLLM\uff09\u7684\u8c03\u5ea6\u7c92\u5ea6\u4e0d\u5339\u914d\uff0c\u73b0\u6709\u7cfb\u7edf\u4e13\u6ce8\u4e8e\u5c40\u90e8\u6bb5\u4f18\u5316\uff0c\u65e0\u6cd5\u6700\u5c0f\u5316\u6574\u4e2a\u4ee3\u7406\u5de5\u4f5c\u6d41\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u3002", "method": "\u63d0\u51faAstraea\u670d\u52a1\u5f15\u64ce\uff0c\u91c7\u7528\u72b6\u6001\u611f\u77e5\u7684\u5206\u5c42\u8c03\u5ea6\u7b97\u6cd5\uff0c\u7ed3\u5408\u8bf7\u6c42\u5386\u53f2\u72b6\u6001\u548c\u672a\u6765\u9884\u6d4b\uff0c\u52a8\u6001\u5206\u7c7bI/O\u5bc6\u96c6\u578b\u548c\u8ba1\u7b97\u5bc6\u96c6\u578b\u8bf7\u6c42\uff0c\u4f7f\u7528\u589e\u5f3a\u7684HRRN\u7b56\u7565\u5e73\u8861\u6548\u7387\u4e0e\u516c\u5e73\u6027\uff0c\u5e76\u5b9e\u73b0\u81ea\u9002\u5e94KV\u7f13\u5b58\u7ba1\u7406\u5668\u667a\u80fd\u5904\u7406I/O\u7b49\u5f85\u671f\u95f4\u7684\u4ee3\u7406\u72b6\u6001\u3002", "result": "Astraea\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5c06\u5e73\u5747\u4f5c\u4e1a\u5b8c\u6210\u65f6\u95f4\u964d\u4f4e\u8fbe25.5%\uff0c\u5728\u9ad8\u8d1f\u8f7d\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u9c81\u68d2\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u6a21\u578b\u89c4\u6a21\u3002", "conclusion": "Astraea\u901a\u8fc7\u5c06\u4f18\u5316\u4ece\u5c40\u90e8\u6bb5\u8f6c\u79fb\u5230\u5168\u5c40\u8bf7\u6c42\u751f\u547d\u5468\u671f\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u667a\u80fd\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\u7684\u8c03\u5ea6\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "topic": "agent analysis"}}
{"id": "2512.13727", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13727", "abs": "https://arxiv.org/abs/2512.13727", "authors": ["Yuhan Tang", "Kangxin Cui", "Jung Ho Park", "Yibo Zhao", "Xuan Jiang", "Haoze He", "Dingyi Zhuang", "Shenhao Wang", "Jiangbo Yu", "Haris Koutsopoulos", "Jinhua Zhao"], "title": "RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing", "comment": null, "summary": "Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply-demand conditions. Adaptive delayed matching creates a trade-off between matching and pickup delays by deciding whether to assign drivers immediately or batch requests. Since outcomes accumulate over long horizons with stochastic dynamics, reinforcement learning (RL) is a suitable framework. However, existing approaches often oversimplify traffic dynamics or use shallow encoders that miss complex spatiotemporal patterns.\n  We introduce the Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE), which formalizes adaptive delayed matching as a regime-aware MDP equipped with a self-attention MoE encoder. Unlike monolithic networks, our experts specialize automatically, improving representation capacity while maintaining computational efficiency. A physics-informed congestion surrogate preserves realistic density-speed feedback, enabling millions of efficient rollouts, while an adaptive reward scheme guards against pathological strategies.\n  With only 12M parameters, our framework outperforms strong baselines. On real-world Uber trajectory data (San Francisco), it improves total reward by over 13%, reducing average matching and pickup delays by 10% and 15% respectively. It demonstrates robustness across unseen demand regimes and stable training. These findings highlight the potential of MoE-enhanced RL for large-scale decision-making with complex spatiotemporal dynamics.", "AI": {"tldr": "\u63d0\u51faRAST-MoE\u6846\u67b6\uff0c\u4f7f\u7528\u4e13\u5bb6\u6df7\u5408\u81ea\u6ce8\u610f\u529b\u7f16\u7801\u5668\u89e3\u51b3\u7f51\u7ea6\u8f66\u5e73\u53f0\u7684\u81ea\u9002\u5e94\u5ef6\u8fdf\u5339\u914d\u95ee\u9898\uff0c\u5728\u771f\u5b9eUber\u6570\u636e\u4e0a\u63d0\u5347\u603b\u5956\u52b113%\uff0c\u51cf\u5c11\u5339\u914d\u548c\u63a5\u9a7e\u5ef6\u8fdf10%\u548c15%\u3002", "motivation": "\u7f51\u7ea6\u8f66\u5e73\u53f0\u9700\u8981\u5728\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u7684\u4f9b\u9700\u6761\u4ef6\u4e0b\u5e73\u8861\u4e58\u5ba2\u7b49\u5f85\u65f6\u95f4\u548c\u7cfb\u7edf\u6548\u7387\u3002\u73b0\u6709\u65b9\u6cd5\u5e38\u8fc7\u5ea6\u7b80\u5316\u4ea4\u901a\u52a8\u6001\u6216\u4f7f\u7528\u6d45\u5c42\u7f16\u7801\u5668\uff0c\u65e0\u6cd5\u6355\u6349\u590d\u6742\u7684\u65f6\u7a7a\u6a21\u5f0f\u3002", "method": "\u63d0\u51faRegime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE)\uff0c\u5c06\u81ea\u9002\u5e94\u5ef6\u8fdf\u5339\u914d\u5f62\u5f0f\u5316\u4e3a\u673a\u5236\u611f\u77e5MDP\uff0c\u914d\u5907\u81ea\u6ce8\u610f\u529bMoE\u7f16\u7801\u5668\u3002\u4e13\u5bb6\u81ea\u52a8\u4e13\u4e1a\u5316\uff0c\u63d0\u9ad8\u8868\u793a\u80fd\u529b\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u62e5\u5835\u4ee3\u7406\u5b9e\u73b0\u9ad8\u6548\u6a21\u62df\uff0c\u81ea\u9002\u5e94\u5956\u52b1\u65b9\u6848\u9632\u6b62\u75c5\u6001\u7b56\u7565\u3002", "result": "\u4ec5\u75281200\u4e07\u53c2\u6570\uff0c\u5728\u771f\u5b9eUber\u8f68\u8ff9\u6570\u636e\uff08\u65e7\u91d1\u5c71\uff09\u4e0a\u603b\u5956\u52b1\u63d0\u5347\u8d85\u8fc713%\uff0c\u5e73\u5747\u5339\u914d\u5ef6\u8fdf\u51cf\u5c1110%\uff0c\u63a5\u9a7e\u5ef6\u8fdf\u51cf\u5c1115%\u3002\u5728\u672a\u89c1\u9700\u6c42\u673a\u5236\u4e0b\u8868\u73b0\u9c81\u68d2\uff0c\u8bad\u7ec3\u7a33\u5b9a\u3002", "conclusion": "MoE\u589e\u5f3a\u7684RL\u5728\u5904\u7406\u590d\u6742\u65f6\u7a7a\u52a8\u6001\u7684\u5927\u89c4\u6a21\u51b3\u7b56\u4e2d\u5177\u6709\u6f5c\u529b\uff0cRAST-MoE\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7f51\u7ea6\u8f66\u5e73\u53f0\u7684\u5ef6\u8fdf\u5339\u914d\u95ee\u9898\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.13764", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13764", "abs": "https://arxiv.org/abs/2512.13764", "authors": ["Przemyslaw Chojecki"], "title": "Mathematics and Coding are Universal AI Benchmarks", "comment": null, "summary": "We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u6570\u5b66\u548c\u7f16\u7a0b\u5728AI\u667a\u80fd\u4f53\u5fc3\u7406\u6d4b\u91cf\u6d4b\u8bd5\u7a7a\u95f4\u4e2d\u7684\u7279\u6b8a\u4f5c\u7528\uff0c\u8bc1\u660e\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u548c\u7f16\u7a0b\u4efb\u52a1\u751f\u6210\u7684\u6d4b\u8bd5\u5b50\u7a7a\u95f4\u5728\u8bc4\u4f30\u5ea6\u91cf\u4e0b\u662f\u7a20\u5bc6\u7684\uff0c\u7f16\u7801\u5177\u6709\u666e\u904d\u6027\uff0c\u800c\u7eaf\u6570\u5b66\u5177\u6709\u8c31\u7a33\u5b9a\u6027\u4f18\u52bf\uff0c\u4e3aAI\u667a\u80fd\u4f53\u9012\u5f52\u81ea\u6211\u6539\u8fdb\u63d0\u4f9b\u4e86\u81ea\u7136\u8d77\u70b9\u3002", "motivation": "\u7814\u7a76\u6570\u5b66\u548c\u7f16\u7a0b\u5728AI\u667a\u80fd\u4f53\u8bc4\u4f30\u4e2d\u7684\u7279\u6b8a\u5730\u4f4d\uff0c\u63a2\u7d22\u5b83\u4eec\u5982\u4f55\u4f5c\u4e3a\"\u901a\u7528\u5750\u6807\"\u6765\u8bc4\u4f30AI\u80fd\u529b\uff0c\u5e76\u7406\u89e3\u6b63\u5f0f\u6570\u5b66\u4e3a\u4f55\u80fd\u6210\u4e3a\u9ad8\u7ea7AI\u667a\u80fd\u4f53\u9012\u5f52\u81ea\u6211\u6539\u8fdb\u7684\u81ea\u7136\u8d77\u70b9\u3002", "method": "\u57fa\u4e8eAAI\u6846\u67b6\u548cGVU\u52a8\u529b\u5b66\uff0c\u5b9a\u4e49\u6570\u5b66\u7ea4\u7ef4\u6982\u5ff5\uff0c\u7ed3\u5408\u5f62\u5f0f\u8bc1\u660e\u6838\uff08\u5982Lean\u3001Coq\uff09\uff0c\u5206\u6790GVU\u6d41\u5728\u6570\u5b66\u7ea4\u7ef4\u4e0a\u7684\u8c31\u7a33\u5b9a\u6027\u3002\u4e3b\u8981\u6280\u672f\u7ed3\u679c\u662f\u5bc6\u5ea6\u5b9a\u7406\uff1a\u5728\u667a\u80fd\u4f53\u8f93\u51fa\u5747\u5300\u7d27\u6027\u548cLipschitz AAI\u6cdb\u51fd\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u6570\u5b66\u5b9a\u7406\u8bc1\u660e\u548c\u7f16\u7a0b\u4efb\u52a1\u751f\u6210\u7684\u6d4b\u8bd5\u5b50\u7a7a\u95f4\u5728\u8bc4\u4f30\u5ea6\u91cf\u4e0b\u662f\u7a20\u5bc6\u7684\u3002", "result": "\u7f16\u7801\u5728\u8868\u8fbe\u6027\u4e0a\u5177\u6709\u666e\u904d\u6027\uff0c\u800c\u7eaf\u6570\u5b66\u867d\u7136\u4e0d\u5177\u5907\u666e\u904d\u8868\u8fbe\u6027\uff0c\u4f46\u5728\u8c31\u7a33\u5b9a\u6027\u65b9\u9762\u5177\u6709\u7279\u6743\u3002\u6570\u5b66\u7ea4\u7ef4\u4e0e\u5f62\u5f0f\u8bc1\u660e\u6838\u7ed3\u5408\u65f6\uff0cGVU\u6d41\u5141\u8bb8\u8c31\u7a33\u5b9a\u7684\u81ea\u6211\u6539\u8fdb\u673a\u5236\u3002\u6570\u5b66\u548c\u7f16\u7a0b\u4e3aAI\u667a\u80fd\u4f53\u8bc4\u4f30\u63d0\u4f9b\u4e86\"\u901a\u7528\u5750\u6807\"\u3002", "conclusion": "\u6570\u5b66\u548c\u7f16\u7a0b\u662f\u8bc4\u4f30AI\u667a\u80fd\u4f53\u7684\u5173\u952e\u7ef4\u5ea6\uff0c\u7f16\u7801\u5177\u6709\u666e\u904d\u8868\u8fbe\u6027\uff0c\u800c\u6b63\u5f0f\u6570\u5b66\u7531\u4e8e\u5176\u8c31\u7a33\u5b9a\u6027\u7279\u6027\uff0c\u6210\u4e3a\u9ad8\u7ea7AI\u667a\u80fd\u4f53\u9012\u5f52\u81ea\u6211\u6539\u8fdb\u7684\u81ea\u7136\u70b9\u706b\u57df\u3002", "topic": "agent analysis"}}
{"id": "2512.13857", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.13857", "abs": "https://arxiv.org/abs/2512.13857", "authors": ["Kamer Ali Yuksel"], "title": "EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery", "comment": null, "summary": "Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle search space prone to structural failure. We introduce EvoLattice, a framework that represents an entire population of candidate programs or agent behaviors within a single directed acyclic graph. Each node stores multiple persistent alternatives, and every valid path through the graph defines a distinct executable candidate, yielding a large combinatorial search space without duplicating structure. EvoLattice enables fine-grained alternative-level evaluation by scoring each alternative across all paths in which it appears, producing statistics that reveal how local design choices affect global performance. These statistics provide a dense, data-driven feedback signal for LLM-guided mutation, recombination, and pruning, while preserving successful components. Structural correctness is guaranteed by a deterministic self-repair mechanism that enforces acyclicity and dependency consistency independently of the LLM. EvoLattice naturally extends to agent evolution by interpreting alternatives as prompt fragments or sub-agent behaviors. Across program synthesis (proxy and optimizer meta-learning), EvoLattice yields more stable evolution, greater expressivity, and stronger improvement trajectories than prior LLM-guided methods. The resulting dynamics resemble quality-diversity optimization, emerging implicitly from EvoLattice's internal multi-alternative representation rather than an explicit external archive.", "AI": {"tldr": "EvoLattice \u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\u7684\u8fdb\u5316\u6846\u67b6\uff0c\u5c06\u5019\u9009\u7a0b\u5e8f\u6216\u667a\u80fd\u4f53\u884c\u4e3a\u8868\u793a\u4e3a\u56fe\u4e2d\u7684\u8282\u70b9\uff0c\u6bcf\u4e2a\u8282\u70b9\u5b58\u50a8\u591a\u4e2a\u6301\u4e45\u5316\u5907\u9009\u65b9\u6848\uff0c\u901a\u8fc7\u4e0d\u540c\u8def\u5f84\u7ec4\u5408\u5f62\u6210\u53ef\u6267\u884c\u5019\u9009\uff0c\u5b9e\u73b0\u66f4\u7a33\u5b9a\u3001\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u7684\u8fdb\u5316\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7a0b\u5e8f\u548c\u667a\u80fd\u4f53\u8fdb\u5316\u65b9\u6cd5\u5927\u591a\u91c7\u7528\u8986\u76d6\u5f0f\u7a81\u53d8\uff0c\u53ea\u7ef4\u62a4\u5355\u4e2a\u5019\u9009\uff0c\u4f1a\u4e22\u5f03\u6709\u7528\u53d8\u4f53\u3001\u906d\u53d7\u7834\u574f\u6027\u7f16\u8f91\uff0c\u4e14\u641c\u7d22\u7a7a\u95f4\u8106\u5f31\u6613\u51fa\u73b0\u7ed3\u6784\u6545\u969c\u3002\u9700\u8981\u4e00\u79cd\u80fd\u4fdd\u7559\u6210\u529f\u7ec4\u4ef6\u3001\u63d0\u4f9b\u66f4\u7a33\u5b9a\u8fdb\u5316\u8fc7\u7a0b\u7684\u65b9\u6cd5\u3002", "method": "EvoLattice \u4f7f\u7528\u6709\u5411\u65e0\u73af\u56fe\u8868\u793a\u6574\u4e2a\u5019\u9009\u79cd\u7fa4\uff0c\u6bcf\u4e2a\u8282\u70b9\u5b58\u50a8\u591a\u4e2a\u6301\u4e45\u5316\u5907\u9009\u65b9\u6848\uff0c\u6bcf\u4e2a\u6709\u6548\u8def\u5f84\u5b9a\u4e49\u4e00\u4e2a\u53ef\u6267\u884c\u5019\u9009\u3002\u901a\u8fc7\u8de8\u8def\u5f84\u8bc4\u4f30\u6bcf\u4e2a\u5907\u9009\u65b9\u6848\uff0c\u83b7\u5f97\u6570\u636e\u9a71\u52a8\u7684\u53cd\u9988\u4fe1\u53f7\uff0c\u7528\u4e8eLLM\u5f15\u5bfc\u7684\u7a81\u53d8\u3001\u91cd\u7ec4\u548c\u526a\u679d\u3002\u5305\u542b\u786e\u5b9a\u6027\u81ea\u4fee\u590d\u673a\u5236\u4fdd\u8bc1\u7ed3\u6784\u6b63\u786e\u6027\u3002", "result": "\u5728\u7a0b\u5e8f\u5408\u6210\uff08\u4ee3\u7406\u548c\u4f18\u5316\u5668\u5143\u5b66\u4e60\uff09\u4efb\u52a1\u4e2d\uff0cEvoLattice \u76f8\u6bd4\u73b0\u6709LLM\u5f15\u5bfc\u65b9\u6cd5\u5c55\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u8fdb\u5316\u3001\u66f4\u5f3a\u7684\u8868\u8fbe\u80fd\u529b\u548c\u66f4\u597d\u7684\u6539\u8fdb\u8f68\u8ff9\u3002\u5176\u52a8\u6001\u7279\u6027\u7c7b\u4f3c\u4e8e\u8d28\u91cf-\u591a\u6837\u6027\u4f18\u5316\uff0c\u4f46\u8fd9\u662f\u4ece\u5185\u90e8\u591a\u5907\u9009\u8868\u793a\u4e2d\u9690\u5f0f\u6d8c\u73b0\u7684\u3002", "conclusion": "EvoLattice \u901a\u8fc7\u56fe\u7ed3\u6784\u7684\u591a\u5907\u9009\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfLLM\u8fdb\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u3001\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u7684\u8fdb\u5316\u8fc7\u7a0b\uff0c\u5e76\u80fd\u81ea\u7136\u6269\u5c55\u5230\u667a\u80fd\u4f53\u8fdb\u5316\u9886\u57df\u3002", "topic": "code agent"}}
{"id": "2512.13978", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13978", "abs": "https://arxiv.org/abs/2512.13978", "authors": ["Yang Cao", "Yubin Chen", "Xuyang Guo", "Zhao Song", "Song Yue", "Jiahao Zhang", "Jiale Zhao"], "title": "Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has led to significant breakthroughs in automated mathematical reasoning and scientific discovery. Georgiev, G${\u00f3}$mez-Serrano, Tao, and Wagner [GGSTW+25] demonstrate that AI systems can explore new constructions and improve existing bounds, illustrating the growing potential of LLMs to accelerate mathematical discovery. Similarly, Bubeck et al. [BCE+25] show that GPT-5 can meaningfully contribute to scientific workflows, from proposing hypotheses to generating proofs and analyses. Despite these advances, a rigorous evaluation of these models on canonical, graduate-level mathematical theory remains necessary to understand their baseline reasoning capabilities. In this paper, we present a comprehensive benchmark of four frontier models: GPT-5-Thinking, Gemini-3-Pro, Claude-Sonnet-4.5-Thinking, and Grok-4 against the classic curriculum of Randomized Algorithms by Motwani and Raghavan [MR95].\n  We tasked each model with generating formal LaTeX proofs for a series of lemmas and exercises spanning the textbook. We find that while the top-tier models (Gemini, and Claude) achieve a high accuracy rate (approx. 66%), demonstrating a robust grasp of probabilistic method and formal logic, other models lag significantly in consistency (approx. 40%). We provide a qualitative analysis of the generated proofs, highlighting differences in conciseness, hallucination rates, and logical structure. Our results suggest that while frontier models have reached a threshold of proficiency suitable for graduate-level pedagogical assistance and formalization, significant variance exists in their reliability for rigorous mathematical derivation. The code and the full set of LLM-generated responses are open-sourced and publicly available at https://github.com/magiclinux/math_benchmark_probability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u524d\u6cbfLLM\u5728\u7814\u7a76\u751f\u7ea7\u968f\u673a\u7b97\u6cd5\u8bfe\u7a0b\u4e0a\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86GPT-5\u3001Gemini-3-Pro\u3001Claude-Sonnet-4.5\u548cGrok-4\u56db\u4e2a\u6a21\u578b\u5728\u751f\u6210\u5f62\u5f0f\u5316LaTeX\u8bc1\u660e\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u6570\u5b66\u63a8\u7406\u548c\u79d1\u5b66\u53d1\u73b0\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u8fd9\u4e9b\u6a21\u578b\u5728\u7ecf\u5178\u7814\u7a76\u751f\u7ea7\u6570\u5b66\u7406\u8bba\u4e0a\u57fa\u51c6\u63a8\u7406\u80fd\u529b\u7684\u4e25\u683c\u8bc4\u4f30\u3002\u9700\u8981\u4e86\u89e3\u5b83\u4eec\u5728\u4e25\u8c28\u6570\u5b66\u63a8\u5bfc\u65b9\u9762\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u3002", "method": "\u4f7f\u7528Motwani\u548cRaghavan\u7684\u300a\u968f\u673a\u7b97\u6cd5\u300b\u6559\u6750\u4f5c\u4e3a\u57fa\u51c6\uff0c\u8981\u6c42\u56db\u4e2a\u524d\u6cbfLLM\uff08GPT-5-Thinking\u3001Gemini-3-Pro\u3001Claude-Sonnet-4.5-Thinking\u3001Grok-4\uff09\u4e3a\u6559\u6750\u4e2d\u7684\u5f15\u7406\u548c\u7ec3\u4e60\u751f\u6210\u5f62\u5f0f\u5316LaTeX\u8bc1\u660e\uff0c\u5e76\u8fdb\u884c\u5b9a\u91cf\u548c\u5b9a\u6027\u5206\u6790\u3002", "result": "\u9876\u7ea7\u6a21\u578b\uff08Gemini\u548cClaude\uff09\u8fbe\u5230\u7ea666%\u7684\u51c6\u786e\u7387\uff0c\u8868\u73b0\u51fa\u5bf9\u6982\u7387\u65b9\u6cd5\u548c\u5f62\u5f0f\u903b\u8f91\u7684\u826f\u597d\u638c\u63e1\uff1b\u5176\u4ed6\u6a21\u578b\u7684\u4e00\u81f4\u6027\u663e\u8457\u8f83\u4f4e\uff08\u7ea640%\uff09\u3002\u5206\u6790\u63ed\u793a\u4e86\u5728\u7b80\u6d01\u6027\u3001\u5e7b\u89c9\u7387\u548c\u903b\u8f91\u7ed3\u6784\u65b9\u9762\u7684\u5dee\u5f02\u3002", "conclusion": "\u524d\u6cbf\u6a21\u578b\u5df2\u8fbe\u5230\u9002\u5408\u7814\u7a76\u751f\u7ea7\u6559\u5b66\u8f85\u52a9\u548c\u5f62\u5f0f\u5316\u7684\u719f\u7ec3\u5ea6\u9608\u503c\uff0c\u4f46\u5728\u4e25\u8c28\u6570\u5b66\u63a8\u5bfc\u7684\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u4ee3\u7801\u548cLLM\u751f\u6210\u54cd\u5e94\u5df2\u5f00\u6e90\u3002", "topic": "agent analysis"}}
{"id": "2512.14427", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14427", "abs": "https://arxiv.org/abs/2512.14427", "authors": ["Gabriele Prato", "Shagun Sodhani", "Alessandro Sordoni", "Sarath Chandar"], "title": "Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models", "comment": null, "summary": "The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.", "AI": {"tldr": "\u7814\u7a76\u4e0d\u540c\u6587\u6863\u6253\u5305\u7b56\u7565\u5bf9LLM\u591a\u8df3\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u6253\u5305\u80fd\u63d0\u5347\u6027\u80fd\u4f46\u589e\u52a0\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u63ed\u793a\u5176\u4f18\u52bf\u673a\u5236\u3002", "motivation": "\u5f53\u524dLLM\u8bad\u7ec3\u4e2d\u666e\u904d\u91c7\u7528\u6587\u6863\u6253\u5305\u7b56\u7565\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u4f46\u8fd9\u79cd\u505a\u6cd5\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u7279\u522b\u662f\u5bf9\u591a\u8df3\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u4e0d\u540c\u6587\u6863\u6253\u5305\u7b56\u7565\uff0c\u6bd4\u8f83\u6253\u5305\u8bad\u7ec3\u4e0e\u5355\u6587\u6863\u8bad\u7ec3\u7684\u6548\u679c\uff0c\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u5f71\u54cd\u6253\u5305\u4f18\u52bf\u7684\u5173\u952e\u56e0\u7d20\u3002", "result": "\u6587\u6863\u6253\u5305\u80fd\u63d0\u5347LLM\u7684\u591a\u8df3\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u9700\u8981\u66f4\u591a\u8ba1\u7b97\u8d44\u6e90\uff1b\u6d88\u878d\u5b9e\u9a8c\u63ed\u793a\u4e86\u6253\u5305\u4f18\u52bf\u7684\u5177\u4f53\u673a\u5236\u548c\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u6df1\u5316\u4e86\u5bf9LLM\u8bad\u7ec3\u52a8\u6001\u7684\u7406\u89e3\uff0c\u4e3a\u4f18\u5316\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u8868\u660e\u6587\u6863\u6253\u5305\u7b56\u7565\u9700\u8981\u5728\u6027\u80fd\u63d0\u5347\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u6743\u8861\u3002", "topic": "agent analysis"}}
{"id": "2512.14014", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14014", "abs": "https://arxiv.org/abs/2512.14014", "authors": ["Shufan Li", "Konstantinos Kallidromitis", "Akash Gokul", "Yusuke Kato", "Kazuki Kozuka", "Aditya Grover"], "title": "MobileWorldBench: Towards Semantic World Modeling For Mobile Agents", "comment": "21 pages, 13 figures", "summary": "World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld", "AI": {"tldr": "\u63d0\u51faMobileWorldBench\u57fa\u51c6\u6d4b\u8bd5\u548cMobileWorld\u6570\u636e\u96c6\uff0c\u63a2\u7d22\u7528\u4e8eGUI\u4ee3\u7406\u7684\u81ea\u7136\u8bed\u8a00\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u8bed\u4e49\u800c\u975e\u50cf\u7d20\u9884\u6d4b\u6765\u6539\u8fdb\u79fb\u52a8\u4ee3\u7406\u7684\u4efb\u52a1\u6210\u529f\u7387", "motivation": "\u73b0\u6709\u50cf\u7d20\u7a7a\u95f4\u4e16\u754c\u6a21\u578b\u5728GUI\u73af\u5883\u4e2d\u9762\u4e34\u5b9e\u9645\u9650\u5236\uff0c\u9884\u6d4b\u590d\u6742\u89c6\u89c9\u5143\u7d20\u56f0\u96be\uff0c\u9700\u8981\u63a2\u7d22\u66ff\u4ee3\u65b9\u6848", "method": "1) \u5f15\u5165MobileWorldBench\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30VLMs\u4f5c\u4e3aGUI\u4ee3\u7406\u4e16\u754c\u6a21\u578b\u7684\u80fd\u529b\uff1b2) \u53d1\u5e03\u5305\u542b140\u4e07\u6837\u672c\u7684MobileWorld\u6570\u636e\u96c6\uff1b3) \u63d0\u51fa\u5c06VLM\u4e16\u754c\u6a21\u578b\u96c6\u6210\u5230\u79fb\u52a8\u4ee3\u7406\u89c4\u5212\u6846\u67b6\u7684\u65b0\u6846\u67b6", "result": "\u8bed\u4e49\u4e16\u754c\u6a21\u578b\u80fd\u76f4\u63a5\u63d0\u5347\u79fb\u52a8\u4ee3\u7406\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0cMobileWorld\u6570\u636e\u96c6\u663e\u8457\u6539\u5584\u4e86VLMs\u7684\u4e16\u754c\u5efa\u6a21\u80fd\u529b", "conclusion": "\u81ea\u7136\u8bed\u8a00\u4e16\u754c\u6a21\u578b\u662fGUI\u4ee3\u7406\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u514b\u670d\u50cf\u7d20\u7a7a\u95f4\u6a21\u578b\u7684\u9650\u5236\uff0c\u63d0\u5347\u4ee3\u7406\u6027\u80fd", "topic": "agent analysis"}}
{"id": "2512.14500", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14500", "abs": "https://arxiv.org/abs/2512.14500", "authors": ["Teodor Poncu", "Ioana Pintilie", "Marius Dragoi", "Dragos Tantaru", "Florin Brad"], "title": "C-ing Clearly: Enhanced Binary Code Explanations using C code", "comment": "18 pages, 5 figures", "summary": "Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.", "AI": {"tldr": "\u63d0\u51faC-ing Clearly\u65b9\u6cd5\uff0c\u5229\u7528C\u4ee3\u7801\u751f\u6210\u5408\u6210\u6570\u636e\u6765\u589e\u5f3aLLM\u5bf9\u6c47\u7f16\u8bed\u8a00\u7684\u7406\u89e3\uff0c\u5728\u4e8c\u8fdb\u5236\u4ee3\u7801\u6458\u8981\u548c\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u6027\u80fd\u63d0\u5347\u3002", "motivation": "LLM\u901a\u5e38\u5728\u9ad8\u7ea7\u7f16\u7a0b\u8bed\u8a00\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u4f4e\u7ea7\u8bed\u8a00\u5982\u6c47\u7f16\u8bed\u8a00\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u9700\u8981\u63d0\u5347LLM\u5bf9\u6c47\u7f16\u4ee3\u7801\u7684\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51faC-ing Clearly\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff0c\u5229\u7528\u5bf9\u5e94\u7684C\u4ee3\u7801\u6765\u589e\u5f3aLLM\u5bf9\u6c47\u7f16\u7684\u7406\u89e3\u3002\u901a\u8fc7\u8be5\u65b9\u6cd5\u751f\u6210\u7684\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728\u4e8c\u8fdb\u5236\u4ee3\u7801\u6458\u8981\u548c\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u6539\u8fdb\u7684LLM\u6027\u80fd\u3002\u5728\u4e0d\u540cLLM\u5bb6\u65cf\u548c\u6a21\u578b\u89c4\u6a21\u4e0a\u90fd\u83b7\u5f97\u4e86\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528C\u4ee3\u7801\u751f\u6210\u5408\u6210\u6570\u636e\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u5347LLM\u5bf9\u6c47\u7f16\u8bed\u8a00\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5728\u76f8\u5173\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u6539\u8fdb\u3002", "topic": "code agent"}}
{"id": "2512.13741", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13741", "abs": "https://arxiv.org/abs/2512.13741", "authors": ["Md. Hasib Ur Rahman"], "title": "The Laminar Flow Hypothesis: Detecting Jailbreaks via Semantic Turbulence in Large Language Models", "comment": null, "summary": "As Large Language Models (LLMs) become ubiquitous, the challenge of securing them against adversarial \"jailbreaking\" attacks has intensified. Current defense strategies often rely on computationally expensive external classifiers or brittle lexical filters, overlooking the intrinsic dynamics of the model's reasoning process. In this work, the Laminar Flow Hypothesis is introduced, which posits that benign inputs induce smooth, gradual transitions in an LLM's high-dimensional latent space, whereas adversarial prompts trigger chaotic, high-variance trajectories - termed Semantic Turbulence - resulting from the internal conflict between safety alignment and instruction-following objectives. This phenomenon is formalized through a novel, zero-shot metric: the variance of layer-wise cosine velocity. Experimental evaluation across diverse small language models reveals a striking diagnostic capability. The RLHF-aligned Qwen2-1.5B exhibits a statistically significant 75.4% increase in turbulence under attack (p less than 0.001), validating the hypothesis of internal conflict. Conversely, Gemma-2B displays a 22.0% decrease in turbulence, characterizing a distinct, low-entropy \"reflex-based\" refusal mechanism. These findings demonstrate that Semantic Turbulence serves not only as a lightweight, real-time jailbreak detector but also as a non-invasive diagnostic tool for categorizing the underlying safety architecture of black-box models.", "AI": {"tldr": "\u63d0\u51fa\"\u5c42\u6d41\u5047\u8bbe\"\uff0c\u8ba4\u4e3a\u826f\u6027\u8f93\u5165\u5728LLM\u6f5c\u5728\u7a7a\u95f4\u4e2d\u4ea7\u751f\u5e73\u6ed1\u8fc7\u6e21\uff0c\u800c\u5bf9\u6297\u6027\u63d0\u793a\u5f15\u53d1\"\u8bed\u4e49\u6e4d\u6d41\"\uff0c\u53ef\u901a\u8fc7\u5c42\u95f4\u4f59\u5f26\u901f\u5ea6\u65b9\u5dee\u68c0\u6d4b\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u8be5\u6307\u6807\u80fd\u6709\u6548\u8bc6\u522b\u8d8a\u72f1\u653b\u51fb\u5e76\u5206\u7c7b\u6a21\u578b\u5b89\u5168\u67b6\u6784\u3002", "motivation": "\u5f53\u524dLLM\u9632\u5fa1\u7b56\u7565\u4f9d\u8d56\u8ba1\u7b97\u6602\u8d35\u7684\u5916\u90e8\u5206\u7c7b\u5668\u6216\u8106\u5f31\u7684\u8bcd\u6c47\u8fc7\u6ee4\u5668\uff0c\u5ffd\u89c6\u4e86\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u7684\u5185\u5728\u52a8\u6001\u3002\u9700\u8981\u66f4\u8f7b\u91cf\u3001\u5b9e\u65f6\u7684\u8d8a\u72f1\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u7406\u89e3\u4e0d\u540c\u6a21\u578b\u7684\u5b89\u5168\u67b6\u6784\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u5c42\u6d41\u5047\u8bbe\u548c\u8bed\u4e49\u6e4d\u6d41\u6982\u5ff5\uff0c\u5f62\u5f0f\u5316\u4e3a\u96f6\u6307\u6807\uff1a\u5c42\u95f4\u4f59\u5f26\u901f\u5ea6\u65b9\u5dee\u3002\u901a\u8fc7\u5b9e\u9a8c\u8bc4\u4f30\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u6297\u6027\u63d0\u793a\u4e0b\u7684\u54cd\u5e94\u6a21\u5f0f\uff0c\u5206\u6790\u4e0d\u540c\u5b89\u5168\u67b6\u6784\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "RLHF\u5bf9\u9f50\u7684Qwen2-1.5B\u5728\u653b\u51fb\u4e0b\u6e4d\u6d41\u589e\u52a075.4%\uff0c\u9a8c\u8bc1\u4e86\u5185\u90e8\u51b2\u7a81\u5047\u8bbe\uff1bGemma-2B\u5219\u663e\u793a22.0%\u7684\u6e4d\u6d41\u51cf\u5c11\uff0c\u8868\u73b0\u51fa\u4e0d\u540c\u7684\"\u57fa\u4e8e\u53cd\u5c04\"\u7684\u62d2\u7edd\u673a\u5236\u3002\u8be5\u6307\u6807\u80fd\u6709\u6548\u68c0\u6d4b\u8d8a\u72f1\u5e76\u5206\u7c7b\u5b89\u5168\u67b6\u6784\u3002", "conclusion": "\u8bed\u4e49\u6e4d\u6d41\u4e0d\u4ec5\u53ef\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u5b9e\u65f6\u8d8a\u72f1\u68c0\u6d4b\u5668\uff0c\u8fd8\u80fd\u4f5c\u4e3a\u975e\u4fb5\u5165\u5f0f\u8bca\u65ad\u5de5\u5177\uff0c\u7528\u4e8e\u5206\u7c7b\u9ed1\u76d2\u6a21\u578b\u7684\u5b89\u5168\u67b6\u6784\u7c7b\u578b\uff0c\u4e3aLLM\u5b89\u5168\u9632\u5fa1\u63d0\u4f9b\u65b0\u89c6\u89d2\u3002", "topic": "agent analysis"}}
{"id": "2512.14043", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14043", "abs": "https://arxiv.org/abs/2512.14043", "authors": ["Enhong Liu", "Haiyu Yang", "Miel Hostens"], "title": "Evaluating Small Language Models for Agentic On-Farm Decision Support Systems", "comment": null, "summary": "Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e8620\u4e2a\u5f00\u6e90\u5c0f\u8bed\u8a00\u6a21\u578b\u5728\u5976\u725b\u517b\u6b96\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b5\u4e2a\u4efb\u52a1\u7279\u5b9a\u4ee3\u7406\u7684AI\u7cfb\u7edf\uff0cQwen-4B\u5728\u591a\u6570\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4f46PySpark\u4e2d\u7684NoSQL\u4ea4\u4e92\u4ecd\u4e0d\u7a33\u5b9a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6709\u6f5c\u529b\u652f\u6301\u5976\u725b\u517b\u6b96\u51b3\u7b56\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u9700\u6c42\u9650\u5236\u4e86\u5728\u519c\u573a\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002\u9700\u8981\u80fd\u591f\u5728\u519c\u573a\u786c\u4ef6\u4e0a\u672c\u5730\u8fd0\u884c\u7684\u8f7b\u91cf\u7ea7\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5728\u519c\u573a\u73b0\u5b9e\u7684\u7b97\u529b\u7ea6\u675f\u4e0b\uff0c\u5bf9HuggingFace\u4e0a\u768420\u4e2a\u5f00\u6e90\u5c0f\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u6587\u732e\u641c\u7d22\u3001\u7f51\u7edc\u641c\u7d22\u3001SQL\u6570\u636e\u5e93\u4ea4\u4e92\u3001NoSQL\u6570\u636e\u5e93\u4ea4\u4e92\u548c\u56fe\u751f\u6210\u4e94\u4e2a\u4efb\u52a1\u7279\u5b9a\u4ee3\u7406\u7684AI\u7cfb\u7edf\u3002\u8bc4\u4f30\u5206\u4e24\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u75285\u4e2a\u6d4b\u8bd5\u95ee\u9898\u8fdb\u884c\u521d\u6b65\u7b5b\u9009\uff0c\u7b2c\u4e8c\u9636\u6bb5\u752830\u4e2a\u95ee\u9898\uff08\u6bcf\u4e2a\u4efb\u52a1\u7c7b\u522b5\u4e2a\uff0c\u52a0\u4e0a\u8bda\u4fe1\u7c7b\u522b\uff09\u8fdb\u884c\u8be6\u7ec6\u8bc4\u4f30\u3002", "result": "Qwen-4B\u5728\u5927\u591a\u6570\u4efb\u52a1\u7c7b\u522b\u4e2d\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u4f46\u5728\u901a\u8fc7PySpark\u8fdb\u884cNoSQL\u6570\u636e\u5e93\u4ea4\u4e92\u65f6\u8868\u73b0\u51fa\u4e0d\u7a33\u5b9a\u7684\u6548\u679c\u3002\u8fd9\u662f\u9996\u4e2a\u660e\u786e\u8bc4\u4f30\u5c0f\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5976\u725b\u517b\u6b96\u51b3\u7b56\u5f15\u64ce\u53ef\u884c\u6027\u7684\u7814\u7a76\u3002", "conclusion": "\u5c0f\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u5de5\u5177\u5728\u5976\u725b\u517b\u6b96\u5b9e\u9645\u90e8\u7f72\u4e2d\u5177\u6709\u524d\u666f\uff0c\u4f46\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u901a\u8fc7\u5fae\u8c03\u6765\u63d0\u5347\u5728\u5976\u725b\u517b\u6b96\u7279\u5b9a\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "topic": "agent analysis"}}
{"id": "2512.14048", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14048", "abs": "https://arxiv.org/abs/2512.14048", "authors": ["Shen Li", "Li Huang", "Shaoxiong Zhan", "Weifeng Sun", "Tao Yin", "Zhongxin Liu", "Meng Yan"], "title": "Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation", "comment": "Accepted at AAAI-2026", "summary": "Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.", "AI": {"tldr": "RoutingGen\uff1a\u4e00\u4e2a\u96be\u5ea6\u611f\u77e5\u7684\u8def\u7531\u6846\u67b6\uff0c\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u52a8\u6001\u9009\u62e9\u63d0\u793a\u7b56\u7565\uff0c\u7b80\u5355\u4efb\u52a1\u7528few-shot\u63d0\u793a\uff0c\u590d\u6742\u4efb\u52a1\u7528Intention Chain-of-Thought\uff08ICoT\uff09\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u5b9e\u73b0SOTA\u6027\u80fd\u5e76\u51cf\u5c1146.37%\u7684token\u4f7f\u7528\u3002", "motivation": "\u73b0\u6709CoT\u63d0\u793a\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u5c40\u9650\uff1a1\uff09\u7edf\u4e00\u5e94\u7528\u5bfc\u81f4\u7b80\u5355\u4efb\u52a1\u4e0a\u8fc7\u5ea6\u601d\u8003\uff1b2\uff09\u7f3a\u4e4f\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u610f\u56fe\u62bd\u8c61\uff08\u5982\u6838\u5fc3\u7b97\u6cd5\u8bbe\u8ba1\u548c\u6548\u7387\u5efa\u6a21\uff09\uff0c\u4f7f\u6a21\u578b\u5173\u6ce8\u8868\u9762\u7ed3\u6784\u800c\u5ffd\u89c6\u5168\u5c40\u76ee\u6807\u3002\u53d7\u8ba4\u77e5\u7ecf\u6d4e\u539f\u5219\u542f\u53d1\uff0c\u9700\u8981\u4ec5\u5728\u5fc5\u8981\u65f6\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\u4ee5\u8282\u7701\u8ba4\u77e5\u8d44\u6e90\u3002", "method": "\u63d0\u51faRoutingGen\u6846\u67b6\uff1a1\uff09\u96be\u5ea6\u611f\u77e5\u8def\u7531\u673a\u5236\uff0c\u52a8\u6001\u8bc4\u4f30\u4efb\u52a1\u590d\u6742\u5ea6\uff1b2\uff09\u7b80\u5355\u4efb\u52a1\u91c7\u7528few-shot\u63d0\u793a\uff1b3\uff09\u590d\u6742\u4efb\u52a1\u91c7\u7528Intention Chain-of-Thought\uff08ICoT\uff09\uff0c\u5f15\u5bfc\u6a21\u578b\u6355\u83b7\u4efb\u52a1\u610f\u56fe\uff08\u6838\u5fc3\u7b97\u6cd5\u903b\u8f91\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u7b49\uff09\u3002", "result": "\u57283\u4e2a\u6a21\u578b\u548c6\u4e2a\u6807\u51c6\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRoutingGen\u5728\u5927\u591a\u6570\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u5e73\u5747\u51cf\u5c1146.37%\u7684token\u4f7f\u7528\u3002ICoT\u5728\u6311\u6218\u6027\u57fa\u51c6\u4e0a\u4f18\u4e8e6\u4e2a\u73b0\u6709\u63d0\u793a\u57fa\u7ebf\u3002", "conclusion": "RoutingGen\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u8def\u7531\u548c\u610f\u56fe\u94fe\u5f0f\u601d\u7ef4\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709CoT\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4e3a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u7684\u63d0\u793a\u7b56\u7565\u3002", "topic": "code agent"}}
{"id": "2512.14554", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14554", "abs": "https://arxiv.org/abs/2512.14554", "authors": ["Nguyen Tien Dong", "Minh-Anh Nguyen", "Thanh Dat Hoang", "Nguyen Tuan Ngoc", "Dao Xuan Quang Minh", "Phan Phi Hai", "Nguyen Thi Ngoc Anh", "Dang Van Tu", "Binh Vu"], "title": "VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models", "comment": null, "summary": "The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.", "AI": {"tldr": "VLegal-Bench\u662f\u9996\u4e2a\u9488\u5bf9\u8d8a\u5357\u6cd5\u5f8b\u7684\u5168\u9762\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b10,450\u4e2a\u6837\u672c\uff0c\u57fa\u4e8eBloom\u8ba4\u77e5\u5206\u7c7b\u6cd5\u8bbe\u8ba1\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u8d8a\u5357\u6cd5\u5f8b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u8d8a\u5357\u6cd5\u5f8b\u7684\u590d\u6742\u6027\u3001\u5c42\u7ea7\u7ed3\u6784\u548c\u9891\u7e41\u4fee\u8ba2\u7ed9\u8bc4\u4f30LLM\u7406\u89e3\u548c\u5e94\u7528\u6cd5\u5f8b\u77e5\u8bc6\u5e26\u6765\u4e86\u6311\u6218\uff0c\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u8d8a\u5357\u6cd5\u5f8b\u9886\u57df\u7684\u8868\u73b0\u3002", "method": "\u57fa\u4e8eBloom\u8ba4\u77e5\u5206\u7c7b\u6cd5\u8bbe\u8ba1\u591a\u5c42\u6b21\u6cd5\u5f8b\u7406\u89e3\u4efb\u52a1\uff0c\u901a\u8fc7\u4e25\u683c\u7684\u6807\u6ce8\u6d41\u7a0b\u751f\u621010,450\u4e2a\u6837\u672c\uff0c\u7531\u6cd5\u5f8b\u4e13\u5bb6\u6807\u6ce8\u548c\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u786e\u4fdd\u6bcf\u4e2a\u6837\u672c\u90fd\u57fa\u4e8e\u6743\u5a01\u6cd5\u5f8b\u6587\u4ef6\u5e76\u53cd\u6620\u771f\u5b9e\u6cd5\u5f8b\u52a9\u7406\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u521b\u5efa\u4e86\u9996\u4e2a\u5168\u9762\u7684\u8d8a\u5357\u6cd5\u5f8b\u57fa\u51c6\u6d4b\u8bd5VLegal-Bench\uff0c\u6db5\u76d6\u4e00\u822c\u6cd5\u5f8b\u95ee\u7b54\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u3001\u591a\u6b65\u63a8\u7406\u548c\u57fa\u4e8e\u8d8a\u5357\u6cd5\u5f8b\u7684\u573a\u666f\u95ee\u9898\u89e3\u51b3\u7b49\u4efb\u52a1\u3002", "conclusion": "VLegal-Bench\u4e3a\u8bc4\u4f30LLM\u5728\u8d8a\u5357\u6cd5\u5f8b\u73af\u5883\u4e2d\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u3001\u900f\u660e\u4e14\u8ba4\u77e5\u77e5\u60c5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u652f\u6301\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u53ef\u89e3\u91ca\u4e14\u7b26\u5408\u4f26\u7406\u7684AI\u8f85\u52a9\u6cd5\u5f8b\u7cfb\u7edf\u3002", "topic": "swe benchmark"}}
{"id": "2512.14079", "categories": ["cs.AI", "cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.14079", "abs": "https://arxiv.org/abs/2512.14079", "authors": ["Mayank Singh", "Vikas Yadav", "Shiva Krishna Reddy Malay", "Shravan Nayak", "Sai Rajeswar", "Sathwik Tejaswi Madhusudhan", "Eduardo Blanco"], "title": "Grammar Search for Multi-Agent Systems", "comment": null, "summary": "Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple, composable components. We show that, despite lacking the generative flexibility of LLMs during the candidate generation stage, our method outperforms prior approaches on four out of five benchmarks across two domains: mathematics and question answering. Furthermore, our method offers additional advantages, including a more cost-efficient search process and the generation of modular, interpretable multi-agent systems with simpler logic.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fa\u5b9a\u53ef\u7ec4\u5408\u7ec4\u4ef6\u7684\u7ed3\u6784\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u641c\u7d22\u6846\u67b6\uff0c\u76f8\u6bd4\u57fa\u4e8eLLM\u7684\u81ea\u7531\u5f62\u5f0f\u641c\u7d22\uff0c\u5728\u6570\u5b66\u548c\u95ee\u7b54\u9886\u57df\u7684\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6709\u56db\u4e2a\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u66f4\u7ecf\u6d4e\u3001\u53ef\u89e3\u91ca\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u81ea\u52a8\u641c\u7d22\u4e3b\u8981\u4f9d\u8d56LLM\u8fdb\u884c\u4ee3\u7801\u7a7a\u95f4\u7684\u81ea\u7531\u5f62\u5f0f\u641c\u7d22\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7f3a\u4e4f\u7ed3\u6784\u6027\u548c\u6548\u7387\u3002\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u4e2a\u66f4\u7ed3\u6784\u5316\u3001\u7ecf\u6d4e\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u641c\u7d22\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u4e00\u7ec4\u56fa\u5b9a\u7684\u7b80\u5355\u53ef\u7ec4\u5408\u7ec4\u4ef6\u6765\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7a7a\u95f4\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56LLM\u7684\u751f\u6210\u7075\u6d3b\u6027\u3002\u901a\u8fc7\u7ec4\u5408\u8fd9\u4e9b\u7ec4\u4ef6\u6765\u6784\u5efa\u5019\u9009\u7cfb\u7edf\u3002", "result": "\u5728\u6570\u5b66\u548c\u95ee\u7b54\u4e24\u4e2a\u9886\u57df\u7684\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u6d4b\u8bd5\u4e0a\u8d85\u8d8a\u4e86\u5148\u524d\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u3002\u540c\u65f6\u5177\u6709\u641c\u7d22\u6210\u672c\u66f4\u4f4e\u3001\u751f\u6210\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u66f4\u6a21\u5757\u5316\u3001\u53ef\u89e3\u91ca\u3001\u903b\u8f91\u66f4\u7b80\u5355\u7684\u4f18\u52bf\u3002", "conclusion": "\u7ed3\u6784\u5316\u7ec4\u4ef6\u65b9\u6cd5\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u641c\u7d22\u4e2d\u6bd4\u81ea\u7531\u5f62\u5f0fLLM\u641c\u7d22\u66f4\u6709\u6548\uff0c\u63d0\u4f9b\u4e86\u6027\u80fd\u3001\u6210\u672c\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u7efc\u5408\u4f18\u52bf\u3002", "topic": "agent analysis"}}
{"id": "2512.13821", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13821", "abs": "https://arxiv.org/abs/2512.13821", "authors": ["Subramanyam Sahoo", "Jared Junkin"], "title": "The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces", "comment": "13 Pages, Initial Work on AI Control. A Preprint", "summary": "Large language models (LLMs) increasingly generate code with minimal human oversight, raising critical concerns about backdoor injection and malicious behavior. We present Cross-Trace Verification Protocol (CTVP), a novel AI control framework that verifies untrusted code-generating models through semantic orbit analysis. Rather than directly executing potentially malicious code, CTVP leverages the model's own predictions of execution traces across semantically equivalent program transformations. By analyzing consistency patterns in these predicted traces, we detect behavioral anomalies indicative of backdoors. Our approach introduces the Adversarial Robustness Quotient (ARQ), which quantifies the computational cost of verification relative to baseline generation, demonstrating exponential growth with orbit size. Theoretical analysis establishes information-theoretic bounds showing non-gamifiability -- adversaries cannot improve through training due to fundamental space complexity constraints. This work demonstrates that semantic orbit analysis provides a scalable, theoretically grounded approach to AI control for code generation tasks.", "AI": {"tldr": "\u63d0\u51faCTVP\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u8f68\u9053\u5206\u6790\u9a8c\u8bc1\u4e0d\u53ef\u4fe1\u4ee3\u7801\u751f\u6210\u6a21\u578b\uff0c\u68c0\u6d4b\u540e\u95e8\u6ce8\u5165\uff0c\u5f15\u5165ARQ\u6307\u6807\u91cf\u5316\u9a8c\u8bc1\u6210\u672c\uff0c\u8bc1\u660e\u4e0d\u53ef\u535a\u5f08\u6027\u3002", "motivation": "\u968f\u7740LLM\u8d8a\u6765\u8d8a\u591a\u5730\u751f\u6210\u4ee3\u7801\u800c\u4eba\u5de5\u76d1\u7763\u51cf\u5c11\uff0c\u540e\u95e8\u6ce8\u5165\u548c\u6076\u610f\u884c\u4e3a\u6210\u4e3a\u5173\u952e\u95ee\u9898\uff0c\u9700\u8981\u53ef\u9760\u7684AI\u63a7\u5236\u6846\u67b6\u6765\u9a8c\u8bc1\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u8de8\u8f68\u8ff9\u9a8c\u8bc1\u534f\u8bae(CTVP)\uff0c\u4e0d\u76f4\u63a5\u6267\u884c\u53ef\u80fd\u6076\u610f\u7684\u4ee3\u7801\uff0c\u800c\u662f\u901a\u8fc7\u5206\u6790\u6a21\u578b\u5728\u8bed\u4e49\u7b49\u4ef7\u7a0b\u5e8f\u53d8\u6362\u4e0a\u7684\u6267\u884c\u8f68\u8ff9\u9884\u6d4b\u4e00\u81f4\u6027\uff0c\u68c0\u6d4b\u884c\u4e3a\u5f02\u5e38\u3002", "result": "\u5f15\u5165\u5bf9\u6297\u9c81\u68d2\u5546(ARQ)\u91cf\u5316\u9a8c\u8bc1\u6210\u672c\uff0c\u663e\u793a\u968f\u8f68\u9053\u5927\u5c0f\u6307\u6570\u589e\u957f\uff1b\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4fe1\u606f\u8bba\u8fb9\u754c\uff0c\u8bc1\u660e\u4e0d\u53ef\u535a\u5f08\u6027\uff0c\u5373\u5bf9\u624b\u65e0\u6cd5\u901a\u8fc7\u8bad\u7ec3\u6539\u8fdb\u3002", "conclusion": "\u8bed\u4e49\u8f68\u9053\u5206\u6790\u4e3a\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u7406\u8bba\u57fa\u7840\u7684AI\u63a7\u5236\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u540e\u95e8\u884c\u4e3a\u3002", "topic": "code agent"}}
{"id": "2512.14157", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.14157", "abs": "https://arxiv.org/abs/2512.14157", "authors": ["Yankai Jiang", "Yujie Zhang", "Peng Zhang", "Yichen Li", "Jintai Chen", "Xiaoming Shi", "Shihui Zhen"], "title": "Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis", "comment": null, "summary": "Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely \"think with images\" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.", "AI": {"tldr": "Ophiuchus\u662f\u4e00\u4e2a\u5de5\u5177\u589e\u5f3a\u7684\u533b\u5b66MLLM\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u805a\u7126\u7ec6\u7c92\u5ea6\u89c6\u89c9\u533a\u57df\u5b9e\u73b0\u7cbe\u786e\u7684\u533b\u5b66\u56fe\u50cf\u8bca\u65ad\u548c\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u533b\u5b66MLLM\u5728\u751f\u6210\u6587\u672c\u63a8\u7406\u94fe\u65b9\u9762\u6709\u8fdb\u5c55\uff0c\u4f46\u5728\u9700\u8981\u52a8\u6001\u8fed\u4ee3\u805a\u7126\u7ec6\u7c92\u5ea6\u89c6\u89c9\u533a\u57df\u7684\u590d\u6742\u4efb\u52a1\u4e2d\u4ecd\u5b58\u5728\u56f0\u96be\uff0c\u65e0\u6cd5\u5b9e\u73b0\u7cbe\u786e\u7684\u5b9a\u4f4d\u548c\u8bca\u65ad\u3002", "method": "\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a1)\u51b7\u542f\u52a8\u8bad\u7ec3\uff0c\u4f7f\u7528\u5de5\u5177\u96c6\u6210\u7684\u63a8\u7406\u6570\u636e\u5b9e\u73b0\u57fa\u672c\u5de5\u5177\u9009\u62e9\u548c\u5173\u952e\u533a\u57df\u68c0\u67e5\uff1b2)\u81ea\u53cd\u601d\u5fae\u8c03\uff0c\u52a0\u5f3a\u53cd\u601d\u63a8\u7406\u5e76\u9f13\u52b1\u91cd\u65b0\u5ba1\u89c6\u5de5\u5177\u8f93\u51fa\uff1b3)\u4ee3\u7406\u5de5\u5177\u5f3a\u5316\u5b66\u4e60\uff0c\u76f4\u63a5\u4f18\u5316\u4efb\u52a1\u7279\u5b9a\u5956\u52b1\u5e76\u6a21\u62df\u4e13\u5bb6\u8bca\u65ad\u884c\u4e3a\u3002", "result": "\u5728\u591a\u79cd\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ecVQA\u3001\u68c0\u6d4b\u548c\u57fa\u4e8e\u63a8\u7406\u7684\u5206\u5272\uff09\u4e2d\uff0cOphiuchus\u6301\u7eed\u4f18\u4e8e\u95ed\u6e90\u548c\u5f00\u6e90\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u533b\u5b66AI\u4ee3\u7406\u901a\u8fc7\u5de5\u5177\u96c6\u6210\u63a8\u7406\u5b9e\u73b0\u771f\u6b63\"\u7528\u56fe\u50cf\u601d\u8003\"\u5f00\u8f9f\u4e86\u9053\u8def\u3002", "topic": "agent analysis"}}
{"id": "2512.14417", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14417", "abs": "https://arxiv.org/abs/2512.14417", "authors": ["Jia Hu", "Junqi Li", "Weimeng Lin", "Peng Jia", "Yuxiong Ji", "Jintao Lai"], "title": "PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals", "comment": null, "summary": "Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created", "AI": {"tldr": "PortAgent\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f66\u8f86\u8c03\u5ea6\u4ee3\u7406\uff0c\u901a\u8fc7\u865a\u62df\u4e13\u5bb6\u56e2\u961f\u81ea\u52a8\u5316\u5b9e\u73b0\u8de8\u81ea\u52a8\u5316\u96c6\u88c5\u7bb1\u7801\u5934\u7684\u8f66\u8f86\u8c03\u5ea6\u7cfb\u7edf\u8fc1\u79fb\uff0c\u65e0\u9700\u6e2f\u53e3\u8fd0\u8425\u4e13\u5bb6\u3001\u6570\u636e\u9700\u6c42\u4f4e\u3001\u90e8\u7f72\u5feb\u901f", "motivation": "\u81ea\u52a8\u5316\u96c6\u88c5\u7bb1\u7801\u5934\uff08ACT\uff09\u7684\u8f66\u8f86\u8c03\u5ea6\u7cfb\u7edf\uff08VDS\uff09\u5546\u4e1a\u5316\u5e94\u7528\u9762\u4e34\u8de8\u7801\u5934\u53ef\u8fc1\u79fb\u6027\u4f4e\u7684\u6311\u6218\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u5bf9\u6e2f\u53e3\u8fd0\u8425\u4e13\u5bb6\u7684\u9ad8\u5ea6\u4f9d\u8d56\u3001\u5bf9\u7801\u5934\u7279\u5b9a\u6570\u636e\u7684\u9ad8\u9700\u6c42\u4ee5\u53ca\u8017\u65f6\u7684\u624b\u52a8\u90e8\u7f72\u8fc7\u7a0b", "method": "\u63d0\u51faPortAgent LLM\u9a71\u52a8\u8f66\u8f86\u8c03\u5ea6\u4ee3\u7406\uff0c\u91c7\u7528\u865a\u62df\u4e13\u5bb6\u56e2\u961f\uff08VET\uff09\u67b6\u6784\uff0c\u5305\u62ec\u77e5\u8bc6\u68c0\u7d22\u5668\u3001\u5efa\u6a21\u5668\u3001\u7f16\u7801\u5668\u548c\u8c03\u8bd5\u5668\u56db\u4e2a\u865a\u62df\u4e13\u5bb6\uff0c\u901a\u8fc7few-shot\u793a\u4f8b\u5b66\u4e60\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u673a\u5236\u83b7\u53d6VDS\u9886\u57df\u77e5\u8bc6\uff0c\u5e76\u5efa\u7acb\u57fa\u4e8eLLM Reflexion\u6846\u67b6\u7684\u81ea\u6821\u6b63\u5faa\u73af\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41", "result": "PortAgent\u5b9e\u73b0\u4e86\u8f66\u8f86\u8c03\u5ea6\u7cfb\u7edf\u8fc1\u79fb\u5de5\u4f5c\u6d41\u7684\u5b8c\u5168\u81ea\u52a8\u5316\uff0c\u6d88\u9664\u4e86\u5bf9\u6e2f\u53e3\u8fd0\u8425\u4e13\u5bb6\u7684\u4f9d\u8d56\uff0c\u964d\u4f4e\u4e86\u5bf9\u7801\u5934\u7279\u5b9a\u6570\u636e\u7684\u9700\u6c42\uff0c\u5e76\u5b9e\u73b0\u4e86\u5feb\u901f\u90e8\u7f72", "conclusion": "PortAgent\u901a\u8fc7LLM\u9a71\u52a8\u7684\u865a\u62df\u4e13\u5bb6\u56e2\u961f\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u96c6\u88c5\u7bb1\u7801\u5934\u8f66\u8f86\u8c03\u5ea6\u7cfb\u7edf\u7684\u53ef\u8fc1\u79fb\u6027\u95ee\u9898\uff0c\u4e3aVDS\u7684\u5546\u4e1a\u5316\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u65b9\u6848", "topic": "agent analysis"}}
{"id": "2512.14474", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14474", "abs": "https://arxiv.org/abs/2512.14474", "authors": ["Annu Rana", "Gaurav Kumar"], "title": "Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling", "comment": null, "summary": "Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.", "AI": {"tldr": "\u63d0\u51faModel-First Reasoning (MFR)\u65b9\u6cd5\uff0c\u8ba9LLM\u5148\u6784\u5efa\u660e\u786e\u7684\u95ee\u9898\u6a21\u578b\uff08\u5b9e\u4f53\u3001\u72b6\u6001\u53d8\u91cf\u3001\u52a8\u4f5c\u3001\u7ea6\u675f\uff09\uff0c\u518d\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u51cf\u5c11\u7ea6\u675f\u8fdd\u53cd\u5e76\u63d0\u9ad8\u89c4\u5212\u8d28\u91cf\u3002", "motivation": "LLM\u5728\u5904\u7406\u590d\u6742\u591a\u6b65\u89c4\u5212\u4efb\u52a1\u65f6\u7ecf\u5e38\u51fa\u73b0\u7ea6\u675f\u8fdd\u53cd\u548c\u4e0d\u4e00\u81f4\u89e3\u51b3\u65b9\u6848\uff0c\u73b0\u6709\u65b9\u6cd5\u5982Chain-of-Thought\u548cReAct\u4f9d\u8d56\u9690\u5f0f\u72b6\u6001\u8ddf\u8e2a\uff0c\u7f3a\u4e4f\u660e\u786e\u7684\u95ee\u9898\u8868\u793a\u3002", "method": "\u63d0\u51faModel-First Reasoning (MFR)\u4e24\u9636\u6bb5\u8303\u5f0f\uff1a1) LLM\u9996\u5148\u6784\u5efa\u660e\u786e\u7684\u95ee\u9898\u6a21\u578b\uff0c\u5b9a\u4e49\u5b9e\u4f53\u3001\u72b6\u6001\u53d8\u91cf\u3001\u52a8\u4f5c\u548c\u7ea6\u675f\uff1b2) \u57fa\u4e8e\u8be5\u6a21\u578b\u751f\u6210\u89e3\u51b3\u65b9\u6848\u8ba1\u5212\u3002", "result": "\u5728\u533b\u7597\u8c03\u5ea6\u3001\u8def\u7ebf\u89c4\u5212\u3001\u8d44\u6e90\u5206\u914d\u3001\u903b\u8f91\u8c1c\u9898\u548c\u7a0b\u5e8f\u5408\u6210\u7b49\u591a\u4e2a\u89c4\u5212\u9886\u57df\u4e2d\uff0cMFR\u76f8\u6bd4Chain-of-Thought\u548cReAct\u51cf\u5c11\u4e86\u7ea6\u675f\u8fdd\u53cd\u5e76\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002", "conclusion": "\u8bb8\u591aLLM\u89c4\u5212\u5931\u8d25\u6e90\u4e8e\u8868\u793a\u7f3a\u9677\u800c\u975e\u63a8\u7406\u9650\u5236\uff0c\u660e\u786e\u5efa\u6a21\u662f\u6784\u5efa\u9c81\u68d2\u548c\u53ef\u89e3\u91caAI\u4ee3\u7406\u7684\u5173\u952e\u7ec4\u4ef6\u3002", "topic": "agent analysis"}}
{"id": "2512.14693", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14693", "abs": "https://arxiv.org/abs/2512.14693", "authors": ["Zitian Gao", "Lynx Chen", "Yihao Xiao", "He Xing", "Ran Tao", "Haoming Luo", "Joey Zhou", "Bryan Dai"], "title": "Universal Reasoning Model", "comment": null, "summary": "Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u901a\u7528\u63a8\u7406\u6a21\u578b\uff08URM\uff09\uff0c\u901a\u8fc7\u77ed\u5377\u79ef\u548c\u622a\u65ad\u53cd\u5411\u4f20\u64ad\u589e\u5f3a\u901a\u7528Transformer\uff0c\u5728ARC-AGI\u57fa\u51c6\u4e0a\u53d6\u5f97SOTA\u6027\u80fd", "motivation": "\u901a\u7528Transformer\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u6027\u80fd\u63d0\u5347\u7684\u5177\u4f53\u6765\u6e90\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u5206\u6790UT\u53d8\u4f53\uff0c\u63ed\u793a\u5176\u6027\u80fd\u63d0\u5347\u7684\u771f\u6b63\u539f\u56e0\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u63a8\u7406\u6a21\u578b\u3002", "method": "\u9996\u5148\u7cfb\u7edf\u5206\u6790\u901a\u7528Transformer\u53d8\u4f53\uff0c\u53d1\u73b0\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u6765\u81ea\u5faa\u73af\u5f52\u7eb3\u504f\u7f6e\u548cTransformer\u7684\u5f3a\u975e\u7ebf\u6027\u7ec4\u4ef6\u3002\u57fa\u4e8e\u6b64\u63d0\u51fa\u901a\u7528\u63a8\u7406\u6a21\u578b\uff08URM\uff09\uff0c\u901a\u8fc7\u77ed\u5377\u79ef\u548c\u622a\u65ad\u53cd\u5411\u4f20\u64ad\u6765\u589e\u5f3a\u901a\u7528Transformer\u3002", "result": "\u5728ARC-AGI\u57fa\u51c6\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff1aARC-AGI 1\u8fbe\u523053.8% pass@1\uff0cARC-AGI 2\u8fbe\u523016.0% pass@1\uff0c\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u901a\u7528Transformer\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u6e90\u4e8e\u5faa\u73af\u5f52\u7eb3\u504f\u7f6e\u548c\u5f3a\u975e\u7ebf\u6027\u7ec4\u4ef6\uff0c\u800c\u975e\u590d\u6742\u7684\u67b6\u6784\u8bbe\u8ba1\u3002\u63d0\u51fa\u7684URM\u6a21\u578b\u901a\u8fc7\u7b80\u5355\u6709\u6548\u7684\u6539\u8fdb\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\u3002", "topic": "agent analysis"}}
{"id": "2512.14100", "categories": ["cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.14100", "abs": "https://arxiv.org/abs/2512.14100", "authors": ["Chunjin Jian", "Xinhua Zhu"], "title": "A First-Order Logic-Based Alternative to Reward Models in RLHF", "comment": null, "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.\n  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.\n  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.", "AI": {"tldr": "\u63d0\u51faS-GRPO\u65b9\u6cd5\uff0c\u7528\u903b\u8f91\u76f8\u4f3c\u6027\u5956\u52b1\u673a\u5236\u66ff\u4ee3\u4f20\u7edf\u5956\u52b1\u5efa\u6a21\uff0c\u901a\u8fc7\u5f62\u5f0f\u903b\u8f91\u4e00\u81f4\u6027\u5f15\u5bfc\u6a21\u578b\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\uff0c\u907f\u514d\u6a21\u578b\u5d29\u6e83\u3002", "motivation": "\u73b0\u6709RLHF\u65b9\u6cd5\u4f9d\u8d56\u5956\u52b1\u6a21\u578b\u7684\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\uff0c\u4f46\u4f20\u7edf\u5956\u52b1\u5efa\u6a21\u5b58\u5728\u542f\u53d1\u5f0f\u4f30\u8ba1\u7684\u5c40\u9650\u6027\u3002\u9700\u8981\u66f4\u7a33\u5b9a\u3001\u903b\u8f91\u4e00\u81f4\u7684\u65b9\u6cd5\u6765\u5bf9\u9f50\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u3002", "method": "\u63d0\u51fa\u903b\u8f91\u76f8\u4f3c\u6027\u5956\u52b1\u673a\u5236\uff0c\u57fa\u4e8e\u5f62\u5f0f\u903b\u8f91\u4e00\u81f4\u6027\u800c\u975e\u542f\u53d1\u5f0f\u5956\u52b1\u4f30\u8ba1\u3002\u5f15\u5165S-GRPO\uff08GRPO\u7684\u76d1\u7763\u53d8\u4f53\uff09\uff0c\u7ed3\u5408\u76d1\u7763\u7ec4\u4ef6\uff0c\u8054\u5408\u4f18\u5316\u751f\u6210\u9879\u3001KL\u6563\u5ea6\u6b63\u5219\u5316\u548c\u57fa\u4e8e\u6807\u7b7e\u7684\u76ee\u6807\u3002", "result": "S-GRPO\u5728\u6027\u80fd\u548c\u9c81\u68d2\u6027\u4e0a\u5747\u4f18\u4e8e\u6807\u51c6\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\uff0c\u5e76\u80fd\u6269\u5c55GRPO\u548cDPO\u7b49\u73b0\u6709\u504f\u597d\u5b66\u4e60\u6846\u67b6\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u3001\u4efb\u52a1\u81ea\u9002\u5e94\u7684\u5bf9\u9f50\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "\u903b\u8f91\u76f8\u4f3c\u6027\u5956\u52b1\u673a\u5236\u548cS-GRPO\u6846\u67b6\u4e3aRLHF\u63d0\u4f9b\u4e86\u66f4\u7a33\u5b9a\u3001\u903b\u8f91\u4e00\u81f4\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u80fd\u6709\u6548\u907f\u514d\u6a21\u578b\u5d29\u6e83\uff0c\u63d0\u5347\u5bf9\u9f50\u6027\u80fd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.14202", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14202", "abs": "https://arxiv.org/abs/2512.14202", "authors": ["Timo Klein", "Thomas Lang", "Andrii Shkabrii", "Alexander Sturm", "Kevin Sidak", "Lukas Miklautz", "Claudia Plant", "Yllka Velaj", "Sebastian Tschiatschek"], "title": "Understanding and Improving Hyperbolic Deep Reinforcement Learning", "comment": null, "summary": "The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincar\u00e9 Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .", "AI": {"tldr": "\u63d0\u51faHyper++\uff0c\u4e00\u79cd\u6539\u8fdb\u7684\u53cc\u66f2\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\uff0c\u901a\u8fc7\u7a33\u5b9a\u68af\u5ea6\u8bad\u7ec3\u3001\u7279\u5f81\u6b63\u5219\u5316\u548c\u4f18\u5316\u53cb\u597d\u7684\u7f51\u7edc\u5c42\u8bbe\u8ba1\uff0c\u89e3\u51b3\u53cc\u66f2\u7279\u5f81\u7a7a\u95f4\u5728RL\u4e2d\u7684\u4f18\u5316\u6311\u6218\u3002", "motivation": "\u53cc\u66f2\u7279\u5f81\u7a7a\u95f4\u80fd\u81ea\u7136\u6355\u6349\u590d\u6742RL\u73af\u5883\u4e2d\u7684\u5c42\u6b21\u548c\u5173\u7cfb\u7ed3\u6784\uff0c\u4f46RL\u7684\u975e\u5e73\u7a33\u6027\u5bfc\u81f4\u4f18\u5316\u56f0\u96be\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u68af\u5ea6\u4e0d\u7a33\u5b9a\u548c\u8bad\u7ec3\u5931\u8d25\u95ee\u9898\u3002", "method": "\u5206\u6790Poincar\u00e9 Ball\u548cHyperboloid\u6a21\u578b\u4e2d\u7684\u68af\u5ea6\u95ee\u9898\uff0c\u63d0\u51faHyper++\uff1a1) \u4f7f\u7528\u5206\u7c7b\u503c\u635f\u5931\u7a33\u5b9acritic\u8bad\u7ec3\uff1b2) \u7279\u5f81\u6b63\u5219\u5316\u4fdd\u8bc1\u6709\u754c\u8303\u6570\uff1b3) \u4f18\u5316\u53cb\u597d\u7684\u53cc\u66f2\u7f51\u7edc\u5c42\u8bbe\u8ba1\u3002", "result": "\u5728ProcGen\u4e0a\u4fdd\u8bc1\u7a33\u5b9a\u5b66\u4e60\uff0c\u4f18\u4e8e\u5148\u524d\u53cc\u66f2\u4ee3\u7406\uff0c\u51cf\u5c11\u7ea630%\u8bad\u7ec3\u65f6\u95f4\uff1b\u5728Atari-5\u4e0a\u663e\u8457\u8d85\u8d8a\u6b27\u51e0\u91cc\u5f97\u548c\u53cc\u66f2\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u53cc\u66f2RL\u7684\u68af\u5ea6\u95ee\u9898\u5e76\u63d0\u51fa\u76f8\u5e94\u89e3\u51b3\u65b9\u6848\uff0cHyper++\u5b9e\u73b0\u4e86\u7a33\u5b9a\u9ad8\u6548\u7684\u53cc\u66f2\u5f3a\u5316\u5b66\u4e60\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684\u5c42\u6b21\u7ed3\u6784\u8868\u793a\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.14617", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14617", "abs": "https://arxiv.org/abs/2512.14617", "authors": ["Alessandro Trapasso", "Luca Iocchi", "Fabio Patrizi"], "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes", "comment": "19 pages, 32 figures, includes appendix", "summary": "Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.", "AI": {"tldr": "QR-MAX\u662f\u9996\u4e2a\u9488\u5bf9\u975e\u9a6c\u5c14\u53ef\u592b\u5956\u52b1\u51b3\u7b56\u8fc7\u7a0b(NMRDPs)\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u901a\u8fc7\u5956\u52b1\u673a\u5206\u89e3\u9a6c\u5c14\u53ef\u592b\u8f6c\u79fb\u5b66\u4e60\u4e0e\u975e\u9a6c\u5c14\u53ef\u592b\u5956\u52b1\u5904\u7406\uff0c\u5b9e\u73b0\u4e86\u591a\u9879\u5f0f\u6837\u672c\u590d\u6742\u5ea6\u7684PAC\u6536\u655b\u4fdd\u8bc1\uff0c\u5e76\u5728\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u4e2d\u6269\u5c55\u4e3aBucket-QR-MAX\u3002", "motivation": "\u8bb8\u591a\u5b9e\u9645\u51b3\u7b56\u95ee\u9898\u6d89\u53ca\u4f9d\u8d56\u4e8e\u6574\u4e2a\u7cfb\u7edf\u5386\u53f2\u7684\u4efb\u52a1\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8fbe\u5230\u5177\u6709\u671f\u671b\u5c5e\u6027\u7684\u72b6\u6001\u3002\u9a6c\u5c14\u53ef\u592b\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e0d\u9002\u5408\u6b64\u7c7b\u4efb\u52a1\uff0c\u800c\u975e\u9a6c\u5c14\u53ef\u592b\u5956\u52b1\u51b3\u7b56\u8fc7\u7a0b(NMRDPs)\u867d\u7136\u80fd\u5904\u7406\u65f6\u95f4\u4f9d\u8d56\u4efb\u52a1\uff0c\u4f46\u957f\u671f\u4ee5\u6765\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\uff08\u8fd1\u6700\u4f18\u6027\u548c\u6837\u672c\u6548\u7387\uff09\u3002", "method": "\u63d0\u51faQR-MAX\u7b97\u6cd5\uff0c\u901a\u8fc7\u5956\u52b1\u673a\u5c06\u9a6c\u5c14\u53ef\u592b\u8f6c\u79fb\u5b66\u4e60\u4e0e\u975e\u9a6c\u5c14\u53ef\u592b\u5956\u52b1\u5904\u7406\u8fdb\u884c\u5206\u89e3\uff0c\u8fd9\u662f\u9996\u4e2a\u5229\u7528\u8fd9\u79cd\u5206\u89e3\u5b9e\u73b0\u591a\u9879\u5f0f\u6837\u672c\u590d\u6742\u5ea6PAC\u6536\u655b\u7684\u57fa\u4e8e\u6a21\u578bRL\u7b97\u6cd5\u3002\u7136\u540e\u6269\u5c55\u4e3aBucket-QR-MAX\uff0c\u4f7f\u7528SimHash-based\u79bb\u6563\u5316\u5668\u5904\u7406\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\uff0c\u4fdd\u6301\u76f8\u540c\u7684\u5206\u89e3\u7ed3\u6784\u3002", "result": "QR-MAX\u5b9e\u73b0\u4e86\u03b5-\u6700\u4f18\u7b56\u7565\u7684PAC\u6536\u655b\uff0c\u5177\u6709\u591a\u9879\u5f0f\u6837\u672c\u590d\u6742\u5ea6\u3002\u5728\u590d\u6742\u5ea6\u9012\u589e\u7684\u73af\u5883\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u6a21\u578bRL\u65b9\u6cd5\u8fdb\u884c\u5b9e\u9a8c\u6bd4\u8f83\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u6837\u672c\u6548\u7387\u63d0\u5347\u548c\u5bfb\u627e\u6700\u4f18\u7b56\u7565\u7684\u9c81\u68d2\u6027\u589e\u5f3a\u3002", "conclusion": "QR-MAX\u89e3\u51b3\u4e86NMRDPs\u4e2d\u957f\u671f\u7f3a\u4e4f\u5f62\u5f0f\u5316\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u5206\u89e3\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u5b66\u4e60\uff0c\u5e76\u5728\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u4e2d\u4fdd\u6301\u76f8\u540c\u4f18\u52bf\uff0c\u4e3a\u975e\u9a6c\u5c14\u53ef\u592b\u4efb\u52a1\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u548c\u5b9e\u8df5\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.15407", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15407", "abs": "https://arxiv.org/abs/2511.15407", "authors": ["Mingyu Zhang", "Lifeng Zhuo", "Tianxi Tan", "Guocan Xie", "Xian Nie", "Yan Li", "Renjie Zhao", "Zizhu He", "Ziyu Wang", "Jiting Cai", "Yong-Lu Li"], "title": "IPR-1: Interactive Physical Reasoner", "comment": "13 pages of main text and 19 pages of appendices. Project page: https://mybearyzhang.github.io/ipr-1", "summary": "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. To study this, we introduce a Game-to-Unseen (G2U) benchmark of 1,000+ heterogeneous games that exhibit significant visual domain gaps. Existing approaches, including VLMs and world models, struggle to capture underlying physics and causality since they are not focused on core mechanisms and overfit to visual details. VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on levels from primitive intuition to goal-driven reasoning, and even surpasses GPT-5 overall. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning. Further demos and project details can be found at https://mybearyzhang.github.io/ipr-1.", "AI": {"tldr": "\u63d0\u51faIPR\uff08\u4ea4\u4e92\u5f0f\u7269\u7406\u63a8\u7406\u5668\uff09\uff0c\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u63a8\u6f14\u6765\u8bc4\u4f30\u548c\u5f3a\u5316VLM\u7b56\u7565\uff0c\u5f15\u5165PhysCode\u7269\u7406\u4e2d\u5fc3\u52a8\u4f5c\u7f16\u7801\uff0c\u57281000+\u6e38\u620f\u4e2d\u9884\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4ece\u76f4\u89c9\u5230\u76ee\u6807\u9a71\u52a8\u7684\u7269\u7406\u63a8\u7406\uff0c\u6027\u80fd\u8d85\u8d8aGPT-5\u3002", "motivation": "\u4eba\u7c7b\u901a\u8fc7\u89c2\u5bdf\u3001\u4ea4\u4e92\u548c\u73af\u5883\u4e92\u52a8\u6765\u5b66\u4e60\u7269\u7406\u548c\u56e0\u679c\u5173\u7cfb\u3002\u7814\u7a76\u667a\u80fd\u4f53\u662f\u5426\u4e5f\u80fd\u901a\u8fc7\u7c7b\u4f3c\u65b9\u5f0f\u83b7\u5f97\u7c7b\u4eba\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u66f4\u591a\u7ecf\u9a8c\u4e2d\u6301\u7eed\u6539\u8fdb\u3002\u73b0\u6709\u65b9\u6cd5\uff08VLMs\u548c\u4e16\u754c\u6a21\u578b\uff09\u96be\u4ee5\u6355\u6349\u5e95\u5c42\u7269\u7406\u548c\u56e0\u679c\u5173\u7cfb\uff0c\u56e0\u4e3a\u5b83\u4eec\u8fc7\u5ea6\u5173\u6ce8\u89c6\u89c9\u7ec6\u8282\u800c\u975e\u6838\u5fc3\u673a\u5236\u3002", "method": "\u63d0\u51faIPR\uff08\u4ea4\u4e92\u5f0f\u7269\u7406\u63a8\u7406\u5668\uff09\uff0c\u4f7f\u7528\u4e16\u754c\u6a21\u578b\u63a8\u6f14\u6765\u8bc4\u5206\u548c\u5f3a\u5316VLM\u7684\u7b56\u7565\u3002\u5f15\u5165PhysCode\u7269\u7406\u4e2d\u5fc3\u52a8\u4f5c\u7f16\u7801\uff0c\u5c06\u8bed\u4e49\u610f\u56fe\u4e0e\u52a8\u529b\u5b66\u5bf9\u9f50\uff0c\u4e3a\u9884\u6d4b\u548c\u63a8\u7406\u63d0\u4f9b\u5171\u4eab\u52a8\u4f5c\u7a7a\u95f4\u3002\u57281000+\u5f02\u8d28\u6e38\u620f\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u3002", "result": "IPR\u5728\u4ece\u539f\u59cb\u76f4\u89c9\u5230\u76ee\u6807\u9a71\u52a8\u63a8\u7406\u7684\u5404\u79cd\u5173\u5361\u4e2d\u8868\u73b0\u7a33\u5065\uff0c\u6574\u4f53\u6027\u80fd\u751a\u81f3\u8d85\u8d8aGPT-5\u3002\u6027\u80fd\u968f\u7740\u8bad\u7ec3\u6e38\u620f\u6570\u91cf\u548c\u4ea4\u4e92\u6b65\u6570\u7684\u589e\u52a0\u800c\u63d0\u5347\uff0c\u5e76\u80fd\u96f6\u6837\u672c\u8fc1\u79fb\u5230\u672a\u89c1\u8fc7\u7684\u6e38\u620f\u3002", "conclusion": "\u7269\u7406\u4e2d\u5fc3\u7684\u4ea4\u4e92\u662f\u5b9e\u73b0\u6301\u7eed\u6539\u8fdb\u7269\u7406\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u9014\u5f84\u3002\u6a21\u578b\u901a\u8fc7\u5927\u91cf\u6e38\u620f\u4ea4\u4e92\u5b66\u4e60\u5230\u4e86\u53ef\u6cdb\u5316\u7684\u7269\u7406\u63a8\u7406\u80fd\u529b\u3002", "topic": "agent analysis"}}
{"id": "tldr.2512.1b019d38", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnews.ycombinator.com%2Fitem%3Fid=46255285%26utm_source=tldrdev/1/0100019b21eb958d-2b38da21-1af5-4b6d-b2b7-cec487b65017-000000/aWnKk_pgpfpCSDUvCzuQeq7p8U5B6nIUpFp4tgxujFs=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnews.ycombinator.com%2Fitem%3Fid=46255285%26utm_source=tldrdev/1/0100019b21eb958d-2b38da21-1af5-4b6d-b2b7-cec487b65017-000000/aWnKk_pgpfpCSDUvCzuQeq7p8U5B6nIUpFp4tgxujFs=435", "authors": ["TLDR Newsletter"], "title": "Ask HN: How can I get better at using AI for programming?", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnews.ycombinator.com%2Fitem%3Fid=46255285%26utm_source=tldrdev/1/0100019b21eb958d-2b38da21-1af5-4b6d-b2b7-cec487b65017-000000/aWnKk_pgpfpCSDUvCzuQeq7p8U5B6nIUpFp4tgxujFs=435", "summary": "Ask HN: How can I get better at using AI for programming? (Hacker News Thread) A dev is struggling to effectively use AI, specifically Claude Code, to rewrite an old jQuery and Django project into SvelteKit. Experienced users recommend using a CLAUDE.md file correctly for persistent instructions, using Claude's \"plan mode\" for task breakdown before implementation, and adding feedback loops through tests to verify the AI's work. Also, Opus 4.5 should be used over any other model for coding whe...", "source": "tldr", "AI": {"tldr": "Hacker News\u8ba8\u8bba\u5982\u4f55\u66f4\u6709\u6548\u4f7f\u7528AI\u7f16\u7a0b\u5de5\u5177\uff08\u7279\u522b\u662fClaude Code\uff09\uff0c\u5206\u4eab\u5c06jQuery/Django\u9879\u76ee\u91cd\u5199\u4e3aSvelteKit\u7684\u7ecf\u9a8c\u6280\u5de7", "motivation": "\u5f00\u53d1\u8005\u5728\u4f7f\u7528AI\u5de5\u5177\uff08\u7279\u522b\u662fClaude Code\uff09\u8fdb\u884c\u7f16\u7a0b\u65f6\u9047\u5230\u56f0\u96be\uff0c\u9700\u8981\u63d0\u9ad8AI\u8f85\u52a9\u7f16\u7a0b\u7684\u6548\u7387\u548c\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u91cd\u6784\u65e7\u9879\u76ee\u65f6", "method": "\u793e\u533a\u7ecf\u9a8c\u5206\u4eab\uff1a\u6b63\u786e\u4f7f\u7528CLAUDE.md\u6587\u4ef6\u63d0\u4f9b\u6301\u4e45\u6307\u4ee4\uff0c\u4f7f\u7528\"plan mode\"\u8fdb\u884c\u4efb\u52a1\u5206\u89e3\uff0c\u901a\u8fc7\u6d4b\u8bd5\u5efa\u7acb\u53cd\u9988\u5faa\u73af\u9a8c\u8bc1AI\u8f93\u51fa\uff0c\u63a8\u8350\u4f7f\u7528Opus 4.5\u6a21\u578b", "result": "\u793e\u533a\u6210\u5458\u5206\u4eab\u4e86\u5b9e\u7528\u7684AI\u7f16\u7a0b\u6280\u5de7\uff0c\u5305\u62ec\u6587\u4ef6\u7ec4\u7ec7\u3001\u4efb\u52a1\u89c4\u5212\u3001\u6d4b\u8bd5\u9a8c\u8bc1\u7b49\u6700\u4f73\u5b9e\u8df5\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u66f4\u6709\u6548\u5730\u5229\u7528AI\u5de5\u5177\u5b8c\u6210\u590d\u6742\u91cd\u6784\u4efb\u52a1", "conclusion": "\u6709\u6548\u4f7f\u7528AI\u7f16\u7a0b\u9700\u8981\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\uff1a\u63d0\u4f9b\u6e05\u6670\u4e0a\u4e0b\u6587\u3001\u5206\u6b65\u89c4\u5212\u3001\u5efa\u7acb\u9a8c\u8bc1\u673a\u5236\uff0c\u5e76\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\uff0c\u8fd9\u4e9b\u6280\u5de7\u80fd\u663e\u8457\u63d0\u9ad8AI\u8f85\u52a9\u7f16\u7a0b\u7684\u6548\u679c", "topic": "code agent"}}
{"id": "tldr.2512.46764549", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fleerob.com%2Fagents%3Futm_source=tldrdev/1/0100019b21eb958d-2b38da21-1af5-4b6d-b2b7-cec487b65017-000000/lXNytNyz4ljfqwsNm8JEe9V1XGLhDsQXCdpK-LyB_3Y=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fleerob.com%2Fagents%3Futm_source=tldrdev/1/0100019b21eb958d-2b38da21-1af5-4b6d-b2b7-cec487b65017-000000/lXNytNyz4ljfqwsNm8JEe9V1XGLhDsQXCdpK-LyB_3Y=435", "authors": ["TLDR Newsletter"], "title": "Coding Agents & Complexity Budgets", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Reading time: 7 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fleerob.com%2Fagents%3Futm_source=tldrdev/1/0100019b21eb958d-2b38da21-1af5-4b6d-b2b7-cec487b65017-000000/lXNytNyz4ljfqwsNm8JEe9V1XGLhDsQXCdpK-LyB_3Y=435", "summary": "Coding Agents & Complexity Budgets (7 minute read) Cursor migrated from a headless CMS to raw code and Markdown after realizing the CMS created unnecessary abstraction and slowed down content updates. They used Cursor's AI coding agents and completed the migration in just three days, spending only $260 in tokens to automate content export, conversion, and codebase refactoring.", "source": "tldr", "AI": {"tldr": "Cursor\u516c\u53f8\u4f7f\u7528AI\u7f16\u7801\u4ee3\u7406\u57283\u5929\u5185\u4ee5260\u7f8e\u5143\u7684\u6210\u672c\u5c06\u5185\u5bb9\u7ba1\u7406\u7cfb\u7edf\u8fc1\u79fb\u5230\u539f\u59cb\u4ee3\u7801\u548cMarkdown\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684CMS\u7cfb\u7edf\u521b\u5efa\u4e86\u4e0d\u5fc5\u8981\u7684\u62bd\u8c61\u5c42\uff0c\u5bfc\u81f4\u5185\u5bb9\u66f4\u65b0\u901f\u5ea6\u53d8\u6162\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u76f4\u63a5\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528Cursor\u7684AI\u7f16\u7801\u4ee3\u7406\u81ea\u52a8\u5316\u5185\u5bb9\u5bfc\u51fa\u3001\u8f6c\u6362\u548c\u4ee3\u7801\u5e93\u91cd\u6784\uff0c\u5b9e\u73b0\u4eceCMS\u5230\u539f\u59cb\u4ee3\u7801\u548cMarkdown\u7684\u8fc1\u79fb\u3002", "result": "\u57283\u5929\u5185\u5b8c\u6210\u8fc1\u79fb\uff0c\u4ec5\u82b1\u8d39260\u7f8e\u5143token\u8d39\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5185\u5bb9\u66f4\u65b0\u6548\u7387\u548c\u5f00\u53d1\u901f\u5ea6\u3002", "conclusion": "AI\u7f16\u7801\u4ee3\u7406\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u4ee3\u7801\u8fc1\u79fb\u4efb\u52a1\uff0c\u4ee5\u8f83\u4f4e\u6210\u672c\u5b9e\u73b0\u5feb\u901f\u7cfb\u7edf\u91cd\u6784\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "topic": "code agent"}}
{"id": "tldr.2512.c6b53035", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fniyikiza.com%2Fposts%2Fcapability-delegation%2F%3Futm_source=tldrinfosec/1/0100019b225807a2-0e116e17-b5db-4319-a291-3cdc8b6ea899-000000/EqbJP7FgvATTK-uUjKkyGPKRelKl63OoqP40fmU__MQ=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fniyikiza.com%2Fposts%2Fcapability-delegation%2F%3Futm_source=tldrinfosec/1/0100019b225807a2-0e116e17-b5db-4319-a291-3cdc8b6ea899-000000/EqbJP7FgvATTK-uUjKkyGPKRelKl63OoqP40fmU__MQ=435", "authors": ["TLDR Newsletter"], "title": "Capabilities Are the Only Way to Secure Agent Delegation", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Reading time: 9 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fniyikiza.com%2Fposts%2Fcapability-delegation%2F%3Futm_source=tldrinfosec/1/0100019b225807a2-0e116e17-b5db-4319-a291-3cdc8b6ea899-000000/EqbJP7FgvATTK-uUjKkyGPKRelKl63OoqP40fmU__MQ=435", "summary": "Capabilities Are the Only Way to Secure Agent Delegation (9 minute read) Traditional IAM systems are inadequate for securing AI agent delegation because they verify identity rather than track authority derivation across dynamic task chains, creating the Confused Deputy problem where agents possess ambient permissions without understanding their origin or intended scope. Capability-based authorization systems address this by treating authority as cryptographically-signed tokens that are explic...", "source": "tldr", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4f20\u7edfIAM\u7cfb\u7edf\u4e0d\u9002\u5408AI\u4ee3\u7406\u6388\u6743\uff0c\u56e0\u4e3a\u5176\u9a8c\u8bc1\u8eab\u4efd\u800c\u975e\u8ddf\u8e2a\u52a8\u6001\u4efb\u52a1\u94fe\u4e2d\u7684\u6743\u9650\u4f20\u9012\uff0c\u5bfc\u81f4\"\u56f0\u60d1\u526f\u624b\"\u95ee\u9898\u3002\u80fd\u529b\u6388\u6743\u7cfb\u7edf\u901a\u8fc7\u52a0\u5bc6\u7b7e\u540d\u4ee4\u724c\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u5c06\u6743\u9650\u4f5c\u4e3a\u53ef\u8ffd\u8e2a\u3001\u53ef\u64a4\u9500\u7684\u4ee4\u724c\u5904\u7406\u3002", "motivation": "\u4f20\u7edf\u8eab\u4efd\u548c\u8bbf\u95ee\u7ba1\u7406(IAM)\u7cfb\u7edf\u5728AI\u4ee3\u7406\u6388\u6743\u573a\u666f\u4e2d\u5b58\u5728\u6839\u672c\u7f3a\u9677\uff0c\u56e0\u4e3a\u5b83\u4eec\u57fa\u4e8e\u8eab\u4efd\u9a8c\u8bc1\u800c\u975e\u6743\u9650\u8ddf\u8e2a\uff0c\u5bfc\u81f4\u4ee3\u7406\u62e5\u6709\u73af\u5883\u6743\u9650\u5374\u4e0d\u7406\u89e3\u5176\u6765\u6e90\u548c\u8303\u56f4\uff0c\u4ea7\u751f\"\u56f0\u60d1\u526f\u624b\"\u95ee\u9898\uff0c\u65e0\u6cd5\u5b89\u5168\u5730\u7ba1\u7406\u52a8\u6001\u4efb\u52a1\u94fe\u4e2d\u7684\u6743\u9650\u59d4\u6258\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u80fd\u529b(capability-based)\u7684\u6388\u6743\u7cfb\u7edf\uff0c\u5c06\u6743\u9650\u8868\u793a\u4e3a\u52a0\u5bc6\u7b7e\u540d\u7684\u4ee4\u724c\uff0c\u8fd9\u4e9b\u4ee4\u724c\u53ef\u4ee5\u660e\u786e\u8ffd\u8e2a\u6743\u9650\u7684\u6765\u6e90\u3001\u8303\u56f4\u548c\u4f20\u9012\u8def\u5f84\uff0c\u786e\u4fdd\u4ee3\u7406\u53ea\u80fd\u6267\u884c\u660e\u786e\u6388\u4e88\u7684\u4efb\u52a1\uff0c\u5e76\u80fd\u968f\u65f6\u64a4\u9500\u6743\u9650\u3002", "result": "\u80fd\u529b\u6388\u6743\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u89e3\u51b3AI\u4ee3\u7406\u6388\u6743\u4e2d\u7684\u5b89\u5168\u95ee\u9898\uff0c\u901a\u8fc7\u52a0\u5bc6\u7b7e\u540d\u4ee4\u724c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u3001\u53ef\u8ffd\u8e2a\u3001\u53ef\u64a4\u9500\u7684\u6743\u9650\u7ba1\u7406\uff0c\u9632\u6b62\u6743\u9650\u6ee5\u7528\u548c\"\u56f0\u60d1\u526f\u624b\"\u95ee\u9898\uff0c\u4e3aAI\u4ee3\u7406\u7684\u5b89\u5168\u59d4\u6258\u63d0\u4f9b\u53ef\u9760\u6846\u67b6\u3002", "conclusion": "\u80fd\u529b\u6388\u6743\u662f\u786e\u4fddAI\u4ee3\u7406\u5b89\u5168\u59d4\u6258\u7684\u552f\u4e00\u6709\u6548\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u52a0\u5bc6\u7b7e\u540d\u4ee4\u724c\u7cfb\u7edf\u89e3\u51b3\u4e86\u4f20\u7edfIAM\u5728\u52a8\u6001\u4efb\u52a1\u94fe\u4e2d\u7684\u6839\u672c\u7f3a\u9677\uff0c\u4e3aAI\u4ee3\u7406\u7684\u5b89\u5168\u64cd\u4f5c\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u6743\u9650\u63a7\u5236\u673a\u5236\u3002", "topic": "agent analysis"}}
{"id": "tldr.2512.abef7ac6", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnathan.rs%2Fposts%2Fdllm-faster-code-generation%2F%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/ZIbbpDj2KvG3gXNtqBDwifLsgA6ycWsEhyyPZiuDvD0=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnathan.rs%2Fposts%2Fdllm-faster-code-generation%2F%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/ZIbbpDj2KvG3gXNtqBDwifLsgA6ycWsEhyyPZiuDvD0=435", "authors": ["TLDR Newsletter"], "title": "Text Diffusion Models are Faster at Writing Code", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Reading time: 7 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnathan.rs%2Fposts%2Fdllm-faster-code-generation%2F%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/ZIbbpDj2KvG3gXNtqBDwifLsgA6ycWsEhyyPZiuDvD0=435", "summary": "Text Diffusion Models are Faster at Writing Code (7 minute read) Diffusion language models generate code at a faster rate than large language models. Increased structure tends to correlate with reduced entropy, which leads to higher confidence token predictions, which directly means more tokens decoded in parallel per step. Tests suggest that it really is the structuredness of the output, not memorization, that matters.", "source": "tldr", "AI": {"tldr": "\u6587\u672c\u6269\u6563\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u6bd4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u66f4\u5feb\uff0c\u8fd9\u662f\u56e0\u4e3a\u4ee3\u7801\u7684\u7ed3\u6784\u6027\u964d\u4f4e\u4e86\u71b5\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5e76\u884c\u89e3\u7801\u6548\u7387", "motivation": "\u7814\u7a76\u6587\u672c\u6269\u6563\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u6548\u7387\u4f18\u52bf\uff0c\u63a2\u7d22\u7ed3\u6784\u6027\u8f93\u51fa\u5982\u4f55\u5f71\u54cd\u751f\u6210\u901f\u5ea6", "method": "\u901a\u8fc7\u5206\u6790\u4ee3\u7801\u7684\u7ed3\u6784\u7279\u6027\u4e0e\u71b5\u7684\u5173\u7cfb\uff0c\u7814\u7a76\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u5e76\u884c\u89e3\u7801\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u5e76\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1", "result": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u901f\u5ea6\u6bd4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u66f4\u5feb\uff0c\u8fd9\u4e3b\u8981\u5f52\u56e0\u4e8e\u4ee3\u7801\u7684\u7ed3\u6784\u6027\u964d\u4f4e\u4e86\u71b5\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u548c\u5e76\u884c\u89e3\u7801\u6548\u7387", "conclusion": "\u4ee3\u7801\u7684\u7ed3\u6784\u6027\u800c\u975e\u8bb0\u5fc6\u6548\u5e94\u662f\u6269\u6563\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u901f\u5ea6\u4f18\u52bf\u7684\u5173\u952e\u56e0\u7d20\uff0c\u8fd9\u4e3a\u9ad8\u6548\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u601d\u8def", "topic": "code agent"}}
{"id": "tldr.2512.b12423bd", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.mintlify.com%2Fblog%2Fassistant-improvements%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/hKwp13rZbgEapavVha37LuInkdcPbVePb4ReeL3KCq4=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.mintlify.com%2Fblog%2Fassistant-improvements%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/hKwp13rZbgEapavVha37LuInkdcPbVePb4ReeL3KCq4=435", "authors": ["TLDR Newsletter"], "title": "Inside our effort to improve the Mintlify assistant", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Reading time: 3 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.mintlify.com%2Fblog%2Fassistant-improvements%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/hKwp13rZbgEapavVha37LuInkdcPbVePb4ReeL3KCq4=435", "summary": "Inside our effort to improve the Mintlify assistant (3 minute read) Mintlify's AI-powered assistant helps end users get answers from docs with clear citations and useful code examples. This article walks through how the team analyzed and improved the assistant after they decided that it wasn't performing the way they wanted. The team rebuilt its feedback pipeline, moved conversation data into ClickHouse, and categorized negative interactions at scale. Its analysis surfaced that search quality...", "source": "tldr", "AI": {"tldr": "Mintlify\u56e2\u961f\u5206\u6790\u5e76\u6539\u8fdb\u4e86\u5176AI\u52a9\u624b\uff0c\u901a\u8fc7\u91cd\u5efa\u53cd\u9988\u7ba1\u9053\u3001\u8fc1\u79fb\u5bf9\u8bdd\u6570\u636e\u5230ClickHouse\u3001\u5927\u89c4\u6a21\u5206\u7c7b\u8d1f\u9762\u4ea4\u4e92\uff0c\u53d1\u73b0\u641c\u7d22\u8d28\u91cf\u662f\u4e3b\u8981\u95ee\u9898", "motivation": "Mintlify\u7684AI\u52a9\u624b\u672a\u80fd\u8fbe\u5230\u9884\u671f\u6027\u80fd\uff0c\u56e2\u961f\u9700\u8981\u5206\u6790\u95ee\u9898\u5e76\u6539\u8fdb\u52a9\u624b\u4ee5\u66f4\u597d\u5730\u5e2e\u52a9\u7528\u6237\u4ece\u6587\u6863\u4e2d\u83b7\u53d6\u7b54\u6848", "method": "\u91cd\u5efa\u53cd\u9988\u7ba1\u9053\uff0c\u5c06\u5bf9\u8bdd\u6570\u636e\u8fc1\u79fb\u5230ClickHouse\u6570\u636e\u5e93\uff0c\u5927\u89c4\u6a21\u5206\u7c7b\u8d1f\u9762\u4ea4\u4e92\uff0c\u5206\u6790\u7528\u6237\u4ea4\u4e92\u6570\u636e", "result": "\u5206\u6790\u53d1\u73b0\u641c\u7d22\u8d28\u91cf\u662f\u4e3b\u8981\u95ee\u9898\uff0c\u901a\u8fc7\u6539\u8fdb\u63aa\u65bd\u63d0\u5347\u4e86\u52a9\u624b\u6027\u80fd", "conclusion": "\u7cfb\u7edf\u5316\u7684\u6570\u636e\u5206\u6790\u548c\u53cd\u9988\u7ba1\u9053\u6539\u8fdb\u662f\u63d0\u5347AI\u52a9\u624b\u6027\u80fd\u7684\u5173\u952e", "topic": "swe application"}}
{"id": "tldr.2512.b3b2c66f", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsolmaz.io%2Fagentic-coding-tools-message-queueing%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/kXIklas8YG4zJj1JCXpXuWL-2Rxn9GyBQ7JKMyyJOR8=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsolmaz.io%2Fagentic-coding-tools-message-queueing%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/kXIklas8YG4zJj1JCXpXuWL-2Rxn9GyBQ7JKMyyJOR8=435", "authors": ["TLDR Newsletter"], "title": "Agentic coding tools should give more control over message queueing", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Reading time: 7 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsolmaz.io%2Fagentic-coding-tools-message-queueing%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/kXIklas8YG4zJj1JCXpXuWL-2Rxn9GyBQ7JKMyyJOR8=435", "summary": "Agentic coding tools should give more control over message queueing (7 minute read) Claude Code uses boundary-aware queuing, where new messages are inserted at natural break points, which changes the model's course of action smoothly without stopping ongoing generation. OpenAI Codex uses post-turn queuing, where user messages wait until the current action finishes completely before they are handled. Agentic tools should implement both types of queuing and let users choose which to use. Having...", "source": "tldr", "AI": {"tldr": "\u8bba\u6587\u8ba8\u8bba\u4e86\u667a\u80fd\u7f16\u7801\u5de5\u5177\u7684\u6d88\u606f\u961f\u5217\u673a\u5236\uff0c\u6bd4\u8f83\u4e86Claude Code\u7684\u8fb9\u754c\u611f\u77e5\u961f\u5217\u548cOpenAI Codex\u7684\u540e\u8f6e\u6b21\u961f\u5217\uff0c\u5efa\u8bae\u667a\u80fd\u5de5\u5177\u5e94\u540c\u65f6\u5b9e\u73b0\u4e24\u79cd\u961f\u5217\u673a\u5236\u5e76\u8ba9\u7528\u6237\u9009\u62e9\u3002", "motivation": "\u5f53\u524d\u667a\u80fd\u7f16\u7801\u5de5\u5177\u7684\u6d88\u606f\u961f\u5217\u5904\u7406\u65b9\u5f0f\u4e0d\u540c\uff0c\u5f71\u54cd\u4e86\u7528\u6237\u4e0eAI\u4ea4\u4e92\u7684\u6d41\u7545\u6027\u548c\u63a7\u5236\u6027\u3002Claude Code\u548cOpenAI Codex\u91c7\u7528\u4e0d\u540c\u7684\u961f\u5217\u7b56\u7565\uff0c\u5404\u6709\u4f18\u7f3a\u70b9\uff0c\u9700\u8981\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u66f4\u7075\u6d3b\u7684\u63a7\u5236\u9009\u9879\u3002", "method": "\u5206\u6790\u6bd4\u8f83\u4e86\u4e24\u79cd\u961f\u5217\u673a\u5236\uff1a1\uff09\u8fb9\u754c\u611f\u77e5\u961f\u5217\uff08Claude Code\uff09\uff1a\u5728\u81ea\u7136\u65ad\u70b9\u5904\u63d2\u5165\u65b0\u6d88\u606f\uff0c\u5e73\u6ed1\u6539\u53d8\u6a21\u578b\u884c\u4e3a\u800c\u4e0d\u4e2d\u65ad\u5f53\u524d\u751f\u6210\uff1b2\uff09\u540e\u8f6e\u6b21\u961f\u5217\uff08OpenAI Codex\uff09\uff1a\u7528\u6237\u6d88\u606f\u7b49\u5f85\u5f53\u524d\u64cd\u4f5c\u5b8c\u5168\u5b8c\u6210\u540e\u624d\u88ab\u5904\u7406\u3002\u5efa\u8bae\u667a\u80fd\u5de5\u5177\u5e94\u540c\u65f6\u5b9e\u73b0\u8fd9\u4e24\u79cd\u673a\u5236\u3002", "result": "\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\uff0c\u53d1\u73b0\u4e0d\u540c\u961f\u5217\u7b56\u7565\u5bf9\u7528\u6237\u4f53\u9a8c\u548c\u5f00\u53d1\u6548\u7387\u6709\u663e\u8457\u5f71\u54cd\u3002\u8fb9\u754c\u611f\u77e5\u961f\u5217\u63d0\u4f9b\u66f4\u6d41\u7545\u7684\u4ea4\u4e92\u4f53\u9a8c\uff0c\u800c\u540e\u8f6e\u6b21\u961f\u5217\u786e\u4fdd\u64cd\u4f5c\u7684\u5b8c\u6574\u6027\u3002\u4e24\u8005\u5404\u6709\u9002\u7528\u573a\u666f\u3002", "conclusion": "\u667a\u80fd\u7f16\u7801\u5de5\u5177\u5e94\u8be5\u540c\u65f6\u5b9e\u73b0\u8fb9\u754c\u611f\u77e5\u961f\u5217\u548c\u540e\u8f6e\u6b21\u961f\u5217\u4e24\u79cd\u6d88\u606f\u5904\u7406\u673a\u5236\uff0c\u5e76\u8ba9\u7528\u6237\u6839\u636e\u5177\u4f53\u9700\u6c42\u9009\u62e9\u4f7f\u7528\u54ea\u79cd\u65b9\u5f0f\uff0c\u4ee5\u63d0\u4f9b\u66f4\u597d\u7684\u63a7\u5236\u6027\u548c\u7075\u6d3b\u6027\u3002", "topic": "code agent"}}
{"id": "tldr.2512.0ba35c25", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flucumr.pocoo.org%2F2025%2F12%2F13%2Fskills-vs-mcp%2F%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/pimyX2Q-_LfFEJmwUmD_0tAvAyulY3wWl4o4mzz5zaU=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flucumr.pocoo.org%2F2025%2F12%2F13%2Fskills-vs-mcp%2F%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/pimyX2Q-_LfFEJmwUmD_0tAvAyulY3wWl4o4mzz5zaU=435", "authors": ["TLDR Newsletter"], "title": "Skills vs Dynamic MCP Loadouts", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Reading time: 7 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flucumr.pocoo.org%2F2025%2F12%2F13%2Fskills-vs-mcp%2F%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/pimyX2Q-_LfFEJmwUmD_0tAvAyulY3wWl4o4mzz5zaU=435", "summary": "Skills vs Dynamic MCP Loadouts (7 minute read) The easiest way to work with tools is to ask agents to write their own tools as a skill. This leaves control of the tool largely to the user. Whenever it breaks or needs modification, the user can just ask the agent to adjust it. Dynamic tool loading with MCP will likely become a thing, but it will probably take quite a few protocol changes to bring in skill-like summaries and built-in manuals for the tools.", "source": "tldr", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4e24\u79cd\u5de5\u5177\u4f7f\u7528\u65b9\u5f0f\uff1a\u8ba9AI\u4ee3\u7406\u7f16\u5199\u6280\u80fd\uff08\u7528\u6237\u63a7\u5236\uff09vs \u52a8\u6001MCP\u5de5\u5177\u52a0\u8f7d\uff08\u9700\u8981\u534f\u8bae\u6539\u8fdb\uff09\uff0c\u8ba4\u4e3a\u6280\u80fd\u65b9\u5f0f\u66f4\u7b80\u5355\u76f4\u63a5", "motivation": "\u63a2\u7d22\u5982\u4f55\u8ba9AI\u4ee3\u7406\u66f4\u6709\u6548\u5730\u4f7f\u7528\u5de5\u5177\uff0c\u6bd4\u8f83\u7528\u6237\u63a7\u5236\u6280\u80fd\u7f16\u5199\u4e0e\u52a8\u6001\u5de5\u5177\u52a0\u8f7d\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52a3\uff0c\u5bfb\u627e\u66f4\u5b9e\u7528\u7684\u5de5\u5177\u96c6\u6210\u65b9\u6848", "method": "\u5bf9\u6bd4\u5206\u6790\u4e24\u79cd\u65b9\u6cd5\uff1a1) \u8ba9\u4ee3\u7406\u7f16\u5199\u6280\u80fd\u4f5c\u4e3a\u5de5\u5177\uff0c\u7528\u6237\u4fdd\u6301\u63a7\u5236\u6743\uff1b2) \u52a8\u6001MCP\u5de5\u5177\u52a0\u8f7d\uff0c\u9700\u8981\u534f\u8bae\u6539\u8fdb\u6765\u652f\u6301\u6280\u80fd\u5f0f\u6458\u8981\u548c\u5185\u7f6e\u624b\u518c", "result": "\u6280\u80fd\u7f16\u5199\u65b9\u6cd5\u66f4\u7b80\u5355\u5b9e\u7528\uff0c\u7528\u6237\u63a7\u5236\u5de5\u5177\u4e14\u6613\u4e8e\u8c03\u6574\uff1b\u52a8\u6001MCP\u52a0\u8f7d\u9700\u8981\u66f4\u591a\u534f\u8bae\u6539\u8fdb\u624d\u80fd\u8fbe\u5230\u7c7b\u4f3c\u6548\u679c", "conclusion": "\u76ee\u524d\u8ba9\u4ee3\u7406\u7f16\u5199\u6280\u80fd\u662f\u66f4\u53ef\u884c\u7684\u5de5\u5177\u4f7f\u7528\u65b9\u6cd5\uff0c\u52a8\u6001MCP\u52a0\u8f7d\u867d\u7136\u524d\u666f\u597d\u4f46\u9700\u8981\u66f4\u591a\u6280\u672f\u53d1\u5c55", "topic": "agent analysis"}}
{"id": "tldr.2512.7c74339c", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Frouxbot.com%2Fp%2Fmcp-code-mode%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/n0RB2NOPkRK4kFzfkV6wV9mYPlcQatK3e4Gh3Y0B8EA=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Frouxbot.com%2Fp%2Fmcp-code-mode%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/n0RB2NOPkRK4kFzfkV6wV9mYPlcQatK3e4Gh3Y0B8EA=435", "authors": ["TLDR Newsletter"], "title": "MCP Writing Code to Call MCP: MCPs All the Way Down", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Reading time: 13 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Frouxbot.com%2Fp%2Fmcp-code-mode%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/n0RB2NOPkRK4kFzfkV6wV9mYPlcQatK3e4Gh3Y0B8EA=435", "summary": "MCP Writing Code to Call MCP: MCPs All the Way Down (13 minute read) This post explores how to build a universal engine for any schema-based integration, without manual plumbing.", "source": "tldr", "AI": {"tldr": "\u6784\u5efa\u901a\u7528\u5f15\u64ce\u5b9e\u73b0\u4efb\u610f\u57fa\u4e8e\u6a21\u5f0f\u7684\u96c6\u6210\uff0c\u65e0\u9700\u624b\u52a8\u8fde\u63a5\u4ee3\u7801", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6a21\u5f0f\u7684\u96c6\u6210\u9700\u8981\u5927\u91cf\u624b\u52a8\u8fde\u63a5\u4ee3\u7801\uff0c\u5f00\u53d1\u6548\u7387\u4f4e\u4e0b\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "method": "\u901a\u8fc7MCP\uff08\u6a21\u5f0f\u8c03\u7528\u534f\u8bae\uff09\u9012\u5f52\u8c03\u7528\u81ea\u8eab\uff0c\u6784\u5efa\u901a\u7528\u5f15\u64ce\u6765\u81ea\u52a8\u5904\u7406\u4efb\u610f\u6a21\u5f0f\u96c6\u6210", "result": "\u5b9e\u73b0\u4e86\u65e0\u9700\u624b\u52a8\u4ee3\u7801\u7684\u901a\u7528\u96c6\u6210\u5f15\u64ce\uff0c\u80fd\u591f\u81ea\u52a8\u5904\u7406\u5404\u79cd\u6a21\u5f0f\u5316\u96c6\u6210\u9700\u6c42", "conclusion": "\u901a\u8fc7MCP\u9012\u5f52\u8c03\u7528\u65b9\u6cd5\uff0c\u6210\u529f\u6784\u5efa\u4e86\u901a\u7528\u96c6\u6210\u5f15\u64ce\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5f00\u53d1\u6548\u7387\u548c\u7cfb\u7edf\u53ef\u9760\u6027", "topic": "code agent"}}
{"id": "tldr.2512.f8c86bf5", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrai%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/yrhSdBSSeVn-CTOSY_ayENxH2u8CIk729QBa7q-PUIU=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrai%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/yrhSdBSSeVn-CTOSY_ayENxH2u8CIk729QBa7q-PUIU=435", "authors": ["TLDR Newsletter"], "title": "advertise with us", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrai%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/yrhSdBSSeVn-CTOSY_ayENxH2u8CIk729QBa7q-PUIU=435", "summary": "MCP Writing Code to Call MCP: MCPs All the Way Down (13 minute read) This post explores how to build a universal engine for any schema-based integration, without manual plumbing.", "source": "tldr", "AI": {"tldr": "\u6784\u5efa\u4e00\u4e2a\u7528\u4e8e\u4efb\u4f55\u57fa\u4e8e\u6a21\u5f0f\u96c6\u6210\u7684\u901a\u7528\u5f15\u64ce\uff0c\u65e0\u9700\u624b\u52a8\u8fde\u63a5\u4ee3\u7801", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6a21\u5f0f\u7684\u96c6\u6210\u9700\u8981\u5927\u91cf\u624b\u52a8\u7f16\u7801\u548c\u8fde\u63a5\u5de5\u4f5c\uff0c\u7f3a\u4e4f\u901a\u7528\u89e3\u51b3\u65b9\u6848", "method": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u81ea\u52a8\u5904\u7406\u4efb\u4f55\u6a21\u5f0f\u96c6\u6210\u7684\u901a\u7528\u5f15\u64ce\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u548c\u81ea\u52a8\u5316\u8fde\u63a5\u5b9e\u73b0", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u5404\u79cd\u6a21\u5f0f\u96c6\u6210\u7684\u901a\u7528\u5f15\u64ce\uff0c\u51cf\u5c11\u4e86\u624b\u52a8\u7f16\u7801\u5de5\u4f5c", "conclusion": "\u901a\u8fc7\u6784\u5efa\u901a\u7528\u96c6\u6210\u5f15\u64ce\uff0c\u53ef\u4ee5\u663e\u8457\u7b80\u5316\u57fa\u4e8e\u6a21\u5f0f\u96c6\u6210\u7684\u5f00\u53d1\u6d41\u7a0b", "topic": "code agent"}}
{"id": "tldr.2512.98e6995f", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/YLF0Fg3uB8sqpfd5FoVk0ahKMGUOed5gCVsmsHhH1To=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/YLF0Fg3uB8sqpfd5FoVk0ahKMGUOed5gCVsmsHhH1To=435", "authors": ["TLDR Newsletter"], "title": "create your own role", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/YLF0Fg3uB8sqpfd5FoVk0ahKMGUOed5gCVsmsHhH1To=435", "summary": "MCP Writing Code to Call MCP: MCPs All the Way Down (13 minute read) This post explores how to build a universal engine for any schema-based integration, without manual plumbing.", "source": "tldr", "AI": {"tldr": "\u6784\u5efa\u4e00\u4e2a\u65e0\u9700\u624b\u52a8\u914d\u7f6e\u7684\u901a\u7528\u5f15\u64ce\uff0c\u7528\u4e8e\u5904\u7406\u4efb\u4f55\u57fa\u4e8e\u6a21\u5f0f\u7684\u96c6\u6210", "motivation": "\u73b0\u6709\u7684\u6a21\u5f0f\u96c6\u6210\u9700\u8981\u5927\u91cf\u624b\u52a8\u914d\u7f6e\u548c\u7ba1\u9053\u5de5\u4f5c\uff0c\u4f5c\u8005\u5e0c\u671b\u521b\u5efa\u4e00\u4e2a\u901a\u7528\u89e3\u51b3\u65b9\u6848\u6765\u7b80\u5316\u8fd9\u4e00\u8fc7\u7a0b", "method": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u81ea\u52a8\u5904\u7406\u4efb\u4f55\u6a21\u5f0f\u96c6\u6210\u7684\u901a\u7528\u5f15\u64ce\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u548c\u81ea\u52a8\u5316\u6765\u6d88\u9664\u624b\u52a8\u914d\u7f6e", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u901a\u7528\u96c6\u6210\u5f15\u64ce\uff0c\u80fd\u591f\u5904\u7406\u5404\u79cd\u6a21\u5f0f\u96c6\u6210\u800c\u65e0\u9700\u624b\u52a8\u7ba1\u9053\u5de5\u4f5c", "conclusion": "\u901a\u8fc7\u6784\u5efa\u901a\u7528\u96c6\u6210\u5f15\u64ce\uff0c\u53ef\u4ee5\u663e\u8457\u7b80\u5316\u6a21\u5f0f\u96c6\u6210\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387", "topic": "code agent"}}
{"id": "tldr.2512.0d099c0c", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/kAluSy5IwYk1lSjUtQzYHV45PpnIIMf8zUvlGHgBneM=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/kAluSy5IwYk1lSjUtQzYHV45PpnIIMf8zUvlGHgBneM=435", "authors": ["TLDR Newsletter"], "title": "Inc.'s Best Bootstrapped businesses", "comment": "Source: TLDR Newsletter, Date: 2025-12-15, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/kAluSy5IwYk1lSjUtQzYHV45PpnIIMf8zUvlGHgBneM=435", "summary": "MCP Writing Code to Call MCP: MCPs All the Way Down (13 minute read) This post explores how to build a universal engine for any schema-based integration, without manual plumbing.", "source": "tldr", "AI": {"tldr": "\u6784\u5efa\u4e00\u4e2a\u65e0\u9700\u624b\u52a8\u914d\u7f6e\u7684\u901a\u7528\u5f15\u64ce\uff0c\u7528\u4e8e\u5904\u7406\u4efb\u4f55\u57fa\u4e8e\u6a21\u5f0f\u7684\u96c6\u6210", "motivation": "\u73b0\u6709\u7684\u6a21\u5f0f\u96c6\u6210\u9700\u8981\u5927\u91cf\u624b\u52a8\u914d\u7f6e\u548c\u7ba1\u9053\u5de5\u4f5c\uff0c\u4f5c\u8005\u5e0c\u671b\u521b\u5efa\u4e00\u4e2a\u901a\u7528\u89e3\u51b3\u65b9\u6848\u6765\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b", "method": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u81ea\u52a8\u5904\u7406\u4efb\u4f55\u6a21\u5f0f\u96c6\u6210\u7684\u901a\u7528\u5f15\u64ce\uff0c\u901a\u8fc7\u4ee3\u7801\u751f\u6210\u548c\u81ea\u52a8\u5316\u6765\u6d88\u9664\u624b\u52a8\u914d\u7f6e", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u5404\u79cd\u6a21\u5f0f\u96c6\u6210\u7684\u901a\u7528\u5f15\u64ce\uff0c\u51cf\u5c11\u4e86\u624b\u52a8\u914d\u7f6e\u5de5\u4f5c", "conclusion": "\u901a\u8fc7\u6784\u5efa\u901a\u7528\u96c6\u6210\u5f15\u64ce\uff0c\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u6a21\u5f0f\u96c6\u6210\u4e2d\u7684\u624b\u52a8\u5de5\u4f5c\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387", "topic": "code agent"}}
{"id": "tldr.2512.3aa9d8fb", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.shopify.com%2Fnews%2Fwinter-26-edition-dev%3Futm_source=comms_paid%26utm_medium=newsletter%26utm_campaign=winter26edition-launch_Q425BACADO%26utm_content=tldrdev-v1/1/0100019b270fa692-84b582a6-0262-4a76-8259-9c1c99efda2f-000000/5aq655fxvhhpd0xTQrlKwx5rUqKOoOIpO5Hs9vthdLA=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.shopify.com%2Fnews%2Fwinter-26-edition-dev%3Futm_source=comms_paid%26utm_medium=newsletter%26utm_campaign=winter26edition-launch_Q425BACADO%26utm_content=tldrdev-v1/1/0100019b270fa692-84b582a6-0262-4a76-8259-9c1c99efda2f-000000/5aq655fxvhhpd0xTQrlKwx5rUqKOoOIpO5Hs9vthdLA=435", "authors": ["TLDR Newsletter"], "title": "Shopify doubles down on AI in the latest large update to its Developer platform", "comment": "Source: TLDR Newsletter, Date: 2025-12-16, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.shopify.com%2Fnews%2Fwinter-26-edition-dev%3Futm_source=comms_paid%26utm_medium=newsletter%26utm_campaign=winter26edition-launch_Q425BACADO%26utm_content=tldrdev-v1/1/0100019b270fa692-84b582a6-0262-4a76-8259-9c1c99efda2f-000000/5aq655fxvhhpd0xTQrlKwx5rUqKOoOIpO5Hs9vthdLA=435", "summary": "Shopify doubles down on AI in the latest large update to its Developer platform (Sponsor) The '26 Winter Edition adds more advanced AI capabilities to Shopify: agents can create dev stores, scaffold apps, run GraphQL operations, and generate validated code across Admin, UI extensions, Liquid, and Hydrogen. Developers can ask questions in natural language and receive working, validated code with direct shopify.dev links. See what's new", "source": "tldr", "AI": {"tldr": "Shopify\u5728\u6700\u65b0\u7684\u5f00\u53d1\u8005\u5e73\u53f0\u66f4\u65b0\u4e2d\u5927\u5e45\u589e\u5f3aAI\u80fd\u529b\uff0c\u4f7fAI\u4ee3\u7406\u80fd\u591f\u521b\u5efa\u5f00\u53d1\u5546\u5e97\u3001\u642d\u5efa\u5e94\u7528\u3001\u6267\u884cGraphQL\u64cd\u4f5c\uff0c\u5e76\u5728\u591a\u4e2a\u6280\u672f\u6808\u4e2d\u751f\u6210\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u4ee3\u7801\u3002", "motivation": "Shopify\u5e0c\u671b\u901a\u8fc7\u589e\u5f3aAI\u80fd\u529b\u6765\u63d0\u5347\u5f00\u53d1\u8005\u4f53\u9a8c\uff0c\u8ba9\u5f00\u53d1\u8005\u80fd\u591f\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u5e76\u83b7\u5f97\u53ef\u76f4\u63a5\u4f7f\u7528\u7684\u9a8c\u8bc1\u4ee3\u7801\uff0c\u4ece\u800c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u548c\u964d\u4f4e\u6280\u672f\u95e8\u69db\u3002", "method": "Shopify\u5728'26\u51ac\u5b63\u7248\u4e2d\u96c6\u6210\u4e86\u66f4\u5148\u8fdb\u7684AI\u529f\u80fd\uff0c\u4f7fAI\u4ee3\u7406\u80fd\u591f\u6267\u884c\u591a\u79cd\u5f00\u53d1\u4efb\u52a1\uff0c\u5305\u62ec\u521b\u5efa\u5f00\u53d1\u5546\u5e97\u3001\u642d\u5efa\u5e94\u7528\u6846\u67b6\u3001\u8fd0\u884cGraphQL\u64cd\u4f5c\uff0c\u5e76\u5728Admin\u3001UI\u6269\u5c55\u3001Liquid\u548cHydrogen\u7b49\u4e0d\u540c\u6280\u672f\u6808\u4e2d\u751f\u6210\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u4ee3\u7801\u3002", "result": "\u5f00\u53d1\u8005\u73b0\u5728\u53ef\u4ee5\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u5e76\u83b7\u5f97\u53ef\u76f4\u63a5\u5de5\u4f5c\u7684\u9a8c\u8bc1\u4ee3\u7801\uff0c\u540c\u65f6\u83b7\u5f97shopify.dev\u7684\u76f4\u63a5\u94fe\u63a5\uff0c\u8fd9\u663e\u8457\u63d0\u5347\u4e86\u5f00\u53d1\u6548\u7387\u548c\u4ee3\u7801\u8d28\u91cf\u3002", "conclusion": "Shopify\u901a\u8fc7\u5927\u89c4\u6a21AI\u96c6\u6210\u6210\u529f\u63d0\u5347\u4e86\u5f00\u53d1\u8005\u5e73\u53f0\u7684\u667a\u80fd\u5316\u6c34\u5e73\uff0c\u4f7f\u5f00\u53d1\u5de5\u4f5c\u66f4\u52a0\u9ad8\u6548\u548c\u4fbf\u6377\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u652f\u6301\u3002", "topic": "code agent"}}
{"id": "tldr.2512.f330851e", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fthedotmack%2Fclaude-mem%3Futm_source=tldrdev/1/0100019b270fa692-84b582a6-0262-4a76-8259-9c1c99efda2f-000000/obZxM2wUUVnl4iwTTB9-r5B5jrj210uBctgDeRLZ_tw=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fthedotmack%2Fclaude-mem%3Futm_source=tldrdev/1/0100019b270fa692-84b582a6-0262-4a76-8259-9c1c99efda2f-000000/obZxM2wUUVnl4iwTTB9-r5B5jrj210uBctgDeRLZ_tw=435", "authors": ["TLDR Newsletter"], "title": "Claude Mem", "comment": "Source: TLDR Newsletter, Date: 2025-12-16, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fthedotmack%2Fclaude-mem%3Futm_source=tldrdev/1/0100019b270fa692-84b582a6-0262-4a76-8259-9c1c99efda2f-000000/obZxM2wUUVnl4iwTTB9-r5B5jrj210uBctgDeRLZ_tw=435", "summary": "Claude Mem (GitHub Repo) Claude-Mem is a Claude Code plugin that provides a persistent memory system by automatically capturing tool usage observations and generating semantic summaries. It injects this relevant context back into future sessions, allowing Claude Code to maintain knowledge continuity across projects.", "source": "tldr", "AI": {"tldr": "Claude Mem\u662f\u4e00\u4e2aClaude Code\u63d2\u4ef6\uff0c\u901a\u8fc7\u81ea\u52a8\u6355\u83b7\u5de5\u5177\u4f7f\u7528\u89c2\u5bdf\u5e76\u751f\u6210\u8bed\u4e49\u6458\u8981\uff0c\u63d0\u4f9b\u6301\u4e45\u5316\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u5c06\u76f8\u5173\u4e0a\u4e0b\u6587\u6ce8\u5165\u672a\u6765\u4f1a\u8bdd\uff0c\u5b9e\u73b0\u8de8\u9879\u76ee\u77e5\u8bc6\u8fde\u7eed\u6027\u3002", "motivation": "\u89e3\u51b3\u4ee3\u7801\u52a9\u624b\u5728\u8de8\u4f1a\u8bdd\u548c\u8de8\u9879\u76ee\u4e2d\u7f3a\u4e4f\u6301\u4e45\u8bb0\u5fc6\u7684\u95ee\u9898\uff0c\u4f7fClaude Code\u80fd\u591f\u8bb0\u4f4f\u4e4b\u524d\u7684\u5de5\u5177\u4f7f\u7528\u548c\u9879\u76ee\u4e0a\u4e0b\u6587\uff0c\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\u548c\u8fde\u7eed\u6027\u3002", "method": "\u5f00\u53d1Claude Code\u63d2\u4ef6\uff0c\u81ea\u52a8\u6355\u83b7\u5de5\u5177\u4f7f\u7528\u89c2\u5bdf\uff0c\u751f\u6210\u8bed\u4e49\u6458\u8981\uff0c\u5efa\u7acb\u6301\u4e45\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u5e76\u5c06\u76f8\u5173\u4e0a\u4e0b\u6587\u6ce8\u5165\u5230\u672a\u6765\u7684\u4f1a\u8bdd\u4e2d\u3002", "result": "\u521b\u5efa\u4e86Claude Mem\u63d2\u4ef6\uff0c\u5b9e\u73b0\u4e86\u8de8\u4f1a\u8bdd\u548c\u8de8\u9879\u76ee\u7684\u77e5\u8bc6\u8fde\u7eed\u6027\uff0c\u4f7fClaude Code\u80fd\u591f\u7ef4\u62a4\u548c\u5229\u7528\u5386\u53f2\u5de5\u5177\u4f7f\u7528\u4fe1\u606f\u3002", "conclusion": "Claude Mem\u901a\u8fc7\u6301\u4e45\u8bb0\u5fc6\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u4e86Claude Code\u7684\u8fde\u7eed\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4e3a\u4ee3\u7801\u52a9\u624b\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u3002", "topic": "code agent"}}
{"id": "wechat.2512.8d076976", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4MDU5MzYyNA==&mid=2247486539&idx=1&sn=c130a2f0aed6970790071bb69e07b4e7&chksm=cebf3f949183306ef594655f095bfc46a2ca0b1f006bfe4e2b8db227965ae46967a6feb2b2df#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4MDU5MzYyNA==&mid=2247486539&idx=1&sn=c130a2f0aed6970790071bb69e07b4e7&chksm=cebf3f949183306ef594655f095bfc46a2ca0b1f006bfe4e2b8db227965ae46967a6feb2b2df#rd", "authors": ["\u4ece\u4e2d\u5b66\u7ade\u8d5b\u5230\u5927\u5b66\u9884\u79d1"], "title": "\u60c5\u7eea\u662f\u51fd\u6570\uff1aAI \u89c6\u89d2\u4e0b\u7684\u4eba\u8111\u964d\u7ef4\u673a\u5236\u4e0e<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\uff08RL\uff09\uff08\u4e0a\uff09", "comment": "Source: WeChat, Published: 2025-12-17 13:52:48", "summary": "\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8fd9\u4e2a\u8bcd\uff0c\u5f88\u591a\u4eba\u542c\u8fc7\uff0c\u4f46\u5927\u591a\u89c9\u5f97\u5b83\u662f\u673a\u623f\u91cc\u7814\u7a76\u5458\u624d\u7528\u7684\u73a9\u610f\u513f\u3002\u4f46\u5f53\u4f60\u628a\u5b83\u653e\u5728\u201c\u60c5\u7eea\u51fd\u6570\u201d\u4e0a\uff0c\u5b83\u53cd\u800c\u53d8\u5f97\u7279\u522b\u76f4\u89c2\u3002RL \u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4e0d\u65ad\u66f4\u65b0\u7684\u6570\u5b66\u7cfb\u7edf\uff0c\u5b83\u7684\u7ed3\u6784\u548c\u6211\u4eec\u7684\u60c5\u7eea\u53cd\u5e94\u51e0\u4e4e\u4e00\u6a21\u4e00\u6837\uff0c\u9760\u4e09", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u8fd9\u4e2a\u8bcd\uff0c\u5f88\u591a\u4eba\u542c\u8fc7\uff0c\u4f46\u5927\u591a\u89c9\u5f97\u5b83\u662f\u673a\u623f\u91cc\u7814\u7a76\u5458\u624d\u7528\u7684\u73a9\u610f\u513f\u3002\u4f46\u5f53\u4f60\u628a\u5b83\u653e\u5728\u201c\u60c5\u7eea\u51fd\u6570\u201d\u4e0a\uff0c\u5b83\u53cd\u800c\u53d8\u5f97\u7279\u522b\u76f4\u89c2\u3002RL \u672c\u8d28\u4e0a\u662f\u4e00\u4e2a\u4e0d\u65ad\u66f4\u65b0\u7684\u6570\u5b66\u7cfb\u7edf\uff0c\u5b83\u7684\u7ed3\u6784\u548c\u6211\u4eec\u7684\u60c5\u7eea\u53cd\u5e94\u51e0\u4e4e\u4e00\u6a21\u4e00\u6837\uff0c\u9760\u4e09", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.9b2a0c58", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0MjY5NzY5OQ==&mid=2247487129&idx=1&sn=ad458e518351ac7a7fb3473d29c1ad19&chksm=c219e203fa2f6b468ae230695993458d8b20291cd6fae2d76459c134c448a3a6f000393ad9ed#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0MjY5NzY5OQ==&mid=2247487129&idx=1&sn=ad458e518351ac7a7fb3473d29c1ad19&chksm=c219e203fa2f6b468ae230695993458d8b20291cd6fae2d76459c134c448a3a6f000393ad9ed#rd", "authors": ["\u4e00\u676f\u4e3a\u54c1"], "title": "\u3010\u57fa\u4e8e\u6a21\u578b\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u3011#1 \u5f15\u8bba\uff1aDyna\u67b6\u6784", "comment": "Source: WeChat, Published: 2025-12-17 12:54:24", "summary": "\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u7684\u6a21\u578b\uff08Model\uff09\u662f\u4e00\u4e2a\u667a\u80fd\u4f53\u53ef\u4ee5\u7528\u6765\u9884\u6d4b\u73af\u5883\u5bf9\u5176\u52a8\u4f5c\u7684\u53cd\u5e94\u7684\u4efb\u4f55\u4e8b\u7269\u3002\u7ed9\u5b9a\u4e00\u4e2a\u72b6\u6001\u548c\u4e00\u4e2a\u52a8\u4f5c\uff0c\u6a21\u578b\u80fd\u4ea7\u751f\u540e\u7ee7\u72b6\u6001\u548c\u4e0b\u4e00\u4e2a\u6536\u76ca\u7684\u9884\u6d4b\u4f5c\u4e3a\u73af\u5883\u7684\u53cd\u5e94\u7ed3\u679c\u3002", "AI": {"tldr": "\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u7684\u6a21\u578b\uff08Model\uff09\u662f\u4e00\u4e2a\u667a\u80fd\u4f53\u53ef\u4ee5\u7528\u6765\u9884\u6d4b\u73af\u5883\u5bf9\u5176\u52a8\u4f5c\u7684\u53cd\u5e94\u7684\u4efb\u4f55\u4e8b\u7269\u3002\u7ed9\u5b9a\u4e00\u4e2a\u72b6\u6001\u548c\u4e00\u4e2a\u52a8\u4f5c\uff0c\u6a21\u578b\u80fd\u4ea7\u751f\u540e\u7ee7\u72b6\u6001\u548c\u4e0b\u4e00\u4e2a\u6536\u76ca\u7684\u9884\u6d4b\u4f5c\u4e3a\u73af\u5883\u7684\u53cd\u5e94\u7ed3\u679c\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.9954f828", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0Njc5ODg0OQ==&mid=2247484550&idx=1&sn=3fbe3641de4b42c5348ed873111dd99e&chksm=c23835348c350764c969662832c53db363253cdbb1a65ca790d66167ce9b23a1ebbc6cfa85d3#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0Njc5ODg0OQ==&mid=2247484550&idx=1&sn=3fbe3641de4b42c5348ed873111dd99e&chksm=c23835348c350764c969662832c53db363253cdbb1a65ca790d66167ce9b23a1ebbc6cfa85d3#rd", "authors": ["EvoDiary"], "title": "OpenAI\uff1a\u8fdb\u5316\u7b56\u7565\u4f5c\u4e3a<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7684\u53ef\u6269\u5c55\u66ff\u4ee3\u65b9\u6848", "comment": "Source: WeChat, Published: 2025-12-17 12:22:33", "summary": "\u5728\u6df1\u5165\u539f\u7406\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u5148\u770b\u770b\u5f53\u65f6\u4e3b\u6d41\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08Deep RL\uff09\u9762\u4e34\u7684\u75db\u70b9\uff1a\u68af\u5ea6\u8ba1\u7b97\u96be\uff1a\u65e0\u8bba\u662f Q-learning \u8fd8\u662f Policy Gradients\uff0c\u672c\u8d28\u4e0a\u90fd\u4f9d\u8d56\u4e8e\u68af\u5ea6\u7684\u53cd\u5411\u4f20\u64ad\u3002", "AI": {"tldr": "\u5728\u6df1\u5165\u539f\u7406\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u5148\u770b\u770b\u5f53\u65f6\u4e3b\u6d41\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08Deep RL\uff09\u9762\u4e34\u7684\u75db\u70b9\uff1a\u68af\u5ea6\u8ba1\u7b97\u96be\uff1a\u65e0\u8bba\u662f Q-learning \u8fd8\u662f Policy Gradients\uff0c\u672c\u8d28\u4e0a\u90fd\u4f9d\u8d56\u4e8e\u68af\u5ea6\u7684\u53cd\u5411\u4f20\u64ad\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.e12d907c", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0NjQ0MDU5NA==&mid=2247484452&idx=1&sn=1901fb008acbda019e73d164fc7aeec9&chksm=c2e408f7e63899f92517cc5a80e76f42c8c670929e7b4b051e93343d71b25d6b7cc21198d1c9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0NjQ0MDU5NA==&mid=2247484452&idx=1&sn=1901fb008acbda019e73d164fc7aeec9&chksm=c2e408f7e63899f92517cc5a80e76f42c8c670929e7b4b051e93343d71b25d6b7cc21198d1c9#rd", "authors": ["\u732b\u53c8\u548c\u7339\u72d0\u7684\u6742\u4e71\u65e5\u8bb0"], "title": "\u732b\u53c8\u7684\u5b66\u4e60\u7b14\u8bb0\u2014\u2014<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>Part3.3", "comment": "Source: WeChat, Published: 2025-12-17 12:04:29", "summary": "\u8fd9\u4f1a\u5c06\u5f3a\u5316\u5b66\u4e60\u7684\u95ee\u9898\u8f6c\u53d8\u4e3a\uff1a\u5176\u4e2d \u662f\u6743\u8861\u7cfb\u6570\uff08trade-off coefficient\uff09\u3002\uff08\u6ce8\u610f\uff1a\u516c\u5f0f\u4e2d\u6211\u4eec\u5047\u8bbe\u7684\u662finfinite-horizon discounted\u8bbe\u5b9a\uff0c\u63a5\u4e0b\u6765\u7684\u8bb2\u8ff0\u4e5f\u90fd\u5728\u8fd9\u4e2a\u8bbe\u5b9a\u4e0b\u5c55\u5f00\uff09\u63a5\u7740\u6211\u4eec\u53ef\u4ee5\u5728\u8fd9\u4e2a\u8bbe\u5b9a\u4e0b\u5b9a\u4e49\u7a0d\u6709\u4e0d\u540c\u7684value function\u3002", "AI": {"tldr": "\u8fd9\u4f1a\u5c06\u5f3a\u5316\u5b66\u4e60\u7684\u95ee\u9898\u8f6c\u53d8\u4e3a\uff1a\u5176\u4e2d \u662f\u6743\u8861\u7cfb\u6570\uff08trade-off coefficient\uff09\u3002\uff08\u6ce8\u610f\uff1a\u516c\u5f0f\u4e2d\u6211\u4eec\u5047\u8bbe\u7684\u662finfinite-horizon discounted\u8bbe\u5b9a\uff0c\u63a5\u4e0b\u6765\u7684\u8bb2\u8ff0\u4e5f\u90fd\u5728\u8fd9\u4e2a\u8bbe\u5b9a\u4e0b\u5c55\u5f00\uff09\u63a5\u7740\u6211\u4eec\u53ef\u4ee5\u5728\u8fd9\u4e2a\u8bbe\u5b9a\u4e0b\u5b9a\u4e49\u7a0d\u6709\u4e0d\u540c\u7684value function\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.c65dff46", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzE5MTYxNjkwMQ==&mid=2247486171&idx=1&sn=70c6c428c5738013c1630e335306431c&chksm=97943d23b9bcce428b59631d14eb75bc7944af9cd711a9ff52f98d1790c17ee71fe2fe74280a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzE5MTYxNjkwMQ==&mid=2247486171&idx=1&sn=70c6c428c5738013c1630e335306431c&chksm=97943d23b9bcce428b59631d14eb75bc7944af9cd711a9ff52f98d1790c17ee71fe2fe74280a#rd", "authors": ["LLM\u70bc\u4e39\u7089"], "title": "2025\u5e74\u00a07\u79cd\u5927\u6a21\u578b\u6700\u6d41\u884c\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7b97\u6cd5\u603b\u7ed3", "comment": "Source: WeChat, Published: 2025-12-17 09:20:23", "summary": "\u7b97\u6cd5\u7b80\u4ecb\uff1a DPO\u505a\u4e86\u4e00\u6b21\u201c\u51cf\u6cd5\u201d\uff1a\u5b83\u5b8c\u5168\u7ed5\u8fc7\u4e86\u4f20\u7edfRLHF\u4e2d\u5148\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u3001\u518d\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7684\u590d\u6742\u6d41\u7a0b\uff0c\u76f4\u63a5\u5c06\u504f\u597d\u5b66\u4e60\u53d8\u6210\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u76d1\u7763\u5b66\u4e60\u95ee\u9898\u3002", "AI": {"tldr": "\u7b97\u6cd5\u7b80\u4ecb\uff1a DPO\u505a\u4e86\u4e00\u6b21\u201c\u51cf\u6cd5\u201d\uff1a\u5b83\u5b8c\u5168\u7ed5\u8fc7\u4e86\u4f20\u7edfRLHF\u4e2d\u5148\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u3001\u518d\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7684\u590d\u6742\u6d41\u7a0b\uff0c\u76f4\u63a5\u5c06\u504f\u597d\u5b66\u4e60\u53d8\u6210\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u76d1\u7763\u5b66\u4e60\u95ee\u9898\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.9eb7938b", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxODQ0MTQzMg==&mid=2247492051&idx=1&sn=6abce216f5ee0ddf2d570dddf7fabfbd&chksm=c0180df44213bd3bd726c282c46abcffd301d1a6783185e5491737f53484ad711663ec85965d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxODQ0MTQzMg==&mid=2247492051&idx=1&sn=6abce216f5ee0ddf2d570dddf7fabfbd&chksm=c0180df44213bd3bd726c282c46abcffd301d1a6783185e5491737f53484ad711663ec85965d#rd", "authors": ["EvoIGroup"], "title": "[\u8bba\u6587\u5206\u4eab]Nature 2025 \u53d1\u73b0\u6700\u5148\u8fdb\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7b97\u6cd5", "comment": "Source: WeChat, Published: 2025-12-17 08:36:16", "summary": "\u5728\u8fd9\u4e2a\u6982\u5ff5\u4e0a\uff0c\u53ef\u4ee5\u628a\u5f3a\u5316\u5b66\u4e60\u7684\u7ec4\u4ef6\u5206\u4e3a\u4e09\u4e2a\u5143\u5b66\u4e60\u7684\u5bf9\u8c61\uff1a\u2460\u5b66\u4e60\u7b97\u6cd5\uff1a\u5b66\u4e60\u5982\u4f55\u66f4\u65b0\u7b56\u7565\uff0c\u6bd4\u5982\u68af\u5ea6\u66f4\u65b0\u89c4\u5219\u3001\u635f\u5931\u51fd\u6570\u7b49\u7b49-\u5143\u5b66\u4e60\u4f18\u5316\u5668\uff1b", "AI": {"tldr": "\u5728\u8fd9\u4e2a\u6982\u5ff5\u4e0a\uff0c\u53ef\u4ee5\u628a\u5f3a\u5316\u5b66\u4e60\u7684\u7ec4\u4ef6\u5206\u4e3a\u4e09\u4e2a\u5143\u5b66\u4e60\u7684\u5bf9\u8c61\uff1a\u2460\u5b66\u4e60\u7b97\u6cd5\uff1a\u5b66\u4e60\u5982\u4f55\u66f4\u65b0\u7b56\u7565\uff0c\u6bd4\u5982\u68af\u5ea6\u66f4\u65b0\u89c4\u5219\u3001\u635f\u5931\u51fd\u6570\u7b49\u7b49-\u5143\u5b66\u4e60\u4f18\u5316\u5668\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.0cea68df", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0Nzg0MjM1MA==&mid=2247484208&idx=1&sn=3fcd54aa21662f0d08220824ee972417&chksm=c2f12e6c4049e2ff6d725eae552017e8335f08220e451a3515f1b133d5cfec59abd6d03e7659#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0Nzg0MjM1MA==&mid=2247484208&idx=1&sn=3fcd54aa21662f0d08220824ee972417&chksm=c2f12e6c4049e2ff6d725eae552017e8335f08220e451a3515f1b133d5cfec59abd6d03e7659#rd", "authors": ["\u667a\u80fd\u8ff7\u8def"], "title": "\u3010Nature 2025\u3011\u8c37\u6b4c\u91cd\u78c5\u53d1\u5e03DiscoRL \uff1a\u8ba9 AI \u81ea\u4e3b\u201c\u53d1\u660e\u201d<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7b97\u6cd5\uff0c\u6027\u80fd\u6a2a\u626b\u4eba\u7c7b\u8bbe\u8ba1", "comment": "Source: WeChat, Published: 2025-12-17 06:08:47", "summary": "\u5728\u4eba\u5de5\u667a\u80fd\u7684\u957f\u6cb3\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7b97\u6cd5\u5982\u540c\u4e00\u628a\u5f00\u542f\u667a\u80fd\u4e4b\u95e8\u7684\u94a5\u5319 \u3002\u4ece\u6218\u80dc\u56f4\u68cb\u51a0\u519b\u7684 AlphaGo \u5230\u638c\u63a7\u590d\u6742\u7269\u7406\u7cfb\u7edf\u7684\u673a\u5668\u4eba\uff0c\u8fd9\u4e9b\u8f89\u714c\u6210\u5c31\u7684\u80cc\u540e\uff0c\u901a\u5e38\u662f\u4eba\u7c7b\u79d1\u5b66\u5bb6\u82b1\u8d39\u6570\u5341\u5e74\u5fc3\u8840\u3001\u57fa\u4e8e\u76f4\u89c9\u548c\u7ecf\u9a8c\u624b\u5de5\u8bbe\u8ba1\u7684\u5b66\u4e60\u89c4\u5219", "AI": {"tldr": "\u5728\u4eba\u5de5\u667a\u80fd\u7684\u957f\u6cb3\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7b97\u6cd5\u5982\u540c\u4e00\u628a\u5f00\u542f\u667a\u80fd\u4e4b\u95e8\u7684\u94a5\u5319 \u3002\u4ece\u6218\u80dc\u56f4\u68cb\u51a0\u519b\u7684 AlphaGo \u5230\u638c\u63a7\u590d\u6742\u7269\u7406\u7cfb\u7edf\u7684\u673a\u5668\u4eba\uff0c\u8fd9\u4e9b\u8f89\u714c\u6210\u5c31\u7684\u80cc\u540e\uff0c\u901a\u5e38\u662f\u4eba\u7c7b\u79d1\u5b66\u5bb6\u82b1\u8d39\u6570\u5341\u5e74\u5fc3\u8840\u3001\u57fa\u4e8e\u76f4\u89c9\u548c\u7ecf\u9a8c\u624b\u5de5\u8bbe\u8ba1\u7684\u5b66\u4e60\u89c4\u5219", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.a0f35c2f", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxNTc4MTc1Ng==&mid=2649479929&idx=1&sn=054a49dae1473d491476366270b935c6&chksm=8298852dd73f348042b9d0a60e27f90cbcdd96c3709c2461e928b1d082d07d4c4c731910bca9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxNTc4MTc1Ng==&mid=2649479929&idx=1&sn=054a49dae1473d491476366270b935c6&chksm=8298852dd73f348042b9d0a60e27f90cbcdd96c3709c2461e928b1d082d07d4c4c731910bca9#rd", "authors": ["\u65b0\u673a\u5668\u89c6\u89c9"], "title": "18\u4e2a\u5e38\u7528\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7b97\u6cd5\u6574\u7406\uff1a\u4ece\u57fa\u7840\u65b9\u6cd5\u5230\u9ad8\u7ea7\u6a21\u578b\u7684\u7406\u8bba\u6280\u672f\u4e0e\u4ee3\u7801\u5b9e\u73b0", "comment": "Source: WeChat, Published: 2025-12-17 03:30:00", "summary": "\u672c\u6587\u7cfb\u7edf\u8bb2\u89e3\u4ece\u57fa\u672c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5230\u9ad8\u7ea7\u6280\u672f\uff08\u5982PPO\u3001A3C\u3001PlaNet\u7b49\uff09\u7684\u5b9e\u73b0\u539f\u7406\u4e0e\u7f16\u7801\u8fc7\u7a0b\uff0c\u65e8\u5728\u901a\u8fc7\u7406\u8bba\u7ed3\u5408\u4ee3\u7801\u7684\u65b9\u5f0f\uff0c\u6784\u5efa\u5bf9\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u5168\u9762\u7406\u89e3\u3002", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bb2\u89e3\u4ece\u57fa\u672c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5230\u9ad8\u7ea7\u6280\u672f\uff08\u5982PPO\u3001A3C\u3001PlaNet\u7b49\uff09\u7684\u5b9e\u73b0\u539f\u7406\u4e0e\u7f16\u7801\u8fc7\u7a0b\uff0c\u65e8\u5728\u901a\u8fc7\u7406\u8bba\u7ed3\u5408\u4ee3\u7801\u7684\u65b9\u5f0f\uff0c\u6784\u5efa\u5bf9\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u5168\u9762\u7406\u89e3\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.db7056c2", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYzNDQzMDMyMQ==&mid=2247483663&idx=1&sn=b7f4d1c2b9c91303e3f7d0a7f409da0c&chksm=f10abe339206b9e41e2436bba988945f899a0ba52ecdef72593ef1f563059c657c53a8e0a35c#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYzNDQzMDMyMQ==&mid=2247483663&idx=1&sn=b7f4d1c2b9c91303e3f7d0a7f409da0c&chksm=f10abe339206b9e41e2436bba988945f899a0ba52ecdef72593ef1f563059c657c53a8e0a35c#rd", "authors": ["\u9ad8\u79d1\u9500\u7814"], "title": "\u4ec0\u4e48\u662f <em class=\"highlight\">Agentic</em> Commerce\uff1f", "comment": "Source: WeChat, Published: 2025-12-17 13:21:49", "summary": "\u201cAgentic Commerce\u201d \u53ef\u4ee5\u7406\u89e3\u4e3a\u201c\u4ee3\u7406\u5f0f\u5546\u52a1\u201d\u6216\u201c\u667a\u80fd\u4f53\u4e3b\u5bfc\u7684\u5546\u4e1a\u201d\u3002\u5b83\u6307\u7684\u662f\u7531\u81ea\u4e3b\u6216\u534a\u81ea\u4e3b\u7684\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u6765\u4e3b\u5bfc\u3001\u6267\u884c\u548c\u4f18\u5316\u5546\u4e1a\u6d41\u7a0b\u4e0e\u6d88\u8d39\u8005\u4e92\u52a8\u7684\u4e00\u79cd\u65b0\u578b\u5546\u4e1a\u6a21\u5f0f\u3002", "AI": {"tldr": "\u201cAgentic Commerce\u201d \u53ef\u4ee5\u7406\u89e3\u4e3a\u201c\u4ee3\u7406\u5f0f\u5546\u52a1\u201d\u6216\u201c\u667a\u80fd\u4f53\u4e3b\u5bfc\u7684\u5546\u4e1a\u201d\u3002\u5b83\u6307\u7684\u662f\u7531\u81ea\u4e3b\u6216\u534a\u81ea\u4e3b\u7684\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u6765\u4e3b\u5bfc\u3001\u6267\u884c\u548c\u4f18\u5316\u5546\u4e1a\u6d41\u7a0b\u4e0e\u6d88\u8d39\u8005\u4e92\u52a8\u7684\u4e00\u79cd\u65b0\u578b\u5546\u4e1a\u6a21\u5f0f\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.f82cb1de", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&mid=2247601405&idx=1&sn=23f76a7fa343c18bd6f1b391397b84cd&chksm=cefa802a9e54ede1c4b580c2890443731926c4e2d7a7901b36cef647d6edfe084710cd98a41a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&mid=2247601405&idx=1&sn=23f76a7fa343c18bd6f1b391397b84cd&chksm=cefa802a9e54ede1c4b580c2890443731926c4e2d7a7901b36cef647d6edfe084710cd98a41a#rd", "authors": ["\u5b66\u672f\u5934\u6761"], "title": "\u97e9\u5bb6\u709c\u6559\u6388\u65b0\u4f5c\uff1a\u4e0b\u4e00\u4ee3<em class=\"highlight\">Agentic</em> AI\u5e94\u5982\u4f55\u201c\u9002\u914d\u201d\uff1f", "comment": "Source: WeChat, Published: 2025-12-17 08:06:23", "summary": "\u968f\u7740\u57fa\u7840\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0cAgentic AI \u8fc5\u901f\u5174\u8d77\uff0c\u5e76\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5728\u79d1\u7814\u3001\u8f6f\u4ef6\u5f00\u53d1\u3001\u836f\u7269\u7814\u53d1\u3001\u4e34\u5e8a\u7814\u7a76\u7b49\u5e7f\u6cdb\u9886\u57df\u3002\u7136\u800c\uff0c\u5de5\u5177\u4f7f\u7528\u4e0d\u7a33\u5b9a\u3001\u957f\u7a0b\u4efb\u52a1\u89c4\u5212\u80fd\u529b\u6709\u9650\u3001\u7279\u5b9a\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3001\u771f\u5b9e\u73af", "AI": {"tldr": "\u968f\u7740\u57fa\u7840\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0cAgentic AI \u8fc5\u901f\u5174\u8d77\uff0c\u5e76\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5728\u79d1\u7814\u3001\u8f6f\u4ef6\u5f00\u53d1\u3001\u836f\u7269\u7814\u53d1\u3001\u4e34\u5e8a\u7814\u7a76\u7b49\u5e7f\u6cdb\u9886\u57df\u3002\u7136\u800c\uff0c\u5de5\u5177\u4f7f\u7528\u4e0d\u7a33\u5b9a\u3001\u957f\u7a0b\u4efb\u52a1\u89c4\u5212\u80fd\u529b\u6709\u9650\u3001\u7279\u5b9a\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3001\u771f\u5b9e\u73af", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.cc460ea1", "categories": ["wechat.article", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIyNjAyNjA1Ng==&mid=2657873058&idx=2&sn=0aa2a133f886aa562efb3860cdb64c75&chksm=f212dd3531cd326b584dddd630e6388a8942a15fe7f2d0a9c899f2b8409ae7b1f08b994de635#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIyNjAyNjA1Ng==&mid=2657873058&idx=2&sn=0aa2a133f886aa562efb3860cdb64c75&chksm=f212dd3531cd326b584dddd630e6388a8942a15fe7f2d0a9c899f2b8409ae7b1f08b994de635#rd", "authors": ["\u5de5\u4e1a4\u4ff1\u4e50\u90e8"], "title": "\u4e9a\u9a6c\u900a | <em class=\"highlight\">Agentic</em>+AI\u5e94\u7528\u6784\u5efa\u5b9e\u8df5\u6307\u5357\uff08\u9644\u4e0b\u8f7d\uff09", "comment": "Source: WeChat, Published: 2025-12-17 01:28:16", "summary": "Agentic AI \u6e90\u4e8e AI Agent \u6280\u672f\uff0c\u7ecf LLM \u8d4b\u80fd\u5b9e\u73b0\u4ece\u9762\u5411\u8fc7\u7a0b\u5230\u9762\u5411\u76ee\u6807\u7684\u67b6\u6784\u8f6c\u578b\uff0c\u662f\u80fd\u81ea\u4e3b\u63a8\u7406\u3001\u89c4\u5212\u5e76\u5b8c\u6210\u4efb\u52a1\u7684\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u6838\u5fc3\u80fd\u529b\u5305\u62ec\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u63a8\u7406\u3001\u81ea\u4e3b\u89c4\u5212\u53ca\u5de5\u5177\u4f7f\u7528\uff0c\u5176\u8bb0\u5fc6\u673a\u5236\uff08\u77ed\u671f\u7ef4\u62a4\u4f1a\u8bdd\u4e0a\u4e0b\u6587\u3001\u957f\u671f\u4f9d", "AI": {"tldr": "Agentic AI \u6e90\u4e8e AI Agent \u6280\u672f\uff0c\u7ecf LLM \u8d4b\u80fd\u5b9e\u73b0\u4ece\u9762\u5411\u8fc7\u7a0b\u5230\u9762\u5411\u76ee\u6807\u7684\u67b6\u6784\u8f6c\u578b\uff0c\u662f\u80fd\u81ea\u4e3b\u63a8\u7406\u3001\u89c4\u5212\u5e76\u5b8c\u6210\u4efb\u52a1\u7684\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u6838\u5fc3\u80fd\u529b\u5305\u62ec\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u63a8\u7406\u3001\u81ea\u4e3b\u89c4\u5212\u53ca\u5de5\u5177\u4f7f\u7528\uff0c\u5176\u8bb0\u5fc6\u673a\u5236\uff08\u77ed\u671f\u7ef4\u62a4\u4f1a\u8bdd\u4e0a\u4e0b\u6587\u3001\u957f\u671f\u4f9d", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.3de6a02d", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5MDQ4MzU5NQ==&mid=2659209039&idx=1&sn=0f729652f3dd56e2f5d3a1a69ab61725&chksm=bcf215391e721a3b9a6fc8a239788d06331d86aadcf4b9dc4ae71501ff0b69174b29135a1b3d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5MDQ4MzU5NQ==&mid=2659209039&idx=1&sn=0f729652f3dd56e2f5d3a1a69ab61725&chksm=bcf215391e721a3b9a6fc8a239788d06331d86aadcf4b9dc4ae71501ff0b69174b29135a1b3d#rd", "authors": ["\u79d1\u6280\u7f8e\u5b66"], "title": "\u5c0f\u7c73\u53d1\u5e03\u6700\u65b0MiMo<em class=\"highlight\">\u5927\u6a21\u578b</em> \u5e03\u5c40\u77ed\u5267 SU7\u5c06\u6362\u4ee3", "comment": "Source: WeChat, Published: 2025-12-17 13:31:11", "summary": "\u53bb\u5e74\u5e74\u5e95\u6709\u6d88\u606f\u79f0\uff0c\u96f7\u519b\u66fe\u5e0c\u671b\u7528\u5343\u4e07\u5e74\u85aa\u6316\u89d2DeepSeek \u5f00\u6e90\u5927\u6a21\u578b DeepSeek-V2 \u7684\u5173\u952e\u5f00\u53d1\u8005\u4e4b\u4e00\u7f57\u798f\u8389\uff0c\u9080\u8bf7\u5979\u5230\u5c0f\u7c73\u5e26\u9886\u56e2\u961f\u4ece\u4e8bAI\u5927\u6a21\u578b\u7814\u7a76\u3002\u4e0a\u4e2a\u6708\uff0c\u6709\u6d88\u606f\u663e\u793a\uff0c\u7f57\u798f\u8389\u5728\u670b\u53cb\u5708\u5b98\u5ba3\u52a0\u5165\u5c0f\u7c73 Xiaomi MiMo \u5927\u6a21\u578b\u56e2\u961f\u3002\u636e\u4e86", "AI": {"tldr": "\u53bb\u5e74\u5e74\u5e95\u6709\u6d88\u606f\u79f0\uff0c\u96f7\u519b\u66fe\u5e0c\u671b\u7528\u5343\u4e07\u5e74\u85aa\u6316\u89d2DeepSeek \u5f00\u6e90\u5927\u6a21\u578b DeepSeek-V2 \u7684\u5173\u952e\u5f00\u53d1\u8005\u4e4b\u4e00\u7f57\u798f\u8389\uff0c\u9080\u8bf7\u5979\u5230\u5c0f\u7c73\u5e26\u9886\u56e2\u961f\u4ece\u4e8bAI\u5927\u6a21\u578b\u7814\u7a76\u3002\u4e0a\u4e2a\u6708\uff0c\u6709\u6d88\u606f\u663e\u793a\uff0c\u7f57\u798f\u8389\u5728\u670b\u53cb\u5708\u5b98\u5ba3\u52a0\u5165\u5c0f\u7c73 Xiaomi MiMo \u5927\u6a21\u578b\u56e2\u961f\u3002\u636e\u4e86", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.0b8ca4aa", "categories": ["wechat.article", "wechat.ai", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI3ODE5Mzc1Ng==&mid=2247511544&idx=1&sn=bca7db25525f75be23d8c44eec238ea1&chksm=ea78c0527ad088c104373826a6d7f12aa8b2714343d75e43d57b1891a3304f03713407d21f1f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI3ODE5Mzc1Ng==&mid=2247511544&idx=1&sn=bca7db25525f75be23d8c44eec238ea1&chksm=ea78c0527ad088c104373826a6d7f12aa8b2714343d75e43d57b1891a3304f03713407d21f1f#rd", "authors": ["\u77e5\u8bc6\u56fe\u8c31\u79d1\u6280"], "title": "<em class=\"highlight\">\u5927\u6a21\u578b</em>\u9a71\u52a8\u7684\u62a4\u7406\u667a\u80fd\u4f53\u5b9e\u8df5\uff1a\u667a\u80fd\u62a4\u7406\u65b0\u65f6\u4ee3\u7684\u5168\u9762\u6982\u8ff0", "comment": "Source: WeChat, Published: 2025-12-17 12:30:27", "summary": "\u4e3a\u6b64\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u4ee3\u7406\uff08LLMDAs\uff09\u5e94\u8fd0\u800c\u751f\u3002\u8fd9\u4e9b\u4ee3\u7406\u672c\u8d28\u4e0a\u662f\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u4ee5 LLM \u4f5c\u4e3a\u6838\u5fc3\u5f15\u64ce\uff0c\u8d1f\u8d23\u8bed\u4e49\u7406\u89e3\u3001\u903b\u8f91\u63a8\u7406\u548c\u4efb\u52a1\u5206\u89e3\uff0c\u4ece\u800c\u5f25\u8865\u4f20\u7edf\u4ee3\u7406\u7684\u4e0d\u8db3\u3002", "AI": {"tldr": "\u4e3a\u6b64\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u4ee3\u7406\uff08LLMDAs\uff09\u5e94\u8fd0\u800c\u751f\u3002\u8fd9\u4e9b\u4ee3\u7406\u672c\u8d28\u4e0a\u662f\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u4ee5 LLM \u4f5c\u4e3a\u6838\u5fc3\u5f15\u64ce\uff0c\u8d1f\u8d23\u8bed\u4e49\u7406\u89e3\u3001\u903b\u8f91\u63a8\u7406\u548c\u4efb\u52a1\u5206\u89e3\uff0c\u4ece\u800c\u5f25\u8865\u4f20\u7edf\u4ee3\u7406\u7684\u4e0d\u8db3\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.46e83387", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI3MDE2NzAxNA==&mid=2247491935&idx=1&sn=510ae221187f3e0cc55776ef9fe42edf&chksm=eb89f6a5ee89811adee8175f0489de197b17269f51a23f3f122a563e2e025dd8ee9ce6062bce#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI3MDE2NzAxNA==&mid=2247491935&idx=1&sn=510ae221187f3e0cc55776ef9fe42edf&chksm=eb89f6a5ee89811adee8175f0489de197b17269f51a23f3f122a563e2e025dd8ee9ce6062bce#rd", "authors": ["\u79d1\u6280\u95f2\u804a\u9986"], "title": "\u5929\u624d\u5c11\u5973\u9996\u79c0\uff0c\u5c0f\u7c73\u5f00\u6e90\u201c\u95ea\u7535\u201d<em class=\"highlight\">\u5927\u6a21\u578b</em>\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53472.6\u500d\uff01", "comment": "Source: WeChat, Published: 2025-12-17 12:28:06", "summary": "\u8fd9\u79cd\u201c\u6a21\u62df\u4e16\u754c\u201d\u7684\u80fd\u529b\uff0c\u6807\u5fd7\u7740\u5927\u6a21\u578b\u6b63\u4ece\u6587\u672c\u7406\u89e3\u5411\u7269\u7406\u4e16\u754c\u8ba4\u77e5\u8fc8\u8fdb\u3002\u53d1\u5e03\u4f1a\u7ed3\u675f\u540e\uff0c\u4f53\u9a8cWeb Demo\u8fc5\u901f\u4e0a\u7ebf\uff0c\u6a21\u578b\u6743\u91cd\u548c\u63a8\u7406\u4ee3\u7801\u5168\u9762\u5f00\u6e90\u3002", "AI": {"tldr": "\u8fd9\u79cd\u201c\u6a21\u62df\u4e16\u754c\u201d\u7684\u80fd\u529b\uff0c\u6807\u5fd7\u7740\u5927\u6a21\u578b\u6b63\u4ece\u6587\u672c\u7406\u89e3\u5411\u7269\u7406\u4e16\u754c\u8ba4\u77e5\u8fc8\u8fdb\u3002\u53d1\u5e03\u4f1a\u7ed3\u675f\u540e\uff0c\u4f53\u9a8cWeb Demo\u8fc5\u901f\u4e0a\u7ebf\uff0c\u6a21\u578b\u6743\u91cd\u548c\u63a8\u7406\u4ee3\u7801\u5168\u9762\u5f00\u6e90\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.ac46a859", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjExMTExNDA2MQ==&mid=2663157388&idx=7&sn=7090a0dab1582ba1040a124a0429c044&chksm=4f550a0f949389a403811a279a2fb738f5e8ed76d7ce77d08cb0ec66eb013b9e041286465d5d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjExMTExNDA2MQ==&mid=2663157388&idx=7&sn=7090a0dab1582ba1040a124a0429c044&chksm=4f550a0f949389a403811a279a2fb738f5e8ed76d7ce77d08cb0ec66eb013b9e041286465d5d#rd", "authors": ["19\u697c"], "title": "\u5c0f\u7c73\u53d1\u5e03\u6700\u65b0MiMo<em class=\"highlight\">\u5927\u6a21\u578b</em>\uff0c\u8d1f\u8d23\u4ebaAI\u201c\u5929\u624d\u5c11\u5973\u201d\u7f57\u798f\u8389\u9996\u79c0", "comment": "Source: WeChat, Published: 2025-12-17 11:51:13", "summary": "\u5f53\u65e5\u4e0a\u5348\uff0c\u5c0f\u7c73\u96c6\u56e2\u5408\u4f19\u4eba\u3001\u96c6\u56e2\u603b\u88c1\u5362\u4f1f\u51b0\u5ba3\u5e03\u5c0f\u7c73\u81ea\u7814AI\u5927\u6a21\u578bXiaomi MiMo-V2-Flash\u6b63\u5f0f\u5f00\u6e90\u4e0a\u7ebf\u3002\u636e\u5c0f\u7c73\u65b9\u9762\u4ecb\u7ecd\uff0cXiaomi MiMo-V2-Flash\u662f\u5c0f\u7c73\u81ea\u7814\u7684\u603b\u53c2\u6570309B\uff08\u6fc0\u6d3b15B\uff09\u7684MoE\u6a21\u578b\uff0c\u4ee3\u7801\u80fd\u529b\u6bd4\u80a9\u6807\u6746\u95ed\u6e90\u6a21\u578bClaude Sonnet 4.5\uff0c\u4f46\u63a8\u7406", "AI": {"tldr": "\u5f53\u65e5\u4e0a\u5348\uff0c\u5c0f\u7c73\u96c6\u56e2\u5408\u4f19\u4eba\u3001\u96c6\u56e2\u603b\u88c1\u5362\u4f1f\u51b0\u5ba3\u5e03\u5c0f\u7c73\u81ea\u7814AI\u5927\u6a21\u578bXiaomi MiMo-V2-Flash\u6b63\u5f0f\u5f00\u6e90\u4e0a\u7ebf\u3002\u636e\u5c0f\u7c73\u65b9\u9762\u4ecb\u7ecd\uff0cXiaomi MiMo-V2-Flash\u662f\u5c0f\u7c73\u81ea\u7814\u7684\u603b\u53c2\u6570309B\uff08\u6fc0\u6d3b15B\uff09\u7684MoE\u6a21\u578b\uff0c\u4ee3\u7801\u80fd\u529b\u6bd4\u80a9\u6807\u6746\u95ed\u6e90\u6a21\u578bClaude Sonnet 4.5\uff0c\u4f46\u63a8\u7406", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.dfc97423", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAwOTUzNTYxOQ==&mid=2680393982&idx=4&sn=5719d90c9f0090b8aed57ef84d3f9cc8&chksm=8014c504d1089db8a243b7d2c978284fa047d33a216f47a46df4f291a0e82fb34709b4ec40c8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAwOTUzNTYxOQ==&mid=2680393982&idx=4&sn=5719d90c9f0090b8aed57ef84d3f9cc8&chksm=8014c504d1089db8a243b7d2c978284fa047d33a216f47a46df4f291a0e82fb34709b4ec40c8#rd", "authors": ["\u5c0f\u767d\u6d4b\u8bc4"], "title": "\u3010\u524d\u6cbf\u3011\u5c0f\u7c73\u53d1\u5e03\u6700\u65b0MiMo<em class=\"highlight\">\u5927\u6a21\u578b</em>", "comment": "Source: WeChat, Published: 2025-12-17 11:22:45", "summary": "\u636e\u4ecb\u7ecd\uff0cXiaomi MiMo-V2-Flash\u5168\u65b0\u5f00\u6e90MoE\u6a21\u578b\uff0c\u603b\u53c2\u6570\u91cf309B\uff0c\u6d3b\u8dc3\u53c2\u6570\u91cf15B\uff0c\u4e13\u4e3a\u667a\u80fd\u4f53AI\u8bbe\u8ba1\uff0c\u4e13\u6ce8\u4e8e\u5feb\uff0c\u5b98\u65b9\u79f0\u5728\u901a\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u548cDeepSeek V3.2\u6027\u80fd\u76f8\u5f53\u4f46\u5ef6\u8fdf\u66f4\u4f4e\u3002", "AI": {"tldr": "\u636e\u4ecb\u7ecd\uff0cXiaomi MiMo-V2-Flash\u5168\u65b0\u5f00\u6e90MoE\u6a21\u578b\uff0c\u603b\u53c2\u6570\u91cf309B\uff0c\u6d3b\u8dc3\u53c2\u6570\u91cf15B\uff0c\u4e13\u4e3a\u667a\u80fd\u4f53AI\u8bbe\u8ba1\uff0c\u4e13\u6ce8\u4e8e\u5feb\uff0c\u5b98\u65b9\u79f0\u5728\u901a\u7528\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u548cDeepSeek V3.2\u6027\u80fd\u76f8\u5f53\u4f46\u5ef6\u8fdf\u66f4\u4f4e\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.99bfc0a9", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU0MjE3MzA4Nw==&mid=2247486545&idx=1&sn=ac309eebf95dc721bf894d4709563404&chksm=fae9e8980e2451f79d4058ede7824a60b0ac27c23f381f02d19a5a56f357c35c9ccc42cfb7dc#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU0MjE3MzA4Nw==&mid=2247486545&idx=1&sn=ac309eebf95dc721bf894d4709563404&chksm=fae9e8980e2451f79d4058ede7824a60b0ac27c23f381f02d19a5a56f357c35c9ccc42cfb7dc#rd", "authors": ["\u79d1\u6280\u5708\u89c2\u5bdf"], "title": "\u5c0f\u7c73<em class=\"highlight\">\u5927\u6a21\u578b</em>MiMo-V2-Flash\u80cc\u540e\uff0c\u5c0f\u7c73\u771f\u6b63\u7684AI\u91ce\u5fc3", "comment": "Source: WeChat, Published: 2025-12-17 11:03:23", "summary": "AI\u5927\u6a21\u578b\uff0c\u5c0f\u7c73\u665a\u5230\u4f46\u6ca1\u6709\u7f3a\u5e2d\uff0c\u5c0f\u7c73\u7684\u5927\u6a21\u578b\u7ec8\u4e8e\u6765\u4e86\u3002\u65e5\u524d\u5c0f\u7c73\u7684\u5927\u6a21\u578bMiMo-V2-Flash\u6b63\u5f0f\u53d1\u5e03\u4e86\uff0c\u603b\u53c2\u6570\u91cf3090\u4ebf\uff0c\u6d3b\u8dc3\u53c2\u6570150\u4ebf\uff0c\u4f7f\u7528\u7684\u662fMoE\uff08\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff09\u67b6\u6784\uff0c\u5728\u591a\u4e2a\u7efc\u5408AI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMiMo-V2-Flash\u4e0eDeepSeek V3.2\u7684\u8868\u73b0\u975e", "AI": {"tldr": "AI\u5927\u6a21\u578b\uff0c\u5c0f\u7c73\u665a\u5230\u4f46\u6ca1\u6709\u7f3a\u5e2d\uff0c\u5c0f\u7c73\u7684\u5927\u6a21\u578b\u7ec8\u4e8e\u6765\u4e86\u3002\u65e5\u524d\u5c0f\u7c73\u7684\u5927\u6a21\u578bMiMo-V2-Flash\u6b63\u5f0f\u53d1\u5e03\u4e86\uff0c\u603b\u53c2\u6570\u91cf3090\u4ebf\uff0c\u6d3b\u8dc3\u53c2\u6570150\u4ebf\uff0c\u4f7f\u7528\u7684\u662fMoE\uff08\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\uff09\u67b6\u6784\uff0c\u5728\u591a\u4e2a\u7efc\u5408AI\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMiMo-V2-Flash\u4e0eDeepSeek V3.2\u7684\u8868\u73b0\u975e", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.26640053", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0MDg1MjIwNg==&mid=2247530443&idx=1&sn=eb009243f94d33ab3ab4b690d57e9d77&chksm=c346f274432a6ced74f8bd2456226d38cd243a6f7f8e9774bdd0e843f2ccfb79d6b8bfde69fc#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0MDg1MjIwNg==&mid=2247530443&idx=1&sn=eb009243f94d33ab3ab4b690d57e9d77&chksm=c346f274432a6ced74f8bd2456226d38cd243a6f7f8e9774bdd0e843f2ccfb79d6b8bfde69fc#rd", "authors": ["OpenMMLab"], "title": "<em class=\"highlight\">\u5927\u6a21\u578b</em>\u8bc4\u6d4b\u57fa\u51c6\u6280\u672f\u89e3\u6790\u4e28AI Insight Talk \u76f4\u64ad\u9884\u544a", "comment": "Source: WeChat, Published: 2025-12-17 10:25:11", "summary": "\u591a\u6a21\u6001\u5927\u6a21\u578b\u6b63\u5728\u4ece\u56fe\u50cf\u3001\u89c6\u9891\u548c\u8bed\u97f3\u7684\u5355\u6a21\u6001\u7406\u89e3\u6a21\u578b\u548c\u751f\u6210\u6a21\u578b\uff0c\u9010\u6e10\u6f14\u8fdb\u4e3a\u5168\u6a21\u6001\u7684\u7406\u89e3\u548c\u751f\u6210\u7edf\u4e00\u6a21\u578b\u3002\u7136\u800c\uff0c\u80fd\u591f\u8fbe\u5230\u7406\u60f3\u6001\u4e2d\uff0c\u4e0d\u540c\u6a21\u6001\u95f4\u7684\u534f\u540c\u4fc3\u8fdb\u3001\u751f\u6210\u548c\u7406\u89e3\u4e92\u76f8\u589e\u5f3a\u7684\u6280\u672f\u8def\u7ebf\u591a\u6837\uff0c\u5c1a\u672a\u6536\u655b\u3002", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u6a21\u578b\u6b63\u5728\u4ece\u56fe\u50cf\u3001\u89c6\u9891\u548c\u8bed\u97f3\u7684\u5355\u6a21\u6001\u7406\u89e3\u6a21\u578b\u548c\u751f\u6210\u6a21\u578b\uff0c\u9010\u6e10\u6f14\u8fdb\u4e3a\u5168\u6a21\u6001\u7684\u7406\u89e3\u548c\u751f\u6210\u7edf\u4e00\u6a21\u578b\u3002\u7136\u800c\uff0c\u80fd\u591f\u8fbe\u5230\u7406\u60f3\u6001\u4e2d\uff0c\u4e0d\u540c\u6a21\u6001\u95f4\u7684\u534f\u540c\u4fc3\u8fdb\u3001\u751f\u6210\u548c\u7406\u89e3\u4e92\u76f8\u589e\u5f3a\u7684\u6280\u672f\u8def\u7ebf\u591a\u6837\uff0c\u5c1a\u672a\u6536\u655b\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.84a63460", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MTE3MzE4MTAyMQ==&mid=2651411702&idx=1&sn=6cb9f86b107d70473c883a2728fef285&chksm=772bbfd2f77216d2fa4f4dfac90ed02f1ff7966f639d34e9c16ee791606059f2cec2a2c1c75f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MTE3MzE4MTAyMQ==&mid=2651411702&idx=1&sn=6cb9f86b107d70473c883a2728fef285&chksm=772bbfd2f77216d2fa4f4dfac90ed02f1ff7966f639d34e9c16ee791606059f2cec2a2c1c75f#rd", "authors": ["TechWeb"], "title": "\u5c0f\u7c73\u53d1\u5e03\u6700\u65b0<em class=\"highlight\">\u5927\u6a21\u578b</em>\uff01", "comment": "Source: WeChat, Published: 2025-12-17 10:15:59", "summary": "\u5927\u4f1a\u524d\u5915\uff0c\u4e13\u4e3a\u6781\u81f4\u63a8\u7406\u6548\u7387\u81ea\u7814\u7684\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u5927\u8bed\u8a00\u6a21\u578bXiaomi MiMo-V2-Flash\u5ba3\u5e03\u6b63\u5f0f\u5f00\u6e90\uff0c\u51ed\u501f\u5176\u5f3a\u5927\u7684\u4ee3\u7801\u4e0eAgent\u80fd\u529b\u3001\u6781\u5feb\u7684\u751f\u6210\u901f\u5ea6\u548c\u4f4e\u5ec9\u7684\u63a8\u7406\u6210\u672c\uff0c\u5728\u591a\u4e2aAgent\u6d4b\u8bc4\u57fa\u51c6\u4e0a\u8dfb\u8eab\u201c\u5168\u7403\u5f00\u6e90\u6a21\u578bTOP2\u201d\u3002", "AI": {"tldr": "\u5927\u4f1a\u524d\u5915\uff0c\u4e13\u4e3a\u6781\u81f4\u63a8\u7406\u6548\u7387\u81ea\u7814\u7684\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u5927\u8bed\u8a00\u6a21\u578bXiaomi MiMo-V2-Flash\u5ba3\u5e03\u6b63\u5f0f\u5f00\u6e90\uff0c\u51ed\u501f\u5176\u5f3a\u5927\u7684\u4ee3\u7801\u4e0eAgent\u80fd\u529b\u3001\u6781\u5feb\u7684\u751f\u6210\u901f\u5ea6\u548c\u4f4e\u5ec9\u7684\u63a8\u7406\u6210\u672c\uff0c\u5728\u591a\u4e2aAgent\u6d4b\u8bc4\u57fa\u51c6\u4e0a\u8dfb\u8eab\u201c\u5168\u7403\u5f00\u6e90\u6a21\u578bTOP2\u201d\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.5a4a3a65", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4NDQwNTI0OQ==&mid=2247588532&idx=1&sn=72c249b4fa628deacd7d84587eb6e477&chksm=ce80ab03b7ed5c9b660cab4617d51e68dd6965679d6f13cd3e1dfbfe69f09f4d173e5f3751e2#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4NDQwNTI0OQ==&mid=2247588532&idx=1&sn=72c249b4fa628deacd7d84587eb6e477&chksm=ce80ab03b7ed5c9b660cab4617d51e68dd6965679d6f13cd3e1dfbfe69f09f4d173e5f3751e2#rd", "authors": ["AI\u79d1\u6280\u5927\u672c\u8425"], "title": "\u5b98\u5ba3\uff01\u524d OpenAI \u534e\u4eba\u79d1\u5b66\u5bb6\u59da\u987a\u96e8\u52a0\u5165\u817e\u8baf\uff0c<em class=\"highlight\">\u5927\u6a21\u578b</em>\u201c\u7cfb\u7edf\u6218\u201d\u5f00\u542f\uff01", "comment": "Source: WeChat, Published: 2025-12-17 09:35:41", "summary": "AI Data \u90e8\uff1a\u7531\u5218\u715c\u5b8f\u8d1f\u8d23\uff0c\u4e13\u6ce8\u4e8e\u5927\u6a21\u578b\u6570\u636e\u53ca\u8bc4\u6d4b\u4f53\u7cfb\u5efa\u8bbe\u3002\u6570\u636e\u8ba1\u7b97\u5e73\u53f0\u90e8\uff1a\u7531\u9648\u9e4f\u8d1f\u8d23\uff0c\u81f4\u529b\u4e8e\u5927\u6570\u636e\u548c\u673a\u5668\u5b66\u4e60\u7684\u6570\u636e\u667a\u80fd\u878d\u5408\u5e73\u53f0\u5efa\u8bbe\u3002\u6ce8\uff1a\u5218\u715c\u5b8f\u4e0e\u9648\u9e4f\u5747\u5411\u516c\u53f8\u526f\u603b\u88c1\u848b\u6770\u6c47\u62a5\uff1b", "AI": {"tldr": "AI Data \u90e8\uff1a\u7531\u5218\u715c\u5b8f\u8d1f\u8d23\uff0c\u4e13\u6ce8\u4e8e\u5927\u6a21\u578b\u6570\u636e\u53ca\u8bc4\u6d4b\u4f53\u7cfb\u5efa\u8bbe\u3002\u6570\u636e\u8ba1\u7b97\u5e73\u53f0\u90e8\uff1a\u7531\u9648\u9e4f\u8d1f\u8d23\uff0c\u81f4\u529b\u4e8e\u5927\u6570\u636e\u548c\u673a\u5668\u5b66\u4e60\u7684\u6570\u636e\u667a\u80fd\u878d\u5408\u5e73\u53f0\u5efa\u8bbe\u3002\u6ce8\uff1a\u5218\u715c\u5b8f\u4e0e\u9648\u9e4f\u5747\u5411\u516c\u53f8\u526f\u603b\u88c1\u848b\u6770\u6c47\u62a5\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.b222f8d6", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIyODgwMDY3MQ==&mid=2247610447&idx=7&sn=4638a3605550ea865128f72d46304e3a&chksm=e90f3f64a8450710e34a3a21108472557bbd41a43d42388486d95660923f851c90da645ea06d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIyODgwMDY3MQ==&mid=2247610447&idx=7&sn=4638a3605550ea865128f72d46304e3a&chksm=e90f3f64a8450710e34a3a21108472557bbd41a43d42388486d95660923f851c90da645ea06d#rd", "authors": ["\u6ce1\u6ce1\u7f51PCPOP"], "title": "\u5c0f\u7c73\u5168\u65b0<em class=\"highlight\">\u5927\u6a21\u578b</em>\u53d1\u5e03\uff0c\u901f\u5ea6\u6bd4DeepSeek\u3001\u8c46\u5305\u66f4\u5feb", "comment": "Source: WeChat, Published: 2025-12-17 09:13:28", "summary": "\u5df2\u6210\u529f\u8dfb\u8eab\u5f53\u524d\u5f00\u6e90\u5927\u6a21\u578b\u7b2c \u4e00\u68af\u961f\u3002\u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u8be5\u6a21\u578b\u7684\u6743\u91cd\u4e0e\u63a8\u7406\u4ee3\u7801\u5747\u91c7\u7528MIT\u534f\u8bae\u5168\u9762\u5f00\u6e90\uff0c\u4e3a\u5f00\u53d1\u8005\u793e\u533a\u63d0\u4f9b\u4e86\u5145\u8db3\u7684\u63a2\u7d22\u7a7a\u95f4\u3002\u6210\u672c\u65b9\u9762\uff0cMiMo-V2-Flash\u4e5f\u5c55\u73b0\u51fa\u6781\u9ad8\u7684\u6027\u4ef7\u6bd4\uff0c\u5176API\u5b9a\u4ef7\u4e3a\u6bcf\u767e\u4e07\u8f93\u5165Token 0.1\u7f8e\u5143\u3001", "AI": {"tldr": "\u5df2\u6210\u529f\u8dfb\u8eab\u5f53\u524d\u5f00\u6e90\u5927\u6a21\u578b\u7b2c \u4e00\u68af\u961f\u3002\u503c\u5f97\u4e00\u63d0\u7684\u662f\uff0c\u8be5\u6a21\u578b\u7684\u6743\u91cd\u4e0e\u63a8\u7406\u4ee3\u7801\u5747\u91c7\u7528MIT\u534f\u8bae\u5168\u9762\u5f00\u6e90\uff0c\u4e3a\u5f00\u53d1\u8005\u793e\u533a\u63d0\u4f9b\u4e86\u5145\u8db3\u7684\u63a2\u7d22\u7a7a\u95f4\u3002\u6210\u672c\u65b9\u9762\uff0cMiMo-V2-Flash\u4e5f\u5c55\u73b0\u51fa\u6781\u9ad8\u7684\u6027\u4ef7\u6bd4\uff0c\u5176API\u5b9a\u4ef7\u4e3a\u6bcf\u767e\u4e07\u8f93\u5165Token 0.1\u7f8e\u5143\u3001", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
