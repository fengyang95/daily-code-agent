<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 9]
- [cs.LG](#cs.LG) [Total: 6]
- [wechat.article](#wechat.article) [Total: 32]
- [tldr.article](#tldr.article) [Total: 16]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.SE](#cs.SE) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 该论文提出将指令层次结构解析重构为推理任务，通过构建VerIH数据集和轻量级强化学习训练，使LLM能够优先处理系统指令而非用户指令，从而提高模型可靠性和抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在现实决策中承担重要角色，需要处理来自多个来源的竞争性指令。建立指令层次结构对于LLM的可靠性和可控性至关重要。

Method: 将指令层次解析重构为推理任务，构建VerIH数据集（包含对齐和冲突的系统-用户指令），使用轻量级强化学习训练模型优先处理系统指令。

Result: 微调后的模型在指令遵循和指令层次基准测试中表现一致提升，推理能力泛化到安全关键场景，增强了对抗越狱和提示注入攻击的鲁棒性。

Conclusion: 通过指令层次推理为构建可靠LLM提供了实用路径，系统提示的更新能够实现可控且稳健的模型行为变化。

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [2] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: UA-Code-Bench是一个用于评估语言模型在乌克兰语中代码生成和竞争编程问题解决能力的新基准，包含500个不同难度的问题，测试显示即使是顶级模型也只能解决一半问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准大多关注从英语翻译的广泛任务或仅评估简单语言理解，缺乏对低资源语言中代码生成能力的全面评估。

Method: 使用Eolymp平台的500个问题，分布在5个难度级别，通过13个领先的专有和开源模型生成Python解决方案，使用一次性提示，在专用环境中通过隐藏测试评估代码正确性。

Result: 结果显示即使是OpenAI o3和GPT-5等顶级模型也只能解决一半问题，突显了低资源自然语言中代码生成的挑战。

Conclusion: 这项工作证明了竞争编程基准在评估大型语言模型方面的价值，特别是在代表性不足的语言中，为多语言代码生成和推理增强模型的未来研究铺平了道路。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [3] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 本文通过29位专家对445个LLM基准测试的系统性审查，发现现有基准在现象测量、任务设计和评分指标方面存在有效性不足的问题，并提出了8项改进建议。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型对于评估其能力和识别部署前的安全或鲁棒性问题至关重要，但可靠测量抽象复杂现象需要强大的构念效度。

Method: 由29位专家评审员对自然语言处理和机器学习顶级会议中的445个LLM基准进行系统性审查，分析测量现象、任务和评分指标的模式。

Result: 发现现有基准在现象测量、任务设计和评分指标方面存在削弱结果声明有效性的模式。

Conclusion: 为研究人员和从业者提供了8项关键建议和详细可操作的指导，以改进LLM基准的开发。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [4] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 本文挑战了先前关于LLM训练样本影响力估计的研究结论，提出中间注意力层比嵌入层更适合计算影响力，并开发了新的评估指标NDR。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型训练样本影响力估计方法由于计算限制通常只使用部分层，先前研究认为嵌入层最适合，但本文发现这种基于抵消效应的假设不可靠。

Method: 通过理论和实证证据分析抵消效应的不可靠性，提出中间注意力层作为更好的影响力估计器，开发了排名和投票等替代标准平均的聚合方法，并提出新的评估指标NDR。

Result: 实验表明中间层在影响力估计上表现更好，新的聚合方法和NDR指标相比抵消效应具有更强的预测能力，推翻了"首层优于末层"的先前认知。

Conclusion: LLM影响力估计中，中间注意力层比嵌入层更有效，标准平均方法不是最优选择，NDR是比抵消效应更好的评估指标。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [5] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim,Jun Li,Ana Beatriz Solana,Carolin M. Pirkl,Benedikt Wiestler,Julia A. Schnabel,Cosmin I. Bercea*

Main category: cs.CL

TL;DR: RADAR是一个基于检索增强诊断推理的智能体系统，用于脑部MRI中的罕见疾病检测，通过检索外部医学知识来指导诊断决策，无需额外训练即可提升罕见病理识别能力。


<details>
  <summary>Details</summary>
Motivation: 罕见疾病在医学影像中数据稀缺，导致AI模型表现不佳。受放射科医生查阅病例报告和文献的临床工作流程启发，开发能够检索相关知识来辅助诊断的系统。

Method: 使用AI智能体访问外部医学知识，通过句子转换器嵌入病例报告和文献，并用FAISS建立索引实现高效相似性搜索，检索临床相关证据来指导诊断决策。

Result: 在包含280种不同罕见疾病的NOVA数据集上，RADAR实现了高达10.2%的性能提升，开源模型如DeepSeek表现提升最为显著。

Conclusion: 检索增强推理是医学影像中低流行度条件的强大范例，检索到的示例提供可解释的、基于文献的解释。

Abstract: Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [6] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 研究发现基础LLMs在语义校准方面表现良好，能够有意义地评估开放域问答任务的置信度，尽管没有经过专门训练。理论揭示了语义校准作为下一个token预测副产品的机制，并发现RL指令微调和思维链推理会破坏这种校准。


<details>
  <summary>Details</summary>
Motivation: LLMs通常缺乏对其输出的有意义的置信度估计。虽然基础LLMs已知具有下一个token校准能力，但尚不清楚它们是否能在token级别之外评估其响应的实际含义的置信度。

Method: 使用基于采样的语义校准概念，建立B-校准的理论框架，该框架通过等价类参数化校准概念。理论基于校准与局部损失最优性之间的连接。

Result: 基础LLMs在问答任务中表现出语义校准能力；RL指令微调会系统性破坏这种校准；思维链推理也会破坏校准。

Conclusion: 基础LLMs能够自然产生语义校准，这是下一个token预测的副产品。RL指令微调和思维链推理会破坏这种内在的校准能力。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [7] [AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent](https://arxiv.org/abs/2511.04921)
*Yu Li,Lehui Li,Qingmin Liao,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 提出了一个基于集体感知的基准和数据集推荐框架，通过自动化数据收集、增强检索器和推理重排器，显著提升了AI实验中数据集和基准推荐的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在数据覆盖不足和过度依赖内容相似性的问题，导致推荐偏向表面相似性而忽略实验适用性。

Method: 1) 自动化数据收集管道链接论文与使用的基准和数据集；2) 集体感知增强检索器结合自描述和聚合引用上下文；3) 推理增强重排器构建显式推理链并生成可解释的推荐理由。

Result: 构建的数据集覆盖了过去五年顶级AI会议中85%使用的数据集和基准，在Recall@20和HitRate@5指标上分别比最强基线提升5.85%和8.30%。

Conclusion: 该方法推进了实验设计的可靠、可解释自动化。

Abstract: Large language model agents are becoming increasingly capable at web-centric
tasks such as information retrieval, complex reasoning. These emerging
capabilities have given rise to surge research interests in developing LLM
agent for facilitating scientific quest. One key application in AI research is
to automate experiment design through agentic dataset and baseline retrieval.
However, prior efforts suffer from limited data coverage, as recommendation
datasets primarily harvest candidates from public portals and omit many
datasets actually used in published papers, and from an overreliance on content
similarity that biases model toward superficial similarity and overlooks
experimental suitability. Harnessing collective perception embedded in the
baseline and dataset citation network, we present a comprehensive framework for
baseline and dataset recommendation. First, we design an automated
data-collection pipeline that links roughly one hundred thousand accepted
papers to the baselines and datasets they actually used. Second, we propose a
collective perception enhanced retriever. To represent the position of each
dataset or baseline within the scholarly network, it concatenates
self-descriptions with aggregated citation contexts. To achieve efficient
candidate recall, we finetune an embedding model on these representations.
Finally, we develop a reasoning-augmented reranker that exact interaction
chains to construct explicit reasoning chains and finetunes a large language
model to produce interpretable justifications and refined rankings. The dataset
we curated covers 85\% of the datasets and baselines used at top AI conferences
over the past five years. On our dataset, the proposed method outperforms the
strongest prior baseline with average gains of +5.85\% in Recall@20, +8.30\% in
HitRate@5. Taken together, our results advance reliable, interpretable
automation of experimental design.

</details>


### [8] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney,Makesh Narsimhan Sreedhar,Liwei Jiang,Traian Rebedea,Christopher Parisien*

Main category: cs.CL

TL;DR: 提出了PBSUITE评估套件，用于系统评估LLM在多轮交互对话中遵守多元化对齐规范的能力，发现现有模型在单轮设置中表现良好，但在多轮对抗性交互中合规性大幅下降。


<details>
  <summary>Details</summary>
Motivation: 现实世界的LLM应用发生在具有独特企业政策、监管要求和使用案例的组织生态系统中，需要评估LLM适应多元化用户价值观和需求的多元化对齐能力。

Method: 开发了PBSUITE评估套件，包含基于30个行业的300个现实LLM行为策略数据集，以及用于在对抗条件下压力测试模型合规性的动态评估框架。

Result: 领先的开源和闭源LLM在单轮设置中保持强大的行为策略遵守（失败率低于4%），但在多轮对抗性交互中合规性显著减弱（失败率高达84%）。

Conclusion: 现有的模型对齐和安全调节方法在现实世界LLM交互中连贯执行多元化行为策略方面存在不足，需要开发更稳健和上下文感知的多元化对齐技术。

Abstract: Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [9] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 本文发现不同语言模型在上下文聚合模式上存在共性，提出了基于注意力展开的Order-Level Attention(OLA)概念，并开发了无需训练的跨模型适配器TOA，能够有效提升未见过的语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索不同语言模型在上下文聚合模式上的共性，这有助于加深对语言模型的理解并促进跨模型知识迁移。

Method: 引入基于注意力展开的Order-Level Attention(OLA)，发现不同语言模型的相同阶数OLA具有显著相似性，并提出了以OLA作为统一句法特征表示的Transferable OLA Adapter(TOA)方法。

Result: 实验证明TOA的跨语言模型泛化能力能够有效提升未见过的语言模型的性能。

Conclusion: 不同语言模型在上下文聚合模式上存在共性，基于OLA的TOA方法能够实现无需参数更新的跨模型知识迁移。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [10] [Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity](https://arxiv.org/abs/2511.04686)
*Pratik Poudel*

Main category: cs.LG

TL;DR: 该论文研究了在大语言模型多轮对话中KV缓存管理策略与模型架构限制（如位置编码完整性）的相互作用，发现当累积KV缓存接近或超过模型训练上下文窗口时，生成质量会急剧下降，且常见驱逐策略可能因破坏位置一致性而恶化性能。


<details>
  <summary>Details</summary>
Motivation: 解决在状态化多轮场景中KV缓存无界增长带来的挑战，特别是关注位置编码完整性这一常被忽视的因素。

Method: 使用状态化基准测试框架进行实证分析，比较不同KV缓存驱逐策略（包括高保留率策略和保持连续上下文的简单策略）对生成质量的影响。

Result: 当累积KV缓存接近或超过模型训练上下文窗口时，LLM生成质量急剧下降；常见驱逐策略（即使是高保留率策略）可能因破坏位置一致性而恶化性能；保持连续上下文块的简单策略能产生更一致的生成结果。

Conclusion: 需要采用尊重架构限制、保持位置结构并超越单纯缓存大小的"缓存健康"整体视角的驱逐技术。

Abstract: The Key-Value (KV) cache is integral to efficient autoregressive inference in
large language models (LLMs), yet its unbounded growth in stateful multi-turn
scenarios presents major challenges. This paper examines the interplay between
KV cache management strategies, the architectural context limits of models like
meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of
positional encodings. Through empirical analysis using a stateful benchmarking
framework, we show that LLM generation quality degrades sharply when the
accumulated KV cache approaches or exceeds the model's trained context window
(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory
exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via
AttentionTop), can worsen performance if they disrupt positional coherence.
Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a
cache by removing non-contiguous tokens can scramble these signals and lead to
degenerative outputs. We further show that simple strategies preserving
contiguous context blocks (e.g., keeping an initial "gist") can yield more
coherent generations than complex or positionally disruptive ones. We advocate
for eviction techniques that respect architectural limits, preserve positional
structure, and view "cache health" holistically beyond mere size.

</details>


### [11] [Grounded Test-Time Adaptation for LLM Agents](https://arxiv.org/abs/2511.04847)
*Arthur Chen,Zuxin Liu,Jianguo Zhang,Akshara Prabhakar,Zhiwei Liu,Shelby Heinecke,Silvio Savarese,Victor Zhong,Caiming Xiong*

Main category: cs.LG

TL;DR: 该论文提出了两种互补策略来解决LLM智能体在新环境中的泛化问题：在线分布适应方法学习轻量级适应向量来对齐环境响应格式，部署时动态基础方法通过探索阶段学习环境的因果动态。


<details>
  <summary>Details</summary>
Motivation: LLM智能体在陌生复杂环境（如未见过的网站或新函数集）中泛化能力差，主要因为预训练与测试条件不匹配，存在语法误解和语义误解两种失败模式。

Method: 提出两种策略：1) 在线分布适应方法学习环境特定的适应向量；2) 部署时动态基础方法通过角色驱动探索阶段系统性地探测和学习环境动态。

Result: 在函数调用和网页导航等基准测试中，两种策略都有效且计算成本低。动态基础方法在复杂环境中特别有效，如在WebArena多站点分割上将成功率从2%提升到23%。

Conclusion: 这些方法为构建更通用和强大的LLM智能体提供了稳健路径，特别是动态基础方法在处理不可预测动态的复杂环境中表现突出。

Abstract: Large language model (LLM)-based agents struggle to generalize to novel and
complex environments, such as unseen websites or new sets of functions, due to
a fundamental mismatch between their pre-training and test-time conditions.
This challenge stems from two distinct failure modes: a syntactic
misunderstanding of environment-specific components like observation formats,
and a semantic misunderstanding of state-transition dynamics, which are only
revealed at test time. To address these issues, we propose two distinct and
complementary strategies for adapting LLM agents by leveraging
environment-specific information available during deployment. First, an online
distributional adaptation method parameterizes environmental nuances by
learning a lightweight adaptation vector that biases the model's output
distribution, enabling rapid alignment with an environment response format.
Second, a deployment-time dynamics grounding method employs a persona-driven
exploration phase to systematically probe and learn the environment's causal
dynamics before task execution, equipping the agent with a nonparametric world
model. We evaluate these strategies across diverse agentic benchmarks,
including function calling and web navigation. Our empirical results show the
effectiveness of both strategies across all benchmarks with minimal
computational cost. We find that dynamics grounding is particularly effective
in complex environments where unpredictable dynamics pose a major obstacle,
demonstrating a robust path toward more generalizable and capable LLM-based
agents. For example, on the WebArena multi-site split, this method increases
the agent's success rate from 2% to 23%.

</details>


### [12] [You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models](https://arxiv.org/abs/2511.04902)
*Shuvendu Roy,Hossein Hajimirsadeghi,Mengyao Zhai,Golnoosh Samei*

Main category: cs.LG

TL;DR: 本文系统研究了无标签强化学习方法在不同规模模型（0.5B-7B参数）上的表现，发现该方法严重依赖基础模型的推理能力，对较弱模型效果不佳。作者提出使用课程学习和数据筛选的方法来改进无标签强化学习。


<details>
  <summary>Details</summary>
Motivation: 探索无标签强化学习方法在较小基础模型上的泛化能力，因为现有研究主要关注大型模型，而较小模型在推理能力有限的情况下是否能从无标签强化学习中受益尚不清楚。

Method: 提出了一种改进的无标签强化学习方法：使用课程学习逐步引入更难的问题，在训练时屏蔽无多数投票的rollouts，并引入数据筛选流程来生成具有预定义难度的样本。

Result: 实验表明原始无标签强化学习方法对较弱模型效果不佳，甚至低于基线水平。而提出的改进方法在所有模型规模和推理能力上都表现出一致的提升。

Conclusion: 无标签强化学习的效果高度依赖基础模型的推理能力，通过课程学习和数据筛选可以显著提升该方法在资源受限模型上的鲁棒性。

Abstract: Recent advances in large language models have demonstrated the promise of
unsupervised reinforcement learning (RL) methods for enhancing reasoning
capabilities without external supervision. However, the generalizability of
these label-free RL approaches to smaller base models with limited reasoning
capabilities remains unexplored. In this work, we systematically investigate
the performance of label-free RL methods across different model sizes and
reasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals
critical limitations: label-free RL is highly dependent on the base model's
pre-existing reasoning capability, with performance often degrading below
baseline levels for weaker models. We find that smaller models fail to generate
sufficiently long or diverse chain-of-thought reasoning to enable effective
self-reflection, and that training data difficulty plays a crucial role in
determining success. To address these challenges, we propose a simple yet
effective method for label-free RL that utilizes curriculum learning to
progressively introduce harder problems during training and mask no-majority
rollouts during training. Additionally, we introduce a data curation pipeline
to generate samples with predefined difficulty. Our approach demonstrates
consistent improvements across all model sizes and reasoning capabilities,
providing a path toward more robust unsupervised RL that can bootstrap
reasoning abilities in resource-constrained models. We make our code available
at https://github.com/BorealisAI/CuMa

</details>


### [13] [Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale](https://arxiv.org/abs/2511.04904)
*Bassel Al Omari,Michael Matthews,Alexander Rutherford,Jakob Nicolaus Foerster*

Main category: cs.LG

TL;DR: 提出了Craftax-MA和Craftax-Coop两个多智能体强化学习基准，前者是Craftax的多智能体扩展，后者引入了异质智能体、交易等需要复杂合作的机制，旨在评估MARL算法的长期依赖和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有MARL基准主要针对短期挑战，无法充分评估长期依赖和泛化能力，需要更具挑战性的基准来推动MARL研究发展。

Method: 基于JAX开发了Craftax-MA多智能体环境，并进一步扩展为Craftax-Coop，引入异质智能体、交易等合作机制，提供快速训练能力。

Result: 分析表明现有算法在该基准中面临长期信用分配、探索和合作等关键挑战，训练2500万次环境交互可在1小时内完成。

Conclusion: Craftax系列基准有潜力推动MARL长期研究，为评估算法在复杂多智能体系统中的表现提供了有效工具。

Abstract: Progress in multi-agent reinforcement learning (MARL) requires challenging
benchmarks that assess the limits of current methods. However, existing
benchmarks often target narrow short-horizon challenges that do not adequately
stress the long-term dependencies and generalization capabilities inherent in
many multi-agent systems. To address this, we first present
\textit{Craftax-MA}: an extension of the popular open-ended RL environment,
Craftax, that supports multiple agents and evaluates a wide range of general
abilities within a single environment. Written in JAX, \textit{Craftax-MA} is
exceptionally fast with a training run using 250 million environment
interactions completing in under an hour. To provide a more compelling
challenge for MARL, we also present \textit{Craftax-Coop}, an extension
introducing heterogeneous agents, trading and more mechanics that require
complex cooperation among agents for success. We provide analysis demonstrating
that existing algorithms struggle with key challenges in this benchmark,
including long-horizon credit assignment, exploration and cooperation, and
argue for its potential to drive long-term research in MARL.

</details>


### [14] [Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction](https://arxiv.org/abs/2511.05396)
*Yiting He,Zhishuai Liu,Weixin Wang,Pan Xu*

Main category: cs.LG

TL;DR: 该论文研究了在线强化学习中的离动态问题，提出了在训练和部署动态不同的情况下，通过引入上确界访问比率来衡量动态不匹配程度，并开发了首个计算高效的在线RMDP算法。


<details>
  <summary>Details</summary>
Motivation: 现有离动态强化学习研究大多假设可以访问生成模型或预收集的数据集，绕过了探索的挑战。本文研究更现实且具有挑战性的设置：智能体仅限于与训练环境进行在线交互。

Method: 引入上确界访问比率来衡量训练动态与部署动态之间的不匹配，提出了基于f-散度的转移不确定性的在线RMDP算法，该算法计算高效且能实现次线性遗憾。

Result: 证明了如果上确界访问比率无界，在线学习将变得指数级困难。提出的算法在在线RMDP中实现了次线性遗憾，并通过数值实验验证了理论结果。

Conclusion: 该工作为在线离动态强化学习提供了理论基础和实用算法，证明了所提算法在遗憾上界和下界方面的最优性。

Abstract: Off-dynamics reinforcement learning (RL), where training and deployment
transition dynamics are different, can be formulated as learning in a robust
Markov decision process (RMDP) where uncertainties in transition dynamics are
imposed. Existing literature mostly assumes access to generative models
allowing arbitrary state-action queries or pre-collected datasets with a good
state coverage of the deployment environment, bypassing the challenge of
exploration. In this work, we study a more realistic and challenging setting
where the agent is limited to online interaction with the training environment.
To capture the intrinsic difficulty of exploration in online RMDPs, we
introduce the supremal visitation ratio, a novel quantity that measures the
mismatch between the training dynamics and the deployment dynamics. We show
that if this ratio is unbounded, online learning becomes exponentially hard. We
propose the first computationally efficient algorithm that achieves sublinear
regret in online RMDPs with $f$-divergence based transition uncertainties. We
also establish matching regret lower bounds, demonstrating that our algorithm
achieves optimal dependence on both the supremal visitation ratio and the
number of interaction episodes. Finally, we validate our theoretical results
through comprehensive numerical experiments.

</details>


### [15] [Usando LLMs para Programar Jogos de Tabuleiro e Variações](https://arxiv.org/abs/2511.05114)
*Álvaro Guglielmin Becker,Lana Bertoldo Rossato,Anderson Rocha Tavares*

Main category: cs.LG

TL;DR: 测试三种大型语言模型（Claude、DeepSeek和ChatGPT）在生成棋盘游戏代码及创建游戏变体方面的能力


<details>
  <summary>Details</summary>
Motivation: 棋盘游戏编程耗时，而大型语言模型能够根据简单上下文信息高效生成代码，有望加速这一过程

Method: 提出一种方法来测试三种LLM在创建棋盘游戏代码和新游戏变体方面的能力

Result: 论文未提供具体结果，但描述了测试方法和模型选择

Conclusion: 论文旨在评估LLM在棋盘游戏代码生成方面的潜力

Abstract: Creating programs to represent board games can be a time-consuming task.
Large Language Models (LLMs) arise as appealing tools to expedite this process,
given their capacity to efficiently generate code from simple contextual
information. In this work, we propose a method to test how capable three LLMs
(Claude, DeepSeek and ChatGPT) are at creating code for board games, as well as
new variants of existing games.

</details>


<div id='wechat.article'></div>

# wechat.article [[Back]](#toc)

### [16] [论文推荐 | 深度<em class="highlight">强化学习</em>引导的多种群协同进化超多目标优化算法](http://mp.weixin.qq.com/s?__biz=MzkzNjkzNzMzNw==&mid=2247483939&idx=1&sn=d7cfc462a47444fbb7c4491c5310f6a4&chksm=c3db92748afe41989f6b7922ac2d5f2cd4d27583be14f411dc530af20c8fb1ab1d9449eadcb5#rd)
*顺丰科技团队*

Main category: wechat.article

TL;DR: 近年来，强化学习因其卓越的决策能力被引入进化算法框架，成为提升算法性能的关键技术。因此，本文提出了一种深度强化学习引导的多种群协同进化超多目标优化算法DQNMaOEA，用于求解复杂的超多目标优化问题。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 近年来，强化学习因其卓越的决策能力被引入进化算法框架，成为提升算法性能的关键技术。因此，本文提出了一种深度强化学习引导的多种群协同进化超多目标优化算法DQNMaOEA，用于求解复杂的超多目标优化问题。

</details>


### [17] [清华上交满分论文证明：<em class="highlight">强化学习</em>并不能让大模型更会思考！](http://mp.weixin.qq.com/s?__biz=MzA5MTIxNTY4MQ==&mid=2461156326&idx=1&sn=3f92d83294a3579713da74551fc3f630&chksm=868d0d167293e99b9155b2ac6aac76e95881b0b3e9a8145982bf8f6b1290517300dfd64ed4de#rd)
*AI工程化*

Main category: wechat.article

TL;DR: 强化学习更像是巩固已有的知识先验，而非在全新概念上实现迭代改进。不过这也不得不让大家重新思考：如何构建真正能够自我改进的大模型。值得一提的是，这是今年NeurIPS唯一获得满分的论文，恭喜这些研究者。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 强化学习更像是巩固已有的知识先验，而非在全新概念上实现迭代改进。不过这也不得不让大家重新思考：如何构建真正能够自我改进的大模型。值得一提的是，这是今年NeurIPS唯一获得满分的论文，恭喜这些研究者。

</details>


### [18] [多智能体<em class="highlight">强化学习</em>在飞行器协同控制中的研究进展](http://mp.weixin.qq.com/s?__biz=MzU3Mjg0MTgwMw==&mid=2247548811&idx=1&sn=b08a6c80d4934cdcdfda474939d505aa&chksm=fd6cffc87c5fb16ce83a4a05cfb70b040d0e5dc555257e62deea06ae17a41da1b8e8abb08769#rd)
*人工智能技术与咨询*

Main category: wechat.article

TL;DR: [15]2. 1 学习框架强化学习。夫决策过程[16]（Markov Decision Process，MDP）。将序贯决策扩展到多智能体时，marl的形式化 研究一般采用马尔科夫博弈（markov， game.mg） 作为框架。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: [15]2. 1 学习框架强化学习。夫决策过程[16]（Markov Decision Process，MDP）。将序贯决策扩展到多智能体时，marl的形式化 研究一般采用马尔科夫博弈（markov， game.mg） 作为框架。

</details>


### [19] [上交博士最新思考：仅用两个问题讲清<em class="highlight">强化学习</em>](http://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&mid=2247727823&idx=1&sn=57603a1e373cf677638eede04b24a7bd&chksm=91dbb80227bb99b00104c1f7c7cbde0bc07a79e4604f123cb07bbdfb6b7d53bce9caf9c4b437#rd)
*AI科技评论*

Main category: wechat.article

TL;DR: 强化学习的过程，本质上是智能体不断收集经验、并用这些经验改进策略的循环。不同算法的差异，很大程度上取决于它们依赖什么样的数据。最直接的方式是“在策略学习”。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 强化学习的过程，本质上是智能体不断收集经验、并用这些经验改进策略的循环。不同算法的差异，很大程度上取决于它们依赖什么样的数据。最直接的方式是“在策略学习”。

</details>


### [20] [零基础也能征服<em class="highlight">强化学习</em>！《Easy RL》蘑菇书带你从入门到精通](http://mp.weixin.qq.com/s?__biz=MzkwODMzNTExMw==&mid=2247487749&idx=1&sn=00228cb0a5a5aec8e096f84e4b3124cb&chksm=c124132ad872b76f19ccd0b921a67708d25159b7fedc9268711d2bdae15c318798e337907cbf#rd)
*腾讯云CloudStudio*

Main category: wechat.article

TL;DR: 第1章强化学习基础。强化学习作为机器学习的重要分支，通过智能体与环境的交互来学习最优策略。...。本音从强化学习的基本概念入手，介绍了智能体、环境、状态、动作、奖励等。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 第1章强化学习基础。强化学习作为机器学习的重要分支，通过智能体与环境的交互来学习最优策略。...。本音从强化学习的基本概念入手，介绍了智能体、环境、状态、动作、奖励等。

</details>


### [21] [基于策略优化的<em class="highlight">强化学习</em>-基础](http://mp.weixin.qq.com/s?__biz=MzE5ODM0MDIyNg==&mid=2247483659&idx=1&sn=6feae38938dac203d34647eb534fccdd&chksm=9710d5147ae92fa7fece8c0fca05f8f4f284e90ffcf43201844bd22baa3b5e5beb450bff5dbc#rd)
*AIer 笔记*

Main category: wechat.article

TL;DR: 在强化学习中，智能体通过与环境的交互来学习策略，以最大化累积奖励。策略优化的目标是最大化期望累积奖励，最大化策略优化方法的核心思想是直接对策略本身进行建模和优化。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 在强化学习中，智能体通过与环境的交互来学习策略，以最大化累积奖励。策略优化的目标是最大化期望累积奖励，最大化策略优化方法的核心思想是直接对策略本身进行建模和优化。

</details>


### [22] [NIPS26唯一满分！<em class="highlight">强化学习</em>正在“杀死”大模型的创造力！](http://mp.weixin.qq.com/s?__biz=Mzg3MjEyMzM4MA==&mid=2247485050&idx=1&sn=464c4226a4d436e0d2edff8f7e54ecdd&chksm=cf122b2eae6399a2f70cf569c1acdb9b2d646ef35583d23cf38026fe721e6c9de6d57ad4a3b9#rd)
*沈公子今天读什么*

Main category: wechat.article

TL;DR: 当前的强化学习方法，真的让LLM学会了“新知识”，还是仅仅让它更擅长从“旧知识”里挑出正确答案？这篇论文的动机，就是要拨开现象看本质，系统性地检验RLVR的真实效果，看看它到底是在“开拓新大陆”，还是在“老城


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 当前的强化学习方法，真的让LLM学会了“新知识”，还是仅仅让它更擅长从“旧知识”里挑出正确答案？这篇论文的动机，就是要拨开现象看本质，系统性地检验RLVR的真实效果，看看它到底是在“开拓新大陆”，还是在“老城

</details>


### [23] [王尔申,吴晓桐,宏晨等 | 基于量化信息内容度量的多智能体<em class="highlight">强化学习</em>](http://mp.weixin.qq.com/s?__biz=MzAxNjgwMjA5Ng==&mid=2651180593&idx=2&sn=78a7f6217ecdfe6fe2e8ddaaba7ff5f3&chksm=810df62388ef29ca1c40497d40562e7eb73fd2237d0d7b2c0fdefb3cdb83a8c96e6056aaca49#rd)
*中国科学信息科学*

Main category: wechat.article

TL;DR: #多智能体强化学习，#部分可观测，#去中心化马尔可夫决策过程，#星际争霸Ⅱ _scis01_研究意义在多智能体强化学习（MARL）中，部分可观测一直是一项重要挑战，因为智能体无法观测全部环境，只能获得局部信息片段。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: #多智能体强化学习，#部分可观测，#去中心化马尔可夫决策过程，#星际争霸Ⅱ _scis01_研究意义在多智能体强化学习（MARL）中，部分可观测一直是一项重要挑战，因为智能体无法观测全部环境，只能获得局部信息片段。

</details>


### [24] [基于<em class="highlight">强化学习</em>的智能体化搜索全面综述：基础、角色、优化、评估与应用](http://mp.weixin.qq.com/s?__biz=MzUyMDc5OTU5NA==&mid=2247717513&idx=3&sn=8a2b0e66775412db9e337f555a741e33&chksm=f8a894f837e29955d677213862ecca9b8c8fa467a58589d9892df9fdbcb3216ff22fbdad0fed#rd)
*一点人工一点智能*

Main category: wechat.article

TL;DR: 在这一新范式下，强化学习（Reinforcement Learning， RL） 提供了一种强大的机制，用于实现自适应与自我改进的搜索行为。本综述首次系统梳理了基于强化学习的智能体化搜索（RL-based agentic search）研究进展，从三个互补维度组织


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 在这一新范式下，强化学习（Reinforcement Learning， RL） 提供了一种强大的机制，用于实现自适应与自我改进的搜索行为。本综述首次系统梳理了基于强化学习的智能体化搜索（RL-based agentic search）研究进展，从三个互补维度组织

</details>


### [25] [LLM<em class="highlight">强化学习</em>算法演进之路：Q-Learning->DQN->PPO->DPO等](http://mp.weixin.qq.com/s?__biz=Mzg4Mjg4NTQxMQ==&mid=2247548631&idx=1&sn=b04acbdcc219b43e2a208b222603806f&chksm=ce563dd0f415183eeb73601cae890df4d6905bec94d0fe51ed6aaf0150717c0c896ac699b0d5#rd)
*大模型之心Tech*

Main category: wechat.article

TL;DR: DPO 第四章节 LLM的GRPO 一、强化学习理论基础Q值： 代表智能体选择某个动作后，一直到最终状态奖励总和的期望， Q值评价动作。V值：代表智能体在这个状态下，一直到最终状态的奖励总和的期望，V值评价状态。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: DPO 第四章节 LLM的GRPO 一、强化学习理论基础Q值： 代表智能体选择某个动作后，一直到最终状态奖励总和的期望， Q值评价动作。V值：代表智能体在这个状态下，一直到最终状态的奖励总和的期望，V值评价状态。

</details>


### [26] [【PDF】动手学<em class="highlight">强化学习</em> 张伟楠 电子版下载](http://mp.weixin.qq.com/s?__biz=MzkwNzcyMTQ3OQ==&mid=2247484978&idx=1&sn=f04e35e5550abf48e48381efb0ff969d&chksm=c1ded7a792a8f216a8c5081205b4a05875171f24ae5a32a6139808a244cda11d796c3c780020#rd)
*芋泥小丸子奶茶*

Main category: wechat.article

TL;DR: 目录第一部分 强化学习基础第 1 章 初探强化学习 2第 2 章 多臂老虎机问题 7第 3 章 马尔可夫决策过程 19第 4 章 动态规划算法 34第 5 章 时序差分算法 47


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 目录第一部分 强化学习基础第 1 章 初探强化学习 2第 2 章 多臂老虎机问题 7第 3 章 马尔可夫决策过程 19第 4 章 动态规划算法 34第 5 章 时序差分算法 47

</details>


### [27] [深夜食堂！<em class="highlight">强化学习</em>基本概念](http://mp.weixin.qq.com/s?__biz=MzkwMjM5NDc4MA==&mid=2247501073&idx=2&sn=3d0338d1e90ab61553e8a2bcd6ac06c2&chksm=c195958534e79410037e38fa9a0534ac040dc953007cf2884cbee5160189fa0b75ea41245cf0#rd)
*机器学习之心HML*

Main category: wechat.article

TL;DR: 强化学习基本概念 1. 核心定义 强化学习（Reinforcement Learning， RL） 是机器学习的一个分支，关注智能体（Agent） 如何在一系列状态（State） 中通过执行动作（Action） 来最大化累积奖励（Reward）。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 强化学习基本概念 1. 核心定义 强化学习（Reinforcement Learning， RL） 是机器学习的一个分支，关注智能体（Agent） 如何在一系列状态（State） 中通过执行动作（Action） 来最大化累积奖励（Reward）。

</details>


### [28] [LLM<em class="highlight">强化学习</em>之路续章——从PPO到DAPO](http://mp.weixin.qq.com/s?__biz=MzAxMTU5Njg4NQ==&mid=2247504959&idx=1&sn=16898f0d324adf973c766d73a09c2266&chksm=9aa9ab8b02911f6231161516b4271a8e68dfa2c26e7093d9ac8c87e22b46be993c8bbca7ebd2#rd)
*关于NLP那些你不知道的事*

Main category: wechat.article

TL;DR: 本文就作为这一话题的序章，让我们继续走进LLM强化学习。一、预备知识1.1 PPO和GRPOPPO（Proximal Policy Optimization，近端策略优化）和GRPO（Group Relative Policy Optimization，群体相对策略优化）的公式见下图1-1。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 本文就作为这一话题的序章，让我们继续走进LLM强化学习。一、预备知识1.1 PPO和GRPOPPO（Proximal Policy Optimization，近端策略优化）和GRPO（Group Relative Policy Optimization，群体相对策略优化）的公式见下图1-1。

</details>


### [29] [深夜食堂！<em class="highlight">强化学习</em>基本概念](http://mp.weixin.qq.com/s?__biz=MzkwMjM5NDc4MA==&mid=2247501068&idx=1&sn=fa33c158034c6a0fe934f4e855bf03f1&chksm=c1db97f5d45fa7bd98f0d7588e6816d2060a7de0ee8102d1df128673dc3560a6f246a8980a97#rd)
*机器学习之心HML*

Main category: wechat.article

TL;DR: 强化学习基本概念 1. 核心定义 强化学习（Reinforcement Learning， RL） 是机器学习的一个分支，关注智能体（Agent） 如何在一系列状态（State） 中通过执行动作（Action） 来最大化累积奖励（Reward）。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 强化学习基本概念 1. 核心定义 强化学习（Reinforcement Learning， RL） 是机器学习的一个分支，关注智能体（Agent） 如何在一系列状态（State） 中通过执行动作（Action） 来最大化累积奖励（Reward）。

</details>


### [30] [<em class="highlight">Agentic</em> AI的三重跃迁：技术、产业与人类协作的新范式](http://mp.weixin.qq.com/s?__biz=Mzk2NDg0NjQ3Mg==&mid=2247483851&idx=1&sn=9232d1adcc3aff74c5ace18e4b9e528a&chksm=c5ee6ca3816ecc80497ddcaec3e0d527e08af5de051d8058fa145e33abd42af1645235a71eeb#rd)
*认知启元*

Main category: wechat.article

TL;DR: 当亚马逊云科技展示其智能体系统能在10分钟内完成传统需2天的Java应用升级时，另一端，中国人民大学团队开源的DeepAnalyze模型正试图用Agentic LLM（大语言模型）重新定义数据科学家的工作流。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 当亚马逊云科技展示其智能体系统能在10分钟内完成传统需2天的Java应用升级时，另一端，中国人民大学团队开源的DeepAnalyze模型正试图用Agentic LLM（大语言模型）重新定义数据科学家的工作流。

</details>


### [31] [<em class="highlight">Agentic</em> RAG，真的是一个很值得去做的方向！！！](http://mp.weixin.qq.com/s?__biz=MzY0MDExNjI1NQ==&mid=2247484484&idx=1&sn=668bd573e08d3715f8dc92024766a681&chksm=f1adef909bb6c5a59cde56f1ac445ff166847eca12d50592c8052fbe5ff885948945819a361c#rd)
*学AI大模型*

Main category: wechat.article

TL;DR: 4.检查任务是否完成（Finished？）） 。是（yes）：生成最终响应 。否。 （no）：返回规划器调整计划。5.多智能体模式。多智能体模式核心特点： 5） multi-agent pattern user query 存在多个智能体，每个智能体都有特定的角色和任。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 4.检查任务是否完成（Finished？）） 。是（yes）：生成最终响应 。否。 （no）：返回规划器调整计划。5.多智能体模式。多智能体模式核心特点： 5） multi-agent pattern user query 存在多个智能体，每个智能体都有特定的角色和任。

</details>


### [32] [DeepEyes V2：迈向 <em class="highlight">Agentic</em> 多模态大模型](http://mp.weixin.qq.com/s?__biz=MzAwMTY3NjA1OA==&mid=2247485551&idx=1&sn=495108ed1001bf1d87ac71af43655723&chksm=9b257c42705d9fc839f0df649d5526435df81ee0c0e164605866065a9743911ed682d584c091#rd)
*小胡学 LLM*

Main category: wechat.article

TL;DR: 关键词：#多模态大模型 #工具调用 #Agentic论文题目：DeepEyesV2： Toward Agentic Multimodal ModelarXiv：2511.05271单位：小红书https：//visual-agent.github.io/Jack Hong *， Chenxiao Zhao*， Chenglin Zhu*， Weiheng Lu， Guohai Xut， XingY...


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 关键词：#多模态大模型 #工具调用 #Agentic论文题目：DeepEyesV2： Toward Agentic Multimodal ModelarXiv：2511.05271单位：小红书https：//visual-agent.github.io/Jack Hong *， Chenxiao Zhao*， Chenglin Zhu*， Weiheng Lu， Guohai Xut， XingYu，

</details>


### [33] [尝试给古典营销人讲懂 <em class="highlight">Agentic</em> AI（长文）- 以 DSP 类比](http://mp.weixin.qq.com/s?__biz=MjM5MDU5OTI1NQ==&mid=2247484894&idx=1&sn=83673bd850b9fab51ed0955bbf5e7230&chksm=a70bfc24882b15e3738a3abcc03fac08265c9ee7956bbfee40d4db08b300c11da48b8f36cebd#rd)
*数字猫头鹰*

Main category: wechat.article

TL;DR: 这就是 Agent 的核心逻辑。Agentic AI，就是把Agency变成了一个AI系统。你给它一个营销目标，它自己去调研市场、分析竞品、制定策略、生成创意、执行投放、优化效果。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 这就是 Agent 的核心逻辑。Agentic AI，就是把Agency变成了一个AI系统。你给它一个营销目标，它自己去调研市场、分析竞品、制定策略、生成创意、执行投放、优化效果。

</details>


### [34] [AI Agent 与 <em class="highlight">Agentic</em> AI：概念分类、应用与挑战](http://mp.weixin.qq.com/s?__biz=MzAxNjIzOTkyOQ==&mid=2449865932&idx=1&sn=7476466cfc8d1d5975a5595351ca916c&chksm=8d25da116865002f95924e286df3cfa880736b3b028d56d83dacb3f8b3bbff4feacc0dbeb128#rd)
*AI贺贺*

Main category: wechat.article

TL;DR: Agentic AI：代表了一种新的 设计范式，其核心特征是 多代理协作、动态任务分解、持久化记忆和协调自治。它并非单个代理的功能增强，而是由多个专业代理组成的、能够完成复杂长期目标的 协同系统。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: Agentic AI：代表了一种新的 设计范式，其核心特征是 多代理协作、动态任务分解、持久化记忆和协调自治。它并非单个代理的功能增强，而是由多个专业代理组成的、能够完成复杂长期目标的 协同系统。

</details>


### [35] [<em class="highlight">Agentic</em>21种设计模式-Routing](http://mp.weixin.qq.com/s?__biz=MzkxNTgxMDAxMg==&mid=2247484266&idx=1&sn=b26bc484150348e43b1165cbccb184c8&chksm=c08663c77b89eed6e88dca84e9163e94af1969ef6dd677e08deb676f81a0bd76d0b5a2ade7d3#rd)
*AI Lab Dev*

Main category: wechat.article

TL;DR: 这段代码演示了一个基于 langchain 和谷歌的生成式人工智能技术的简单代理系统。该系统设置了一个“协调器”，根据用户的请求意图（如预订、查询信息或请求内容不明确等），将请求路由到不同的模拟“子Agent”处理程序。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 这段代码演示了一个基于 langchain 和谷歌的生成式人工智能技术的简单代理系统。该系统设置了一个“协调器”，根据用户的请求意图（如预订、查询信息或请求内容不明确等），将请求路由到不同的模拟“子Agent”处理程序。

</details>


### [36] [别了，传统工作流！<em class="highlight">Agentic</em> Workflow 正成为新架构标杆](http://mp.weixin.qq.com/s?__biz=MzYyNDQ2MTk2OA==&mid=2247483701&idx=1&sn=0731e2cfc7994a54cf176f94ec12531e&chksm=f1330bd115a1f5415dd6ad41796bcb4fafc8066aab751bd5fd0aaa9fb2aac0c2cb930d403ee1#rd)
*AI旋转矩阵*

Main category: wechat.article

TL;DR: 中图：AI Non-agentic 工作流；下图：Agentic 工作流Agentic Workflow 如何工作？当一个或多个 Agent 引导并塑造任务进程时，AI 工作流就变成了 Agentic Workflow。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 中图：AI Non-agentic 工作流；下图：Agentic 工作流Agentic Workflow 如何工作？当一个或多个 Agent 引导并塑造任务进程时，AI 工作流就变成了 Agentic Workflow。

</details>


### [37] [工具调用能力成AI新战场，开闭源<em class="highlight">模型</em>齐头并进丨大语言<em class="highlight">模型</em>10月最新榜单揭晓](http://mp.weixin.qq.com/s?__biz=MzkyNzg1MzMxNg==&mid=2247487749&idx=1&sn=3054becb1def19c1ef0a03b0f6b18fa6&chksm=c3434fd3969ef88dfe51fa4a91b3597dd851944d40d070d04ee750ac4ccdbe7f998def561ff4#rd)
*司南评测体系*

Main category: wechat.article

TL;DR: 大模型技术在全球范围内持续演进，各大科技公司纷纷推出新一代模型，重点强化智能体方向的核心能力，包括编程、工具使用和深度信息检索等，无一不在提升实际问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大模型技术在全球范围内持续演进，各大科技公司纷纷推出新一代模型，重点强化智能体方向的核心能力，包括编程、工具使用和深度信息检索等，无一不在提升实际问题解决能力。

</details>


### [38] [天崩了！GPT 5跌下“神坛”。国产<em class="highlight">大模型</em>却逆势“抽打”](http://mp.weixin.qq.com/s?__biz=Mzk0MzYxMjgwNw==&mid=2247489302&idx=1&sn=12bc1f4a33844893a7d1f21d025c17df&chksm=c202d5d1fbb1de1029f137884c3568e08046e6cd7361201846a5edaef0c1cc423ba6369a08d0#rd)
*AI芯界*

Main category: wechat.article

TL;DR: 二、 商汤此次对外开源的SenseNova-SI空间智能大模型家族，带来了2B与8B两种参数量级的版本。依据最新出炉的评测结果，SenseNova-SI系列模型在空间智能领域的多个权威基准测试（涵盖VSI、MMSI、MindCube以及ViewSpatial等）中成绩斐然


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 二、 商汤此次对外开源的SenseNova-SI空间智能大模型家族，带来了2B与8B两种参数量级的版本。依据最新出炉的评测结果，SenseNova-SI系列模型在空间智能领域的多个权威基准测试（涵盖VSI、MMSI、MindCube以及ViewSpatial等）中成绩斐然

</details>


### [39] [数字安全企业发布《<em class="highlight">大模型</em>安全白皮书》！ 提出“外挂式安全+平台原生安全”双轨治理策略](http://mp.weixin.qq.com/s?__biz=MjM5MjAzMTk0NA==&mid=2649558517&idx=3&sn=6d4e570c85a1ad9a22b00b9f26d62a12&chksm=bf19f7a0869c76f62b18320537d1aae51d5c93fbcf1791c30ef20e2df2e8776cfebdae14fada#rd)
*中国消费者报*

Main category: wechat.article

TL;DR: 大模型 大模型 大模型数据与 智能体 用户端 基础设施安全 内容安全 知识库安全 风险 风险 算力主机 内容安全 数据安全 agent安全 用户端安全 安全 提示注入攻击 数据泄漏 api安全 大模型访问控制 设备控制 价值观错误 隐私泄露


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大模型 大模型 大模型数据与 智能体 用户端 基础设施安全 内容安全 知识库安全 风险 风险 算力主机 内容安全 数据安全 agent安全 用户端安全 安全 提示注入攻击 数据泄漏 api安全 大模型访问控制 设备控制 价值观错误 隐私泄露

</details>


### [40] [讯飞发布全新星火<em class="highlight">大模型</em>，智能体平台开源惠及千万开发者](http://mp.weixin.qq.com/s?__biz=MjM5ODA0OTUyMA==&mid=2657517277&idx=1&sn=fd0cc54f8cca63b4739353d6f7567f61&chksm=bc97ff2906b8f1bc25ec1d471afe637bdd4213b2f09f9e86b24d838db2d16ccf52d463a530a2#rd)
*万能的大熊*

Main category: wechat.article

TL;DR: 技术筑基：星火X1.5重塑大模型天花板■刘庆峰指出，AI产业红利兑现需聚焦于四个关键核心：自主可控、软硬一体、行业纵深、个性化。本次大会，深度推理大模型讯飞星火X1.5发布是技术筑基的关键。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 技术筑基：星火X1.5重塑大模型天花板■刘庆峰指出，AI产业红利兑现需聚焦于四个关键核心：自主可控、软硬一体、行业纵深、个性化。本次大会，深度推理大模型讯飞星火X1.5发布是技术筑基的关键。

</details>


### [41] [征求意见稿丨网络安全标准实践指南——<em class="highlight">大模型</em>一体机产品安全基本要求（附下载）](http://mp.weixin.qq.com/s?__biz=MzI2MDk2NDA0OA==&mid=2247535722&idx=1&sn=9b03f1da063d6ebd7449267cc7497ce2&chksm=eb4607f1f09346129180b4523e5a5b75ba6229757a29afd133f534af0e20967e7f68ffbedd4e#rd)
*工业安全产业联盟平台*

Main category: wechat.article

TL;DR: 随着人工智能技术的深度发展和大模型能力的不断突破，大模型 一体机作为集成智能体协同、模型处理、数据管理、系统硬件于一体 的综合性ai产品，正成为推动企业智能化转型和ai应用落地的核心载 体，在政务服务、医疗健


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 随着人工智能技术的深度发展和大模型能力的不断突破，大模型 一体机作为集成智能体协同、模型处理、数据管理、系统硬件于一体 的综合性ai产品，正成为推动企业智能化转型和ai应用落地的核心载 体，在政务服务、医疗健

</details>


### [42] [AI<em class="highlight">大模型</em>·白皮书 | 2025年AI<em class="highlight">大模型</em>开发生态白皮书](http://mp.weixin.qq.com/s?__biz=MzIzMDgwODcyNA==&mid=2247596905&idx=2&sn=756c0c025c2540882475eba99fb737d4&chksm=e9652d073cadb193ab0ba1c2fcf70d1590977c42a475daa959fd97717ce191fd5a17adc93831#rd)
*木木自由*

Main category: wechat.article

TL;DR: ▲回复“9”，AI大模型·领地，一起学习AI大模型，持续更新AI大模型学习路径相关资料~（精彩大模型观点、学习资料、书籍分享···等你一起来乘风破浪~


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: ▲回复“9”，AI大模型·领地，一起学习AI大模型，持续更新AI大模型学习路径相关资料~（精彩大模型观点、学习资料、书籍分享···等你一起来乘风破浪~

</details>


### [43] [SCALE | 2025 年 10 月《<em class="highlight">大模型</em> SQL 能力排行榜》发布](http://mp.weixin.qq.com/s?__biz=MzU2NzgwMTg0MA==&mid=2247523971&idx=1&sn=bf53822e2de6b576a02e1843a495f148&chksm=fd446483487da8cfadca8efe2298dbfcca22b44e988883114fa4477937656f5e74435ce9f9aa#rd)
*爱可生开源社区*

Main category: wechat.article

TL;DR: 本月，榜单迎来了蚂蚁百灵大模型团队发布的两大 万亿级 参数的模型：Ling-1T[2] 和 Ring-1T[3]。every step evolves： scaling reinforcement learning for trillion-scale thinking model ling team， inclusion ai* *see contributions section （sec. ...


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 本月，榜单迎来了蚂蚁百灵大模型团队发布的两大 万亿级 参数的模型：Ling-1T[2] 和 Ring-1T[3]。every step evolves： scaling reinforcement learning for trillion-scale thinking model ling team， inclusion ai* *see contributions section （sec. 6） for full author list. w

</details>


### [44] [1024丨开发者论道：<em class="highlight">大模型</em>落地实践与挑战破局](http://mp.weixin.qq.com/s?__biz=MzU0MzkxNDgwOQ==&mid=2247516237&idx=4&sn=b06e797c29a68ad81899748cee79b1fe&chksm=fadea490858078613d2a0bfeb48624f59ec1a6ec11534260874783ddfdebb2b4b01496bbe36c#rd)
*讯飞产业加速中心*

Main category: wechat.article

TL;DR: 2023年后，大模型技术的突破带来根本性变革，华为逐步转向以大模型为核心、融合小模型优势的“大小结合”路径，实现了语义理解、内容生成与任务规划能力的跃升。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 2023年后，大模型技术的突破带来根本性变革，华为逐步转向以大模型为核心、融合小模型优势的“大小结合”路径，实现了语义理解、内容生成与任务规划能力的跃升。

</details>


### [45] [算法跃迁：Transformer与<em class="highlight">大模型</em>的智能革命](http://mp.weixin.qq.com/s?__biz=MzE5ODc5MDQ0OA==&mid=2247483695&idx=1&sn=dc1655c102b6416597cf6277bfb8d7df&chksm=9704e755b679ccc3dd015a0665fb2c06ff9fd0b318091c65aae0b785b5106046b44bae22d754#rd)
*架构与运维*

Main category: wechat.article

TL;DR: 大模型已成为当前人工智能技术发展的核心驱动力，展现出强大的通用性和泛化能力。应用形态：* 智能体：大模型赋予了智能体前所未有的自主决策和规划能力。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大模型已成为当前人工智能技术发展的核心驱动力，展现出强大的通用性和泛化能力。应用形态：* 智能体：大模型赋予了智能体前所未有的自主决策和规划能力。

</details>


### [46] [每周AI<em class="highlight">大模型</em>更新速递11.03~11.09](http://mp.weixin.qq.com/s?__biz=MzAxNjYxOTY3NQ==&mid=2455622396&idx=1&sn=695e371ef1f1f92c01a41662d4bb2b5f&chksm=8d40a11007a3608806ebabcc95119b2026e05f586c25c0e119e71e12b8a31ee70668b9ff9e9d#rd)
*大模型评测及优化NoneLinear*

Main category: wechat.article

TL;DR: 大模型/agent评测技术交流：关注公众号，发送消息"进群"


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大模型/agent评测技术交流：关注公众号，发送消息"进群"

</details>


### [47] [2025年TOP 9 <em class="highlight">大模型</em>](http://mp.weixin.qq.com/s?__biz=Mzk0NDE5Nzg1Ng==&mid=2247514523&idx=2&sn=0b89c1f39eb436e3eca6c4013a878faa&chksm=c27d9247c401bb95420d0187acc4986b66325a1014871ebf800b3aa5f89bd2bf585a3ee8c3f9#rd)
*kaggle竞赛宝典*

Main category: wechat.article

TL;DR: 引言 本文汇总了全球的主流大模型，并分析最新趋势和重要创新。以下，我们重点介绍了我们认为目前在行业内引起关注的 9 个 LLM，每个模型都具备独特的功能和专业优势，在自然语言处理、代码合成、小样本学习或可扩展性


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 引言 本文汇总了全球的主流大模型，并分析最新趋势和重要创新。以下，我们重点介绍了我们认为目前在行业内引起关注的 9 个 LLM，每个模型都具备独特的功能和专业优势，在自然语言处理、代码合成、小样本学习或可扩展性

</details>


<div id='tldr.article'></div>

# tldr.article [[Back]](#toc)

### [48] [How compliance teams can save 15+ hours/week with Agentic AI](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgo.sprinto.com%2Flp-soc-2-newsletter%3Futm_source=Newsletter%26utm_medium=Referral%26utm_campaign=TLDRInfosec%26utm_term=6thNov/1/0100019a597f985a-f7d92982-70c0-4855-905a-070f584752bf-000000/GQYmAJ9j4KoDupYZcQ-MqUrfpjLh7RNzSOfvFyMvukU=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Sprinto使用Agentic AI自动化合规流程，帮助企业节省时间并快速获得合规认证，已帮助Anaconda在几周内完成合规并达成七位数交易


<details>
  <summary>Details</summary>
Motivation: 合规团队花费过多时间在SOC 2和ISO 27001等合规流程上，需要更高效的解决方案

Method: 使用Agentic AI技术自动收集证据、监控风险并保持审计就绪状态

Result: Anaconda使用Sprinto在几周内完成合规并获得七位数交易，团队每周节省15+小时

Conclusion: Agentic AI能够显著提升合规效率，为企业节省时间和资源

Abstract: How compliance teams can save 15+ hours/week with Agentic AI (Sponsor) SOC 2 and ISO 27001 shouldn't eat 40% of your team's time in 2026. Sprinto uses Agentic AI to autonomously collect evidence, monitor risks, and keep you audit-read. Anaconda got compliant with Sprinto and closed a seven-figure deal within weeks. TLDR readers get $1,000 off + an Ultrahuman Ring once you get compliant.

</details>


### [49] [Move faster with AI: Build secure, maintainable code you can trust](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.sonarsource.com%2Fsem%2Fvibe-then-verify%2F%3Futm_medium=paid%26utm_source=tldr%26utm_campaign=ss-vibethenverify25%26utm_content=newsletter-primary-tldr-ai-251106-x%26utm_term=ww-psp-x%26s_category=Paid%26s_source=Paid%2520Other%26s_origin=tldr/2/0100019a598b0997-34a11e75-ef3a-48e4-8f4f-0982f74a47b5-000000/3HRKQ5ZzlvAEw9j-w6NS8DwtJpLeNq0Oi_Pw5jMillY=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: SonarQube提供自动化代码审查，帮助团队在AI加速开发的同时确保代码质量和安全


<details>
  <summary>Details</summary>
Motivation: AI加速开发产生大量代码，但代码质量和安全验证成为瓶颈，需要自动化工具来确保代码可信度

Method: 使用SonarQube进行持续分析和自动化代码审查，早期检测和修复问题

Result: 团队能够无惧地使用AI，获得持续的质量和安全分析

Conclusion: 自动化代码审查工具可以帮助团队在AI时代保持代码质量和安全

Abstract: Move faster with AI: Build secure, maintainable code you can trust (Sponsor) AI is speeding things up, but all that new code creates a bottleneck — who's verifying the quality and security? Don't let unverified code stall your merges.Sonar's automated review gives you the control back, building the trust you need in every line of code, human- or AI-written. With SonarQube, your team can: Use AI without fear: Get continuous analysis for quality and security. Fix issues early: Detect and apply ...

</details>


### [50] [Use AI without fear](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.sonarsource.com%2Fsem%2Fvibe-then-verify%2F%3Futm_medium=paid%26utm_source=tldr%26utm_campaign=ss-vibethenverify25%26utm_content=newsletter-primary-tldr-ai-251106-x%26utm_term=ww-psp-x%26s_category=Paid%26s_source=Paid%2520Other%26s_origin=tldr/2/0100019a598b0997-34a11e75-ef3a-48e4-8f4f-0982f74a47b5-000000/3HRKQ5ZzlvAEw9j-w6NS8DwtJpLeNq0Oi_Pw5jMillY=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: SonarQube提供自动化代码审查，帮助团队在AI加速开发的同时确保代码质量和安全性


<details>
  <summary>Details</summary>
Motivation: AI加速代码生成但缺乏质量验证，导致代码质量和安全问题成为瓶颈

Method: 使用SonarQube进行持续自动化代码分析，检测质量和安全问题

Result: 团队可以无惧使用AI，早期发现并修复问题，建立对代码的信任

Conclusion: 自动化代码审查是应对AI生成代码质量挑战的有效解决方案

Abstract: Move faster with AI: Build secure, maintainable code you can trust (Sponsor) AI is speeding things up, but all that new code creates a bottleneck — who's verifying the quality and security? Don't let unverified code stall your merges.Sonar's automated review gives you the control back, building the trust you need in every line of code, human- or AI-written. With SonarQube, your team can: Use AI without fear: Get continuous analysis for quality and security. Fix issues early: Detect and apply ...

</details>


### [51] [Fix issues early](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.sonarsource.com%2Fsem%2Fvibe-then-verify%2F%3Futm_medium=paid%26utm_source=tldr%26utm_campaign=ss-vibethenverify25%26utm_content=newsletter-primary-tldr-ai-251106-x%26utm_term=ww-psp-x%26s_category=Paid%26s_source=Paid%2520Other%26s_origin=tldr/2/0100019a598b0997-34a11e75-ef3a-48e4-8f4f-0982f74a47b5-000000/3HRKQ5ZzlvAEw9j-w6NS8DwtJpLeNq0Oi_Pw5jMillY=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: SonarQube提供自动化代码审查，帮助团队在AI加速开发的同时确保代码质量和安全性


<details>
  <summary>Details</summary>
Motivation: AI加速开发产生大量新代码，但缺乏质量验证和安全审查，可能阻碍代码合并流程

Method: 使用SonarQube进行持续分析和自动化代码审查，早期检测和修复问题

Result: 团队可以无惧地使用AI，获得持续的质量和安全分析，建立对代码的信任

Conclusion: 自动化代码审查工具可以帮助团队在AI时代保持代码质量和安全标准

Abstract: Move faster with AI: Build secure, maintainable code you can trust (Sponsor) AI is speeding things up, but all that new code creates a bottleneck — who's verifying the quality and security? Don't let unverified code stall your merges.Sonar's automated review gives you the control back, building the trust you need in every line of code, human- or AI-written. With SonarQube, your team can: Use AI without fear: Get continuous analysis for quality and security. Fix issues early: Detect and apply ...

</details>


### [52] [Maintain your standards](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.sonarsource.com%2Fsem%2Fvibe-then-verify%2F%3Futm_medium=paid%26utm_source=tldr%26utm_campaign=ss-vibethenverify25%26utm_content=newsletter-primary-tldr-ai-251106-x%26utm_term=ww-psp-x%26s_category=Paid%26s_source=Paid%2520Other%26s_origin=tldr/2/0100019a598b0997-34a11e75-ef3a-48e4-8f4f-0982f74a47b5-000000/3HRKQ5ZzlvAEw9j-w6NS8DwtJpLeNq0Oi_Pw5jMillY=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: SonarQube提供自动化代码审查，帮助团队在使用AI生成代码时确保质量和安全，避免未经验证的代码阻碍合并流程。


<details>
  <summary>Details</summary>
Motivation: 随着AI加速代码生成，大量新代码的质量和安全性验证成为瓶颈，需要自动化工具来确保代码可靠性。

Method: 使用SonarQube进行持续分析和自动化代码审查，检测并早期修复质量问题。

Result: 团队能够无惧地使用AI生成代码，获得持续的质量和安全分析，在早期发现并解决问题。

Conclusion: 自动化代码审查工具如SonarQube对于管理AI生成代码的质量和安全至关重要，帮助团队建立对代码的信任。

Abstract: Move faster with AI: Build secure, maintainable code you can trust (Sponsor) AI is speeding things up, but all that new code creates a bottleneck — who's verifying the quality and security? Don't let unverified code stall your merges.Sonar's automated review gives you the control back, building the trust you need in every line of code, human- or AI-written. With SonarQube, your team can: Use AI without fear: Get continuous analysis for quality and security. Fix issues early: Detect and apply ...

</details>


### [53] [Semantic Search for Cursor's Coding Agent](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcursor.com%2Fblog%2Fsemsearch%3Futm_source=tldrai/1/0100019a598b0997-34a11e75-ef3a-48e4-8f4f-0982f74a47b5-000000/nN5jS5xw3tbTh-gllZVMPeBsbLn18ePBQBg9cKfJw84=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Cursor的编码代理通过集成自定义语义搜索功能，显著提升了代码库搜索的准确性和效率，减少了用户迭代次数，并更好地保留了代码变更。


<details>
  <summary>Details</summary>
Motivation: 传统代码搜索方法在准确性和效率方面存在不足，影响了编码代理的性能和用户体验。

Method: 在Cursor编码代理中集成了自定义的语义搜索功能，专门针对代码库进行优化。

Result: 该改进显著提高了搜索准确性，减少了用户所需的迭代次数，并更好地保持了代码变更的完整性。

Conclusion: 语义搜索技术能够有效提升编码代理的性能和用户体验。

Abstract: Semantic Search for Cursor's Coding Agent (4 minute read) Cursor's coding agent improved performance by incorporating custom semantic search over codebases, leading to higher accuracy, fewer user iterations, and better retention of code changes.

</details>


### [54] [You don't need 10 different AI tools to deploy an agent](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.outsystems.com%2Flow-code-platform%2Fagentic-ai-workbench%2F%3Futm_source=tldr%26utm_medium=social-paid%26utm_campaign=none%26utm_adid=tldr-ai-newsletter-November25%26utm_content=webpage%26utm_campaignteam=digital-mktg%26utm_partner=none/1/0100019a598b0997-34a11e75-ef3a-48e4-8f4f-0982f74a47b5-000000/rXr-aUBWZuakCLoQrUungNhQ6SDft7KKk9Tmktc0eXg=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: OutSystems Agent Workbench是一个无需编码的平台，提供安全护栏和自动化质量审查，帮助企业快速部署AI代理系统。


<details>
  <summary>Details</summary>
Motivation: 解决企业在部署AI代理时需要使用多个不同工具的问题，简化AI代理的开发和部署流程。

Method: 提供无代码工具、安全护栏和自动化质量审查功能，支持人机协作。

Result: 博世、喜力和EDP等公司已使用该平台构建AI代理系统。

Conclusion: 单一平台即可实现AI代理的快速部署，无需多个工具。

Abstract: You don't need 10 different AI tools to deploy an agent (Sponsor) It only takes 1 platform to fast track agentic AI. OutSystems Agent Workbench provides no-code tools, security guardrails, and automated quality reviews so you can deliver human-AI collaboration without the sprawl. Bosch, Heineken, and EDP are already using it to build agentic AI systems. Build with Agent Workbench

</details>


### [55] [Build better software to build software better](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fslack.engineering%2Fbuild-better-software-to-build-software-better%2F%3Futm_source=tldrdevops/1/0100019a5e35b7f2-3cf5a618-2df3-41f4-849c-9833356660ec-000000/Sbz_c1szArzdrclq3uWdrii_f22Q1NkAQgWdH76TCVQ=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 通过将Bazel与经典软件工程原则结合，Quip和Slack Canvas后端构建流水线从60分钟加速到最快25分钟（前端缓存时），整体速度提升最高达6倍。关键改进包括切断前后端依赖、用Starlark重写Python构建编排代码，以及组合细粒度工作单元。


<details>
  <summary>Details</summary>
Motivation: 改善软件构建效率，缩短构建时间，提升开发团队的开发体验和生产力。

Method: 结合Bazel构建工具与经典软件工程原则，切断前后端依赖关系，将Python构建编排代码重写为Starlark，并采用细粒度工作单元组合的方式优化构建流程。

Result: 构建时间从60分钟减少到最快25分钟（前端缓存时），整体构建速度提升最高达6倍。

Conclusion: 通过系统性的构建流程优化，可以显著提升软件构建效率，为开发团队带来更好的开发体验。

Abstract: Build better software to build software better (12 minute read) By combining Bazel with classic software engineering principles, the Quip and Slack Canvas backend build pipeline was sped up from 60 minutes to as little as 25 minutes when the frontend was cached, and up to six times faster overall. Key to the improvement was severing dependencies between the frontend and backend, rewriting Python build orchestration code in Starlark, and composing granular units of work. Analysis of the build ...

</details>


### [56] [Code research projects with async coding agents like Claude Code and Codex](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsimonwillison.net%2F2025%2FNov%2F6%2Fasync-code-research%2F%3Futm_source=tldrdevops/1/0100019a5e35b7f2-3cf5a618-2df3-41f4-849c-9833356660ec-000000/etfjDyWiE07pN0e_HOPU9h3ik4360WamQs1PjzQ3JKc=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 介绍了一种名为“代码研究”的新工作流程，使用异步编码代理（如Claude Code、Codex和Gemini Jules）自主运行实验，通过可执行的验证概念来回答编程问题。


<details>
  <summary>Details</summary>
Motivation: 传统编程问题解答方式效率较低，需要人工参与和验证。通过自动化代理运行实验，可以提高问题解答的效率和可靠性。

Method: 为这些编码代理分配专用的GitHub仓库并提供完整的网络访问权限，让开发者能够每天启动多个研究任务，这些任务独立返回可验证的结果。

Result: 该方法能够实现编程问题的自动化实验验证，提供可执行的验证概念作为答案。

Conclusion: 代码研究工作流程通过异步编码代理显著提高了编程问题解答的效率和自动化程度。

Abstract: Code research projects with async coding agents like Claude Code and Codex (8 minute read) A new workflow called “code research” uses asynchronous coding agents such as Claude Code, Codex, and Gemini Jules to autonomously run experiments that answer programming questions through executable proof-of-concepts. By assigning these agents dedicated GitHub repositories with full network access, developers can launch multiple research tasks daily that independently return verifiable results with min...

</details>


### [57] [Deepnote](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fdeepnote%2Fdeepnote%3Futm_source=tldrdevops/1/0100019a5e35b7f2-3cf5a618-2df3-41f4-849c-9833356660ec-000000/3Lru4IyqwpZShl_lLVZgtFdnz5M4F3SjdoYufZ3HG8o=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Deepnote是一个基于Jupyter的AI原生代码编辑器平台，拥有超过50万数据专业人士用户，提供AI代理、现代化UI、新块类型和原生数据集成功能。


<details>
  <summary>Details</summary>
Motivation: 为数据专业人士提供比传统Jupyter更现代化、功能更强大的协作式笔记本平台，整合AI能力提升开发效率。

Method: 开发开源平台，支持AI原生代码编辑，提供免费云访问服务，特别是面向学生和教育工作者。

Result: 成功构建了被50万数据专业人士使用的平台，作为Jupyter的继任者获得了广泛采用。

Conclusion: Deepnote通过整合AI能力和现代化设计，为数据科学工作流提供了更高效、更协作的开发环境。

Abstract: Deepnote (GitHub Repo) Deepnote, used by over 500,000 data professionals, is a successor to Jupyter that adds an AI agent, sleek UI, new block types, and native data integrations. The Deepnote open-source platform allows users to edit and run notebooks in AI-native code editors and offers free cloud access to students and educators.

</details>


### [58] [How agentic AI is changing cloud security](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.sysdig.com%2Fblog%2Fhow-agentic-ai-is-changing-cloud-security%3Futm_source=tldrdevops/1/0100019a5e35b7f2-3cf5a618-2df3-41f4-849c-9833356660ec-000000/g8-wOwKuaoCT7pdOoy3dTU73fYWJ2i4b9RqOWQ7yXXY=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Agentic AI正在将云安全从被动助手转变为能够自主推理、学习和行动的主动队友，实现更智能、快速和自适应的云防护


<details>
  <summary>Details</summary>
Motivation: 传统的云安全工具多为被动响应，需要人工干预。Agentic AI旨在通过自主代理主动分析环境、评估业务风险并采取行动，提升云安全防护的效率和适应性

Method: Sysdig采用自主代理方法，这些代理能够分析云环境、评估业务风险，并主动采取措施加强防御

Result: 该方法实现了云安全从被动到主动的转变，使安全防护更加智能、快速和自适应

Conclusion: Agentic AI正在彻底改变云安全范式，通过自主代理实现更高效、主动的安全防护

Abstract: How agentic AI is changing cloud security (5 minute read) Agentic AI transforms cloud security by evolving from passive copilots to proactive teammates capable of reasoning, learning, and acting autonomously. Sysdig's approach uses autonomous agents that analyze environments, assess business risk, and take action to strengthen defenses, marking a shift toward smarter, faster, and more adaptive cloud protection.

</details>


### [59] [Accelerating LLM inference with speculative decoding: Lessons from LinkedIn's Hiring Assistant](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Fblog%2Fengineering%2Fai%2Faccelerating-llm-inference-with-speculative-decoding-lessons-from-linkedins-hiring-assistant%3Futm_source=tldrdevops/1/0100019a5e35b7f2-3cf5a618-2df3-41f4-849c-9833356660ec-000000/WRoB4wyk9U7VdwjB1PlDQXuJDAJPpCQUii7tESOqdOs=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: LinkedIn的招聘助手采用n-gram推测解码技术来加速LLM推理，在保持质量的同时实现了近4倍的吞吐量提升和66%的P90端到端延迟降低。


<details>
  <summary>Details</summary>
Motivation: 解决LinkedIn招聘助手AI代理在文本生成过程中的延迟问题，提升用户体验的响应速度。

Method: 使用n-gram推测解码技术来加速大型语言模型的推理过程。

Result: 在相同QPS下实现了近4倍的吞吐量提升，P90端到端延迟降低了66%。

Conclusion: 推测解码技术能有效加速LLM推理而不牺牲质量，显著改善AI代理的性能表现。

Abstract: Accelerating LLM inference with speculative decoding: Lessons from LinkedIn's Hiring Assistant (5 minute read) LinkedIn's Hiring Assistant, the company's first AI agent for recruiters, now uses n-gram speculative decoding to address latency challenges and improve the responsiveness of the user experience. The technique accelerates text generation without sacrificing quality and resulted in a nearly 4x higher throughput at the same queries per second, as well as a 66% reduction in P90 end-to-e...

</details>


### [60] [Reining in your AI coding agents with complete enterprise context](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.tabnine.com%2Fwebinar%2Fbeyond-autocomplete-how-agentic-ai-is-rewriting-enterprise-software%2F%3Futm_campaign=219047143-Agentic%2520Launch%26utm_source=tldr%26utm_medium=quicklinks/2/0100019a5e391d7e-ded80193-111e-4e53-8496-155a8791a352-000000/bOeq7CZQjJXCKBohQgzkQRlH_3Feg6m1hJuF3X7KMwM=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 企业级AI编码代理需要完整上下文才能有效工作，包括代码、标准、合规规则和知识库等


<details>
  <summary>Details</summary>
Motivation: AI编码代理默认不会遵循企业规则，需要完整的企业上下文才能有效工作

Method: 通过上下文感知的代理AI在真实企业开发环境中工作

Result: 展示了上下文感知代理AI在企业开发环境中的实际应用

Conclusion: 完整的企业上下文是AI编码代理成功部署的关键

Abstract: Reining in your AI coding agents with complete enterprise context (Sponsor) AI doesn't want to follow your rules by default. But there is a solution...Even enterprises with highly complex codebases use agentic AI to drive development - as long as agents have complete context. This goes beyond just code and includes standards, compliance rules, knowledge bases, and more.In this webinar, Tabnine will demonstrate how context-aware agentic AI works inside a real enterprise dev environment. Join t...

</details>


### [61] [Build better software to build software better](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fslack.engineering%2Fbuild-better-software-to-build-software-better%3Futm_source=tldrwebdev/1/0100019a5e391d7e-ded80193-111e-4e53-8496-155a8791a352-000000/aWCWCP8ISiE64zZT8mHwie7sRN_FK5xVtR59NPhElQc=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Slack工程团队通过应用Bazel和经典软件工程原则，将构建流水线时间从60分钟大幅减少


<details>
  <summary>Details</summary>
Motivation: 解决构建流水线时间过长的问题，提高开发效率和团队生产力

Method: 使用Bazel构建系统，实施缓存、并行化和更好的粒度控制等软件工程优化原则

Result: 成功将构建时间从60分钟显著缩短

Conclusion: 将构建性能优化视为代码性能优化，应用经典软件工程原则可以有效提升构建效率

Abstract: Build better software to build software better (8 minute read) Slack's engineering team reduced its build pipeline time from 60 minutes by applying classic software engineering principles to its build system using Bazel. They treated build performance optimization like code performance optimization by implementing caching (storing results of expensive build work), parallelization (spreading work across multiple compute resources), and better granularity (breaking work into smaller, more effic...

</details>


### [62] [You Should Write An Agent](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ffly.io%2Fblog%2Feveryone-write-an-agent%2F%3Futm_source=tldrwebdev/1/0100019a5e391d7e-ded80193-111e-4e53-8496-155a8791a352-000000/flwi95GpJRhU06lQJBJC7VJsSq3xrYt0kqw6Q5RTQUU=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 本文介绍了如何创建具有个性和工具集成的基本LLM代理，展示了设置LLM与环境交互循环的简易性，并强调了理解上下文工程、令牌限制和代理设计决策对于构建有效安全代理的重要性。


<details>
  <summary>Details</summary>
Motivation: 鼓励开发者尝试LLM代理，因为它们实际上实现起来相当简单，通过展示基础代理的创建过程来降低入门门槛。

Method: 通过创建具有个性和工具集成的基本代理，设置LLM与环境交互的循环，并考虑上下文工程、令牌限制等设计因素。

Result: 展示了构建LLM代理的实际可行性，证明了即使是基础代理也能实现有效的环境交互功能。

Conclusion: LLM代理的实现并不复杂，开发者应该积极尝试，同时需要重视上下文工程、令牌限制和安全设计等关键因素。

Abstract: You Should Write An Agent (13 minute read) Devs should experiment with LLM agents as they are actually quite simple to implement. This article goes over how to create basic agents with personalities and tool integration, showing how easy it is to set up a loop where an LLM interacts with the environment. Understanding context engineering, token limits, and agent design decisions is necessary for building effective and secure agents.

</details>


### [63] [1,500+ PRs Later: Spotify's Journey with Our Background Coding Agent](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fengineering.atspotify.com%2F2025%2F11%2Fspotifys-background-coding-agent-part-1%3Futm_source=tldrwebdev/1/0100019a5e391d7e-ded80193-111e-4e53-8496-155a8791a352-000000/0YYwdDZrg2nqbo1eFlHuB36jYfb4QkBeroVoS2kPHtI=430)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Spotify成功将AI编码代理集成到其舰队管理系统中，生成了1500多个合并的拉取请求，用于自动化代码维护任务，如依赖更新、语言现代化和复杂迁移。


<details>
  <summary>Details</summary>
Motivation: 自动化代码维护任务，减少工程师手动处理依赖更新、语言现代化和复杂迁移等重复性工作的时间。

Method: 在舰队管理系统中集成AI编码代理，允许工程师定义舰队范围的变更，由AI代理自动执行代码维护任务。

Result: 生成了1500多个合并的拉取请求，将手动编码时间减少了60-90%。

Conclusion: AI编码代理在自动化代码维护方面取得了显著成功，大幅提高了效率。

Abstract: 1,500+ PRs Later: Spotify's Journey with Our Background Coding Agent (Part 1) (8 minute read) Spotify has successfully integrated AI coding agents into its Fleet Management system, which has generated over 1,500 merged pull requests for automated code maintenance tasks like dependency updates, language modernization, and complex migrations. The AI-powered approach has reduced manual coding time by 60-90% compared to traditional methods and allows engineers to define fleet-wide changes using n...

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [64] [Real-Time Reasoning Agents in Evolving Environments](https://arxiv.org/abs/2511.04898)
*Yule Wen,Yixin Ye,Yanzhe Zhang,Diyi Yang,Hao Zhu*

Main category: cs.AI

TL;DR: 提出了实时推理作为动态环境中智能体的新问题框架，构建了Real-Time Reasoning Gym测试平台，比较了反应式智能体和规划式智能体两种范式，并提出了同时使用两种推理范式的AgileThinker方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的智能体需要在动态环境中同时做出逻辑性和及时性的判断，而现有语言模型推理方法未能充分考虑环境的动态特性。

Method: 构建Real-Time Reasoning Gym测试平台，研究反应式智能体（有限推理计算）和规划式智能体（扩展推理计算）两种范式，提出同时使用两种推理范式的AgileThinker方法。

Result: 实验表明即使最先进的模型也难以在两种范式中同时做出逻辑性和及时性的判断，而AgileThinker在任务难度和时间压力增加时始终优于单一推理范式的智能体。

Conclusion: 实时推理是开发实用智能体的关键测试平台，为时间约束AI系统研究提供了基础，指明了实现实时能力智能体的路径。

Abstract: Agents in the real world must make not only logical but also timely
judgments. This requires continuous awareness of the dynamic environment:
hazards emerge, opportunities arise, and other agents act, while the agent's
reasoning is still unfolding. Despite advances in language model reasoning,
existing approaches fail to account for this dynamic nature. We introduce
real-time reasoning as a new problem formulation for agents in evolving
environments and build Real-Time Reasoning Gym to demonstrate it. We study two
paradigms for deploying language models in agents: (1) reactive agents, which
employ language models with bounded reasoning computation for rapid responses,
and (2) planning agents, which allow extended reasoning computation for complex
problems. Our experiments show that even state-of-the-art models struggle with
making logical and timely judgments in either paradigm. To address this
limitation, we propose AgileThinker, which simultaneously engages both
reasoning paradigms. AgileThinker consistently outperforms agents engaging only
one reasoning paradigm as the task difficulty and time pressure rise,
effectively balancing reasoning depth and response latency. Our work
establishes real-time reasoning as a critical testbed for developing practical
agents and provides a foundation for research in temporally constrained AI
systems, highlighting a path toward real-time capable agents.

</details>


### [65] [Reasoning Is All You Need for Urban Planning AI](https://arxiv.org/abs/2511.05375)
*Sijie Yang,Jiatong Li,Filip Biljecki*

Main category: cs.AI

TL;DR: 提出了一个基于推理AI的智能城市规划框架，通过多智能体协作实现价值导向、规则约束和可解释的规划决策，增强而非替代人类规划师的判断能力。


<details>
  <summary>Details</summary>
Motivation: 传统AI在城市规划中主要进行数据分析预测，但缺乏透明推理和决策能力。需要开发能够考虑约束条件、利益相关者价值并进行透明推理的AI辅助决策系统。

Method: 提出了Agentic Urban Planning AI Framework，包含三个认知层（感知、基础、推理）和六个逻辑组件（分析、生成、验证、评估、协作、决策），通过多智能体协作框架实现。

Result: 框架展示了AI智能体如何系统探索解决方案空间、验证法规合规性、透明地权衡利弊，为人类规划师提供计算推理能力支持。

Conclusion: 该框架表明AI智能体可以通过计算推理能力增强人类规划师的判断，而不是替代他们，为城市规划决策提供透明、可解释的辅助工具。

Abstract: AI has proven highly successful at urban planning analysis -- learning
patterns from data to predict future conditions. The next frontier is
AI-assisted decision-making: agents that recommend sites, allocate resources,
and evaluate trade-offs while reasoning transparently about constraints and
stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,
ReAct, and multi-agent collaboration frameworks -- now make this vision
achievable.
  This position paper presents the Agentic Urban Planning AI Framework for
reasoning-capable planning agents that integrates three cognitive layers
(Perception, Foundation, Reasoning) with six logic components (Analysis,
Generation, Verification, Evaluation, Collaboration, Decision) through a
multi-agents collaboration framework. We demonstrate why planning decisions
require explicit reasoning capabilities that are value-based (applying
normative principles), rule-grounded (guaranteeing constraint satisfaction),
and explainable (generating transparent justifications) -- requirements that
statistical learning alone cannot fulfill. We compare reasoning agents with
statistical learning, present a comprehensive architecture with benchmark
evaluation metrics, and outline critical research challenges. This framework
shows how AI agents can augment human planners by systematically exploring
solution spaces, verifying regulatory compliance, and deliberating over
trade-offs transparently -- not replacing human judgment but amplifying it with
computational reasoning capabilities.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [66] [Agentic Refactoring: An Empirical Study of AI Coding Agents](https://arxiv.org/abs/2511.04824)
*Kosei Horikawa,Hao Li,Yutaro Kashiwa,Bram Adams,Hajimu Iida,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 该论文对AI代理在真实开源Java项目中的重构活动进行了大规模实证研究，发现重构是AI开发范式中的常见活动，代理主要进行低层次、一致性导向的编辑，相比人类更关注局部改进而非高层次设计变更。


<details>
  <summary>Details</summary>
Motivation: AI代理编码工具正在改变软件工程格局，但缺乏关于代理重构实践、与人类重构比较及其对代码质量影响的实证理解。

Method: 基于AIDev数据集，分析了15,451个重构实例，涵盖12,256个拉取请求和14,988次提交，对Java项目进行大规模实证研究。

Result: 重构是AI开发范式中的常见活动（26.1%的提交明确针对重构），代理重构主要集中于低层次编辑（如变量类型更改11.8%、参数重命名10.4%），动机主要是可维护性（52.5%）和可读性（28.1%），在结构指标上带来小而显著的改进。

Conclusion: AI代理重构主要关注局部代码质量改进，与人类重构形成互补，为理解AI在软件工程中的实际应用提供了重要见解。

Abstract: Agentic coding tools, such as OpenAI Codex, Claude Code, and Cursor, are
transforming the software engineering landscape. These AI-powered systems
function as autonomous teammates capable of planning and executing complex
development tasks. Agents have become active participants in refactoring, a
cornerstone of sustainable software development aimed at improving internal
code quality without altering observable behavior. Despite their increasing
adoption, there is a critical lack of empirical understanding regarding how
agentic refactoring is utilized in practice, how it compares to human-driven
refactoring, and what impact it has on code quality. To address this empirical
gap, we present a large-scale study of AI agent-generated refactorings in
real-world open-source Java projects, analyzing 15,451 refactoring instances
across 12,256 pull requests and 14,988 commits derived from the AIDev dataset.
Our empirical analysis shows that refactoring is a common and intentional
activity in this development paradigm, with agents explicitly targeting
refactoring in 26.1% of commits. Analysis of refactoring types reveals that
agentic efforts are dominated by low-level, consistency-oriented edits, such as
Change Variable Type (11.8%), Rename Parameter (10.4%), and Rename Variable
(8.5%), reflecting a preference for localized improvements over the high-level
design changes common in human refactoring. Additionally, the motivations
behind agentic refactoring focus overwhelmingly on internal quality concerns,
with maintainability (52.5%) and readability (28.1%). Furthermore, quantitative
evaluation of code quality metrics shows that agentic refactoring yields small
but statistically significant improvements in structural metrics, particularly
for medium-level changes, reducing class size and complexity (e.g., Class LOC
median $\Delta$ = -15.25).

</details>


### [67] [Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach](https://arxiv.org/abs/2511.04849)
*Quang-Dung Nguyen,Tri-Dung Tran,Thanh-Hieu Chu,Hoang-Loc Tran,Xiangwei Cheng,Dirk Slama*

Main category: cs.SE

TL;DR: 该研究探讨了使用提示工程策略来优化大型语言模型在软件定义车辆代码生成中的表现，发现少量样本提示策略在调整模型输出以匹配预期结果方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 软件定义车辆的发展需要高效代码生成工具，但专有模型架构的限制阻碍了大型语言模型在此特定任务中的应用，因此研究如何通过提示工程来优化模型表现。

Method: 使用系统提示和先进的提示工程技术设计高效提示结构，在不同模型上进行广泛实验，包括裸模型和各种提示技术，使用专门创建的基准来评估模型在SDV代码生成中的性能。

Result: 结果显示，采用少量样本提示策略的模型在定量指标上表现最优，能够更好地调整LLM输出以匹配预期结果。

Conclusion: 仅通过精心设计的系统提示，无需训练会话或访问基础设计，就能有效优化大型语言模型在软件定义车辆代码生成任务中的表现。

Abstract: The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in
the automotive industry, where software now plays a pivotal role in defining
vehicle functionality, enabling rapid innovation of modern vehicles. Developing
SDV-specific applications demands advanced tools to streamline code generation
and improve development efficiency. In recent years, general-purpose large
language models (LLMs) have demonstrated transformative potential across
domains. Still, restricted access to proprietary model architectures hinders
their adaption to specific tasks like SDV code generation. In this study, we
propose using prompts, a common and basic strategy to interact with LLMs and
redirect their responses. Using only system prompts with an appropriate and
efficient prompt structure designed using advanced prompt engineering
techniques, LLMs can be crafted without requiring a training session or access
to their base design. This research investigates the extensive experiments on
different models by applying various prompting techniques, including bare
models, using a benchmark specifically created to evaluate LLMs' performance in
generating SDV code. The results reveal that the model with a few-shot
prompting strategy outperforms the others in adjusting the LLM answers to match
the expected outcomes based on quantitative metrics.

</details>


### [68] [CodeMapper: A Language-Agnostic Approach to Mapping Code Regions Across Commits](https://arxiv.org/abs/2511.05205)
*Huimin Hu,Michael Pradel*

Main category: cs.SE

TL;DR: CodeMapper解决了代码映射问题，能够在不同提交之间找到特定代码区域的对应关系，支持多种编程语言和代码元素类型。


<details>
  <summary>Details</summary>
Motivation: 现有工具如git diff无法聚焦开发者选择的特定代码区域，而其他技术又局限于特定编程语言和代码元素，因此需要一种通用的代码映射方法。

Method: CodeMapper采用两阶段方法：第一阶段通过分析差异、检测代码移动和搜索特定代码片段来计算候选区域；第二阶段通过计算相似度选择最可能的目标区域。

Result: 在四个数据集上的评估显示，CodeMapper能正确识别71.0%-94.5%的预期目标区域，比现有最佳基线方法提升了1.5-58.8个百分点。

Conclusion: CodeMapper提供了一种独立于特定程序元素和编程语言的代码映射解决方案，显著提升了代码区域映射的准确性。

Abstract: During software evolution, developers commonly face the problem of mapping a
specific code region from one commit to another. For example, they may want to
determine how the condition of an if-statement, a specific line in a
configuration file, or the definition of a function changes. We call this the
code mapping problem. Existing techniques, such as git diff, address this
problem only insufficiently because they show all changes made to a file
instead of focusing on a code region of the developer's choice. Other
techniques focus on specific code elements and programming languages (e.g.,
methods in Java), limiting their applicability. This paper introduces
CodeMapper, an approach to address the code mapping problem in a way that is
independent of specific program elements and programming languages. Given a
code region in one commit, CodeMapper finds the corresponding region in another
commit. The approach consists of two phases: (i) computing candidate regions by
analyzing diffs, detecting code movements, and searching for specific code
fragments, and (ii) selecting the most likely target region by calculating
similarities. Our evaluation applies CodeMapper to four datasets, including two
new hand-annotated datasets containing code region pairs in ten popular
programming languages. CodeMapper correctly identifies the expected target
region in 71.0%--94.5% of all cases, improving over the best available
baselines by 1.5--58.8 absolute percent points.

</details>


### [69] [Code Review Automation using Retrieval Augmented Generation](https://arxiv.org/abs/2511.05302)
*Qianru Meng,Xiao Zhang,Zhaochen Ren,Joost Visser*

Main category: cs.SE

TL;DR: 提出了RARe方法，结合检索和生成技术，利用RAG框架将外部领域知识融入代码审查过程，显著提升了自动化代码审查的质量。


<details>
  <summary>Details</summary>
Motivation: 自动化代码审查虽然能减轻人工负担，但现有方法生成的评论要么偏离重点，要么过于笼统，需要更准确和具体的审查意见。

Method: 使用密集检索器从代码库中选择最相关的审查记录，然后利用LLM的上下文学习能力生成最终审查意见，结合了检索式和生成式方法的优势。

Result: 在两个基准数据集上超越了现有最优方法，BLEU-4得分分别达到12.32和12.96，并通过人工评估和案例研究验证了其有效性。

Conclusion: RARe方法通过整合外部知识显著提升了自动化代码审查的质量，证明了RAG框架在此任务中的实用性和可靠性。

Abstract: Code review is essential for maintaining software quality but is
labor-intensive. Automated code review generation offers a promising solution
to this challenge. Both deep learning-based generative techniques and
retrieval-based methods have demonstrated strong performance in this task.
However, despite these advancements, there are still some limitations where
generated reviews can be either off-point or overly general. To address these
issues, we introduce Retrieval-Augmented Reviewer (RARe), which leverages
Retrieval-Augmented Generation (RAG) to combine retrieval-based and generative
methods, explicitly incorporating external domain knowledge into the code
review process. RARe uses a dense retriever to select the most relevant reviews
from the codebase, which then enrich the input for a neural generator,
utilizing the contextual learning capacity of large language models (LLMs), to
produce the final review. RARe outperforms state-of-the-art methods on two
benchmark datasets, achieving BLEU-4 scores of 12.32 and 12.96, respectively.
Its effectiveness is further validated through a detailed human evaluation and
a case study using an interpretability tool, demonstrating its practical
utility and reliability.

</details>


### [70] [SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models](https://arxiv.org/abs/2511.05459)
*Jingxuan Xu,Ken Deng,Weihao Li,Songwei Yu,Huaixi Tang,Haoyang Huang,Zhiyi Lai,Zizheng Zhan,Yanan Wu,Chenchen Zhang,Kepeng Lei,Yifan Yao,Xinping Lei,Wenqiang Zhu,Zongxian Feng,Han Li,Junqi Xiong,Dailin Li,Zuchen Gao,Kun Wu,Wen Xiang,Ziqi Zhan,Yuanxing Zhang,Wuxuan Gong,Ziyuan Gao,Guanxiang Wang,Yirong Xue,Xiaojiang Zhang,Jinghui Wang,Huiming Wang,Wenhao Zhuang,Zhaoxiang Zhang,Yuqun Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu*

Main category: cs.SE

TL;DR: SWE-Compass是一个全面的软件工程基准测试，涵盖8种任务类型、8种编程场景和10种编程语言，包含2000个来自真实GitHub拉取请求的高质量实例，用于评估LLM在软件工程中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM在软件工程中能力的基准测试存在任务覆盖范围窄、语言偏见和与真实开发者工作流程不够匹配的问题，需要更全面的评估框架。

Method: 引入SWE-Compass基准测试，统一异构代码相关评估到结构化且与生产环境对齐的框架中，基于真实GitHub拉取请求构建2000个高质量实例，并在两种代理框架(SWE-Agent和Claude Code)下评估十个最先进的LLM。

Result: 揭示了不同任务类型、语言和场景之间的难度层次结构，为诊断和推进LLM在代理编码能力方面提供了严格且可复现的基础。

Conclusion: SWE-Compass通过与真实世界开发者实践对齐，为评估和提升LLM在软件工程中的能力提供了全面且实用的基准测试框架。

Abstract: Evaluating large language models (LLMs) for software engineering has been
limited by narrow task coverage, language bias, and insufficient alignment with
real-world developer workflows. Existing benchmarks often focus on algorithmic
problems or Python-centric bug fixing, leaving critical dimensions of software
engineering underexplored. To address these gaps, we introduce SWE-Compass1, a
comprehensive benchmark that unifies heterogeneous code-related evaluations
into a structured and production-aligned framework. SWE-Compass spans 8 task
types, 8 programming scenarios, and 10 programming languages, with 2000
high-quality instances curated from authentic GitHub pull requests and refined
through systematic filtering and validation. We benchmark ten state-of-the-art
LLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear
hierarchy of difficulty across task types, languages, and scenarios. Moreover,
by aligning evaluation with real-world developer practices, SWE-Compass
provides a rigorous and reproducible foundation for diagnosing and advancing
agentic coding capabilities in large language models.

</details>


### [71] [A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](https://arxiv.org/abs/2511.05476)
*Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy*

Main category: cs.SE

TL;DR: 提出了MetaCompress框架，通过蜕变测试系统评估代码语言模型知识蒸馏中的行为保真度，发现传统准确率评估无法捕捉师生模型间的深层行为差异。


<details>
  <summary>Details</summary>
Motivation: 当前代码语言模型部署面临高计算成本和环境影响，知识蒸馏是压缩模型的有效方法，但现有准确率评估无法深入评估学生模型对教师模型行为模仿的程度。

Method: 提出MetaCompress蜕变测试框架，通过行为保持的蜕变关系系统比较师生模型的输出，评估行为保真度。在三个知识蒸馏技术(Compressor、AVATAR、MORPH)上验证。

Result: MetaCompress识别出学生模型中高达62%的行为差异，传统评估下学生模型在对抗攻击中性能下降高达285%。

Conclusion: 知识蒸馏管道中需要行为保真度评估，MetaCompress是测试压缩代码语言模型的实用框架。

Abstract: Transformer-based language models of code have achieved state-of-the-art
performance across a wide range of software analytics tasks, but their
practical deployment remains limited due to high computational costs, slow
inference speeds, and significant environmental impact. To address these
challenges, recent research has increasingly explored knowledge distillation as
a method for compressing a large language model of code (the teacher) into a
smaller model (the student) while maintaining performance. However, the degree
to which a student model deeply mimics the predictive behavior and internal
representations of its teacher remains largely unexplored, as current
accuracy-based evaluation provides only a surface-level view of model quality
and often fails to capture more profound discrepancies in behavioral fidelity
between the teacher and student models. To address this gap, we empirically
show that the student model often fails to deeply mimic the teacher model,
resulting in up to 285% greater performance drop under adversarial attacks,
which is not captured by traditional accuracy-based evaluation. Therefore, we
propose MetaCompress, a metamorphic testing framework that systematically
evaluates behavioral fidelity by comparing the outputs of teacher and student
models under a set of behavior-preserving metamorphic relations. We evaluate
MetaCompress on two widely studied tasks, using compressed versions of popular
language models of code, obtained via three different knowledge distillation
techniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress
identifies up to 62% behavioral discrepancies in student models, underscoring
the need for behavioral fidelity evaluation within the knowledge distillation
pipeline and establishing MetaCompress as a practical framework for testing
compressed language models of code derived through knowledge distillation.

</details>
