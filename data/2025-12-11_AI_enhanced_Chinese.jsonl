{"id": "2512.09006", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.09006", "abs": "https://arxiv.org/abs/2512.09006", "authors": ["Dyna Soumhane Ouchebara", "St\u00e9phane Dupont"], "title": "Llama-based source code vulnerability detection: Prompt engineering vs Fine tuning", "comment": "20 pages, Accepted at ESORICS 2025", "summary": "The significant increase in software production, driven by the acceleration of development cycles over the past two decades, has led to a steady rise in software vulnerabilities, as shown by statistics published yearly by the CVE program. The automation of the source code vulnerability detection (CVD) process has thus become essential, and several methods have been proposed ranging from the well established program analysis techniques to the more recent AI-based methods. Our research investigates Large Language Models (LLMs), which are considered among the most performant AI models to date, for the CVD task. The objective is to study their performance and apply different state-of-the-art techniques to enhance their effectiveness for this task. We explore various fine-tuning and prompt engineering settings. We particularly suggest one novel approach for fine-tuning LLMs which we call Double Fine-tuning, and also test the understudied Test-Time fine-tuning approach. We leverage the recent open-source Llama-3.1 8B, with source code samples extracted from BigVul and PrimeVul datasets. Our conclusions highlight the importance of fine-tuning to resolve the task, the performance of Double tuning, as well as the potential of Llama models for CVD. Though prompting proved ineffective, Retrieval augmented generation (RAG) performed relatively well as an example selection technique. Overall, some of our research questions have been answered, and many are still on hold, which leaves us many future work perspectives. Code repository is available here: https://github.com/DynaSoumhaneOuchebara/Llama-based-vulnerability-detection.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u7d22\u4f7f\u7528Llama-3.1 8B\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u901a\u8fc7\u53cc\u91cd\u5fae\u8c03\u548c\u6d4b\u8bd5\u65f6\u5fae\u8c03\u7b49\u65b9\u6cd5\u63d0\u5347\u6027\u80fd\uff0c\u53d1\u73b0\u5fae\u8c03\u5bf9\u4efb\u52a1\u89e3\u51b3\u81f3\u5173\u91cd\u8981\uff0c\u800c\u63d0\u793a\u5de5\u7a0b\u6548\u679c\u6709\u9650\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u5468\u671f\u52a0\u901f\u5bfc\u81f4\u8f6f\u4ef6\u6f0f\u6d1e\u6570\u91cf\u6301\u7eed\u589e\u957f\uff0c\u81ea\u52a8\u5316\u6f0f\u6d1e\u68c0\u6d4b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5f53\u524d\u6027\u80fd\u6700\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6e90\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5e94\u7528\u5404\u79cd\u5148\u8fdb\u6280\u672f\u63d0\u5347\u5176\u6548\u679c\u3002", "method": "\u4f7f\u7528Llama-3.1 8B\u5f00\u6e90\u6a21\u578b\uff0c\u4eceBigVul\u548cPrimeVul\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6e90\u4ee3\u7801\u6837\u672c\u3002\u63a2\u7d22\u591a\u79cd\u5fae\u8c03\u548c\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u7279\u522b\u63d0\u51fa\u53cc\u91cd\u5fae\u8c03\u65b9\u6cd5\uff0c\u5e76\u6d4b\u8bd5\u4e86\u8f83\u5c11\u7814\u7a76\u7684\u6d4b\u8bd5\u65f6\u5fae\u8c03\u65b9\u6cd5\uff0c\u540c\u65f6\u8bc4\u4f30\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4f5c\u4e3a\u793a\u4f8b\u9009\u62e9\u6280\u672f\u7684\u6548\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5fae\u8c03\u5bf9\u89e3\u51b3\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u53cc\u91cd\u5fae\u8c03\u8868\u73b0\u51fa\u826f\u597d\u6027\u80fd\uff0cLlama\u6a21\u578b\u5728\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002\u63d0\u793a\u5de5\u7a0b\u6548\u679c\u4e0d\u4f73\uff0c\u4f46\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4f5c\u4e3a\u793a\u4f8b\u9009\u62e9\u6280\u672f\u8868\u73b0\u76f8\u5bf9\u8f83\u597d\u3002", "conclusion": "\u7814\u7a76\u90e8\u5206\u95ee\u9898\u5f97\u5230\u89e3\u7b54\uff0c\u4f46\u4ecd\u6709\u8bb8\u591a\u95ee\u9898\u5f85\u89e3\u51b3\uff0c\u4e3a\u672a\u6765\u5de5\u4f5c\u63d0\u4f9b\u4e86\u591a\u4e2a\u7814\u7a76\u65b9\u5411\u3002\u5fae\u8c03\u662f\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\u7684\u5173\u952e\uff0cLlama\u6a21\u578b\u5728\u8be5\u9886\u57df\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002", "topic": "code agent"}}
{"id": "2512.09108", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09108", "abs": "https://arxiv.org/abs/2512.09108", "authors": ["Paul Brookes", "Vardan Voskanyan", "Rafail Giavrimis", "Matthew Truscott", "Mina Ilieva", "Chrystalla Pavlou", "Alexandru Staicu", "Manal Adham", "Will Evers- Hood", "Jingzhi Gong", "Kejia Zhang", "Matvey Fedoseev", "Vishal Sharma", "Roman Bauer", "Zheng Wang", "Hema Nair", "Wei Jie", "Tianhua Xu", "Aurora Constantin", "Leslie Kanthan", "Michail Basios"], "title": "Evolving Excellence: Automated Optimization of LLM-based Agents", "comment": null, "summary": "Agentic AI systems built on large language models (LLMs) offer significant potential for automating complex workflows, from software development to customer support. However, LLM agents often underperform due to suboptimal configurations; poorly tuned prompts, tool descriptions, and parameters that typically require weeks of manual refinement. Existing optimization methods either are too complex for general use or treat components in isolation, missing critical interdependencies.\n  We present ARTEMIS, a no-code evolutionary optimization platform that jointly optimizes agent configurations through semantically-aware genetic operators. Given only a benchmark script and natural language goals, ARTEMIS automatically discovers configurable components, extracts performance signals from execution logs, and evolves configurations without requiring architectural modifications.\n  We evaluate ARTEMIS on four representative agent systems: the \\emph{ALE Agent} for competitive programming on AtCoder Heuristic Contest, achieving a \\textbf{$13.6\\%$ improvement} in acceptance rate; the \\emph{Mini-SWE Agent} for code optimization on SWE-Perf, with a statistically significant \\textbf{10.1\\% performance gain}; and the \\emph{CrewAI Agent} for cost and mathematical reasoning on Math Odyssey, achieving a statistically significant \\textbf{$36.9\\%$ reduction} in the number of tokens required for evaluation. We also evaluate the \\emph{MathTales-Teacher Agent} powered by a smaller open-source model (Qwen2.5-7B) on GSM8K primary-level mathematics problems, achieving a \\textbf{22\\% accuracy improvement} and demonstrating that ARTEMIS can optimize agents based on both commercial and local models.", "AI": {"tldr": "ARTEMIS\u662f\u4e00\u4e2a\u65e0\u9700\u4ee3\u7801\u7684\u8fdb\u5316\u4f18\u5316\u5e73\u53f0\uff0c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7684\u9057\u4f20\u7b97\u5b50\u8054\u5408\u4f18\u5316AI\u4ee3\u7406\u914d\u7f6e\uff0c\u5728\u591a\u4e2a\u4ee3\u7406\u7cfb\u7edf\u4e0a\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684AI\u4ee3\u7406\u7cfb\u7edf\u5728\u81ea\u52a8\u5316\u590d\u6742\u5de5\u4f5c\u6d41\u7a0b\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u901a\u5e38\u56e0\u914d\u7f6e\u4e0d\u4f73\u800c\u8868\u73b0\u4e0d\u4f73\u3002\u73b0\u6709\u4f18\u5316\u65b9\u6cd5\u8981\u4e48\u8fc7\u4e8e\u590d\u6742\uff0c\u8981\u4e48\u5b64\u7acb\u5904\u7406\u7ec4\u4ef6\uff0c\u5ffd\u7565\u4e86\u5173\u952e\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u3002", "method": "ARTEMIS\u662f\u4e00\u4e2a\u65e0\u9700\u4ee3\u7801\u7684\u8fdb\u5316\u4f18\u5316\u5e73\u53f0\uff0c\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u7684\u9057\u4f20\u7b97\u5b50\u8054\u5408\u4f18\u5316\u4ee3\u7406\u914d\u7f6e\u3002\u7ed9\u5b9a\u57fa\u51c6\u811a\u672c\u548c\u81ea\u7136\u8bed\u8a00\u76ee\u6807\uff0c\u5b83\u80fd\u81ea\u52a8\u53d1\u73b0\u53ef\u914d\u7f6e\u7ec4\u4ef6\uff0c\u4ece\u6267\u884c\u65e5\u5fd7\u4e2d\u63d0\u53d6\u6027\u80fd\u4fe1\u53f7\uff0c\u5e76\u5728\u65e0\u9700\u67b6\u6784\u4fee\u6539\u7684\u60c5\u51b5\u4e0b\u8fdb\u5316\u914d\u7f6e\u3002", "result": "\u5728\u56db\u4e2a\u4ee3\u8868\u6027\u4ee3\u7406\u7cfb\u7edf\u4e0a\u8bc4\u4f30\uff1aALE Agent\u5728AtCoder Heuristic Contest\u4e0a\u63a5\u53d7\u7387\u63d0\u534713.6%\uff1bMini-SWE Agent\u5728SWE-Perf\u4e0a\u6027\u80fd\u663e\u8457\u63d0\u534710.1%\uff1bCrewAI Agent\u5728Math Odyssey\u4e0a\u8bc4\u4f30\u6240\u9700token\u6570\u663e\u8457\u51cf\u5c1136.9%\uff1b\u57fa\u4e8eQwen2.5-7B\u7684MathTales-Teacher Agent\u5728GSM8K\u4e0a\u51c6\u786e\u7387\u63d0\u534722%\u3002", "conclusion": "ARTEMIS\u80fd\u591f\u6709\u6548\u4f18\u5316\u57fa\u4e8e\u5546\u4e1a\u548c\u672c\u5730\u6a21\u578b\u7684AI\u4ee3\u7406\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u6216\u67b6\u6784\u4fee\u6539\u3002", "topic": "agent analysis"}}
{"id": "2512.09088", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09088", "abs": "https://arxiv.org/abs/2512.09088", "authors": ["Adrian Ryser", "Florian Allwein", "Tim Schlippe"], "title": "Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study", "comment": null, "summary": "Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in everyday use, we conducted a qualitative study with 192 participants. Our findings show that hallucinations do not result in blanket mistrust but instead lead to context-sensitive trust calibration. Building on the calibrated trust model by Lee & See [2] and Afroogh et al.'s trust-related factors [3], we confirm expectancy [3], [4], prior experience [3], [4], [5], and user expertise & domain knowledge [3], [4] as userrelated (human) trust factors, and identify intuition as an additional factor relevant for hallucination detection. Additionally, we found that trust dynamics are further influenced by contextual factors, particularly perceived risk [3] and decision stakes [6]. Consequently, we validate the recursive trust calibration process proposed by Bl\u00f6baum [7] and extend it by including intuition as a user-related trust factor. Based on these insights, we propose practical recommendations for responsible and reflective LLM use.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u5982\u4f55\u5f71\u54cd\u7528\u6237\u4fe1\u4efb\uff0c\u53d1\u73b0\u5e7b\u89c9\u4e0d\u4f1a\u5bfc\u81f4\u5168\u9762\u4e0d\u4fe1\u4efb\uff0c\u800c\u662f\u5f15\u53d1\u60c5\u5883\u654f\u611f\u7684\u4fe1\u4efb\u6821\u51c6\uff0c\u5e76\u8bc6\u522b\u51fa\u76f4\u89c9\u4f5c\u4e3a\u65b0\u7684\u7528\u6237\u76f8\u5173\u4fe1\u4efb\u56e0\u7d20\u3002", "motivation": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u7684\u5e7b\u89c9\uff08\u770b\u4f3c\u5408\u7406\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u8f93\u51fa\uff09\u5982\u4f55\u5f71\u54cd\u7528\u6237\u5bf9LLM\u7684\u4fe1\u4efb\u4ee5\u53ca\u7528\u6237\u4e0eLLM\u7684\u4e92\u52a8\u65b9\u5f0f\uff0c\u7279\u522b\u662f\u5728\u65e5\u5e38\u4f7f\u7528\u573a\u666f\u4e2d\u3002", "method": "\u91c7\u7528\u5b9a\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u5bf9192\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u7814\u7a76\uff0c\u63a2\u7d22\u5e7b\u89c9\u5728\u65e5\u5e38\u4f7f\u7528\u4e2d\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5e7b\u89c9\u4e0d\u4f1a\u5bfc\u81f4\u5168\u9762\u4e0d\u4fe1\u4efb\uff0c\u800c\u662f\u5f15\u53d1\u60c5\u5883\u654f\u611f\u7684\u4fe1\u4efb\u6821\u51c6\uff1b\u786e\u8ba4\u4e86\u671f\u671b\u3001\u5148\u524d\u7ecf\u9a8c\u3001\u7528\u6237\u4e13\u4e1a\u77e5\u8bc6\u548c\u9886\u57df\u77e5\u8bc6\u4f5c\u4e3a\u7528\u6237\u76f8\u5173\u4fe1\u4efb\u56e0\u7d20\uff1b\u8bc6\u522b\u51fa\u76f4\u89c9\u4f5c\u4e3a\u5e7b\u89c9\u68c0\u6d4b\u7684\u989d\u5916\u56e0\u7d20\uff1b\u53d1\u73b0\u4fe1\u4efb\u52a8\u6001\u8fd8\u53d7\u60c5\u5883\u56e0\u7d20\u5f71\u54cd\uff0c\u7279\u522b\u662f\u611f\u77e5\u98ce\u9669\u548c\u51b3\u7b56\u98ce\u9669\u3002", "conclusion": "\u9a8c\u8bc1\u4e86Bl\u00f6baum\u63d0\u51fa\u7684\u9012\u5f52\u4fe1\u4efb\u6821\u51c6\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u7eb3\u5165\u76f4\u89c9\u4f5c\u4e3a\u7528\u6237\u76f8\u5173\u4fe1\u4efb\u56e0\u7d20\u8fdb\u884c\u4e86\u6269\u5c55\uff1b\u57fa\u4e8e\u7814\u7a76\u53d1\u73b0\u63d0\u51fa\u4e86\u8d1f\u8d23\u4efb\u548c\u53cd\u601d\u6027LLM\u4f7f\u7528\u7684\u5b9e\u7528\u5efa\u8bae\u3002", "topic": "agent analysis"}}
{"id": "2512.08950", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08950", "abs": "https://arxiv.org/abs/2512.08950", "authors": ["Aseel Rawashdeh"], "title": "Optimizing Algorithms for Mobile Health Interventions with Active Querying Optimization", "comment": null, "summary": "Reinforcement learning in mobile health (mHealth) interventions requires balancing intervention efficacy with user burden, particularly when state measurements (for example, user surveys or feedback) are costly yet essential. The Act-Then-Measure (ATM) heuristic addresses this challenge by decoupling control and measurement actions within the Action-Contingent Noiselessly Observable Markov Decision Process (ACNO-MDP) framework. However, the standard ATM algorithm relies on a temporal-difference-inspired Q-learning method, which is prone to instability in sparse and noisy environments. In this work, we propose a Bayesian extension to ATM that replaces standard Q-learning with a Kalman filter-style Bayesian update, maintaining uncertainty-aware estimates of Q-values and enabling more stable and sample-efficient learning. We evaluate our method in both toy environments and clinically motivated testbeds. In small, tabular environments, Bayesian ATM achieves comparable or improved scalarized returns with substantially lower variance and more stable policy behavior. In contrast, in larger and more complex mHealth settings, both the standard and Bayesian ATM variants perform poorly, suggesting a mismatch between ATM's modeling assumptions and the structural challenges of real-world mHealth domains. These findings highlight the value of uncertainty-aware methods in low-data settings while underscoring the need for new RL algorithms that explicitly model causal structure, continuous states, and delayed feedback under observation cost constraints.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d1d\u53f6\u65af\u6269\u5c55\u7684ATM\u7b97\u6cd5\uff0c\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5f0f\u66f4\u65b0\u66ff\u4ee3\u6807\u51c6Q\u5b66\u4e60\uff0c\u5728\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u4e2d\u5b9e\u73b0\u66f4\u7a33\u5b9a\u3001\u6837\u672c\u6548\u7387\u66f4\u9ad8\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u4f46\u5728\u590d\u6742\u771f\u5b9e\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u9700\u8981\u5728\u5e72\u9884\u6548\u679c\u548c\u7528\u6237\u8d1f\u62c5\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u72b6\u6001\u6d4b\u91cf\u6210\u672c\u9ad8\u6602\u4f46\u81f3\u5173\u91cd\u8981\u7684\u60c5\u51b5\u4e0b\u3002\u6807\u51c6ATM\u7b97\u6cd5\u4f7f\u7528TD-Q\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u7a00\u758f\u548c\u566a\u58f0\u73af\u5883\u4e2d\u5bb9\u6613\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51faATM\u7684\u8d1d\u53f6\u65af\u6269\u5c55\uff0c\u7528\u5361\u5c14\u66fc\u6ee4\u6ce2\u5f0f\u8d1d\u53f6\u65af\u66f4\u65b0\u66ff\u4ee3\u6807\u51c6Q\u5b66\u4e60\uff0c\u7ef4\u62a4Q\u503c\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u4f30\u8ba1\uff0c\u5b9e\u73b0\u66f4\u7a33\u5b9a\u548c\u6837\u672c\u6548\u7387\u66f4\u9ad8\u7684\u5b66\u4e60\u3002", "result": "\u5728\u5c0f\u578b\u8868\u683c\u73af\u5883\u4e2d\uff0c\u8d1d\u53f6\u65afATM\u5b9e\u73b0\u4e86\u76f8\u5f53\u6216\u6539\u8fdb\u7684\u6807\u91cf\u5316\u56de\u62a5\uff0c\u65b9\u5dee\u663e\u8457\u964d\u4f4e\uff0c\u7b56\u7565\u884c\u4e3a\u66f4\u7a33\u5b9a\u3002\u4f46\u5728\u66f4\u5927\u66f4\u590d\u6742\u7684\u79fb\u52a8\u5065\u5eb7\u8bbe\u7f6e\u4e2d\uff0c\u6807\u51c6\u548c\u8d1d\u53f6\u65afATM\u53d8\u4f53\u90fd\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u65b9\u6cd5\u5728\u4f4e\u6570\u636e\u8bbe\u7f6e\u4e2d\u5177\u6709\u4ef7\u503c\uff0c\u4f46\u9700\u8981\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6765\u663e\u5f0f\u5efa\u6a21\u56e0\u679c\u7ed3\u6784\u3001\u8fde\u7eed\u72b6\u6001\u548c\u89c2\u6d4b\u6210\u672c\u7ea6\u675f\u4e0b\u7684\u5ef6\u8fdf\u53cd\u9988\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.09543", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09543", "abs": "https://arxiv.org/abs/2512.09543", "authors": ["Arihant Tripathy", "Ch Pavan Harshit", "Karthik Vaidhyanathan"], "title": "SWEnergy: An Empirical Study on Energy Efficiency in Agentic Issue Resolution Frameworks with SLMs", "comment": "8 pages, 5 figures, 1 table. Accepted to AGENT 2026 (ICSE 2026 workshop)", "summary": "Context. LLM-based autonomous agents in software engineering rely on large, proprietary models, limiting local deployment. This has spurred interest in Small Language Models (SLMs), but their practical effectiveness and efficiency within complex agentic frameworks for automated issue resolution remain poorly understood.\n  Goal. We investigate the performance, energy efficiency, and resource consumption of four leading agentic issue resolution frameworks when deliberately constrained to using SLMs. We aim to assess the viability of these systems for this task in resource-limited settings and characterize the resulting trade-offs.\n  Method. We conduct a controlled evaluation of four leading agentic frameworks (SWE-Agent, OpenHands, Mini SWE Agent, AutoCodeRover) using two SLMs (Gemma-3 4B, Qwen-3 1.7B) on the SWE-bench Verified Mini benchmark. On fixed hardware, we measure energy, duration, token usage, and memory over 150 runs per configuration.\n  Results. We find that framework architecture is the primary driver of energy consumption. The most energy-intensive framework, AutoCodeRover (Gemma), consumed 9.4x more energy on average than the least energy-intensive, OpenHands (Gemma). However, this energy is largely wasted. Task resolution rates were near-zero, demonstrating that current frameworks, when paired with SLMs, consume significant energy on unproductive reasoning loops. The SLM's limited reasoning was the bottleneck for success, but the framework's design was the bottleneck for efficiency.\n  Conclusions. Current agentic frameworks, designed for powerful LLMs, fail to operate efficiently with SLMs. We find that framework architecture is the primary driver of energy consumption, but this energy is largely wasted due to the SLMs' limited reasoning. Viable low-energy solutions require shifting from passive orchestration to architectures that actively manage SLM weaknesses.", "AI": {"tldr": "\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u79cd\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\u5728\u4ec5\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLMs)\u65f6\u7684\u6027\u80fd\u3001\u80fd\u8017\u548c\u8d44\u6e90\u6d88\u8017\uff0c\u53d1\u73b0\u6846\u67b6\u67b6\u6784\u662f\u80fd\u8017\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46SLMs\u7684\u6709\u9650\u63a8\u7406\u80fd\u529b\u5bfc\u81f4\u4efb\u52a1\u89e3\u51b3\u7387\u63a5\u8fd1\u96f6\uff0c\u80fd\u91cf\u88ab\u6d6a\u8d39\u5728\u65e0\u751f\u4ea7\u529b\u7684\u63a8\u7406\u5faa\u73af\u4e2d\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u4e3b\u4ee3\u7406\u4f9d\u8d56\u5927\u578b\u4e13\u6709\u6a21\u578b\uff0c\u9650\u5236\u4e86\u672c\u5730\u90e8\u7f72\u3002\u867d\u7136\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(SLMs)\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5b83\u4eec\u5728\u590d\u6742\u4ee3\u7406\u6846\u67b6\u4e2d\u7528\u4e8e\u81ea\u52a8\u5316\u95ee\u9898\u89e3\u51b3\u7684\u5b9e\u9645\u6548\u679c\u548c\u6548\u7387\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u5728\u56fa\u5b9a\u786c\u4ef6\u4e0a\uff0c\u5bf9\u56db\u79cd\u9886\u5148\u7684\u4ee3\u7406\u6846\u67b6(SWE-Agent\u3001OpenHands\u3001Mini SWE Agent\u3001AutoCodeRover)\u4f7f\u7528\u4e24\u79cdSLMs(Gemma-3 4B\u3001Qwen-3 1.7B)\uff0c\u5728SWE-bench Verified Mini\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u63a7\u5236\u8bc4\u4f30\uff0c\u6d4b\u91cf\u80fd\u91cf\u3001\u6301\u7eed\u65f6\u95f4\u3001\u4ee4\u724c\u4f7f\u7528\u548c\u5185\u5b58\uff0c\u6bcf\u4e2a\u914d\u7f6e\u8fd0\u884c150\u6b21\u3002", "result": "\u6846\u67b6\u67b6\u6784\u662f\u80fd\u8017\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u6700\u8017\u80fd\u7684AutoCodeRover(Gemma)\u6bd4\u6700\u8282\u80fd\u7684OpenHands(Gemma)\u5e73\u5747\u591a\u6d88\u80179.4\u500d\u80fd\u91cf\u3002\u4f46\u4efb\u52a1\u89e3\u51b3\u7387\u63a5\u8fd1\u96f6\uff0c\u8868\u660e\u5f53\u524d\u6846\u67b6\u4e0eSLMs\u914d\u5bf9\u65f6\uff0c\u5927\u91cf\u80fd\u91cf\u88ab\u6d6a\u8d39\u5728\u65e0\u751f\u4ea7\u529b\u7684\u63a8\u7406\u5faa\u73af\u4e2d\u3002SLMs\u7684\u6709\u9650\u63a8\u7406\u662f\u6210\u529f\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u800c\u6846\u67b6\u8bbe\u8ba1\u662f\u6548\u7387\u7684\u74f6\u9888\u3002", "conclusion": "\u5f53\u524d\u4e3a\u5f3a\u5927LLMs\u8bbe\u8ba1\u7684\u4ee3\u7406\u6846\u67b6\u65e0\u6cd5\u4e0eSLMs\u9ad8\u6548\u534f\u540c\u5de5\u4f5c\u3002\u6846\u67b6\u67b6\u6784\u662f\u80fd\u8017\u7684\u4e3b\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46\u7531\u4e8eSLMs\u7684\u6709\u9650\u63a8\u7406\u80fd\u529b\uff0c\u8fd9\u4e9b\u80fd\u91cf\u5927\u90e8\u5206\u88ab\u6d6a\u8d39\u3002\u53ef\u884c\u7684\u4f4e\u80fd\u8017\u89e3\u51b3\u65b9\u6848\u9700\u8981\u4ece\u88ab\u52a8\u7f16\u6392\u8f6c\u5411\u4e3b\u52a8\u7ba1\u7406SLM\u5f31\u70b9\u7684\u67b6\u6784\u3002", "topic": "agent analysis"}}
{"id": "2512.08952", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.08952", "abs": "https://arxiv.org/abs/2512.08952", "authors": ["Filippo Cenacchi", "Deborah Richards", "Longbing Cao"], "title": "Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis", "comment": null, "summary": "Testing humanoid robots with users is slow, causes wear, and limits iteration and diversity. Yet screening agents must master conversational timing, prosody, backchannels, and what to attend to in faces and speech for Depression and PTSD. Most simulators omit policy learning with nonverbal dynamics; many controllers chase task accuracy while underweighting trust, pacing, and rapport. We virtualise the humanoid as a conversational agent to train without hardware burden. Our agent-centred, simulation-first pipeline turns interview data into 276 Unreal Engine MetaHuman patients with synchronised speech, gaze/face, and head-torso poses, plus PHQ-8 and PCL-C flows. A perception-fusion-policy loop decides what and when to speak, when to backchannel, and how to avoid interruptions, under a safety shield. Training uses counterfactual replay (bounded nonverbal perturbations) and an uncertainty-aware turn manager that probes to reduce diagnostic ambiguity. Results are simulation-only; the humanoid is the transfer target. In comparing three controllers, a custom TD3 (Twin Delayed DDPG) outperformed PPO and CEM, achieving near-ceiling coverage with steadier pace at comparable rewards. Decision-quality analyses show negligible turn overlap, aligned cut timing, fewer clarification prompts, and shorter waits. Performance stays stable under modality dropout and a renderer swap, and rankings hold on a held-out patient split. Contributions: (1) an agent-centred simulator that turns interviews into 276 interactive patients with bounded nonverbal counterfactuals; (2) a safe learning loop that treats timing and rapport as first-class control variables; (3) a comparative study (TD3 vs PPO/CEM) with clear gains in completeness and social timing; and (4) ablations and robustness analyses explaining the gains and enabling clinician-supervised humanoid pilots.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u865a\u62df\u4eba\u5f62\u673a\u5668\u4eba\u5bf9\u8bdd\u4ee3\u7406\u8bad\u7ec3\u7cfb\u7edf\uff0c\u5c06\u771f\u5b9e\u8bbf\u8c08\u6570\u636e\u8f6c\u5316\u4e3a276\u4e2a\u865a\u62df\u60a3\u8005\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u793e\u4ea4\u4e92\u52a8\u7b56\u7565\uff0cTD3\u7b97\u6cd5\u5728\u5bf9\u8bdd\u5b8c\u6574\u6027\u548c\u793e\u4ea4\u65f6\u673a\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u771f\u5b9e\u4eba\u5f62\u673a\u5668\u4eba\u6d4b\u8bd5\u5b58\u5728\u901f\u5ea6\u6162\u3001\u8bbe\u5907\u78e8\u635f\u3001\u8fed\u4ee3\u53d7\u9650\u7b49\u95ee\u9898\uff0c\u800c\u73b0\u6709\u6a21\u62df\u5668\u5927\u591a\u5ffd\u7565\u4e86\u975e\u8bed\u8a00\u52a8\u6001\u7684\u7b56\u7565\u5b66\u4e60\uff0c\u63a7\u5236\u5668\u8fc7\u4e8e\u5173\u6ce8\u4efb\u52a1\u51c6\u786e\u6027\u800c\u5ffd\u89c6\u4e86\u4fe1\u4efb\u3001\u8282\u594f\u548c\u878d\u6d3d\u5173\u7cfb\u7b49\u793e\u4ea4\u56e0\u7d20\u3002", "method": "\u5c06\u4eba\u5f62\u673a\u5668\u4eba\u865a\u62df\u5316\u4e3a\u5bf9\u8bdd\u4ee3\u7406\uff0c\u4f7f\u7528276\u4e2aUnreal Engine MetaHuman\u865a\u62df\u60a3\u8005\uff08\u5305\u542b\u540c\u6b65\u8bed\u97f3\u3001\u89c6\u7ebf/\u9762\u90e8\u8868\u60c5\u548c\u5934\u8eaf\u59ff\u52bf\uff09\uff0c\u91c7\u7528\u611f\u77e5-\u878d\u5408-\u7b56\u7565\u5faa\u73af\u51b3\u7b56\u4f55\u65f6\u8bf4\u8bdd\u3001\u4f55\u65f6\u56de\u5e94\u3001\u5982\u4f55\u907f\u514d\u6253\u65ad\uff0c\u4f7f\u7528\u53cd\u4e8b\u5b9e\u56de\u653e\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u56de\u5408\u7ba1\u7406\u5668\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u81ea\u5b9a\u4e49TD3\u7b97\u6cd5\u5728\u4e09\u4e2a\u63a7\u5236\u5668\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u8fbe\u5230\u63a5\u8fd1\u4e0a\u9650\u7684\u5bf9\u8bdd\u8986\u76d6\u7387\uff0c\u8282\u594f\u66f4\u7a33\u5b9a\uff0c\u5956\u52b1\u76f8\u5f53\u3002\u51b3\u7b56\u8d28\u91cf\u5206\u6790\u663e\u793a\u53ef\u5ffd\u7565\u7684\u56de\u5408\u91cd\u53e0\u3001\u5bf9\u9f50\u7684\u6253\u65ad\u65f6\u673a\u3001\u66f4\u5c11\u7684\u6f84\u6e05\u63d0\u793a\u548c\u66f4\u77ed\u7684\u7b49\u5f85\u65f6\u95f4\u3002\u6027\u80fd\u5728\u6a21\u6001\u4e22\u5931\u548c\u6e32\u67d3\u5668\u66f4\u6362\u4e0b\u4fdd\u6301\u7a33\u5b9a\u3002", "conclusion": "\u63d0\u51fa\u7684\u4ee3\u7406\u4e2d\u5fc3\u6a21\u62df\u5668\u80fd\u591f\u6709\u6548\u8bad\u7ec3\u793e\u4ea4\u4e92\u52a8\u7b56\u7565\uff0cTD3\u7b97\u6cd5\u5728\u5bf9\u8bdd\u5b8c\u6574\u6027\u548c\u793e\u4ea4\u65f6\u673a\u65b9\u9762\u4f18\u4e8ePPO\u548cCEM\uff0c\u4e3a\u4e34\u5e8a\u76d1\u7763\u4e0b\u7684\u4eba\u5f62\u673a\u5668\u4eba\u8bd5\u70b9\u63d0\u4f9b\u4e86\u57fa\u7840\u3002", "topic": "agent analysis"}}
{"id": "2512.08944", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08944", "abs": "https://arxiv.org/abs/2512.08944", "authors": ["Yudong Wang", "Zhe Yang", "Wenhan Ma", "Zhifang Sui", "Liang Zhao"], "title": "Enhancing Reliability across Short and Long-Form QA via Reinforcement Learning", "comment": null, "summary": "While reinforcement learning has unlocked unprecedented complex reasoning in large language models, it has also amplified their propensity for hallucination, creating a critical trade-off between capability and reliability. This work confronts this challenge by introducing a targeted RL framework designed to mitigate both intrinsic and extrinsic hallucinations across short and long-form question answering. We address extrinsic hallucinations (flawed internal knowledge) by creating a novel training set from open-ended conversions of TriviaQA. Concurrently, we tackle intrinsic hallucinations (unfaithfulness to context) by leveraging long-form texts from FineWeb in a fact-grounding reward scheme. To further bolster reliability, our framework explicitly rewards the model for refusing to answer unanswerable questions, thereby cultivating crucial cautiousness. Extensive experiments demonstrate that our methodology yields significant performance gains across a diverse suite of benchmarks, substantially reducing both hallucination types. Ultimately, this research contributes a practical framework for resolving the critical tension between advanced reasoning and factual trustworthiness, paving the way for more capable and reliable large language models.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4e0d\u540c\u6570\u636e\u96c6\u5904\u7406\u5185\u5728\u548c\u5916\u5728\u5e7b\u89c9\uff0c\u5e76\u5956\u52b1\u6a21\u578b\u62d2\u7edd\u56de\u7b54\u4e0d\u53ef\u56de\u7b54\u7684\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u63a8\u7406\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u5e7b\u89c9\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u867d\u7136\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4e5f\u52a0\u5267\u4e86\u5e7b\u89c9\u95ee\u9898\uff0c\u5f62\u6210\u4e86\u80fd\u529b\u4e0e\u53ef\u9760\u6027\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\u3002\u9700\u8981\u89e3\u51b3\u5185\u5728\u5e7b\u89c9\uff08\u4e0d\u5fe0\u5b9e\u4e8e\u4e0a\u4e0b\u6587\uff09\u548c\u5916\u5728\u5e7b\u89c9\uff08\u5185\u90e8\u77e5\u8bc6\u7f3a\u9677\uff09\u7684\u53cc\u91cd\u6311\u6218\u3002", "method": "1) \u4f7f\u7528TriviaQA\u7684\u5f00\u653e\u5f0f\u8f6c\u6362\u521b\u5efa\u8bad\u7ec3\u96c6\u5904\u7406\u5916\u5728\u5e7b\u89c9\uff1b2) \u5229\u7528FineWeb\u7684\u957f\u6587\u672c\u8fdb\u884c\u4e8b\u5b9e\u57fa\u7840\u5956\u52b1\u65b9\u6848\u5904\u7406\u5185\u5728\u5e7b\u89c9\uff1b3) \u660e\u786e\u5956\u52b1\u6a21\u578b\u62d2\u7edd\u56de\u7b54\u4e0d\u53ef\u56de\u7b54\u7684\u95ee\u9898\u4ee5\u57f9\u517b\u8c28\u614e\u6027\u3002", "result": "\u5728\u591a\u6837\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u4e24\u79cd\u7c7b\u578b\u7684\u5e7b\u89c9\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u7406\u80fd\u529b\u4e0e\u4e8b\u5b9e\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u7d27\u5f20\u5173\u7cfb\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u9ad8\u7ea7\u63a8\u7406\u4e0e\u4e8b\u5b9e\u53ef\u4fe1\u5ea6\u4e4b\u95f4\u7684\u5173\u952e\u77db\u76fe\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u66f4\u53ef\u9760\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u94fa\u5e73\u4e86\u9053\u8def\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.09142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09142", "abs": "https://arxiv.org/abs/2512.09142", "authors": ["Sergio Burdisso", "S\u00e9verin Baroudi", "Yanis Labrak", "David Grunert", "Pawel Cyrta", "Yiyang Chen", "Srikanth Madikeri", "Esa\u00fa Villatoro-Tello", "Thomas Schaaf", "Ricard Marxer", "Petr Motlicek"], "title": "SDialog: A Python Toolkit for End-to-End Agent Building, User Simulation, Dialog Generation, and Evaluation", "comment": "Pre-print submitted to EACL System Demonstration (under review)", "summary": "We present SDialog, an MIT-licensed open-source Python toolkit that unifies dialog generation, evaluation and mechanistic interpretability into a single end-to-end framework for building and analyzing LLM-based conversational agents. Built around a standardized \\texttt{Dialog} representation, SDialog provides: (1) persona-driven multi-agent simulation with composable orchestration for controlled, synthetic dialog generation, (2) comprehensive evaluation combining linguistic metrics, LLM-as-a-judge and functional correctness validators, (3) mechanistic interpretability tools for activation inspection and steering via feature ablation and induction, and (4) audio generation with full acoustic simulation including 3D room modeling and microphone effects. The toolkit integrates with all major LLM backends, enabling mixed-backend experiments under a unified API. By coupling generation, evaluation, and interpretability in a dialog-centric architecture, SDialog enables researchers to build, benchmark and understand conversational systems more systematically.", "AI": {"tldr": "SDialog\u662f\u4e00\u4e2a\u5f00\u6e90Python\u5de5\u5177\u5305\uff0c\u96c6\u6210\u4e86\u5bf9\u8bdd\u751f\u6210\u3001\u8bc4\u4f30\u548c\u673a\u5236\u53ef\u89e3\u91ca\u6027\uff0c\u7528\u4e8e\u6784\u5efa\u548c\u5206\u6790\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u4ee3\u7406\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u7edf\u4e00\u7684\u6846\u67b6\u6765\u7cfb\u7edf\u6027\u5730\u6784\u5efa\u3001\u8bc4\u4f30\u548c\u7406\u89e3\u57fa\u4e8eLLM\u7684\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u9700\u8981\u5c06\u751f\u6210\u3001\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u6574\u5408\u5230\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5e73\u53f0\u4e2d\u3002", "method": "\u56f4\u7ed5\u6807\u51c6\u5316\u7684Dialog\u8868\u793a\u6784\u5efa\uff0c\u63d0\u4f9b\uff1a1\uff09\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u4ee3\u7406\u6a21\u62df\u4e0e\u53ef\u7ec4\u5408\u7f16\u6392\uff1b2\uff09\u7ed3\u5408\u8bed\u8a00\u6307\u6807\u3001LLM\u4f5c\u4e3a\u8bc4\u5224\u548c\u529f\u80fd\u6b63\u786e\u6027\u9a8c\u8bc1\u5668\u7684\u7efc\u5408\u8bc4\u4f30\uff1b3\uff09\u901a\u8fc7\u7279\u5f81\u6d88\u878d\u548c\u8bf1\u5bfc\u8fdb\u884c\u6fc0\u6d3b\u68c0\u67e5\u548c\u5f15\u5bfc\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u5de5\u5177\uff1b4\uff09\u5305\u542b3D\u623f\u95f4\u5efa\u6a21\u548c\u9ea6\u514b\u98ce\u6548\u679c\u7684\u5b8c\u6574\u58f0\u5b66\u6a21\u62df\u97f3\u9891\u751f\u6210\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2aMIT\u8bb8\u53ef\u7684\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u96c6\u6210\u4e86\u6240\u6709\u4e3b\u8981LLM\u540e\u7aef\uff0c\u652f\u6301\u7edf\u4e00API\u4e0b\u7684\u6df7\u5408\u540e\u7aef\u5b9e\u9a8c\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u80fd\u591f\u66f4\u7cfb\u7edf\u5730\u6784\u5efa\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u7406\u89e3\u5bf9\u8bdd\u7cfb\u7edf\u3002", "conclusion": "SDialog\u901a\u8fc7\u5c06\u751f\u6210\u3001\u8bc4\u4f30\u548c\u53ef\u89e3\u91ca\u6027\u8026\u5408\u5230\u4ee5\u5bf9\u8bdd\u4e3a\u4e2d\u5fc3\u7684\u67b6\u6784\u4e2d\uff0c\u4e3a\u6784\u5efa\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u7406\u89e3\u5bf9\u8bdd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2512.09679", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.09679", "abs": "https://arxiv.org/abs/2512.09679", "authors": ["Naizhu Jin", "Zhong Li", "Guang Yang", "Tian Zhang", "Qingkai Zeng"], "title": "Understanding Chain-of-Thought Effectiveness in Code Generation: An Empirical and Information-Theoretic Analysis", "comment": null, "summary": "Large language models (LLMs) achieve strong performance on code generation, but the mechanisms by which Chain-of-Thought (CoT) prompting helps remain unclear. We present a systematic empirical and information-theoretic study of CoT effectiveness in neural code generation, evaluating five paradigms (Zero-Shot, Zero-Shot CoT, Self-Planning, Structured CoT, Reasoning-CoT) across six Python benchmarks, a multilingual benchmark with 12 programming languages, and six models from 7B to 480B parameters, using conditional mutual information $I(Y;C|X)$ as a conceptual lens. Our results show that externally guided CoT consistently outperforms direct generation, with structured methods improving Pass@1 by 5--12\\% on average while using substantially fewer tokens than reflective reasoning, and that CoT benefits depend on language type systems and model capacity. We further find that reasoning \\emph{quality} is critical: high-quality structured CoT from strong generators yields significantly higher accuracy than lightweight alternatives with the same template, whereas naive Zero-Shot CoT can even degrade performance. These findings provide practical guidance for choosing CoT strategies based on model capacity, language characteristics, and task complexity.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u89c6\u89d2\u7cfb\u7edf\u7814\u7a76CoT\u63d0\u793a\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u4f5c\u7528\u673a\u5236\uff0c\u53d1\u73b0\u7ed3\u6784\u5316CoT\u65b9\u6cd5\u5728\u51cf\u5c11token\u4f7f\u7528\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5176\u6548\u679c\u53d7\u8bed\u8a00\u7c7b\u578b\u7cfb\u7edf\u548c\u6a21\u578b\u5bb9\u91cf\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u4ee3\u7801\u751f\u6210\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46CoT\u63d0\u793a\u5982\u4f55\u63d0\u5347\u6027\u80fd\u7684\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u5b9e\u8bc1\u548c\u4fe1\u606f\u8bba\u7814\u7a76\u63ed\u793aCoT\u5728\u795e\u7ecf\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u6709\u6548\u6027\u539f\u7406\u3002", "method": "\u4f7f\u7528\u6761\u4ef6\u4e92\u4fe1\u606fI(Y;C|X)\u4f5c\u4e3a\u6982\u5ff5\u6846\u67b6\uff0c\u8bc4\u4f30\u4e94\u79cdCoT\u8303\u5f0f\uff08Zero-Shot\u3001Zero-Shot CoT\u3001Self-Planning\u3001Structured CoT\u3001Reasoning-CoT\uff09\uff0c\u5728\u516d\u4e2aPython\u57fa\u51c6\u3001\u4e00\u4e2a\u5305\u542b12\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u4ee5\u53ca6\u4e2a7B\u5230480B\u53c2\u6570\u7684\u6a21\u578b\u4e0a\u8fdb\u884c\u7cfb\u7edf\u5b9e\u9a8c\u3002", "result": "\u5916\u90e8\u5f15\u5bfc\u7684CoT\u59cb\u7ec8\u4f18\u4e8e\u76f4\u63a5\u751f\u6210\uff0c\u7ed3\u6784\u5316\u65b9\u6cd5\u5e73\u5747\u63d0\u5347Pass@1 5-12%\u4e14\u6bd4\u53cd\u601d\u63a8\u7406\u4f7f\u7528\u66f4\u5c11token\uff1bCoT\u6548\u679c\u53d7\u8bed\u8a00\u7c7b\u578b\u7cfb\u7edf\u548c\u6a21\u578b\u5bb9\u91cf\u5f71\u54cd\uff1b\u63a8\u7406\u8d28\u91cf\u81f3\u5173\u91cd\u8981\uff1a\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316CoT\u6bd4\u76f8\u540c\u6a21\u677f\u7684\u8f7b\u91cf\u66ff\u4ee3\u65b9\u6848\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u800c\u6734\u7d20Zero-Shot CoT\u751a\u81f3\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u57fa\u4e8e\u6a21\u578b\u5bb9\u91cf\u3001\u8bed\u8a00\u7279\u6027\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u9009\u62e9CoT\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u63ed\u793a\u4e86CoT\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u6709\u6548\u673a\u5236\u3002", "topic": "code agent"}}
{"id": "2512.09458", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09458", "abs": "https://arxiv.org/abs/2512.09458", "authors": ["S\u0142awomir Nowaczyk"], "title": "Architectures for Building Agentic AI", "comment": "This is a preprint of a chapter accepted for publication in Generative and Agentic AI Reliability: Architectures, Challenges, and Trust for Autonomous Systems, published by Springer Nature", "summary": "This chapter argues that the reliability of agentic and generative AI is chiefly an architectural property. We define agentic systems as goal-directed, tool-using decision makers operating in closed loops, and show how reliability emerges from principled componentisation (goal manager, planner, tool-router, executor, memory, verifiers, safety monitor, telemetry), disciplined interfaces (schema-constrained, validated, least-privilege tool calls), and explicit control and assurance loops. Building on classical foundations, we propose a practical taxonomy-tool-using agents, memory-augmented agents, planning and self-improvement agents, multi-agent systems, and embodied or web agents - and analyse how each pattern reshapes the reliability envelope and failure modes. We distil design guidance on typed schemas, idempotency, permissioning, transactional semantics, memory provenance and hygiene, runtime governance (budgets, termination conditions), and simulate-before-actuate safeguards.", "AI": {"tldr": "\u672c\u6587\u8ba4\u4e3aAI\u4ee3\u7406\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u4e3b\u8981\u662f\u4e00\u4e2a\u67b6\u6784\u5c5e\u6027\uff0c\u901a\u8fc7\u7ec4\u4ef6\u5316\u3001\u63a5\u53e3\u89c4\u8303\u548c\u663e\u5f0f\u63a7\u5236\u5faa\u73af\u6765\u5b9e\u73b0\u53ef\u9760\u6027\u4fdd\u969c\u3002", "motivation": "\u63a2\u8ba8\u5982\u4f55\u6784\u5efa\u53ef\u9760\u7684AI\u4ee3\u7406\u7cfb\u7edf\uff0c\u5f3a\u8c03\u53ef\u9760\u6027\u4e0d\u5e94\u662f\u4e8b\u540e\u6dfb\u52a0\u7684\u7279\u6027\uff0c\u800c\u662f\u7cfb\u7edf\u67b6\u6784\u7684\u5185\u5728\u5c5e\u6027\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7ec4\u4ef6\u5316\u67b6\u6784\u7684\u65b9\u6cd5\uff1a\u5b9a\u4e49\u4ee3\u7406\u7cfb\u7edf\u4e3a\u5177\u6709\u76ee\u6807\u7ba1\u7406\u3001\u89c4\u5212\u3001\u5de5\u5177\u8def\u7531\u3001\u6267\u884c\u5668\u3001\u8bb0\u5fc6\u3001\u9a8c\u8bc1\u5668\u3001\u5b89\u5168\u76d1\u63a7\u7b49\u7ec4\u4ef6\u7684\u95ed\u73af\u51b3\u7b56\u7cfb\u7edf\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u6a21\u5f0f\u3001\u63a5\u53e3\u7ea6\u675f\u3001\u63a7\u5236\u5faa\u73af\u7b49\u8bbe\u8ba1\u539f\u5219\u786e\u4fdd\u53ef\u9760\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u4ee3\u7406\u7cfb\u7edf\u7684\u5b9e\u7528\u5206\u7c7b\u6cd5\uff08\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u3001\u8bb0\u5fc6\u589e\u5f3a\u4ee3\u7406\u3001\u89c4\u5212\u4e0e\u81ea\u6211\u6539\u8fdb\u4ee3\u7406\u3001\u591a\u4ee3\u7406\u7cfb\u7edf\u3001\u5177\u8eab\u6216\u7f51\u7edc\u4ee3\u7406\uff09\uff0c\u5206\u6790\u4e86\u6bcf\u79cd\u6a21\u5f0f\u5982\u4f55\u91cd\u5851\u53ef\u9760\u6027\u8fb9\u754c\u548c\u6545\u969c\u6a21\u5f0f\uff0c\u5e76\u63d0\u70bc\u4e86\u5177\u4f53\u7684\u8bbe\u8ba1\u6307\u5bfc\u539f\u5219\u3002", "conclusion": "AI\u4ee3\u7406\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u53ef\u4ee5\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u67b6\u6784\u8bbe\u8ba1\u6765\u5b9e\u73b0\uff0c\u5305\u62ec\u7ec4\u4ef6\u5316\u3001\u63a5\u53e3\u89c4\u8303\u3001\u663e\u5f0f\u63a7\u5236\u5faa\u73af\u7b49\u6838\u5fc3\u539f\u5219\uff0c\u8fd9\u4e3a\u6784\u5efa\u53ef\u9760\u7684AI\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bbe\u8ba1\u6846\u67b6\u3002", "topic": "agent analysis"}}
{"id": "2512.09149", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09149", "abs": "https://arxiv.org/abs/2512.09149", "authors": ["Anton Vasiliuk", "Irina Abdullaeva", "Polina Druzhinina", "Anton Razzhigaev", "Andrey Kuznetsov"], "title": "MindShift: Analyzing Language Models' Reactions to Psychological Prompts", "comment": null, "summary": "Large language models (LLMs) hold the potential to absorb and reflect personality traits and attitudes specified by users. In our study, we investigated this potential using robust psychometric measures. We adapted the most studied test in psychological literature, namely Minnesota Multiphasic Personality Inventory (MMPI) and examined LLMs' behavior to identify traits. To asses the sensitivity of LLMs' prompts and psychological biases we created personality-oriented prompts, crafting a detailed set of personas that vary in trait intensity. This enables us to measure how well LLMs follow these roles. Our study introduces MindShift, a benchmark for evaluating LLMs' psychological adaptability. The results highlight a consistent improvement in LLMs' role perception, attributed to advancements in training datasets and alignment techniques. Additionally, we observe significant differences in responses to psychometric assessments across different model types and families, suggesting variability in their ability to emulate human-like personality traits. MindShift prompts and code for LLM evaluation will be publicly available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86MindShift\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u9002\u5e94\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u6539\u7f16MMPI\u5fc3\u7406\u6d4b\u8bd5\u548c\u521b\u5efa\u4e0d\u540c\u4eba\u683c\u5f3a\u5ea6\u7684\u89d2\u8272\u63d0\u793a\uff0c\u7814\u7a76LLMs\u6a21\u62df\u4eba\u7c7b\u4eba\u683c\u7279\u8d28\u7684\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u5438\u6536\u548c\u53cd\u6620\u7528\u6237\u6307\u5b9a\u7684\u4eba\u683c\u7279\u8d28\u548c\u6001\u5ea6\uff0c\u8bc4\u4f30LLMs\u5728\u5fc3\u7406\u9002\u5e94\u6027\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u4e86\u89e3\u4e0d\u540c\u6a21\u578b\u5728\u6a21\u62df\u4eba\u7c7b\u4eba\u683c\u7279\u8d28\u65b9\u9762\u7684\u5dee\u5f02\u3002", "method": "\u6539\u7f16\u5fc3\u7406\u5b66\u4e2d\u6700\u5e38\u7528\u7684\u6d4b\u8bd5MMPI\uff0c\u521b\u5efa\u4eba\u683c\u5bfc\u5411\u7684\u63d0\u793a\uff0c\u8bbe\u8ba1\u4e0d\u540c\u7279\u8d28\u5f3a\u5ea6\u7684\u4eba\u7269\u89d2\u8272\uff0c\u6784\u5efaMindShift\u57fa\u51c6\u6765\u8bc4\u4f30LLMs\u7684\u5fc3\u7406\u9002\u5e94\u6027\uff0c\u5206\u6790\u4e0d\u540c\u6a21\u578b\u7c7b\u578b\u548c\u5bb6\u65cf\u5bf9\u5fc3\u7406\u8bc4\u4f30\u7684\u53cd\u5e94\u5dee\u5f02\u3002", "result": "\u7ed3\u679c\u663e\u793aLLMs\u5728\u89d2\u8272\u611f\u77e5\u65b9\u9762\u6709\u6301\u7eed\u6539\u8fdb\uff0c\u8fd9\u5f52\u56e0\u4e8e\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u5bf9\u9f50\u6280\u672f\u7684\u8fdb\u6b65\u3002\u4e0d\u540c\u6a21\u578b\u7c7b\u578b\u548c\u5bb6\u65cf\u5728\u5fc3\u7406\u8bc4\u4f30\u53cd\u5e94\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8868\u660e\u5b83\u4eec\u5728\u6a21\u62df\u4eba\u7c7b\u4eba\u683c\u7279\u8d28\u80fd\u529b\u4e0a\u5b58\u5728\u53d8\u5f02\u6027\u3002", "conclusion": "LLMs\u786e\u5b9e\u80fd\u591f\u53cd\u6620\u6307\u5b9a\u7684\u4eba\u683c\u7279\u8d28\uff0cMindShift\u57fa\u51c6\u4e3a\u8bc4\u4f30LLMs\u7684\u5fc3\u7406\u9002\u5e94\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u6a21\u578b\u5728\u4eba\u683c\u6a21\u62df\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\u53cd\u6620\u4e86\u8bad\u7ec3\u548c\u67b6\u6784\u7684\u4e0d\u540c\u5f71\u54cd\u3002", "topic": "agent analysis"}}
{"id": "2512.09212", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.09212", "abs": "https://arxiv.org/abs/2512.09212", "authors": ["Zixuan Liu", "Siavash H. Khajavi", "Guangkai Jiang", "Xinru Liu"], "title": "Targeting Misalignment: A Conflict-Aware Framework for Reward-Model-based LLM Alignment", "comment": null, "summary": "Reward-model-based fine-tuning is a central paradigm in aligning Large Language Models with human preferences. However, such approaches critically rely on the assumption that proxy reward models accurately reflect intended supervision, a condition often violated due to annotation noise, bias, or limited coverage. This misalignment can lead to undesirable behaviors, where models optimize for flawed signals rather than true human values. In this paper, we investigate a novel framework to identify and mitigate such misalignment by treating the fine-tuning process as a form of knowledge integration. We focus on detecting instances of proxy-policy conflicts, cases where the base model strongly disagrees with the proxy. We argue that such conflicts often signify areas of shared ignorance, where neither the policy nor the reward model possesses sufficient knowledge, making them especially susceptible to misalignment. To this end, we propose two complementary metrics for identifying these conflicts: a localized Proxy-Policy Alignment Conflict Score (PACS) and a global Kendall-Tau Distance measure. Building on this insight, we design an algorithm named Selective Human-in-the-loop Feedback via Conflict-Aware Sampling (SHF-CAS) that targets high-conflict QA pairs for additional feedback, refining both the reward model and policy efficiently. Experiments on two alignment tasks demonstrate that our approach enhances general alignment performance, even when trained with a biased proxy reward. Our work provides a new lens for interpreting alignment failures and offers a principled pathway for targeted refinement in LLM training.", "AI": {"tldr": "\u63d0\u51faSHF-CAS\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u6d4b\u4ee3\u7406\u5956\u52b1\u6a21\u578b\u4e0e\u57fa\u7840\u6a21\u578b\u4e4b\u95f4\u7684\u51b2\u7a81\u6765\u8bc6\u522b\u5bf9\u9f50\u5931\u8d25\u533a\u57df\uff0c\u5e76\u9488\u5bf9\u9ad8\u51b2\u7a81\u6837\u672c\u8fdb\u884c\u9009\u62e9\u6027\u4eba\u7c7b\u53cd\u9988\uff0c\u4ee5\u63d0\u5347LLM\u5bf9\u9f50\u6548\u679c\u3002", "motivation": "\u57fa\u4e8e\u5956\u52b1\u6a21\u578b\u7684\u5fae\u8c03\u65b9\u6cd5\u5047\u8bbe\u4ee3\u7406\u5956\u52b1\u6a21\u578b\u80fd\u51c6\u786e\u53cd\u6620\u4eba\u7c7b\u504f\u597d\uff0c\u4f46\u5b9e\u9645\u4e2d\u5e38\u56e0\u6807\u6ce8\u566a\u58f0\u3001\u504f\u89c1\u6216\u8986\u76d6\u4e0d\u8db3\u800c\u5931\u6548\uff0c\u5bfc\u81f4\u6a21\u578b\u4f18\u5316\u9519\u8bef\u4fe1\u53f7\u800c\u975e\u771f\u5b9e\u4eba\u7c7b\u4ef7\u503c\u89c2\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u4e92\u8865\u6307\u6807\uff1a\u5c40\u90e8\u4ee3\u7406-\u7b56\u7565\u5bf9\u9f50\u51b2\u7a81\u5206\u6570(PACS)\u548c\u5168\u5c40Kendall-Tau\u8ddd\u79bb\uff1b\u57fa\u4e8e\u6b64\u8bbe\u8ba1SHF-CAS\u7b97\u6cd5\uff0c\u9488\u5bf9\u9ad8\u51b2\u7a81QA\u5bf9\u8fdb\u884c\u9009\u62e9\u6027\u4eba\u7c7b\u53cd\u9988\uff0c\u540c\u65f6\u4f18\u5316\u5956\u52b1\u6a21\u578b\u548c\u7b56\u7565\u3002", "result": "\u5728\u4e24\u4e2a\u5bf9\u9f50\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5373\u4f7f\u5728\u6709\u504f\u4ee3\u7406\u5956\u52b1\u4e0b\u4e5f\u80fd\u63d0\u5347\u6574\u4f53\u5bf9\u9f50\u6027\u80fd\u3002", "conclusion": "\u4e3a\u89e3\u91ca\u5bf9\u9f50\u5931\u8d25\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5e76\u4e3aLLM\u8bad\u7ec3\u4e2d\u7684\u9488\u5bf9\u6027\u4f18\u5316\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u8def\u5f84\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.08965", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.08965", "abs": "https://arxiv.org/abs/2512.08965", "authors": ["Glenn Matlin", "Siddharth", "Anirudh JM", "Aditya Shukla", "Yahya Hassan", "Sudheer Chava"], "title": "Financial Instruction Following Evaluation (FIFE)", "comment": "Accepted at NeurIPS 2025 Generative AI in Finance Workshop (GenAI Finance), San Diego. Camera-ready version. Code and data: https://github.com/gtfintechlab/FIFE/", "summary": "Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.", "AI": {"tldr": "FIFE\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u5206\u6790\u4efb\u52a1\u4e2d\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u7684\u9ad8\u96be\u5ea6\u57fa\u51c6\uff0c\u5305\u542b88\u4e2a\u4eba\u5de5\u7f16\u5199\u7684\u63d0\u793a\u548c\u53ef\u9a8c\u8bc1\u7ea6\u675f\u7cfb\u7edf\u3002\u8bc4\u4f30\u663e\u793a\u5f00\u6e90\u6743\u91cd\u6a21\u578b\u4f18\u4e8e\u4e13\u6709\u7cfb\u7edf\uff0c\u4f46\u6240\u6709\u6a21\u578b\u90fd\u96be\u4ee5\u5b8c\u5168\u6ee1\u8db3\u590d\u6742\u8981\u6c42\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u3001\u76f8\u4e92\u4f9d\u8d56\u7684\u6307\u4ee4\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u91d1\u878d\u7b49\u9ad8\u7cbe\u5ea6\u8981\u6c42\u9886\u57df\u3002\u9700\u8981\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u91d1\u878d\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3002", "method": "\u521b\u5efaFIFE\u57fa\u51c6\uff0c\u5305\u542b88\u4e2a\u4eba\u5de5\u7f16\u5199\u7684\u91d1\u878d\u5206\u6790\u63d0\u793a\uff0c\u91c7\u7528\u5e26\u6709\u53ef\u94fe\u5f0f\u9a8c\u8bc1\u7ea6\u675f\u7684\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u5956\u52b1\u4fe1\u53f7\u3002\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8bc4\u4f3053\u4e2a\u6a21\u578b\uff08\u4e13\u6709\u3001\u5f00\u6e90\u6743\u91cd\u3001\u5f00\u6e90\uff09\u3002", "result": "\u6027\u80fd\u5c42\u6b21\u660e\u663e\uff1a\u9876\u7ea7\u5f00\u6e90\u6743\u91cd\u6a21\u578b\uff0876.1\u4e25\u683c/79.5\u5bbd\u677e\uff09\u4f18\u4e8e\u9886\u5148\u7684\u4e13\u6709\u7cfb\u7edf\uff0865.9\u4e25\u683c/70.5\u5bbd\u677e\uff09\uff0c\u800c\u6700\u4f73\u5f00\u6e90\u6a21\u578b\u663e\u8457\u843d\u540e\uff0845.5\u4e25\u683c/48.9\u5bbd\u677e\uff09\u3002\u6240\u6709\u6a21\u578b\u90fd\u96be\u4ee5\u5b8c\u5168\u6ee1\u8db3FIFE\u7684\u590d\u6742\u8981\u6c42\u3002", "conclusion": "FIFE\u57fa\u51c6\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u91d1\u878d\u6307\u4ee4\u9075\u5faa\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5f00\u6e90\u6743\u91cd\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u4e13\u6709\u7cfb\u7edf\u3002\u53d1\u5e03\u6570\u636e\u96c6\u548c\u4ee3\u7801\u4f5c\u4e3a\u5f00\u6e90\u8d44\u6e90\uff0c\u4fc3\u8fdb\u91d1\u878d\u9886\u57df\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u3002", "topic": "agent analysis"}}
{"id": "2512.09831", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.09831", "abs": "https://arxiv.org/abs/2512.09831", "authors": ["Chainarong Amornbunchornvej"], "title": "Interpretation as Linear Transformation: A Cognitive-Geometric Model of Belief and Meaning", "comment": "The first draft of cognitive geometry model", "summary": "This paper develops a geometric framework for modeling belief, motivation, and influence across cognitively heterogeneous agents. Each agent is represented by a personalized value space, a vector space encoding the internal dimensions through which the agent interprets and evaluates meaning. Beliefs are formalized as structured vectors-abstract beings-whose transmission is mediated by linear interpretation maps. A belief survives communication only if it avoids the null spaces of these maps, yielding a structural criterion for intelligibility, miscommunication, and belief death.\n  Within this framework, I show how belief distortion, motivational drift, counterfactual evaluation, and the limits of mutual understanding arise from purely algebraic constraints. A central result-\"the No-Null-Space Leadership Condition\"-characterizes leadership as a property of representational reachability rather than persuasion or authority. More broadly, the model explains how abstract beings can propagate, mutate, or disappear as they traverse diverse cognitive geometries.\n  The account unifies insights from conceptual spaces, social epistemology, and AI value alignment by grounding meaning preservation in structural compatibility rather than shared information or rationality. I argue that this cognitive-geometric perspective clarifies the epistemic boundaries of influence in both human and artificial systems, and offers a general foundation for analyzing belief dynamics across heterogeneous agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u51e0\u4f55\u6846\u67b6\uff0c\u7528\u4e8e\u5efa\u6a21\u8ba4\u77e5\u5f02\u6784\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4fe1\u5ff5\u3001\u52a8\u673a\u548c\u5f71\u54cd\u3002\u6bcf\u4e2a\u667a\u80fd\u4f53\u7531\u4e2a\u6027\u5316\u7684\u4ef7\u503c\u7a7a\u95f4\u8868\u793a\uff0c\u4fe1\u5ff5\u88ab\u5f62\u5f0f\u5316\u4e3a\u7ed3\u6784\u5316\u5411\u91cf\uff0c\u5176\u4f20\u64ad\u53d7\u7ebf\u6027\u89e3\u91ca\u6620\u5c04\u8c03\u8282\u3002\u4fe1\u5ff5\u53ea\u6709\u5728\u907f\u514d\u8fd9\u4e9b\u6620\u5c04\u7684\u96f6\u7a7a\u95f4\u65f6\u624d\u80fd\u5728\u4ea4\u6d41\u4e2d\u5b58\u6d3b\uff0c\u8fd9\u4e3a\u53ef\u7406\u89e3\u6027\u3001\u8bef\u89e3\u548c\u4fe1\u5ff5\u6d88\u4ea1\u63d0\u4f9b\u4e86\u7ed3\u6784\u6807\u51c6\u3002", "motivation": "\u52a8\u673a\u662f\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5206\u6790\u5f02\u6784\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4fe1\u5ff5\u52a8\u6001\uff0c\u89e3\u51b3\u4fe1\u5ff5\u4f20\u64ad\u3001\u52a8\u673a\u6f02\u79fb\u548c\u76f8\u4e92\u7406\u89e3\u7684\u9650\u5236\u95ee\u9898\u3002\u8be5\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7ed3\u6784\u517c\u5bb9\u6027\u800c\u975e\u5171\u4eab\u4fe1\u606f\u6216\u7406\u6027\u6765\u7edf\u4e00\u6982\u5ff5\u7a7a\u95f4\u3001\u793e\u4f1a\u8ba4\u8bc6\u8bba\u548cAI\u4ef7\u503c\u5bf9\u9f50\u7684\u89c1\u89e3\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1\uff09\u5c06\u6bcf\u4e2a\u667a\u80fd\u4f53\u8868\u793a\u4e3a\u4e2a\u6027\u5316\u7684\u4ef7\u503c\u7a7a\u95f4\uff08\u5411\u91cf\u7a7a\u95f4\uff09\uff1b2\uff09\u5c06\u4fe1\u5ff5\u5f62\u5f0f\u5316\u4e3a\u7ed3\u6784\u5316\u5411\u91cf\uff1b3\uff09\u4f7f\u7528\u7ebf\u6027\u89e3\u91ca\u6620\u5c04\u6765\u8c03\u8282\u4fe1\u5ff5\u4f20\u8f93\uff1b4\uff09\u5f15\u5165\"\u65e0\u96f6\u7a7a\u95f4\u9886\u5bfc\u6761\u4ef6\"\u4f5c\u4e3a\u9886\u5bfc\u529b\u7684\u4ee3\u6570\u7279\u5f81\uff1b5\uff09\u5206\u6790\u4fe1\u5ff5\u5728\u7a7f\u8d8a\u4e0d\u540c\u8ba4\u77e5\u51e0\u4f55\u65f6\u7684\u4f20\u64ad\u3001\u53d8\u5f02\u6216\u6d88\u5931\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u5305\u62ec\uff1a1\uff09\u4fe1\u5ff5\u5931\u771f\u3001\u52a8\u673a\u6f02\u79fb\u548c\u53cd\u4e8b\u5b9e\u8bc4\u4f30\u6e90\u4e8e\u4ee3\u6570\u7ea6\u675f\uff1b2\uff09\u9886\u5bfc\u529b\u88ab\u8868\u5f81\u4e3a\u8868\u793a\u53ef\u8fbe\u6027\u7684\u5c5e\u6027\u800c\u975e\u8bf4\u670d\u6216\u6743\u5a01\uff1b3\uff09\u4fe1\u5ff5\u53ea\u6709\u5728\u907f\u514d\u89e3\u91ca\u6620\u5c04\u7684\u96f6\u7a7a\u95f4\u65f6\u624d\u80fd\u5b58\u6d3b\uff1b4\uff09\u8be5\u6846\u67b6\u89e3\u91ca\u4e86\u62bd\u8c61\u5b9e\u4f53\u5982\u4f55\u5728\u591a\u6837\u8ba4\u77e5\u51e0\u4f55\u4e2d\u4f20\u64ad\u3001\u53d8\u5f02\u6216\u6d88\u5931\u3002", "conclusion": "\u7ed3\u8bba\u662f\u8fd9\u79cd\u8ba4\u77e5\u51e0\u4f55\u89c6\u89d2\u6f84\u6e05\u4e86\u4eba\u7c7b\u548c\u4eba\u5de5\u7cfb\u7edf\u4e2d\u5f71\u54cd\u7684\u8ba4\u77e5\u8fb9\u754c\uff0c\u4e3a\u5206\u6790\u5f02\u6784\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4fe1\u5ff5\u52a8\u6001\u63d0\u4f9b\u4e86\u901a\u7528\u57fa\u7840\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u7ed3\u6784\u517c\u5bb9\u6027\u800c\u975e\u5171\u4eab\u4fe1\u606f\u6216\u7406\u6027\u6765\u7edf\u4e00\u610f\u4e49\u4fdd\u5b58\uff0c\u4e3a\u7406\u89e3\u4fe1\u5ff5\u4f20\u64ad\u548c\u5f71\u54cd\u9650\u5236\u63d0\u4f9b\u4e86\u65b0\u6846\u67b6\u3002", "topic": "agent analysis"}}
{"id": "2512.09882", "categories": ["cs.AI", "cs.CR", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.09882", "abs": "https://arxiv.org/abs/2512.09882", "authors": ["Justin W. Lin", "Eliot Krzysztof Jones", "Donovan Julian Jasper", "Ethan Jun-shen Ho", "Anna Wu", "Arnold Tianyi Yang", "Neil Perry", "Andy Zou", "Matt Fredrikson", "J. Zico Kolter", "Percy Liang", "Dan Boneh", "Daniel E. Ho"], "title": "Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing", "comment": null, "summary": "We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 hosts across 12 subnets. ARTEMIS is a multi-agent framework featuring dynamic prompt generation, arbitrary sub-agents, and automatic vulnerability triaging. In our comparative study, ARTEMIS placed second overall, discovering 9 valid vulnerabilities with an 82% valid submission rate and outperforming 9 of 10 human participants. While existing scaffolds such as Codex and CyAgent underperformed relative to most human participants, ARTEMIS demonstrated technical sophistication and submission quality comparable to the strongest participants. We observe that AI agents offer advantages in systematic enumeration, parallel exploitation, and cost -- certain ARTEMIS variants cost $18/hour versus $60/hour for professional penetration testers. We also identify key capability gaps: AI agents exhibit higher false-positive rates and struggle with GUI-based tasks.", "AI": {"tldr": "ARTEMIS\u591a\u667a\u80fd\u4f53\u6846\u67b6\u5728\u771f\u5b9e\u4f01\u4e1a\u7f51\u7edc\u73af\u5883\u4e2d\u4e0e\u4eba\u7c7b\u7f51\u7edc\u5b89\u5168\u4e13\u5bb6\u8fdb\u884c\u9996\u6b21\u5168\u9762\u5bf9\u6bd4\u8bc4\u4f30\uff0c\u57288000\u53f0\u4e3b\u673a\u7f51\u7edc\u4e2d\u6392\u540d\u7b2c\u4e8c\uff0c\u53d1\u73b09\u4e2a\u6709\u6548\u6f0f\u6d1e\uff0c\u8d85\u8fc79/10\u7684\u4eba\u7c7b\u53c2\u4e0e\u8005\uff0c\u6210\u672c\u4ec5\u4e3a\u4eba\u7c7b\u4e13\u5bb6\u768430%\u3002", "motivation": "\u9996\u6b21\u5728\u771f\u5b9e\u4f01\u4e1a\u73af\u5883\u4e2d\u7cfb\u7edf\u8bc4\u4f30AI\u667a\u80fd\u4f53\u4e0e\u4eba\u7c7b\u7f51\u7edc\u5b89\u5168\u4e13\u5bb6\u7684\u5b9e\u9645\u8868\u73b0\u5dee\u5f02\uff0c\u63a2\u7d22AI\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u548c\u5c40\u9650\u6027\u3002", "method": "\u5728\u5305\u542b8000\u53f0\u4e3b\u673a\u300112\u4e2a\u5b50\u7f51\u7684\u5927\u578b\u5927\u5b66\u7f51\u7edc\u4e2d\uff0c\u5bf9\u6bd4\u8bc4\u4f3010\u540d\u7f51\u7edc\u5b89\u5168\u4e13\u5bb6\u30016\u4e2a\u73b0\u6709AI\u667a\u80fd\u4f53\u4ee5\u53ca\u65b0\u5f00\u53d1\u7684ARTEMIS\u591a\u667a\u80fd\u4f53\u6846\u67b6\u3002ARTEMIS\u91c7\u7528\u52a8\u6001\u63d0\u793a\u751f\u6210\u3001\u4efb\u610f\u5b50\u667a\u80fd\u4f53\u521b\u5efa\u548c\u81ea\u52a8\u6f0f\u6d1e\u5206\u7c7b\u6280\u672f\u3002", "result": "ARTEMIS\u603b\u4f53\u6392\u540d\u7b2c\u4e8c\uff0c\u53d1\u73b09\u4e2a\u6709\u6548\u6f0f\u6d1e\uff0c\u6709\u6548\u63d0\u4ea4\u738782%\uff0c\u8d85\u8fc79\u540d\u4eba\u7c7b\u53c2\u4e0e\u8005\u3002\u73b0\u6709\u667a\u80fd\u4f53\u5982Codex\u548cCyAgent\u8868\u73b0\u4e0d\u5982\u5927\u591a\u6570\u4eba\u7c7b\u53c2\u4e0e\u8005\u3002AI\u667a\u80fd\u4f53\u5728\u7cfb\u7edf\u679a\u4e3e\u3001\u5e76\u884c\u5229\u7528\u548c\u6210\u672c\u65b9\u9762\u6709\u4f18\u52bf\uff08ARTEMIS\u6210\u672c18\u7f8e\u5143/\u5c0f\u65f6 vs \u4eba\u7c7b60\u7f8e\u5143/\u5c0f\u65f6\uff09\uff0c\u4f46\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\u548cGUI\u4efb\u52a1\u5904\u7406\u56f0\u96be\u7b49\u80fd\u529b\u5dee\u8ddd\u3002", "conclusion": "AI\u667a\u80fd\u4f53\u5728\u7f51\u7edc\u5b89\u5168\u9886\u57df\u5c55\u73b0\u51fa\u4e0e\u9876\u5c16\u4eba\u7c7b\u4e13\u5bb6\u76f8\u5f53\u7684\u6280\u672f\u6210\u719f\u5ea6\u548c\u63d0\u4ea4\u8d28\u91cf\uff0c\u5177\u6709\u6210\u672c\u6548\u76ca\u548c\u89c4\u6a21\u5316\u4f18\u52bf\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u8bef\u62a5\u7387\u9ad8\u548cGUI\u4efb\u52a1\u5904\u7406\u7b49\u5173\u952e\u80fd\u529b\u5dee\u8ddd\u3002", "topic": "agent analysis"}}
{"id": "2512.09897", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.09897", "abs": "https://arxiv.org/abs/2512.09897", "authors": ["Haoye Lu", "Pavan Seshadri", "Kaheer Suleman"], "title": "SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments", "comment": null, "summary": "Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.", "AI": {"tldr": "SCOPE\uff1a\u4e00\u79cd\u4e00\u6b21\u6027\u5206\u5c42\u89c4\u5212\u5668\uff0c\u5229\u7528LLM\u751f\u6210\u7684\u5b50\u76ee\u6807\u4ec5\u521d\u59cb\u5316\u65f6\u9884\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u6548\u7387\u4f46\u727a\u7272\u53ef\u89e3\u91ca\u6027", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u89c4\u5212\u65b9\u6cd5\u4f9d\u8d56\u8bad\u7ec3\u548c\u63a8\u7406\u671f\u95f4\u9891\u7e41\u67e5\u8be2LLM\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u9ad8\u6548\u90e8\u7f72\uff1b\u540c\u65f6\u4f7f\u7528\u9884\u8bad\u7ec3\u56fa\u5b9a\u53c2\u6570\u7684LLM\uff0c\u65e0\u6cd5\u9488\u5bf9\u76ee\u6807\u4efb\u52a1\u8fdb\u884c\u9002\u914d", "method": "\u63d0\u51faSCOPE\u65b9\u6cd5\uff1a\u4ec5\u521d\u59cb\u5316\u65f6\u4f7f\u7528LLM\u751f\u6210\u5b50\u76ee\u6807\uff0c\u7136\u540e\u9884\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u5b66\u751f\u6a21\u578b\uff1b\u76f4\u63a5\u4ece\u793a\u4f8b\u8f68\u8ff9\u63a8\u5bfc\u5b50\u76ee\u6807\uff0c\u907f\u514d\u91cd\u590dLLM\u67e5\u8be2", "result": "\u5728TextCraft\u73af\u5883\u4e2d\uff0c\u76f8\u6bd4ADaPT\u76840.52\u6210\u529f\u7387\uff0cSCOPE\u8fbe\u52300.56\u6210\u529f\u7387\uff0c\u63a8\u7406\u65f6\u95f4\u4ece164.4\u79d2\u964d\u81f33.0\u79d2", "conclusion": "LLM\u751f\u6210\u7684\u5b50\u76ee\u6807\u867d\u53ef\u80fd\u6b21\u4f18\uff0c\u4f46\u80fd\u4e3a\u6587\u672c\u89c4\u5212\u4efb\u52a1\u7684\u5206\u5c42\u76ee\u6807\u5206\u89e3\u63d0\u4f9b\u826f\u597d\u8d77\u70b9\uff1bSCOPE\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6548\u7387", "topic": "agent analysis"}}
{"id": "2512.09487", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.09487", "abs": "https://arxiv.org/abs/2512.09487", "authors": ["Yucan Guo", "Miao Su", "Saiping Guan", "Zihao Sun", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng"], "title": "RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) integrates non-parametric knowledge into Large Language Models (LLMs), typically from unstructured texts and structured graphs. While recent progress has advanced text-based RAG to multi-turn reasoning through Reinforcement Learning (RL), extending these advances to hybrid retrieval introduces additional challenges. Existing graph-based or hybrid systems typically depend on fixed or handcrafted retrieval pipelines, lacking the ability to integrate supplementary evidence as reasoning unfolds. Besides, while graph evidence provides relational structures crucial for multi-hop reasoning, it is substantially more expensive to retrieve. To address these limitations, we introduce \\model{}, an RL-based framework that enables LLMs to perform multi-turn and adaptive graph-text hybrid RAG. \\model{} jointly optimizes the entire generation process via RL, allowing the model to learn when to reason, what to retrieve from either texts or graphs, and when to produce final answers, all within a unified generation policy. To guide this learning process, we design a two-stage training framework that accounts for both task outcome and retrieval efficiency, enabling the model to exploit hybrid evidence while avoiding unnecessary retrieval overhead. Experimental results across five question answering benchmarks demonstrate that \\model{} significantly outperforms existing RAG baselines, highlighting the benefits of end-to-end RL in supporting adaptive and efficient retrieval for complex reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u8f6e\u81ea\u9002\u5e94\u56fe-\u6587\u672c\u6df7\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u4f18\u5316\u5b9e\u73b0\u9ad8\u6548\u68c0\u7d22\u548c\u590d\u6742\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u56fe\u6216\u6df7\u5408\u7684\u68c0\u7d22\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u56fa\u5b9a\u6216\u624b\u5de5\u5236\u4f5c\u7684\u68c0\u7d22\u6d41\u7a0b\uff0c\u7f3a\u4e4f\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6574\u5408\u8865\u5145\u8bc1\u636e\u7684\u80fd\u529b\u3002\u540c\u65f6\uff0c\u56fe\u8bc1\u636e\u68c0\u7d22\u6210\u672c\u663e\u8457\u66f4\u9ad8\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u68c0\u7d22\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u6574\u4e2a\u751f\u6210\u8fc7\u7a0b\uff0c\u8ba9\u6a21\u578b\u5b66\u4e60\u4f55\u65f6\u63a8\u7406\u3001\u4ece\u6587\u672c\u6216\u56fe\u4e2d\u68c0\u7d22\u4ec0\u4e48\u3001\u4f55\u65f6\u751f\u6210\u6700\u7ec8\u7b54\u6848\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u540c\u65f6\u8003\u8651\u4efb\u52a1\u7ed3\u679c\u548c\u68c0\u7d22\u6548\u7387\u3002", "result": "\u5728\u4e94\u4e2a\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u6846\u67b6\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684RAG\u57fa\u7ebf\uff0c\u5c55\u793a\u4e86\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u5728\u652f\u6301\u81ea\u9002\u5e94\u548c\u9ad8\u6548\u68c0\u7d22\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u7684\u81ea\u9002\u5e94\u6df7\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u80fd\u591f\u6709\u6548\u652f\u6301\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff0c\u5728\u4fdd\u6301\u68c0\u7d22\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.09675", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.09675", "abs": "https://arxiv.org/abs/2512.09675", "authors": ["Leyi Pan", "Shuchang Tao", "Yunpeng Zhai", "Zheyu Fu", "Liancheng Fang", "Minghua He", "Lingzhe Zhang", "Zhaoyang Liu", "Bolin Ding", "Aiwei Liu", "Lijie Wen"], "title": "d-TreeRPO: Towards More Reliable Policy Optimization for Diffusion Language Models", "comment": "16 pages, 5 figures, 3tables", "summary": "Reliable reinforcement learning (RL) for diffusion large language models (dLLMs) requires both accurate advantage estimation and precise estimation of prediction probabilities. Existing RL methods for dLLMs fall short in both aspects: they rely on coarse or unverifiable reward signals, and they estimate prediction probabilities without accounting for the bias relative to the true, unbiased expected prediction probability that properly integrates over all possible decoding orders. To mitigate these issues, we propose \\emph{d}-TreeRPO, a reliable RL framework for dLLMs that leverages tree-structured rollouts and bottom-up advantage computation based on verifiable outcome rewards to provide fine-grained and verifiable step-wise reward signals. When estimating the conditional transition probability from a parent node to a child node, we theoretically analyze the estimation error between the unbiased expected prediction probability and the estimate obtained via a single forward pass, and find that higher prediction confidence leads to lower estimation error. Guided by this analysis, we introduce a time-scheduled self-distillation loss during training that enhances prediction confidence in later training stages, thereby enabling more accurate probability estimation and improved convergence. Experiments show that \\emph{d}-TreeRPO outperforms existing baselines and achieves significant gains on multiple reasoning benchmarks, including +86.2 on Sudoku, +51.6 on Countdown, +4.5 on GSM8K, and +5.3 on Math500. Ablation studies and computational cost analyses further demonstrate the effectiveness and practicality of our design choices.", "AI": {"tldr": "d-TreeRPO\uff1a\u9488\u5bf9\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u6811\u7ed3\u6784\u5c55\u5f00\u548c\u53ef\u9a8c\u8bc1\u5956\u52b1\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u4fe1\u53f7\uff0c\u7ed3\u5408\u65f6\u95f4\u8c03\u5ea6\u81ea\u84b8\u998f\u63d0\u5347\u9884\u6d4b\u7f6e\u4fe1\u5ea6\uff0c\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347", "motivation": "\u73b0\u6709\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1\uff09\u4f9d\u8d56\u7c97\u7cd9\u6216\u4e0d\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u4fe1\u53f7\uff1b2\uff09\u9884\u6d4b\u6982\u7387\u4f30\u8ba1\u5b58\u5728\u504f\u5dee\uff0c\u672a\u8003\u8651\u6240\u6709\u53ef\u80fd\u89e3\u7801\u987a\u5e8f\u7684\u79ef\u5206\u3002\u9700\u8981\u66f4\u53ef\u9760\u7684RL\u6846\u67b6\u6765\u63d0\u5347dLLMs\u7684\u6027\u80fd", "method": "\u63d0\u51fad-TreeRPO\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u6811\u7ed3\u6784\u5c55\u5f00\u548c\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u7ed3\u679c\u5956\u52b1\u7684\u81ea\u5e95\u5411\u4e0a\u4f18\u52bf\u8ba1\u7b97\uff0c\u63d0\u4f9b\u7ec6\u7c92\u5ea6\u53ef\u9a8c\u8bc1\u7684\u6b65\u8fdb\u5956\u52b1\u4fe1\u53f7\uff1b2\uff09\u7406\u8bba\u5206\u6790\u65e0\u504f\u671f\u671b\u9884\u6d4b\u6982\u7387\u4e0e\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4f30\u8ba1\u4e4b\u95f4\u7684\u8bef\u5dee\uff0c\u53d1\u73b0\u9ad8\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u5bf9\u5e94\u4f4e\u4f30\u8ba1\u8bef\u5dee\uff1b3\uff09\u5f15\u5165\u65f6\u95f4\u8c03\u5ea6\u81ea\u84b8\u998f\u635f\u5931\uff0c\u5728\u8bad\u7ec3\u540e\u671f\u589e\u5f3a\u9884\u6d4b\u7f6e\u4fe1\u5ea6\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u6982\u7387\u4f30\u8ba1\u548c\u6536\u655b", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\uff1aSudoku +86.2\uff0cCountdown +51.6\uff0cGSM8K +4.5\uff0cMath500 +5.3\u3002\u6d88\u878d\u7814\u7a76\u548c\u8ba1\u7b97\u6210\u672c\u5206\u6790\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u9009\u62e9\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027", "conclusion": "d-TreeRPO\u901a\u8fc7\u6811\u7ed3\u6784\u5c55\u5f00\u3001\u53ef\u9a8c\u8bc1\u5956\u52b1\u4fe1\u53f7\u548c\u65f6\u95f4\u8c03\u5ea6\u81ea\u84b8\u998f\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u7684\u8bad\u7ec3\u548c\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347", "topic": "agentic reinforcement learning"}}
{"id": "2512.09756", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.09756", "abs": "https://arxiv.org/abs/2512.09756", "authors": ["Chonghua Liao", "Ke Wang", "Yuchuan Wu", "Fei Huang", "Yongbin Li"], "title": "MOA: Multi-Objective Alignment for Role-Playing Agents", "comment": null, "summary": "Role-playing agents (RPAs) must simultaneously master many conflicting skills -- following multi-turn instructions, exhibiting domain knowledge, and adopting a consistent linguistic style. Existing work either relies on supervised fine-tuning (SFT) that over-fits surface cues and yields low diversity, or applies reinforcement learning (RL) that fails to learn multiple dimensions for comprehensive RPA optimization. We present MOA (Multi-Objective Alignment), a reinforcement-learning framework that enables multi-dimensional, fine-grained rubric optimization for general RPAs. MOA introduces a novel multi-objective optimization strategy that trains simultaneously on multiple fine-grained rubrics to boost optimization performance. Besides, to address the issues of model output diversity and quality, we have also employed thought-augmented rollout with off-policy guidance. Extensive experiments on challenging benchmarks such as PersonaGym and RoleMRC show that MOA enables an 8B model to match or even outperform strong baselines such as GPT-4o and Claude across numerous dimensions. This demonstrates the great potential of MOA in building RPAs that can simultaneously meet the demands of role knowledge, persona style, diverse scenarios, and complex multi-turn conversations.", "AI": {"tldr": "MOA\u662f\u4e00\u4e2a\u591a\u76ee\u6807\u5bf9\u9f50\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u4f18\u5316\u591a\u4e2a\u7ec6\u7c92\u5ea6\u8bc4\u5206\u6807\u51c6\u6765\u63d0\u5347\u89d2\u8272\u626e\u6f14\u4ee3\u7406\u7684\u7efc\u5408\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f7f8B\u6a21\u578b\u8fbe\u5230\u6216\u8d85\u8d8aGPT-4o\u7b49\u5f3a\u5927\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u89d2\u8272\u626e\u6f14\u4ee3\u7406\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u76d1\u7763\u5fae\u8c03\u5bb9\u6613\u8fc7\u62df\u5408\u8868\u9762\u7ebf\u7d22\u4e14\u591a\u6837\u6027\u4f4e\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u96be\u4ee5\u540c\u65f6\u4f18\u5316\u591a\u4e2a\u7ef4\u5ea6\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5168\u9762\u4f18\u5316\u89d2\u8272\u77e5\u8bc6\u3001\u98ce\u683c\u4e00\u81f4\u6027\u3001\u573a\u666f\u591a\u6837\u6027\u548c\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51faMOA\u6846\u67b6\uff0c\u91c7\u7528\u591a\u76ee\u6807\u4f18\u5316\u7b56\u7565\u540c\u65f6\u8bad\u7ec3\u591a\u4e2a\u7ec6\u7c92\u5ea6\u8bc4\u5206\u6807\u51c6\u3002\u5f15\u5165\u601d\u7ef4\u589e\u5f3a\u7684rollout\u548c\u79bb\u7b56\u7565\u6307\u5bfc\u6765\u89e3\u51b3\u8f93\u51fa\u591a\u6837\u6027\u548c\u8d28\u91cf\u95ee\u9898\u3002", "result": "\u5728PersonaGym\u548cRoleMRC\u7b49\u6311\u6218\u6027\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMOA\u4f7f8B\u6a21\u578b\u80fd\u591f\u5339\u914d\u751a\u81f3\u8d85\u8d8aGPT-4o\u548cClaude\u7b49\u5f3a\u5927\u57fa\u7ebf\uff0c\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "MOA\u5c55\u793a\u4e86\u6784\u5efa\u80fd\u591f\u540c\u65f6\u6ee1\u8db3\u89d2\u8272\u77e5\u8bc6\u3001\u98ce\u683c\u3001\u573a\u666f\u591a\u6837\u6027\u548c\u590d\u6742\u591a\u8f6e\u5bf9\u8bdd\u9700\u6c42\u7684\u89d2\u8272\u626e\u6f14\u4ee3\u7406\u7684\u5de8\u5927\u6f5c\u529b\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.09854", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.09854", "abs": "https://arxiv.org/abs/2512.09854", "authors": ["Muneeb Ur Raheem Khan"], "title": "Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement", "comment": null, "summary": "Large language models (LLMs) increasingly mediate human communication, decision support, content creation, and information retrieval. Despite impressive fluency, these systems frequently produce biased or stereotypical content, especially when prompted with socially sensitive language. A growing body of research has demonstrated that such biases disproportionately affect low-resource languages, where training data is limited and culturally unrepresentative. This paper presents a comprehensive study of inference-time bias mitigation, a strategy that avoids retraining or fine-tuning and instead operates directly on model outputs. Building on preference-ranking models (PRMs), we introduce a unified evaluation framework comparing three methods: (1) baseline single-word generation, (2) PRM-Select best-of-N sampling, and (3) PRM-Sequential refinement guided by PRM critiques. We evaluate these techniques across 200 English prompts and their Urdu counterparts, designed to reflect socio-cultural contexts relevant to gender, ethnicity, religion, nationality, disability, profession, age, and socioeconomic categories. Using GPT-3.5 as a candidate generator and GPT-4o-mini as a PRM-based bias and utility scorer, we provide an extensive quantitative analysis of bias reduction, utility preservation, and cross-lingual disparities. Our findings show: (a) substantial gains over the baseline for both languages; (b) consistently lower fairness scores for Urdu across all methods, highlighting structural inequities in multilingual LLM training; and (c) distinct improvement trajectories between PRM-Select and PRM-Sequential. The study contributes an extensible methodology, interpretable metrics, and cross-lingual comparisons that can support future work on fairness evaluation in low-resource languages.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u63a8\u7406\u9636\u6bb5\u51cf\u8f7b\u5927\u8bed\u8a00\u6a21\u578b\u504f\u89c1\u7684\u4e09\u79cd\u65b9\u6cd5\uff0c\u7279\u522b\u5173\u6ce8\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u4e4c\u5c14\u90fd\u8bed\uff09\u4e0e\u82f1\u8bed\u7684\u5bf9\u6bd4\uff0c\u53d1\u73b0\u4e4c\u5c14\u90fd\u8bed\u5728\u6240\u6709\u65b9\u6cd5\u4e2d\u90fd\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u516c\u5e73\u6027\u5206\u6570\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7ecf\u5e38\u4ea7\u751f\u6709\u504f\u89c1\u6216\u523b\u677f\u5370\u8c61\u7684\u5185\u5bb9\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u793e\u4f1a\u654f\u611f\u8bdd\u9898\u65f6\u3002\u8fd9\u79cd\u504f\u89c1\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u5c24\u4e3a\u4e25\u91cd\uff0c\u56e0\u4e3a\u8bad\u7ec3\u6570\u636e\u6709\u9650\u4e14\u6587\u5316\u4ee3\u8868\u6027\u4e0d\u8db3\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u5fae\u8c03\u7684\u63a8\u7406\u9636\u6bb5\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6bd4\u8f83\u4e09\u79cd\u65b9\u6cd5\uff1a(1) \u57fa\u7ebf\u5355\u8bcd\u751f\u6210\uff0c(2) PRM-Select\u6700\u4f73N\u91c7\u6837\uff0c(3) PRM-Sequential\u57fa\u4e8ePRM\u6279\u8bc4\u7684\u5e8f\u5217\u4f18\u5316\u3002\u4f7f\u7528GPT-3.5\u4f5c\u4e3a\u5019\u9009\u751f\u6210\u5668\uff0cGPT-4o-mini\u4f5c\u4e3a\u57fa\u4e8ePRM\u7684\u504f\u89c1\u548c\u6548\u7528\u8bc4\u5206\u5668\uff0c\u5728200\u4e2a\u82f1\u8bed\u63d0\u793a\u53ca\u5176\u4e4c\u5c14\u90fd\u8bed\u5bf9\u5e94\u7248\u672c\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a(a) \u6240\u6709\u65b9\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u90fd\u6709\u663e\u8457\u6539\u8fdb\uff1b(b) \u4e4c\u5c14\u90fd\u8bed\u5728\u6240\u6709\u65b9\u6cd5\u4e2d\u7684\u516c\u5e73\u6027\u5206\u6570\u90fd\u8f83\u4f4e\uff0c\u7a81\u663e\u4e86\u591a\u8bed\u8a00LLM\u8bad\u7ec3\u4e2d\u7684\u7ed3\u6784\u6027\u4e0d\u5e73\u7b49\uff1b(c) PRM-Select\u548cPRM-Sequential\u65b9\u6cd5\u663e\u793a\u51fa\u4e0d\u540c\u7684\u6539\u8fdb\u8f68\u8ff9\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u8bba\u3001\u53ef\u89e3\u91ca\u7684\u6307\u6807\u548c\u8de8\u8bed\u8a00\u6bd4\u8f83\uff0c\u652f\u6301\u672a\u6765\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u9762\u7684\u5de5\u4f5c\uff0c\u63ed\u793a\u4e86\u591a\u8bed\u8a00LLM\u8bad\u7ec3\u4e2d\u5b58\u5728\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u95ee\u9898\u3002", "topic": "agent analysis"}}
{"id": "2512.09368", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.09368", "abs": "https://arxiv.org/abs/2512.09368", "authors": ["Mingyuan Li", "Chunyu Liu", "Zhuojun Li", "Xiao Liu", "Guangsheng Yu", "Bo Du", "Jun Shen", "Qiang Wu"], "title": "CFLight: Enhancing Safety with Traffic Signal Control through Counterfactual Learning", "comment": null, "summary": "Traffic accidents result in millions of injuries and fatalities globally, with a significant number occurring at intersections each year. Traffic Signal Control (TSC) is an effective strategy for enhancing safety at these urban junctures. Despite the growing popularity of Reinforcement Learning (RL) methods in optimizing TSC, these methods often prioritize driving efficiency over safety, thus failing to address the critical balance between these two aspects. Additionally, these methods usually need more interpretability. CounterFactual (CF) learning is a promising approach for various causal analysis fields. In this study, we introduce a novel framework to improve RL for safety aspects in TSC. This framework introduces a novel method based on CF learning to address the question: ``What if, when an unsafe event occurs, we backtrack to perform alternative actions, and will this unsafe event still occur in the subsequent period?'' To answer this question, we propose a new structure causal model to predict the result after executing different actions, and we propose a new CF module that integrates with additional ``X'' modules to promote safe RL practices. Our new algorithm, CFLight, which is derived from this framework, effectively tackles challenging safety events and significantly improves safety at intersections through a near-zero collision control strategy. Through extensive numerical experiments on both real-world and synthetic datasets, we demonstrate that CFLight reduces collisions and improves overall traffic performance compared to conventional RL methods and the recent safe RL model. Moreover, our method represents a generalized and safe framework for RL methods, opening possibilities for applications in other domains. The data and code are available in the github https://github.com/MJLee00/CFLight-Enhancing-Safety-with-Traffic-Signal-Control-through-Counterfactual-Learning.", "AI": {"tldr": "\u63d0\u51faCFLight\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5b66\u4e60\u589e\u5f3a\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u7684\u5b89\u5168\u6027\uff0c\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u78b0\u649e\u4e8b\u6545", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u8fc7\u4e8e\u5173\u6ce8\u6548\u7387\u800c\u5ffd\u89c6\u5b89\u5168\u6027\uff0c\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002\u4ea4\u901a\u4e8b\u6545\u5728\u4ea4\u53c9\u53e3\u9891\u53d1\uff0c\u9700\u8981\u5e73\u8861\u5b89\u5168\u4e0e\u6548\u7387\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u5b66\u4e60\u7684\u65b0\u6846\u67b6\uff0c\u6784\u5efa\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u9884\u6d4b\u4e0d\u540c\u884c\u52a8\u7684\u7ed3\u679c\uff0c\u8bbe\u8ba1\u53cd\u4e8b\u5b9e\u6a21\u5757\u4e0e\"X\"\u6a21\u5757\u96c6\u6210\uff0c\u5f00\u53d1CFLight\u7b97\u6cd5\u5b9e\u73b0\u8fd1\u96f6\u78b0\u649e\u63a7\u5236\u7b56\u7565", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCFLight\u76f8\u6bd4\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u548c\u8fd1\u671f\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\uff0c\u80fd\u51cf\u5c11\u78b0\u649e\u5e76\u63d0\u5347\u6574\u4f53\u4ea4\u901a\u6027\u80fd", "conclusion": "CFLight\u4e3a\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u5b89\u5168\u7684\u6846\u67b6\uff0c\u5728\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u4e2d\u6709\u6548\u5e73\u8861\u5b89\u5168\u4e0e\u6548\u7387\uff0c\u5e76\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u9886\u57df\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "2512.09706", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09706", "abs": "https://arxiv.org/abs/2512.09706", "authors": ["Kaichen He", "Zihao Wang", "Muyao Li", "Anji Liu", "Yitao Liang"], "title": "Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning", "comment": null, "summary": "The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces--such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dynamic environments where the optimal granularity of interaction varies contextually. To bridge this gap, we propose CrossAgent, a unified agentic model that masters heterogeneous action spaces and autonomously selects the most effective interface for each step of a trajectory. We introduce a comprehensive training pipeline that integrates cold-start supervised fine-tuning with a Multi-Turn Group Relative Policy Optimization (GRPO) algorithm. This approach enables the agent to learn adaptive action switching--balancing high-level efficiency with low-level precision--without human-specified rules. Extensive experiments on over 800 tasks in the open-world Minecraft environment demonstrate that CrossAgent achieves state-of-the-art performance. By dynamically leveraging the strengths of diverse action spaces, our model significantly outperforms fixed-action baselines, exhibiting superior generalization and efficiency in long-horizon reasoning. All code and models are available at https://github.com/CraftJarvis/OpenHA", "AI": {"tldr": "CrossAgent\u662f\u4e00\u4e2a\u7edf\u4e00\u667a\u80fd\u4f53\u6a21\u578b\uff0c\u80fd\u591f\u638c\u63e1\u5f02\u6784\u52a8\u4f5c\u7a7a\u95f4\u5e76\u5728\u8f68\u8ff9\u7684\u6bcf\u4e00\u6b65\u81ea\u4e3b\u9009\u62e9\u6700\u6709\u6548\u7684\u4ea4\u4e92\u63a5\u53e3\uff0c\u5728Minecraft\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u667a\u80fd\u4f53\u901a\u5e38\u5c40\u9650\u4e8e\u9759\u6001\u3001\u9884\u5b9a\u4e49\u7684\u52a8\u4f5c\u7a7a\u95f4\uff08\u5982\u4ec5\u4f7f\u7528API\u3001GUI\u4e8b\u4ef6\u6216\u673a\u5668\u4eba\u547d\u4ee4\uff09\uff0c\u8fd9\u79cd\u521a\u6027\u9650\u5236\u4e86\u5b83\u4eec\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u56e0\u4e3a\u6700\u4f18\u4ea4\u4e92\u7c92\u5ea6\u4f1a\u968f\u4e0a\u4e0b\u6587\u53d8\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u8bad\u7ec3\u6d41\u7a0b\uff0c\u7ed3\u5408\u51b7\u542f\u52a8\u76d1\u7763\u5fae\u8c03\u548c\u591a\u8f6e\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u7b97\u6cd5\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5b66\u4e60\u81ea\u9002\u5e94\u52a8\u4f5c\u5207\u6362\uff0c\u65e0\u9700\u4eba\u5de5\u6307\u5b9a\u89c4\u5219\u3002", "result": "\u5728\u5f00\u653e\u4e16\u754cMinecraft\u73af\u5883\u4e2d\u7684800\u591a\u4e2a\u4efb\u52a1\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0cCrossAgent\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u52a8\u6001\u5229\u7528\u591a\u6837\u5316\u52a8\u4f5c\u7a7a\u95f4\u7684\u4f18\u52bf\uff0c\u663e\u8457\u4f18\u4e8e\u56fa\u5b9a\u52a8\u4f5c\u57fa\u7ebf\u3002", "conclusion": "CrossAgent\u5c55\u793a\u4e86\u5728\u5f02\u6784\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u81ea\u9002\u5e94\u5207\u6362\u7684\u80fd\u529b\uff0c\u5728\u957f\u65f6\u7a0b\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u6548\u7387\uff0c\u4e3a\u667a\u80fd\u4f53\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "topic": "agent analysis"}}
{"id": "2512.09909", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09909", "abs": "https://arxiv.org/abs/2512.09909", "authors": ["Andrew Elashkin", "Orna Grumberg"], "title": "STACHE: Local Black-Box Explanations for Reinforcement Learning Policies", "comment": null, "summary": "Reinforcement learning agents often behave unexpectedly in sparse-reward or safety-critical environments, creating a strong need for reliable debugging and verification tools. In this paper, we propose STACHE, a comprehensive framework for generating local, black-box explanations for an agent's specific action within discrete Markov games. Our method produces a Composite Explanation consisting of two complementary components: (1) a Robustness Region, the connected neighborhood of states where the agent's action remains invariant, and (2) Minimal Counterfactuals, the smallest state perturbations required to alter that decision. By exploiting the structure of factored state spaces, we introduce an exact, search-based algorithm that circumvents the fidelity gaps of surrogate models. Empirical validation on Gymnasium environments demonstrates that our framework not only explains policy actions, but also effectively captures the evolution of policy logic during training - from erratic, unstable behavior to optimized, robust strategies - providing actionable insights into agent sensitivity and decision boundaries.", "AI": {"tldr": "STACHE\u6846\u67b6\u4e3a\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u6e38\u620f\u4e2d\u7684\u667a\u80fd\u4f53\u884c\u4e3a\u751f\u6210\u5c40\u90e8\u9ed1\u76d2\u89e3\u91ca\uff0c\u5305\u542b\u9c81\u68d2\u6027\u533a\u57df\u548c\u6700\u5c0f\u53cd\u4e8b\u5b9e\u4e24\u4e2a\u4e92\u8865\u7ec4\u4ef6\uff0c\u901a\u8fc7\u7cbe\u786e\u641c\u7d22\u7b97\u6cd5\u907f\u514d\u4ee3\u7406\u6a21\u578b\u7684\u4fdd\u771f\u5ea6\u5dee\u8ddd\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u5728\u7a00\u758f\u5956\u52b1\u6216\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u7ecf\u5e38\u8868\u73b0\u51fa\u610f\u5916\u884c\u4e3a\uff0c\u9700\u8981\u53ef\u9760\u7684\u8c03\u8bd5\u548c\u9a8c\u8bc1\u5de5\u5177\u6765\u7406\u89e3\u667a\u80fd\u4f53\u51b3\u7b56\u3002", "method": "\u63d0\u51faSTACHE\u6846\u67b6\uff0c\u751f\u6210\u5305\u542b\u9c81\u68d2\u6027\u533a\u57df\uff08\u667a\u80fd\u4f53\u884c\u52a8\u4e0d\u53d8\u7684\u8fde\u901a\u90bb\u57df\u72b6\u6001\uff09\u548c\u6700\u5c0f\u53cd\u4e8b\u5b9e\uff08\u6539\u53d8\u51b3\u7b56\u6240\u9700\u7684\u6700\u5c0f\u72b6\u6001\u6270\u52a8\uff09\u7684\u590d\u5408\u89e3\u91ca\u3002\u5229\u7528\u56e0\u5b50\u5316\u72b6\u6001\u7a7a\u95f4\u7ed3\u6784\uff0c\u5f15\u5165\u7cbe\u786e\u7684\u57fa\u4e8e\u641c\u7d22\u7684\u7b97\u6cd5\uff0c\u907f\u514d\u4ee3\u7406\u6a21\u578b\u7684\u4fdd\u771f\u5ea6\u5dee\u8ddd\u3002", "result": "\u5728Gymnasium\u73af\u5883\u4e2d\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u8868\u660e\uff0c\u8be5\u6846\u67b6\u4e0d\u4ec5\u80fd\u89e3\u91ca\u7b56\u7565\u884c\u52a8\uff0c\u8fd8\u80fd\u6709\u6548\u6355\u6349\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7b56\u7565\u903b\u8f91\u7684\u6f14\u53d8\u2014\u2014\u4ece\u4e0d\u7a33\u5b9a\u884c\u4e3a\u5230\u4f18\u5316\u7a33\u5065\u7b56\u7565\uff0c\u63d0\u4f9b\u4e86\u5bf9\u667a\u80fd\u4f53\u654f\u611f\u6027\u548c\u51b3\u7b56\u8fb9\u754c\u7684\u53ef\u884c\u89c1\u89e3\u3002", "conclusion": "STACHE\u4e3a\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5c40\u90e8\u9ed1\u76d2\u89e3\u91ca\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u667a\u80fd\u4f53\u51b3\u7b56\u8fc7\u7a0b\u548c\u8c03\u8bd5\u7b56\u7565\u884c\u4e3a\u3002", "topic": "agent analysis"}}
{"id": "2512.09796", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09796", "abs": "https://arxiv.org/abs/2512.09796", "authors": ["Fu Feng", "Ruixiao Shi", "Yucheng Xie", "Jianlu Shen", "Jing Wang", "Xin Geng"], "title": "Knowledge Diversion for Efficient Morphology Control and Policy Transfer", "comment": null, "summary": "Universal morphology control aims to learn a universal policy that generalizes across heterogeneous agent morphologies, with Transformer-based controllers emerging as a popular choice. However, such architectures incur substantial computational costs, resulting in high deployment overhead, and existing methods exhibit limited cross-task generalization, necessitating training from scratch for each new task. To this end, we propose \\textbf{DivMorph}, a modular training paradigm that leverages knowledge diversion to learn decomposable controllers. DivMorph factorizes randomly initialized Transformer weights into factor units via SVD prior to training and employs dynamic soft gating to modulate these units based on task and morphology embeddings, separating them into shared \\textit{learngenes} and morphology- and task-specific \\textit{tailors}, thereby achieving knowledge disentanglement. By selectively activating relevant components, DivMorph enables scalable and efficient policy deployment while supporting effective policy transfer to novel tasks. Extensive experiments demonstrate that DivMorph achieves state-of-the-art performance, achieving a 3$\\times$ improvement in sample efficiency over direct finetuning for cross-task transfer and a 17$\\times$ reduction in model size for single-agent deployment.", "AI": {"tldr": "DivMorph\u63d0\u51fa\u6a21\u5757\u5316\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u77e5\u8bc6\u5206\u6d41\u5b66\u4e60\u53ef\u5206\u89e3\u63a7\u5236\u5668\uff0c\u5b9e\u73b0\u8de8\u5f62\u6001\u548c\u8de8\u4efb\u52a1\u7684\u901a\u7528\u7b56\u7565\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u6837\u672c\u6548\u7387\u548c\u51cf\u5c0f\u6a21\u578b\u89c4\u6a21\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u5f62\u6001\u63a7\u5236\u65b9\u6cd5\u4e2d\uff0c\u57fa\u4e8eTransformer\u7684\u63a7\u5236\u5668\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u90e8\u7f72\u5f00\u9500\u5927\uff0c\u4e14\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u8981\u4e3a\u6bcf\u4e2a\u65b0\u4efb\u52a1\u4ece\u5934\u8bad\u7ec3\u3002", "method": "\u901a\u8fc7SVD\u5c06\u968f\u673a\u521d\u59cb\u5316\u7684Transformer\u6743\u91cd\u5206\u89e3\u4e3a\u56e0\u5b50\u5355\u5143\uff0c\u5229\u7528\u52a8\u6001\u8f6f\u95e8\u63a7\u6839\u636e\u4efb\u52a1\u548c\u5f62\u6001\u5d4c\u5165\u8c03\u5236\u8fd9\u4e9b\u5355\u5143\uff0c\u5206\u79bb\u4e3a\u5171\u4eab\u7684learngenes\u548c\u7279\u5b9a\u4e8e\u5f62\u6001/\u4efb\u52a1\u7684tailors\uff0c\u5b9e\u73b0\u77e5\u8bc6\u89e3\u8026\u3002", "result": "DivMorph\u5728\u8de8\u4efb\u52a1\u8fc1\u79fb\u4e2d\u6bd4\u76f4\u63a5\u5fae\u8c03\u63d0\u53473\u500d\u6837\u672c\u6548\u7387\uff0c\u5728\u5355\u667a\u80fd\u4f53\u90e8\u7f72\u4e2d\u51cf\u5c1117\u500d\u6a21\u578b\u89c4\u6a21\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "DivMorph\u901a\u8fc7\u6a21\u5757\u5316\u77e5\u8bc6\u89e3\u8026\u5b9e\u73b0\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u7684\u7b56\u7565\u90e8\u7f72\uff0c\u652f\u6301\u6709\u6548\u7684\u8de8\u4efb\u52a1\u7b56\u7565\u8fc1\u79fb\u3002", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2512.9d32348d", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftechcrunch.com%2F2025%2F12%2F08%2Fgoogle-details-security-measures-for-chromes-agentic-features%2F%3Futm_source=tldrinfosec/1/0100019b0370649b-68c0b392-e73c-4e79-807e-04a6898c67a8-000000/iBTe168ZeTj4cAKRaH25d1M2QYZQ1kevo9aeBkk645Y=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftechcrunch.com%2F2025%2F12%2F08%2Fgoogle-details-security-measures-for-chromes-agentic-features%2F%3Futm_source=tldrinfosec/1/0100019b0370649b-68c0b392-e73c-4e79-807e-04a6898c67a8-000000/iBTe168ZeTj4cAKRaH25d1M2QYZQ1kevo9aeBkk645Y=434", "authors": ["TLDR Newsletter"], "title": "Google details security measures for Chrome's agentic features", "comment": "Source: TLDR Newsletter, Date: 2025-12-09, Reading time: 3 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftechcrunch.com%2F2025%2F12%2F08%2Fgoogle-details-security-measures-for-chromes-agentic-features%2F%3Futm_source=tldrinfosec/1/0100019b0370649b-68c0b392-e73c-4e79-807e-04a6898c67a8-000000/iBTe168ZeTj4cAKRaH25d1M2QYZQ1kevo9aeBkk645Y=434", "summary": "Google details security measures for Chrome's agentic features (3 minute read) Chrome's upcoming AI \u201cagentic\u201d features will act on users' behalf to complete tasks such as shopping or filling out forms, while also reducing security risks. It uses separate models to check that planned actions align with user goals and to vet URLs, limits what page data agents can read or modify, and asks for explicit permission before accessing sensitive sites, using passwords, or completing purchases.", "source": "tldr", "AI": {"tldr": "Google\u4ecb\u7ecd\u4e86Chrome\u6d4f\u89c8\u5668\u4e2dAI\u4ee3\u7406\u529f\u80fd\u7684\u5b89\u5168\u63aa\u65bd\uff0c\u5305\u62ec\u4f7f\u7528\u72ec\u7acb\u6a21\u578b\u9a8c\u8bc1\u64cd\u4f5c\u4e0e\u7528\u6237\u76ee\u6807\u7684\u4e00\u81f4\u6027\u3001\u5ba1\u67e5URL\u3001\u9650\u5236\u9875\u9762\u6570\u636e\u8bbf\u95ee\u6743\u9650\uff0c\u4ee5\u53ca\u5728\u8bbf\u95ee\u654f\u611f\u7f51\u7ad9\u3001\u4f7f\u7528\u5bc6\u7801\u6216\u5b8c\u6210\u8d2d\u4e70\u524d\u8981\u6c42\u660e\u786e\u6388\u6743\u3002", "motivation": "\u968f\u7740Chrome\u6d4f\u89c8\u5668\u5f15\u5165AI\u4ee3\u7406\u529f\u80fd\uff08\u53ef\u4ee3\u8868\u7528\u6237\u5b8c\u6210\u8d2d\u7269\u3001\u586b\u5199\u8868\u5355\u7b49\u4efb\u52a1\uff09\uff0c\u9700\u8981\u786e\u4fdd\u8fd9\u4e9b\u81ea\u52a8\u5316\u529f\u80fd\u4e0d\u4f1a\u5e26\u6765\u5b89\u5168\u98ce\u9669\uff0c\u4fdd\u62a4\u7528\u6237\u6570\u636e\u548c\u9690\u79c1\u3002", "method": "\u91c7\u7528\u591a\u5c42\u5b89\u5168\u67b6\u6784\uff1a1\uff09\u4f7f\u7528\u72ec\u7acb\u6a21\u578b\u9a8c\u8bc1\u4ee3\u7406\u8ba1\u5212\u7684\u64cd\u4f5c\u662f\u5426\u7b26\u5408\u7528\u6237\u76ee\u6807\uff1b2\uff09\u4f7f\u7528\u72ec\u7acb\u6a21\u578b\u5ba1\u67e5URL\u5b89\u5168\u6027\uff1b3\uff09\u9650\u5236\u4ee3\u7406\u53ef\u8bfb\u53d6\u6216\u4fee\u6539\u7684\u9875\u9762\u6570\u636e\u8303\u56f4\uff1b4\uff09\u5728\u8bbf\u95ee\u654f\u611f\u7f51\u7ad9\u3001\u4f7f\u7528\u5bc6\u7801\u6216\u5b8c\u6210\u8d2d\u4e70\u524d\u8981\u6c42\u7528\u6237\u660e\u786e\u6388\u6743\u3002", "result": "\u901a\u8fc7\u4e0a\u8ff0\u5b89\u5168\u63aa\u65bd\uff0cChrome\u7684AI\u4ee3\u7406\u529f\u80fd\u80fd\u591f\u5728\u81ea\u52a8\u5316\u5b8c\u6210\u4efb\u52a1\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u6f5c\u5728\u7684\u5b89\u5168\u98ce\u9669\uff0c\u4fdd\u62a4\u7528\u6237\u514d\u53d7\u6076\u610f\u64cd\u4f5c\u548c\u6570\u636e\u6cc4\u9732\u7684\u5a01\u80c1\u3002", "conclusion": "Google\u4e3aChrome\u7684AI\u4ee3\u7406\u529f\u80fd\u8bbe\u8ba1\u4e86\u4e00\u5957\u5168\u9762\u7684\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u578b\u9a8c\u8bc1\u3001\u6743\u9650\u9650\u5236\u548c\u7528\u6237\u6388\u6743\u7b49\u591a\u91cd\u673a\u5236\uff0c\u5728\u63d0\u4f9b\u4fbf\u5229\u7684\u540c\u65f6\u786e\u4fdd\u4e86\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002", "topic": "agent analysis"}}
{"id": "tldr.2512.ccd38a82", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftechcrunch.com%2F2025%2F12%2F08%2Fclaude-code-is-coming-to-slack-and-thats-a-bigger-deal-than-it-sounds%2F%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/ZCFzF3qOn4tq1hBejg0M0GhHJULKp07omYhfzAeYnWc=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftechcrunch.com%2F2025%2F12%2F08%2Fclaude-code-is-coming-to-slack-and-thats-a-bigger-deal-than-it-sounds%2F%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/ZCFzF3qOn4tq1hBejg0M0GhHJULKp07omYhfzAeYnWc=434", "authors": ["TLDR Newsletter"], "title": "Claude Code in Slack", "comment": "Source: TLDR Newsletter, Date: 2025-12-09, Reading time: 3 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftechcrunch.com%2F2025%2F12%2F08%2Fclaude-code-is-coming-to-slack-and-thats-a-bigger-deal-than-it-sounds%2F%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/ZCFzF3qOn4tq1hBejg0M0GhHJULKp07omYhfzAeYnWc=434", "summary": "Claude Code in Slack (3 minute read) Anthropic is launching Claude Code in Slack, allowing devs to run full coding sessions directly from threads. With workflow automation, repo context detection, and progress updates, this shift embeds AI deeper into team collaboration rather than traditional IDEs.", "source": "tldr", "AI": {"tldr": "Anthropic\u5728Slack\u4e2d\u63a8\u51faClaude Code\u529f\u80fd\uff0c\u8ba9\u5f00\u53d1\u8005\u53ef\u4ee5\u76f4\u63a5\u5728Slack\u7ebf\u7a0b\u4e2d\u8fd0\u884c\u5b8c\u6574\u7684\u7f16\u7801\u4f1a\u8bdd\uff0c\u5305\u542b\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u3001\u4ed3\u5e93\u4e0a\u4e0b\u6587\u68c0\u6d4b\u548c\u8fdb\u5ea6\u66f4\u65b0\u7b49\u529f\u80fd\u3002", "motivation": "\u5c06AI\u66f4\u6df1\u5c42\u6b21\u5730\u5d4c\u5165\u56e2\u961f\u534f\u4f5c\u73af\u5883\uff0c\u800c\u4e0d\u662f\u4f20\u7edf\u7684IDE\u4e2d\uff0c\u4f7f\u5f00\u53d1\u56e2\u961f\u80fd\u591f\u5728\u65e5\u5e38\u6c9f\u901a\u5de5\u5177\u4e2d\u76f4\u63a5\u8fdb\u884c\u7f16\u7801\u5de5\u4f5c\uff0c\u63d0\u9ad8\u534f\u4f5c\u6548\u7387\u3002", "method": "\u5728Slack\u5e73\u53f0\u96c6\u6210Claude Code\u529f\u80fd\uff0c\u63d0\u4f9b\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u3001\u4ed3\u5e93\u4e0a\u4e0b\u6587\u68c0\u6d4b\u548c\u8fdb\u5ea6\u66f4\u65b0\u7b49\u7279\u6027\uff0c\u8ba9\u5f00\u53d1\u8005\u80fd\u591f\u5728Slack\u7ebf\u7a0b\u4e2d\u76f4\u63a5\u8fdb\u884c\u7f16\u7801\u4f1a\u8bdd\u3002", "result": "\u6210\u529f\u5728Slack\u4e2d\u90e8\u7f72\u4e86Claude Code\u529f\u80fd\uff0c\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u5728\u56e2\u961f\u534f\u4f5c\u5de5\u5177\u4e2d\u76f4\u63a5\u8fd0\u884c\u5b8c\u6574\u7684\u7f16\u7801\u4f1a\u8bdd\uff0c\u5b9e\u73b0\u4e86AI\u4e0e\u56e2\u961f\u534f\u4f5c\u73af\u5883\u7684\u6df1\u5ea6\u96c6\u6210\u3002", "conclusion": "\u901a\u8fc7\u5c06AI\u7f16\u7801\u52a9\u624b\u76f4\u63a5\u96c6\u6210\u5230Slack\u8fd9\u6837\u7684\u56e2\u961f\u534f\u4f5c\u5e73\u53f0\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u652f\u6301\u56e2\u961f\u5f00\u53d1\u5de5\u4f5c\uff0c\u4ee3\u8868\u4e86AI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u5411\u534f\u4f5c\u73af\u5883\u8f6c\u79fb\u7684\u8d8b\u52bf\u3002", "topic": "code agent"}}
{"id": "tldr.2512.cd18b70b", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsecurity.googleblog.com%2F2025%2F12%2Farchitecting-security-for-agentic.html%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/b7xDJgOFS7KojNEeacBCTSqdIFTEyPlUtHw_E47ecaI=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsecurity.googleblog.com%2F2025%2F12%2Farchitecting-security-for-agentic.html%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/b7xDJgOFS7KojNEeacBCTSqdIFTEyPlUtHw_E47ecaI=434", "authors": ["TLDR Newsletter"], "title": "Architecting Security for Agentic Capabilities in Chrome", "comment": "Source: TLDR Newsletter, Date: 2025-12-09, Reading time: 15 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsecurity.googleblog.com%2F2025%2F12%2Farchitecting-security-for-agentic.html%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/b7xDJgOFS7KojNEeacBCTSqdIFTEyPlUtHw_E47ecaI=434", "summary": "Architecting Security for Agentic Capabilities in Chrome (15 minute read) Agentic browsers all face the threat of indirect prompt injection, which can appear anywhere and cause agents to take unwanted actions. Google has invested in a layered defense that includes both deterministic and probabilistic defenses to make it difficult and costly for attackers to cause harm. It created the user alignment critic, which vets an agent's actions using a separate model isolated from untrusted content. I...", "source": "tldr", "AI": {"tldr": "Google\u4e3aChrome\u6d4f\u89c8\u5668\u4e2d\u7684\u667a\u80fd\u4ee3\u7406\u80fd\u529b\u8bbe\u8ba1\u591a\u5c42\u5b89\u5168\u9632\u5fa1\u67b6\u6784\uff0c\u91cd\u70b9\u9632\u8303\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u901a\u8fc7\u7528\u6237\u5bf9\u9f50\u8bc4\u8bba\u5bb6\u7b49\u673a\u5236\u9694\u79bb\u9a8c\u8bc1\u4ee3\u7406\u884c\u4e3a\u3002", "motivation": "\u6240\u6709\u5177\u5907\u4ee3\u7406\u80fd\u529b\u7684\u6d4f\u89c8\u5668\u90fd\u9762\u4e34\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u8fd9\u79cd\u653b\u51fb\u53ef\u80fd\u51fa\u73b0\u5728\u4efb\u4f55\u5730\u65b9\u5e76\u5bfc\u81f4\u4ee3\u7406\u6267\u884c\u6709\u5bb3\u64cd\u4f5c\u3002\u9700\u8981\u5efa\u7acb\u6709\u6548\u7684\u5b89\u5168\u9632\u5fa1\u673a\u5236\u6765\u4fdd\u62a4\u7528\u6237\u3002", "method": "\u91c7\u7528\u5206\u5c42\u9632\u5fa1\u7b56\u7565\uff0c\u7ed3\u5408\u786e\u5b9a\u6027\u548c\u6982\u7387\u6027\u9632\u5fa1\u63aa\u65bd\u3002\u521b\u5efa\u7528\u6237\u5bf9\u9f50\u8bc4\u8bba\u5bb6\uff0c\u4f7f\u7528\u72ec\u7acb\u4e8e\u4e0d\u53d7\u4fe1\u4efb\u5185\u5bb9\u7684\u9694\u79bb\u6a21\u578b\u6765\u5ba1\u67e5\u4ee3\u7406\u7684\u64cd\u4f5c\u3002", "result": "Google\u6295\u8d44\u5efa\u7acb\u4e86\u591a\u5c42\u9632\u5fa1\u4f53\u7cfb\uff0c\u4f7f\u653b\u51fb\u8005\u96be\u4ee5\u9020\u6210\u635f\u5bb3\u4e14\u653b\u51fb\u6210\u672c\u9ad8\u6602\u3002\u7528\u6237\u5bf9\u9f50\u8bc4\u8bba\u5bb6\u673a\u5236\u80fd\u591f\u6709\u6548\u5ba1\u67e5\u4ee3\u7406\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u5206\u5c42\u5b89\u5168\u67b6\u6784\u548c\u7528\u6237\u5bf9\u9f50\u8bc4\u8bba\u5bb6\u7b49\u673a\u5236\uff0c\u53ef\u4ee5\u6709\u6548\u9632\u8303\u4ee3\u7406\u6d4f\u89c8\u5668\u4e2d\u7684\u95f4\u63a5\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u4fdd\u62a4\u7528\u6237\u5b89\u5168\u3002", "topic": "agent analysis"}}
{"id": "tldr.2512.5ce3a8ed", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmartin.kleppmann.com%2F2025%2F12%2F08%2Fai-formal-verification.html%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/F-uBQbtQPqa3Uxfry4vz5RlWGyWUa0p-SMyb8OkL9q0=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmartin.kleppmann.com%2F2025%2F12%2F08%2Fai-formal-verification.html%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/F-uBQbtQPqa3Uxfry4vz5RlWGyWUa0p-SMyb8OkL9q0=434", "authors": ["TLDR Newsletter"], "title": "Prediction: AI will make formal verification go mainstream", "comment": "Source: TLDR Newsletter, Date: 2025-12-09, Reading time: 6 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmartin.kleppmann.com%2F2025%2F12%2F08%2Fai-formal-verification.html%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/F-uBQbtQPqa3Uxfry4vz5RlWGyWUa0p-SMyb8OkL9q0=434", "summary": "Prediction: AI will make formal verification go mainstream (6 minute read) AI-generated code needs formal verification to automate the review process and counteract the imprecise and probabilistic nature of LLMs.", "source": "tldr", "AI": {"tldr": "AI\u5c06\u4f7f\u5f62\u5f0f\u9a8c\u8bc1\u6210\u4e3a\u4e3b\u6d41\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u6765\u5e94\u5bf9LLM\u751f\u6210\u4ee3\u7801\u7684\u4e0d\u7cbe\u786e\u6027\u548c\u6982\u7387\u6027\u672c\u8d28", "motivation": "AI\u751f\u6210\u7684\u4ee3\u7801\u9700\u8981\u5f62\u5f0f\u9a8c\u8bc1\u6765\u81ea\u52a8\u5316\u5ba1\u67e5\u8fc7\u7a0b\uff0c\u5e76\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4e0d\u7cbe\u786e\u548c\u6982\u7387\u6027\u672c\u8d28", "method": "\u8be5\u5185\u5bb9\u4e3b\u8981\u662f\u4e00\u4e2a\u9884\u6d4b\u6027\u89c2\u70b9\uff0c\u800c\u975e\u5177\u4f53\u7684\u7814\u7a76\u65b9\u6cd5\u3002\u5b83\u63d0\u51fa\u5c06\u5f62\u5f0f\u9a8c\u8bc1\u6280\u672f\u4e0eAI\u751f\u6210\u7684\u4ee3\u7801\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u9a8c\u8bc1\u6d41\u7a0b\u6765\u786e\u4fdd\u4ee3\u7801\u8d28\u91cf", "result": "\u9884\u6d4bAI\u5c06\u4f7f\u5f62\u5f0f\u9a8c\u8bc1\u6280\u672f\u6210\u4e3a\u4e3b\u6d41\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u4ee3\u7801\u5ba1\u67e5\u8fc7\u7a0b\u6765\u63d0\u9ad8AI\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027", "conclusion": "\u5f62\u5f0f\u9a8c\u8bc1\u5c06\u6210\u4e3a\u5e94\u5bf9AI\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u6311\u6218\u7684\u5173\u952e\u6280\u672f\uff0c\u4f7f\u5f62\u5f0f\u9a8c\u8bc1\u4ece\u5b66\u672f\u7814\u7a76\u8d70\u5411\u5de5\u4e1a\u5e94\u7528\u4e3b\u6d41", "topic": "code agent"}}
{"id": "tldr.2512.a0d2adf8", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fdocs.rs%2Fadk-rust%2F0.1.4%2Fadk_rust%2F%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/pPw5yvw_aWznhKvlA13Xjcic3I6aI03HH2Y4tPpsvgk=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fdocs.rs%2Fadk-rust%2F0.1.4%2Fadk_rust%2F%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/pPw5yvw_aWznhKvlA13Xjcic3I6aI03HH2Y4tPpsvgk=434", "authors": ["TLDR Newsletter"], "title": "Agent Development Kit for Rust", "comment": "Source: TLDR Newsletter, Date: 2025-12-09, Reading time: 14 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fdocs.rs%2Fadk-rust%2F0.1.4%2Fadk_rust%2F%3Futm_source=tldrai/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/pPw5yvw_aWznhKvlA13Xjcic3I6aI03HH2Y4tPpsvgk=434", "summary": "Agent Development Kit (ADK) for Rust (14 minute read) adk_rust is a flexible and modular framework for developing and deploying AI agents in Rust.", "source": "tldr", "AI": {"tldr": "ADK_Rust\u662f\u4e00\u4e2a\u7528\u4e8e\u5728Rust\u4e2d\u5f00\u53d1\u548c\u90e8\u7f72AI\u4ee3\u7406\u7684\u7075\u6d3b\u6a21\u5757\u5316\u6846\u67b6", "motivation": "\u4e3aRust\u5f00\u53d1\u8005\u63d0\u4f9b\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8eAI\u4ee3\u7406\u5f00\u53d1\u7684\u5de5\u5177\u5305\uff0c\u89e3\u51b3\u73b0\u6709\u6846\u67b6\u5728Rust\u751f\u6001\u4e2d\u7684\u4e0d\u8db3", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7075\u6d3b\u4e14\u6a21\u5757\u5316\u7684\u6846\u67b6\u67b6\u6784\uff0c\u652f\u6301AI\u4ee3\u7406\u7684\u5f00\u53d1\u548c\u90e8\u7f72", "result": "\u6210\u529f\u5b9e\u73b0\u4e86ADK_Rust\u6846\u67b6\uff0c\u4e3aRust\u793e\u533a\u63d0\u4f9b\u4e86AI\u4ee3\u7406\u5f00\u53d1\u5de5\u5177", "conclusion": "ADK_Rust\u662f\u4e00\u4e2a\u6709\u6548\u7684Rust AI\u4ee3\u7406\u5f00\u53d1\u6846\u67b6\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u7684\u7a7a\u767d", "topic": "code agent"}}
{"id": "tldr.2512.6b208361", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrai%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/kbGtaGdfvWayIorf4gL0xm34mCIJRXJb9XilCwJKW1E=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrai%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/kbGtaGdfvWayIorf4gL0xm34mCIJRXJb9XilCwJKW1E=434", "authors": ["TLDR Newsletter"], "title": "advertise with us", "comment": "Source: TLDR Newsletter, Date: 2025-12-09, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrai%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/kbGtaGdfvWayIorf4gL0xm34mCIJRXJb9XilCwJKW1E=434", "summary": "Agent Development Kit (ADK) for Rust (14 minute read) adk_rust is a flexible and modular framework for developing and deploying AI agents in Rust.", "source": "tldr", "AI": {"tldr": "ADK for Rust\u662f\u4e00\u4e2a\u7075\u6d3b\u6a21\u5757\u5316\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728Rust\u4e2d\u5f00\u53d1\u548c\u90e8\u7f72AI\u667a\u80fd\u4f53", "motivation": "\u4e3aRust\u5f00\u53d1\u8005\u63d0\u4f9b\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8eAI\u667a\u80fd\u4f53\u5f00\u53d1\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u73b0\u6709\u5de5\u5177\u5728Rust\u751f\u6001\u4e2d\u7684\u4e0d\u8db3", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7075\u6d3b\u4e14\u6a21\u5757\u5316\u7684\u6846\u67b6\u67b6\u6784\uff0c\u652f\u6301AI\u667a\u80fd\u4f53\u7684\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u7ba1\u7406", "result": "\u6210\u529f\u5b9e\u73b0\u4e86ADK for Rust\u6846\u67b6\uff0c\u4e3aRust\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86AI\u667a\u80fd\u4f53\u5f00\u53d1\u5de5\u5177", "conclusion": "ADK for Rust\u586b\u8865\u4e86Rust\u751f\u6001\u4e2dAI\u667a\u80fd\u4f53\u5f00\u53d1\u6846\u67b6\u7684\u7a7a\u767d\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c", "topic": "code agent"}}
{"id": "tldr.2512.38c71f9f", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/dejGGhwakUOqvVzGj4ehelWGgcgzUgKcyqH1r4bMyqI=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/dejGGhwakUOqvVzGj4ehelWGgcgzUgKcyqH1r4bMyqI=434", "authors": ["TLDR Newsletter"], "title": "create your own role", "comment": "Source: TLDR Newsletter, Date: 2025-12-09, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/dejGGhwakUOqvVzGj4ehelWGgcgzUgKcyqH1r4bMyqI=434", "summary": "Agent Development Kit (ADK) for Rust (14 minute read) adk_rust is a flexible and modular framework for developing and deploying AI agents in Rust.", "source": "tldr", "AI": {"tldr": "ADK\u662f\u4e00\u4e2a\u7528Rust\u5f00\u53d1\u7684\u7075\u6d3b\u6a21\u5757\u5316AI\u4ee3\u7406\u6846\u67b6", "motivation": "\u4e3aRust\u5f00\u53d1\u8005\u63d0\u4f9b\u4e00\u4e2a\u7075\u6d3b\u3001\u6a21\u5757\u5316\u7684AI\u4ee3\u7406\u5f00\u53d1\u6846\u67b6\uff0c\u7b80\u5316AI\u4ee3\u7406\u7684\u5f00\u53d1\u548c\u90e8\u7f72", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8eRust\u7684\u6846\u67b6\uff0c\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u63d0\u4f9b\u7075\u6d3b\u7684\u7ec4\u4ef6\u548c\u5de5\u5177\u96c6", "result": "\u6210\u529f\u521b\u5efa\u4e86ADK\u6846\u67b6\uff0c\u652f\u6301\u5728Rust\u73af\u5883\u4e2d\u9ad8\u6548\u5f00\u53d1\u548c\u90e8\u7f72AI\u4ee3\u7406", "conclusion": "ADK\u4e3aRust\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684AI\u4ee3\u7406\u5f00\u53d1\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8Rust\u5728AI\u9886\u57df\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "tldr.2512.2619703e", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/GfhZHngIKKXzVe8iThqO-jV4LYq3RF-qg7QywA_mDR8=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/GfhZHngIKKXzVe8iThqO-jV4LYq3RF-qg7QywA_mDR8=434", "authors": ["TLDR Newsletter"], "title": "Inc.'s Best Bootstrapped businesses", "comment": "Source: TLDR Newsletter, Date: 2025-12-09, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b0378b9c4-1e5fb954-7f79-4358-a873-e6733828b7f3-000000/GfhZHngIKKXzVe8iThqO-jV4LYq3RF-qg7QywA_mDR8=434", "summary": "Agent Development Kit (ADK) for Rust (14 minute read) adk_rust is a flexible and modular framework for developing and deploying AI agents in Rust.", "source": "tldr", "AI": {"tldr": "ADK_Rust\u662f\u4e00\u4e2a\u7528\u4e8eRust\u8bed\u8a00\u5f00\u53d1AI\u4ee3\u7406\u7684\u7075\u6d3b\u6a21\u5757\u5316\u6846\u67b6", "motivation": "\u4e3aRust\u5f00\u53d1\u8005\u63d0\u4f9b\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u6784\u5efa\u548c\u90e8\u7f72AI\u4ee3\u7406\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u73b0\u6709\u5de5\u5177\u5728Rust\u751f\u6001\u4e2d\u7684\u4e0d\u8db3", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7075\u6d3b\u3001\u6a21\u5757\u5316\u7684\u6846\u67b6\u67b6\u6784\uff0c\u652f\u6301AI\u4ee3\u7406\u7684\u5f00\u53d1\u548c\u90e8\u7f72", "result": "\u6210\u529f\u5f00\u53d1\u51faADK_Rust\u6846\u67b6\uff0c\u4e3aRust\u793e\u533a\u63d0\u4f9b\u4e86AI\u4ee3\u7406\u5f00\u53d1\u5de5\u5177", "conclusion": "ADK_Rust\u662f\u4e00\u4e2a\u6709\u6548\u7684Rust AI\u4ee3\u7406\u5f00\u53d1\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8Rust\u5728AI\u4ee3\u7406\u9886\u57df\u7684\u53d1\u5c55", "topic": "code agent"}}
{"id": "wechat.2512.654e3100", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg5MDE5NTEyNg==&mid=2247513772&idx=1&sn=9771105877949a5a4d133755966e1925&chksm=ce05bc5013deb7b84e38dc575be99c66562dc0239980bccc8673ea65fdbedcaa1fa5feb4db20#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg5MDE5NTEyNg==&mid=2247513772&idx=1&sn=9771105877949a5a4d133755966e1925&chksm=ce05bc5013deb7b84e38dc575be99c66562dc0239980bccc8673ea65fdbedcaa1fa5feb4db20#rd", "authors": ["CSE\u4fe1\u606f\u65f6\u4ee3"], "title": "\u79d1\u666e\u4e13\u680f| <em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u5982\u4f55\u6559\u4f1a\u673a\u5668\u201c\u601d\u8003\u201d\u5e76\u201c\u521b\u9020\u201d", "comment": "Source: WeChat, Published: 2025-12-11 11:39:07", "summary": "\u4e00\u3001 \u521d\u671f\uff1a\u50cf\u5a74\u513f\u5b66\u6b65\u4e00\u6837\u7684\u667a\u80fd \u4ec0\u4e48\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u672c\u662f\u601d\u60f3\uff1f\u60f3\u8c61\u4e00\u4e0b\u6559\u4e00\u4e2a\u5a74\u513f\u8d70\u8def[1]\u3002\u4ed6\u4e0d\u4f1a\u8bf4\u8bdd\uff0c\u4e5f\u542c\u4e0d\u61c2\u590d\u6742\u7684\u6307\u4ee4\u3002\u4f60\u6240\u80fd\u505a\u7684\uff0c\u5c31\u662f\u5728\u4ed6\u8fc8\u51fa\u6b63\u786e\u4e00\u6b65\u65f6\uff0c\u7ed9\u4e00\u4e2a\u7cd6\u679c\u3001\u997c\u5e72\u548c\u9f13\u52b1\uff08\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5956\u52b1\uff09\uff0c", "AI": {"tldr": "\u4e00\u3001 \u521d\u671f\uff1a\u50cf\u5a74\u513f\u5b66\u6b65\u4e00\u6837\u7684\u667a\u80fd \u4ec0\u4e48\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u672c\u662f\u601d\u60f3\uff1f\u60f3\u8c61\u4e00\u4e0b\u6559\u4e00\u4e2a\u5a74\u513f\u8d70\u8def[1]\u3002\u4ed6\u4e0d\u4f1a\u8bf4\u8bdd\uff0c\u4e5f\u542c\u4e0d\u61c2\u590d\u6742\u7684\u6307\u4ee4\u3002\u4f60\u6240\u80fd\u505a\u7684\uff0c\u5c31\u662f\u5728\u4ed6\u8fc8\u51fa\u6b63\u786e\u4e00\u6b65\u65f6\uff0c\u7ed9\u4e00\u4e2a\u7cd6\u679c\u3001\u997c\u5e72\u548c\u9f13\u52b1\uff08\u4f5c\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5956\u52b1\uff09\uff0c", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.2c9abf73", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzMDU5NDc4Nw==&mid=2247494719&idx=1&sn=e1ad151a199e251eae861ae20daa35dd&chksm=c3b12cb8c70dca519ebb9b2c113057086fe11c420f5a67de4031ccf237707f4367dc75b02b75#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzMDU5NDc4Nw==&mid=2247494719&idx=1&sn=e1ad151a199e251eae861ae20daa35dd&chksm=c3b12cb8c70dca519ebb9b2c113057086fe11c420f5a67de4031ccf237707f4367dc75b02b75#rd", "authors": ["\u673a\u5668\u4eba\u89c4\u5212\u4e0e\u63a7\u5236\u7814\u7a76\u6240"], "title": "2026\u5e74<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7684\u7b97\u6cd5\u521b\u65b0\u5efa\u8bae\uff08\u8bf7\u6536\u85cf\uff09", "comment": "Source: WeChat, Published: 2025-12-11 04:03:37", "summary": "\u514d\u8d39\u83b7\u53d6\u5168\u90e8\u8bba\u6587+\u5f00\u6e90\u4ee3\u7801 \u5f3a\u5316\u5b66\u4e60+\u5927\u6a21\u578b \u73b0\u5728\u4e0e\u5927\u6a21\u578b\u7ed3\u5408\u5728\u9876\u4f1a\uff08NeurIPS/ICLR/ICML\uff09\u4e0a\u5c5e\u4e8e\u201c\u6d41\u91cf\u5bc6\u7801\u201d\uff0c\u65e0\u8bba\u662f\u5c06RL\u7528\u4e8e\u5bf9\u9f50\u5fae\u8c03\uff08\u6bd4\u5982RLHF\uff09\u3001agent\u51b3\u7b56\u89c4\u5212\uff0c\u8fd8\u662f\u7528LLM\u751f\u6210\u5956\u52b1\u51fd\u6570/\u73af\u5883\uff0c\u90fd\u5bb9\u6613\u4ea7\u751fnovelty\u3002", "AI": {"tldr": "\u514d\u8d39\u83b7\u53d6\u5168\u90e8\u8bba\u6587+\u5f00\u6e90\u4ee3\u7801 \u5f3a\u5316\u5b66\u4e60+\u5927\u6a21\u578b \u73b0\u5728\u4e0e\u5927\u6a21\u578b\u7ed3\u5408\u5728\u9876\u4f1a\uff08NeurIPS/ICLR/ICML\uff09\u4e0a\u5c5e\u4e8e\u201c\u6d41\u91cf\u5bc6\u7801\u201d\uff0c\u65e0\u8bba\u662f\u5c06RL\u7528\u4e8e\u5bf9\u9f50\u5fae\u8c03\uff08\u6bd4\u5982RLHF\uff09\u3001agent\u51b3\u7b56\u89c4\u5212\uff0c\u8fd8\u662f\u7528LLM\u751f\u6210\u5956\u52b1\u51fd\u6570/\u73af\u5883\uff0c\u90fd\u5bb9\u6613\u4ea7\u751fnovelty\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.49f0c7ee", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&mid=2247724626&idx=1&sn=ec0f3c6e91b10fd554ca2095a8fd3240&chksm=ce91f50ffecc5b47b6852f4f34561e51d68141a22f3df1630909117bdcb8d1de9455421affee#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4OTEwNjMzMA==&mid=2247724626&idx=1&sn=ec0f3c6e91b10fd554ca2095a8fd3240&chksm=ce91f50ffecc5b47b6852f4f34561e51d68141a22f3df1630909117bdcb8d1de9455421affee#rd", "authors": ["arXiv\u6bcf\u65e5\u5b66\u672f\u901f\u9012"], "title": "2026\u5e74<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7684\u7b97\u6cd5\u521b\u65b0\u5efa\u8bae\uff08\u8bf7\u6536\u85cf\uff09", "comment": "Source: WeChat, Published: 2025-12-11 03:54:26", "summary": "\u514d\u8d39\u83b7\u53d6\u5168\u90e8\u8bba\u6587+\u5f00\u6e90\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60+\u5927\u6a21\u578b\u73b0\u5728\u4e0e\u5927\u6a21\u578b\u7ed3\u5408\u5728\u9876\u4f1a\uff08NeurIPS/ICLR/ICML\uff09\u4e0a\u5c5e\u4e8e\u201c\u6d41\u91cf\u5bc6\u7801\u201d\uff0c\u65e0\u8bba\u662f\u5c06RL\u7528\u4e8e\u5bf9\u9f50\u5fae\u8c03\uff08\u6bd4\u5982RLHF\uff09\u3001agent\u51b3\u7b56\u89c4\u5212\uff0c\u8fd8\u662f\u7528LLM\u751f\u6210\u5956\u52b1\u51fd\u6570/\u73af\u5883\uff0c\u90fd\u5bb9\u6613\u4ea7\u751fnovelty\u3002", "AI": {"tldr": "\u514d\u8d39\u83b7\u53d6\u5168\u90e8\u8bba\u6587+\u5f00\u6e90\u4ee3\u7801\u5f3a\u5316\u5b66\u4e60+\u5927\u6a21\u578b\u73b0\u5728\u4e0e\u5927\u6a21\u578b\u7ed3\u5408\u5728\u9876\u4f1a\uff08NeurIPS/ICLR/ICML\uff09\u4e0a\u5c5e\u4e8e\u201c\u6d41\u91cf\u5bc6\u7801\u201d\uff0c\u65e0\u8bba\u662f\u5c06RL\u7528\u4e8e\u5bf9\u9f50\u5fae\u8c03\uff08\u6bd4\u5982RLHF\uff09\u3001agent\u51b3\u7b56\u89c4\u5212\uff0c\u8fd8\u662f\u7528LLM\u751f\u6210\u5956\u52b1\u51fd\u6570/\u73af\u5883\uff0c\u90fd\u5bb9\u6613\u4ea7\u751fnovelty\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.4e407f39", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0MjUxMzg3OQ==&mid=2247496920&idx=1&sn=1e82acf9ae58b3870d7f6a192e25b677&chksm=c30aa00b579616974f4b1f0e4973feb8607341ce4061ebc0fca4683b9f539440f6107545e75e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0MjUxMzg3OQ==&mid=2247496920&idx=1&sn=1e82acf9ae58b3870d7f6a192e25b677&chksm=c30aa00b579616974f4b1f0e4973feb8607341ce4061ebc0fca4683b9f539440f6107545e75e#rd", "authors": ["\u6df1\u591c\u52aa\u529b\u5199Python"], "title": "\u6740\u75af\u4e86\uff012026<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7b97\u6cd5\u521b\u65b0 \uff01\uff01", "comment": "Source: WeChat, Published: 2025-12-11 03:36:48", "summary": "\u514d\u8d39\u83b7\u53d6\u5168\u90e8\u8bba\u6587+\u5f00\u6e90\u4ee3\u7801 \u5f3a\u5316\u5b66\u4e60+\u5927\u6a21\u578b \u73b0\u5728\u4e0e\u5927\u6a21\u578b\u7ed3\u5408\u5728\u9876\u4f1a\uff08NeurIPS/ICLR/ICML\uff09\u4e0a\u5c5e\u4e8e\u201c\u6d41\u91cf\u5bc6\u7801\u201d\uff0c\u65e0\u8bba\u662f\u5c06RL\u7528\u4e8e\u5bf9\u9f50\u5fae\u8c03\uff08\u6bd4\u5982RLHF\uff09\u3001agent\u51b3\u7b56\u89c4\u5212\uff0c\u8fd8\u662f\u7528LLM\u751f\u6210\u5956\u52b1\u51fd\u6570/\u73af\u5883\uff0c\u90fd\u5bb9\u6613\u4ea7\u751fnovelty\u3002", "AI": {"tldr": "\u514d\u8d39\u83b7\u53d6\u5168\u90e8\u8bba\u6587+\u5f00\u6e90\u4ee3\u7801 \u5f3a\u5316\u5b66\u4e60+\u5927\u6a21\u578b \u73b0\u5728\u4e0e\u5927\u6a21\u578b\u7ed3\u5408\u5728\u9876\u4f1a\uff08NeurIPS/ICLR/ICML\uff09\u4e0a\u5c5e\u4e8e\u201c\u6d41\u91cf\u5bc6\u7801\u201d\uff0c\u65e0\u8bba\u662f\u5c06RL\u7528\u4e8e\u5bf9\u9f50\u5fae\u8c03\uff08\u6bd4\u5982RLHF\uff09\u3001agent\u51b3\u7b56\u89c4\u5212\uff0c\u8fd8\u662f\u7528LLM\u751f\u6210\u5956\u52b1\u51fd\u6570/\u73af\u5883\uff0c\u90fd\u5bb9\u6613\u4ea7\u751fnovelty\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.93c9e5af", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0OTMzOTc3Mg==&mid=2247508838&idx=1&sn=c74fa6b1e84a442c59fc8002d555a3dd&chksm=c205bf9fc416114c3bc63ad29f1fef2f899efac112a6173aea2fbff96c07f43b1bed9ac7832d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0OTMzOTc3Mg==&mid=2247508838&idx=1&sn=c74fa6b1e84a442c59fc8002d555a3dd&chksm=c205bf9fc416114c3bc63ad29f1fef2f899efac112a6173aea2fbff96c07f43b1bed9ac7832d#rd", "authors": ["\u4e5d\u7ae0\u4e91\u6781DataCanvas\u667a\u80fd\u7814\u7a76\u9662"], "title": "Forrester\uff1a\u8fd1\u516d\u6210\u4e2d\u56fd\u4f01\u4e1a\u5df2\u91c7\u7528<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6280\u672f\u63d0\u9ad8\u63a8\u7406\u6548\u7387\uff08\u9644\u62a5\u544a\u539f\u6587\uff09", "comment": "Source: WeChat, Published: 2025-12-11 03:31:03", "summary": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e0d\u4ec5\u9700\u6295\u5165\u6602\u8d35\u57fa\u7840\u8bbe\u65bd\u3001\u50a8\u5907\u6df1\u539a\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e14\u5de5\u4f5c\u6d41\u7a0b\u8017\u65f6\u5197\u957f\uff0c\u4e25\u91cd\u62d6\u7d2f\u6280\u672f\u8fed\u4ee3\u901f\u5ea6\u3002\u800c\u65e0\u670d\u52a1\u5668\u5f3a\u5316\u5b66\u4e60\uff08Serverless RL\uff09\u7684\u51fa\u73b0\u6709\u6548\u6253\u7834\u8fd9\u4e9b\u58c1\u5792\uff0c\u65e0\u8bba\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\u8fd8\u662f\u884c\u4e1a\u65b0\u624b\uff0c\u90fd\u80fd\u83b7\u5f97\u66f4\u4f18\u5f00", "AI": {"tldr": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e0d\u4ec5\u9700\u6295\u5165\u6602\u8d35\u57fa\u7840\u8bbe\u65bd\u3001\u50a8\u5907\u6df1\u539a\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e14\u5de5\u4f5c\u6d41\u7a0b\u8017\u65f6\u5197\u957f\uff0c\u4e25\u91cd\u62d6\u7d2f\u6280\u672f\u8fed\u4ee3\u901f\u5ea6\u3002\u800c\u65e0\u670d\u52a1\u5668\u5f3a\u5316\u5b66\u4e60\uff08Serverless RL\uff09\u7684\u51fa\u73b0\u6709\u6548\u6253\u7834\u8fd9\u4e9b\u58c1\u5792\uff0c\u65e0\u8bba\u7ecf\u9a8c\u4e30\u5bcc\u7684\u5f00\u53d1\u8005\u8fd8\u662f\u884c\u4e1a\u65b0\u624b\uff0c\u90fd\u80fd\u83b7\u5f97\u66f4\u4f18\u5f00", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.2d3d73b7", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247672352&idx=1&sn=9d01dcb4bace24658a31b2cbccc61c78&chksm=fdc6c9878666d86b1c58e3dcd5371ab1c0285f786a1a89d662e4ab49ce728e4cbf03df4288e9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU2OTA0NzE2NA==&mid=2247672352&idx=1&sn=9d01dcb4bace24658a31b2cbccc61c78&chksm=fdc6c9878666d86b1c58e3dcd5371ab1c0285f786a1a89d662e4ab49ce728e4cbf03df4288e9#rd", "authors": ["\u4e13\u77e5"], "title": "\u6df1\u5ea6<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u4e0e\u6a21\u4eff\u5b66\u4e60\u5bfc\u8bba", "comment": "Source: WeChat, Published: 2025-12-11 03:01:58", "summary": "\u82e5\u8bfb\u8005\u5bf9\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u611f\u5174\u8da3\uff0c\u5efa\u8bae\u7ee7\u7eed\u9605\u8bfb\u7b2c 3 \u7ae0\uff08\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff09\u548c\u7b2c 4 \u7ae0\uff08\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff09\u3002\u82e5\u540c\u65f6\u5e0c\u671b\u4e86\u89e3\u6df1\u5ea6\u6a21\u4eff\u5b66\u4e60\uff0c\u53ef\u7ee7\u7eed\u9605\u8bfb\u7b2c 5 \u7ae0\uff08\u6df1\u5ea6\u6a21\u4eff\u5b66\u4e60\uff09\u3002", "AI": {"tldr": "\u82e5\u8bfb\u8005\u5bf9\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u611f\u5174\u8da3\uff0c\u5efa\u8bae\u7ee7\u7eed\u9605\u8bfb\u7b2c 3 \u7ae0\uff08\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff09\u548c\u7b2c 4 \u7ae0\uff08\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff09\u3002\u82e5\u540c\u65f6\u5e0c\u671b\u4e86\u89e3\u6df1\u5ea6\u6a21\u4eff\u5b66\u4e60\uff0c\u53ef\u7ee7\u7eed\u9605\u8bfb\u7b2c 5 \u7ae0\uff08\u6df1\u5ea6\u6a21\u4eff\u5b66\u4e60\uff09\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.aa36a720", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyODk2MDQwNw==&mid=2247485107&idx=1&sn=52f5440bdae47fd2a6d056ae9b6ef8d1&chksm=c3984b7ec580af62deec9061a72b21b6c5c21fa1e37f2b872e9938ea28da90e7c1d4e223f19d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyODk2MDQwNw==&mid=2247485107&idx=1&sn=52f5440bdae47fd2a6d056ae9b6ef8d1&chksm=c3984b7ec580af62deec9061a72b21b6c5c21fa1e37f2b872e9938ea28da90e7c1d4e223f19d#rd", "authors": ["\u767e\u7075\u5927\u6a21\u578b"], "title": "AReaL v0.5.0 - <em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6846\u67b6\u7684\u67b6\u6784\u9769\u65b0\uff0c\u6267\u4e00\u9a6d\u4e07\uff0c\u667a\u4f53\u540c\u534f", "comment": "Source: WeChat, Published: 2025-12-11 01:00:53", "summary": "1\u3001\u957f\u5c3e\u95ee\u9898\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5305\u542b\u4e24\u4e2a\u5173\u952e\u9636\u6bb5\uff1aRollout \u4e0e Training\u3002\u5728\u5f53\u524d SPMD \u67b6\u6784\u4e2d\uff1a\u6bcf\u4e2a\u8bad\u7ec3\u8fdb\u7a0b\u72ec\u7acb\u63d0\u4ea4\u56fa\u5b9a\u6570\u91cf\u7684 prompt \u81f3\u63a8\u7406\u5f15\u64ce\uff1b\u7531\u4e8e\u751f\u6210\u957f\u5ea6\u4e0d\u53ef\u9884\u6d4b\uff0c\u90e8\u5206\u8fdb\u7a0b\u53ef\u80fd\u7531\u4e8e\u957f\u5c3e\u4efb\u52a1\uff0c\u9700\u957f\u65f6\u95f4\u7b49\u5f85\uff1b", "AI": {"tldr": "1\u3001\u957f\u5c3e\u95ee\u9898\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5305\u542b\u4e24\u4e2a\u5173\u952e\u9636\u6bb5\uff1aRollout \u4e0e Training\u3002\u5728\u5f53\u524d SPMD \u67b6\u6784\u4e2d\uff1a\u6bcf\u4e2a\u8bad\u7ec3\u8fdb\u7a0b\u72ec\u7acb\u63d0\u4ea4\u56fa\u5b9a\u6570\u91cf\u7684 prompt \u81f3\u63a8\u7406\u5f15\u64ce\uff1b\u7531\u4e8e\u751f\u6210\u957f\u5ea6\u4e0d\u53ef\u9884\u6d4b\uff0c\u90e8\u5206\u8fdb\u7a0b\u53ef\u80fd\u7531\u4e8e\u957f\u5c3e\u4efb\u52a1\uff0c\u9700\u957f\u65f6\u95f4\u7b49\u5f85\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.a34d2042", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzMDI0NDY1Mw==&mid=2247485407&idx=1&sn=048cbdcf99c7fb73829137029816c4be&chksm=c36695100f9318b2c704c233d5562def3f0a3394ac3245693ab2e25aebdc2ed2c357a042f359#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzMDI0NDY1Mw==&mid=2247485407&idx=1&sn=048cbdcf99c7fb73829137029816c4be&chksm=c36695100f9318b2c704c233d5562def3f0a3394ac3245693ab2e25aebdc2ed2c357a042f359#rd", "authors": ["AI\u7ed8\u754cStudio"], "title": "1.4 <em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\uff08Reinforcement Learning\uff09", "comment": "Source: WeChat, Published: 2025-12-11 00:06:20", "summary": "\u5f3a\u5316\u5b66\u4e60\u662f\u4ec0\u4e48\uff1f\u5f3a\u5316\u5b66\u4e60\u662f\u201c\u667a\u80fd\u4f53\uff08Agent\uff09\u201d\u5728\u201c\u73af\u5883\uff08Environment\uff09\u201d\u4e2d\u4e0d\u65ad\u91c7\u53d6\u884c\u52a8\uff0c\u901a\u8fc7\u5956\u52b1\u548c\u60e9\u7f5a\u5b66\u4e60\u6700\u4f18\u884c\u4e3a\u7b56\u7565\u7684\u8fc7\u7a0b\u3002\u5b83\u4e0d\u662f\u6a21\u4eff\u5b66\u4e60\uff0c\u4e0d\u662f\u6807\u7b7e\u5b66\u4e60\uff0c\u800c\u662f\u4e00\u79cd\u57fa\u4e8e\u53cd\u9988\u7684\u63a2\u7d22\u5f0f\u5b66\u4e60\u3002", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\u662f\u4ec0\u4e48\uff1f\u5f3a\u5316\u5b66\u4e60\u662f\u201c\u667a\u80fd\u4f53\uff08Agent\uff09\u201d\u5728\u201c\u73af\u5883\uff08Environment\uff09\u201d\u4e2d\u4e0d\u65ad\u91c7\u53d6\u884c\u52a8\uff0c\u901a\u8fc7\u5956\u52b1\u548c\u60e9\u7f5a\u5b66\u4e60\u6700\u4f18\u884c\u4e3a\u7b56\u7565\u7684\u8fc7\u7a0b\u3002\u5b83\u4e0d\u662f\u6a21\u4eff\u5b66\u4e60\uff0c\u4e0d\u662f\u6807\u7b7e\u5b66\u4e60\uff0c\u800c\u662f\u4e00\u79cd\u57fa\u4e8e\u53cd\u9988\u7684\u63a2\u7d22\u5f0f\u5b66\u4e60\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.48326bd9", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&mid=2247504017&idx=1&sn=17cb6ebb3006fa2f7073d73c9da157e3&chksm=fd3544784e096eb1213c0bc06bc993e6f54f5bf1f997e956ca7d07d1194d1e9c45cc4c777e3e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU2ODgzMTM5NA==&mid=2247504017&idx=1&sn=17cb6ebb3006fa2f7073d73c9da157e3&chksm=fd3544784e096eb1213c0bc06bc993e6f54f5bf1f997e956ca7d07d1194d1e9c45cc4c777e3e#rd", "authors": ["CAAI\u8ba4\u77e5\u7cfb\u7edf\u4e0e\u4fe1\u606f\u5904\u7406\u4e13\u59d4\u4f1a"], "title": "\u6e05\u534e\u5927\u5b66+\u5357\u6d0b\u7406\u5de5 VLA-RL\uff1a\u901a\u8fc7\u53ef\u6269\u5c55\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u5b9e\u73b0\u7cbe\u901a\u548c\u901a\u7528\u7684\u673a\u5668\u4eba\u64cd\u4f5c", "comment": "Source: WeChat, Published: 2025-12-10 16:00:00", "summary": "\u56e0\u6b64\uff0c\u5f3a\u5316\u5b66\u4e60\u5df2\u6210\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u8303\u5f0f\uff0c\u901a\u8fc7\u5728\u65e0\u9650\u5236\u72b6\u6001\u8986\u76d6\u7684\u5728\u7ebf\u6536\u96c6\u6570\u636e\u4e0a\u8fdb\u884c\u57f9\u8bad\uff0c\u5b9e\u73b0\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u7684\u6539\u8fdb\u3002\u4eba\u4eec\u5f88\u81ea\u7136\u5730\u4f1a\u95ee\uff1a\u6211\u4eec\u80fd\u5426\u5728\u81ea\u7531\u843d\u4f53\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u5b9e\u73b0\u7c7b\u4f3c\u7684\u57fa\u4e8eRL\u7684\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u6548\u76ca\uff1f", "AI": {"tldr": "\u56e0\u6b64\uff0c\u5f3a\u5316\u5b66\u4e60\u5df2\u6210\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u8303\u5f0f\uff0c\u901a\u8fc7\u5728\u65e0\u9650\u5236\u72b6\u6001\u8986\u76d6\u7684\u5728\u7ebf\u6536\u96c6\u6570\u636e\u4e0a\u8fdb\u884c\u57f9\u8bad\uff0c\u5b9e\u73b0\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u7684\u6539\u8fdb\u3002\u4eba\u4eec\u5f88\u81ea\u7136\u5730\u4f1a\u95ee\uff1a\u6211\u4eec\u80fd\u5426\u5728\u81ea\u7531\u843d\u4f53\u673a\u5668\u4eba\u64cd\u4f5c\u4e2d\u5b9e\u73b0\u7c7b\u4f3c\u7684\u57fa\u4e8eRL\u7684\u6d4b\u8bd5\u65f6\u95f4\u7f29\u653e\u6548\u76ca\uff1f", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.018deae0", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxMjM2MDIyNQ==&mid=2247660555&idx=1&sn=c8bda86d9077a1035c102742092b8cc1&chksm=c0ce842f4c8daa7c6bb6ca49c33651c6a10ac85db5c35fd2eeada7f65c297b24132446a78577#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxMjM2MDIyNQ==&mid=2247660555&idx=1&sn=c8bda86d9077a1035c102742092b8cc1&chksm=c0ce842f4c8daa7c6bb6ca49c33651c6a10ac85db5c35fd2eeada7f65c297b24132446a78577#rd", "authors": ["DataFunSummit"], "title": "<em class=\"highlight\">\u667a\u80fd\u4f53</em>\u5373\u5f00\u53d1\u8005\uff1a\u8bbaAI\u5982\u4f55\u91cd\u5851\u7f16\u7a0b\u8fb9\u754c\u4e0e\u4eba\u673a\u534f\u540c\u672a\u6765", "comment": "Source: WeChat, Published: 2025-12-11 10:03:45", "summary": "\u5927\u5bb6\u6838\u5fc3\u5173\u6ce8\u7684 Code Agent \u80fd\u529b\u8fb9\u754c\uff0c\u6211\u8ba4\u4e3a\u5176\u53d1\u5c55\u4f1a\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1aWeb Coding\uff08\u5f53\u524d\u9636\u6bb5\uff09\uff1a\u8fd9\u4e2a\u9636\u6bb5\u5f3a\u8c03\u4eba\u673a\u6df1\u5ea6\u4ea4\u4e92\u3002\u7531\u4eba\u53d1\u8d77\u9700\u6c42\u3001\u5f15\u5bfc AI\u3001Review \u4ee3\u7801\u5e76\u8d1f\u8d23\u540e\u7eed\u64cd\u4f5c\u3002", "AI": {"tldr": "\u5927\u5bb6\u6838\u5fc3\u5173\u6ce8\u7684 Code Agent \u80fd\u529b\u8fb9\u754c\uff0c\u6211\u8ba4\u4e3a\u5176\u53d1\u5c55\u4f1a\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1aWeb Coding\uff08\u5f53\u524d\u9636\u6bb5\uff09\uff1a\u8fd9\u4e2a\u9636\u6bb5\u5f3a\u8c03\u4eba\u673a\u6df1\u5ea6\u4ea4\u4e92\u3002\u7531\u4eba\u53d1\u8d77\u9700\u6c42\u3001\u5f15\u5bfc AI\u3001Review \u4ee3\u7801\u5e76\u8d1f\u8d23\u540e\u7eed\u64cd\u4f5c\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.737741c5", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxOTU5NTU4MQ==&mid=2247496636&idx=1&sn=32120ede8fd2e8cb80f2a08042c0a627&chksm=9a8b4cc42271fd77a54a1bc14eb2144c62e366cd70a874e0bea1273877b2a0cbb1559fe21dc8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxOTU5NTU4MQ==&mid=2247496636&idx=1&sn=32120ede8fd2e8cb80f2a08042c0a627&chksm=9a8b4cc42271fd77a54a1bc14eb2144c62e366cd70a874e0bea1273877b2a0cbb1559fe21dc8#rd", "authors": ["ChallengeHub"], "title": "\u4ec0\u4e48\u662f\u667a\u80fd\u4f53\u5de5\u7a0bAgent Engineering\uff1f\u8ba9 AI\u4ece\u201c\u80fd\u8dd1\u201c\u5230\u201c\u6562\u7528\u201c\u7684\u5173\u952e", "comment": "Source: WeChat, Published: 2025-12-11 13:49:22", "summary": "\u7b80\u5355\u7684\u5927\u6a21\u578b\u5e94\u7528\u867d\u7136\u4e5f\u6709\u70b9\u968f\u673a\uff0c\u4f46\u884c\u4e3a\u8fd8\u7b97\u53ef\u63a7\u3002\u667a\u80fd\u4f53\u4e0d\u4e00\u6837\uff0c\u5b83\u4eec\u8981\u8de8\u591a\u4e2a\u6b65\u9aa4\u63a8\u7406\u3001\u8c03\u5de5\u5177\u3001\u6839\u636e\u4e0a\u4e0b\u6587\u9002\u5e94\u3002\u8ba9\u5b83\u6709\u7528\u7684\u7279\u6027\uff0c\u4e5f\u8ba9\u5b83\u7684\u884c\u4e3a\u5b8c\u5168\u4e0d\u540c\u4e8e\u4f20\u7edf\u8f6f\u4ef6\uff1a", "AI": {"tldr": "\u7b80\u5355\u7684\u5927\u6a21\u578b\u5e94\u7528\u867d\u7136\u4e5f\u6709\u70b9\u968f\u673a\uff0c\u4f46\u884c\u4e3a\u8fd8\u7b97\u53ef\u63a7\u3002\u667a\u80fd\u4f53\u4e0d\u4e00\u6837\uff0c\u5b83\u4eec\u8981\u8de8\u591a\u4e2a\u6b65\u9aa4\u63a8\u7406\u3001\u8c03\u5de5\u5177\u3001\u6839\u636e\u4e0a\u4e0b\u6587\u9002\u5e94\u3002\u8ba9\u5b83\u6709\u7528\u7684\u7279\u6027\uff0c\u4e5f\u8ba9\u5b83\u7684\u884c\u4e3a\u5b8c\u5168\u4e0d\u540c\u4e8e\u4f20\u7edf\u8f6f\u4ef6\uff1a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.1f361ee5", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3NTQ4NjczNw==&mid=2650675810&idx=2&sn=8b1d21b6bad1db0a82b1ec3bd45fb6a2&chksm=86b8db77d1830b563ccad8c6f354c62f35ba417ddd715b1ed65c7ce91457c39f0ac6d7416596#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3NTQ4NjczNw==&mid=2650675810&idx=2&sn=8b1d21b6bad1db0a82b1ec3bd45fb6a2&chksm=86b8db77d1830b563ccad8c6f354c62f35ba417ddd715b1ed65c7ce91457c39f0ac6d7416596#rd", "authors": ["\u767d\u9cb8\u51fa\u6d77"], "title": "\u4e3a\u4ec0\u4e48\u4eca\u5e74\u6700\u8d5a\u94b1\u3001\u6700\u5bb9\u6613\u878d\u8d44\u3001\u6700\u5bb9\u6613\u8dd1\u51fa\u7206\u6b3e\u7684 AI \u65b9\u5411\uff0c\u5168\u90fd\u6307\u5411\u89c6\u9891\u751f\u6210\uff1f", "comment": "Source: WeChat, Published: 2025-12-11 13:30:47", "summary": "\u5927\u6a21\u578b\u5982\u679c\u8981\u4ecePPT \u4e0a\u7684\u6545\u4e8b\u843d\u5230\u5b9e\u9645\u73b0\u91d1\u6d41\uff0c\u89c6\u9891\u662f\u7b2c\u4e00\u6279\u771f\u6b63\u80fd\u95ed\u73af\u7684\u573a\u666f\u3002\u6587\u672c\u6a21\u578b\u505a Copilot\u3001\u5199\u4ee3\u7801\u3001\u505a\u641c\u7d22\uff0c\u66f4\u591a\u662f\u63d0\u9ad8\u6548\u7387\uff0c\u89c6\u9891\u6a21\u578b\u5219\u662f\u76f4\u63a5\u5e2e\u4f60\u7701\u6389\u4e00\u90e8\u5206\u5916\u5305\u9884\u7b97\u548c\u56e2\u961f headcount\uff0c\u751a\u81f3\u91cd\u5199\u6574\u4e2a\u521b\u4f5c\u5de5\u4f5c\u6d41\u3002", "AI": {"tldr": "\u5927\u6a21\u578b\u5982\u679c\u8981\u4ecePPT \u4e0a\u7684\u6545\u4e8b\u843d\u5230\u5b9e\u9645\u73b0\u91d1\u6d41\uff0c\u89c6\u9891\u662f\u7b2c\u4e00\u6279\u771f\u6b63\u80fd\u95ed\u73af\u7684\u573a\u666f\u3002\u6587\u672c\u6a21\u578b\u505a Copilot\u3001\u5199\u4ee3\u7801\u3001\u505a\u641c\u7d22\uff0c\u66f4\u591a\u662f\u63d0\u9ad8\u6548\u7387\uff0c\u89c6\u9891\u6a21\u578b\u5219\u662f\u76f4\u63a5\u5e2e\u4f60\u7701\u6389\u4e00\u90e8\u5206\u5916\u5305\u9884\u7b97\u548c\u56e2\u961f headcount\uff0c\u751a\u81f3\u91cd\u5199\u6574\u4e2a\u521b\u4f5c\u5de5\u4f5c\u6d41\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.641dd918", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU1NTUxNTM0Mg==&mid=2247586518&idx=2&sn=bea35eb2ee60815abe22df5f7c1830b6&chksm=fa8184125d52fe9735c1aa1caf81c178ef0070512e493e05194f9a2777ae6af91ef5b5646dce#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU1NTUxNTM0Mg==&mid=2247586518&idx=2&sn=bea35eb2ee60815abe22df5f7c1830b6&chksm=fa8184125d52fe9735c1aa1caf81c178ef0070512e493e05194f9a2777ae6af91ef5b5646dce#rd", "authors": ["AI\u601d\u60f3\u4f1a"], "title": "MIT\u6700\u65b0\u53d1\u73b0\uff1a\u8fd9\u5341\u5e74\uff0c\u7b97\u6cd5\u8fdb\u6b65\u88ab\u9ad8\u4f30\u4e86", "comment": "Source: WeChat, Published: 2025-12-11 13:21:22", "summary": "\u540c\u65f6\uff0c\u8fd9\u4e5f\u610f\u5473\u7740\u7b97\u6cd5\u8fdb\u6b65\u5bf9\u5927\u6a21\u578b\u5f00\u53d1\u8005\u7684\u76ca\u5904\u8fdc\u5927\u4e8e\u5bf9\u5c0f\u89c4\u6a21\u53c2\u4e0e\u8005\u7684\u76ca\u5904\u3002\u89c4\u6a21\u4e0d\u53d8\u578b\u7b97\u6cd5\u672c\u6587\u9996\u5148\u901a\u8fc7\u5927\u91cf\u7684\u6d88\u878d\u5b9e\u9a8c\u6765\u5206\u6790\u5355\u4e2a\u7b97\u6cd5\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u7ed8\u5236\u51fa\u7b97\u6cd5\u6539\u8fdb\u7684\u7ec6\u7c92\u5ea6\u56fe\u666f\u3002", "AI": {"tldr": "\u540c\u65f6\uff0c\u8fd9\u4e5f\u610f\u5473\u7740\u7b97\u6cd5\u8fdb\u6b65\u5bf9\u5927\u6a21\u578b\u5f00\u53d1\u8005\u7684\u76ca\u5904\u8fdc\u5927\u4e8e\u5bf9\u5c0f\u89c4\u6a21\u53c2\u4e0e\u8005\u7684\u76ca\u5904\u3002\u89c4\u6a21\u4e0d\u53d8\u578b\u7b97\u6cd5\u672c\u6587\u9996\u5148\u901a\u8fc7\u5927\u91cf\u7684\u6d88\u878d\u5b9e\u9a8c\u6765\u5206\u6790\u5355\u4e2a\u7b97\u6cd5\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u7ed8\u5236\u51fa\u7b97\u6cd5\u6539\u8fdb\u7684\u7ec6\u7c92\u5ea6\u56fe\u666f\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.d545f81d", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYyMzA3MDkxMw==&mid=2247483673&idx=1&sn=4d0d5acf75cf099d89fa4e0976bfd95b&chksm=fee4d7d8cf1862c819e7c1079f352773174dc23c428c15694e4dbe91ce233c764497303b57e8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYyMzA3MDkxMw==&mid=2247483673&idx=1&sn=4d0d5acf75cf099d89fa4e0976bfd95b&chksm=fee4d7d8cf1862c819e7c1079f352773174dc23c428c15694e4dbe91ce233c764497303b57e8#rd", "authors": ["\u5b66\u4e60\u4e0e\u601d\u8003CN"], "title": "\u56fd\u5185\u4e3b\u8981\u7684<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5f00\u53d1\u6846\u67b6\u53ca\u5176\u7279\u70b9", "comment": "Source: WeChat, Published: 2025-12-11 13:17:22", "summary": "\u56fd\u5185\u4e3b\u8981\u7684\u5927\u6a21\u578b\u5f00\u53d1\u6846\u67b6\u53ca\u5176\u7279\u70b9\uff1a", "AI": {"tldr": "\u56fd\u5185\u4e3b\u8981\u7684\u5927\u6a21\u578b\u5f00\u53d1\u6846\u67b6\u53ca\u5176\u7279\u70b9\uff1a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.5a6bfcde", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg5NjA5MzQ3MQ==&mid=2247531792&idx=1&sn=a8305c6913a30755876f7cc33bb54974&chksm=c1b4a347b4b55b760c1f44065e49a83bd93e7a48fda79b54b1b9aa49779f35d4df581371c10f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg5NjA5MzQ3MQ==&mid=2247531792&idx=1&sn=a8305c6913a30755876f7cc33bb54974&chksm=c1b4a347b4b55b760c1f44065e49a83bd93e7a48fda79b54b1b9aa49779f35d4df581371c10f#rd", "authors": ["\u4e09\u5ce1\u901a\u822a\u53d1\u5e03"], "title": "\u6700\u9ad8\u8363\u8a89\uff01\u4e09\u5ce1\u901a\u822a<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5728\u9996\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93<em class=\"highlight\">\u5927\u6a21\u578b</em>\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u4e2d\u8363\u83b7\u7279\u522b\u63a8\u8350\u5956\uff01", "comment": "Source: WeChat, Published: 2025-12-11 12:53:46", "summary": "\u70ed\u70c8\u795d\u8d3a\u4e09\u5ce1\u901a\u822a\u5927\u6a21\u578b\u5b89\u5168\u76d1\u7ba1\u667a\u80fd\u4f53\u8363\u83b7\u9996\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u7279\u522b\u63a8\u8350\u595612\u670810\u65e5\uff0c\u7b2c\u4e00\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u5168\u56fd\u603b\u51b3\u8d5b\u5728\u798f\u5efa\u53a6\u95e8\u843d\u4e0b\u5e37\u5e55\u3002", "AI": {"tldr": "\u70ed\u70c8\u795d\u8d3a\u4e09\u5ce1\u901a\u822a\u5927\u6a21\u578b\u5b89\u5168\u76d1\u7ba1\u667a\u80fd\u4f53\u8363\u83b7\u9996\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u7279\u522b\u63a8\u8350\u595612\u670810\u65e5\uff0c\u7b2c\u4e00\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u5168\u56fd\u603b\u51b3\u8d5b\u5728\u798f\u5efa\u53a6\u95e8\u843d\u4e0b\u5e37\u5e55\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.aa4f6dfa", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg5NDcyMTk5Nw==&mid=2247496216&idx=1&sn=506c624d660d67de70ad219dcda24b4c&chksm=c13fafd6c8de418ab721b2733d0fdccd94bb854d31196b7b818cd13a4e232eb524f99b23c62e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg5NDcyMTk5Nw==&mid=2247496216&idx=1&sn=506c624d660d67de70ad219dcda24b4c&chksm=c13fafd6c8de418ab721b2733d0fdccd94bb854d31196b7b818cd13a4e232eb524f99b23c62e#rd", "authors": ["Zenlayer"], "title": "Zenlayer AI Gateway \u767b\u9646 Dify \u5e02\u573a\uff0c\u8f7b\u88c5\u4e0a\u9635\u642d\u5efa AI Agent", "comment": "Source: WeChat, Published: 2025-12-11 12:48:43", "summary": "\u5927\u6a21\u578b\u9009\u578b\u8017\u65f6\u8d39\u529b\uff0c\u9700\u9010\u4e00\u5206\u6790\u4e0d\u540c\u6a21\u578b\u7684\u4f18\u52bf\u80fd\u529b\u9700\u5728\u5404\u5927\u6a21\u578b\u4f9b\u5e94\u5546\u6ce8\u518c\u591a\u4e2a\u8d26\u6237\uff0c\u624d\u80fd\u83b7\u53d6\u5bf9\u5e94\u7684\u591a\u4e32 API \u5bc6\u94a5\u8f9b\u82e6\u642d\u5efa\u7684\u5de5\u4f5c\u6d41\u5e38\u53d7\u6a21\u578b\u7a33\u5b9a\u6027\u5f71\u54cd\uff0c\u63a8\u7406\u5361\u987f\u6210\u4e3a\u5e38\u6001", "AI": {"tldr": "\u5927\u6a21\u578b\u9009\u578b\u8017\u65f6\u8d39\u529b\uff0c\u9700\u9010\u4e00\u5206\u6790\u4e0d\u540c\u6a21\u578b\u7684\u4f18\u52bf\u80fd\u529b\u9700\u5728\u5404\u5927\u6a21\u578b\u4f9b\u5e94\u5546\u6ce8\u518c\u591a\u4e2a\u8d26\u6237\uff0c\u624d\u80fd\u83b7\u53d6\u5bf9\u5e94\u7684\u591a\u4e32 API \u5bc6\u94a5\u8f9b\u82e6\u642d\u5efa\u7684\u5de5\u4f5c\u6d41\u5e38\u53d7\u6a21\u578b\u7a33\u5b9a\u6027\u5f71\u54cd\uff0c\u63a8\u7406\u5361\u987f\u6210\u4e3a\u5e38\u6001", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.517f286e", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU0NjU0ODk2Mg==&mid=2247501995&idx=1&sn=f950b5eb63d194ec1c20a4089756d1cb&chksm=fafdd2171ab09335b06521dc83a4f2441df76d693303d01e3a011c376a67794c26386b5db911#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU0NjU0ODk2Mg==&mid=2247501995&idx=1&sn=f950b5eb63d194ec1c20a4089756d1cb&chksm=fafdd2171ab09335b06521dc83a4f2441df76d693303d01e3a011c376a67794c26386b5db911#rd", "authors": ["\u817e\u8baf\u4f18\u56fe\u5b9e\u9a8c\u5ba4"], "title": "2026 Light\u521b\u9020\u8425\u542f\u52a8\uff1a\u540c\u5b66\uff0c\u548cAI\u4e00\u8d77\uff0c\u4e3a\u516c\u76ca\u505a\u70b9\u4e8b\uff01", "comment": "Source: WeChat, Published: 2025-12-11 12:05:07", "summary": "02.\u6280\u672f\u8d4b\u80fd\u5347\u7ea7\uff1aADP\u5e73\u53f0\u3001\u6df7\u5143\u5927\u6a21\u578b\u7b49\u6784\u6210\u5168\u94fe\u8def\u652f\u6301\u4f53\u7cfb\u4e3a\u4e86\u964d\u4f4eAI\u5e94\u7528\u5f00\u53d1\u95e8\u69db\uff0c\u6b64\u6b21Light\u521b\u9020\u8425\u4e3a\u9752\u5e74\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u5957\u8986\u76d6\u5f00\u53d1\u3001\u8bad\u7ec3\u3001\u90e8\u7f72\u5168\u6d41\u7a0b\u7684\u6280\u672f\u201c\u6b66\u5668\u5e93\u201d\u3002", "AI": {"tldr": "02.\u6280\u672f\u8d4b\u80fd\u5347\u7ea7\uff1aADP\u5e73\u53f0\u3001\u6df7\u5143\u5927\u6a21\u578b\u7b49\u6784\u6210\u5168\u94fe\u8def\u652f\u6301\u4f53\u7cfb\u4e3a\u4e86\u964d\u4f4eAI\u5e94\u7528\u5f00\u53d1\u95e8\u69db\uff0c\u6b64\u6b21Light\u521b\u9020\u8425\u4e3a\u9752\u5e74\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u5957\u8986\u76d6\u5f00\u53d1\u3001\u8bad\u7ec3\u3001\u90e8\u7f72\u5168\u6d41\u7a0b\u7684\u6280\u672f\u201c\u6b66\u5668\u5e93\u201d\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.7619ff00", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyNjc1ODI1OQ==&mid=2247488279&idx=1&sn=01e19969b17f784dea50df8f88521bc2&chksm=c3dc83de78969aa5ea6468b3ffc7f6ecd1cfecb71cf8f6bce2df928b0ada105b66a1ad5f787b#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyNjc1ODI1OQ==&mid=2247488279&idx=1&sn=01e19969b17f784dea50df8f88521bc2&chksm=c3dc83de78969aa5ea6468b3ffc7f6ecd1cfecb71cf8f6bce2df928b0ada105b66a1ad5f787b#rd", "authors": ["\u8d22\u4e2dTMT"], "title": "\u4e00\u77f3\u5343\u6d6a\uff1a\u590d\u76d8\u4e2d\u56fd<em class=\"highlight\">\u5927\u6a21\u578b</em>2025", "comment": "Source: WeChat, Published: 2025-12-11 11:46:47", "summary": "\u4ece2023\u5e74\u7684\u201c\u767e\u6a21\u5927\u6218\u201d\uff0c\u52302025\u5e74DeepSeek\u6a2a\u7a7a\u51fa\u4e16\u3001\u8de8\u5165Agent\u5143\u5e74\uff0c\u4e2d\u56fd\u5927\u6a21\u578b\u884c\u4e1a\u5728OpenAI ChatGPT\u9762\u4e16\u540e\uff0c\u4ece\u8ddf\u968f\u5230\u53e6\u8def\u5e76\u884c\uff0c\u5b9e\u73b0\u4e86\u4e00\u6bb5\u4e0d\u5c0f\u7684\u8de8\u8d8a\u3002", "AI": {"tldr": "\u4ece2023\u5e74\u7684\u201c\u767e\u6a21\u5927\u6218\u201d\uff0c\u52302025\u5e74DeepSeek\u6a2a\u7a7a\u51fa\u4e16\u3001\u8de8\u5165Agent\u5143\u5e74\uff0c\u4e2d\u56fd\u5927\u6a21\u578b\u884c\u4e1a\u5728OpenAI ChatGPT\u9762\u4e16\u540e\uff0c\u4ece\u8ddf\u968f\u5230\u53e6\u8def\u5e76\u884c\uff0c\u5b9e\u73b0\u4e86\u4e00\u6bb5\u4e0d\u5c0f\u7684\u8de8\u8d8a\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.df3c2b7e", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0NjIxNjkxNw==&mid=2247538762&idx=1&sn=cd656229ef1d97efc8b1e8833b85752f&chksm=c2813eff075e1cbe26ca2af09fe5289f254718b11af17596aff203b2df3df2e11e34a2d4dee3#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0NjIxNjkxNw==&mid=2247538762&idx=1&sn=cd656229ef1d97efc8b1e8833b85752f&chksm=c2813eff075e1cbe26ca2af09fe5289f254718b11af17596aff203b2df3df2e11e34a2d4dee3#rd", "authors": ["\u89c2\u7f51\u8d22\u7ecf"], "title": "Meta\u4e0a\u4ebf\u5e74\u85aa\u7684\u7814\u7a76\u5458\u4eec\uff0c\u5374\u5728\u5077\u5e08\u4e2d\u56fd\u5f00\u6e90<em class=\"highlight\">\u6a21\u578b</em>", "comment": "Source: WeChat, Published: 2025-12-11 11:18:34", "summary": "\u624e\u514b\u4f2f\u683c\u6325\u821e\u91cd\u91d1\u62db\u6765\u7684AI\u5927\u725b\u4eec\u8ba1\u5212\u5f00\u53d1\u7684\u95ed\u6e90\u5927\u6a21\u578b\uff0c\u7adf\u7136\u662f\u901a\u8fc7\u4e2d\u56fd\u7684\u5f00\u6e90\u6a21\u578b\u6765\u8bad\u7ec3\uff0c\u8fd9\u4e0d\u4ec5\u610f\u5473\u7740\u5982\u4eca\u4e2d\u56fd\u5f00\u6e90\u9635\u8425\u7684\u5d1b\u8d77\uff0c\u4e5f\u4ee3\u8868\u624e\u514b\u4f2f\u683c\u66fe\u7ecf\u7684\u7f8e\u56fd\u5f00\u6e90\u9738\u4e3b\u8c6a\u8a00\uff0c\u7ec8\u7a76\u6ca1\u6709\u62b5\u8fc7\u6765\u81ea\u4e2d\u56fd\u7684\u7ade\u4e89\u538b\u529b\u3002", "AI": {"tldr": "\u624e\u514b\u4f2f\u683c\u6325\u821e\u91cd\u91d1\u62db\u6765\u7684AI\u5927\u725b\u4eec\u8ba1\u5212\u5f00\u53d1\u7684\u95ed\u6e90\u5927\u6a21\u578b\uff0c\u7adf\u7136\u662f\u901a\u8fc7\u4e2d\u56fd\u7684\u5f00\u6e90\u6a21\u578b\u6765\u8bad\u7ec3\uff0c\u8fd9\u4e0d\u4ec5\u610f\u5473\u7740\u5982\u4eca\u4e2d\u56fd\u5f00\u6e90\u9635\u8425\u7684\u5d1b\u8d77\uff0c\u4e5f\u4ee3\u8868\u624e\u514b\u4f2f\u683c\u66fe\u7ecf\u7684\u7f8e\u56fd\u5f00\u6e90\u9738\u4e3b\u8c6a\u8a00\uff0c\u7ec8\u7a76\u6ca1\u6709\u62b5\u8fc7\u6765\u81ea\u4e2d\u56fd\u7684\u7ade\u4e89\u538b\u529b\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.23c90d46", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5NzMwOTIxNQ==&mid=2649476444&idx=2&sn=a37dd67424ed8a6f6b2baa26a7bedfbf&chksm=bfc526c3598895fc93a9252f9df3de5e075d73be79bcd2c84d9c026bde60da07a0e8de706116#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5NzMwOTIxNQ==&mid=2649476444&idx=2&sn=a37dd67424ed8a6f6b2baa26a7bedfbf&chksm=bfc526c3598895fc93a9252f9df3de5e075d73be79bcd2c84d9c026bde60da07a0e8de706116#rd", "authors": ["\u5e7f\u4e1c\u7701\u667a\u80fd\u4ea4\u901a\u534f\u4f1a"], "title": "\u559c\u62a5\uff01\u5e7f\u4e1c\u4ea4\u901a\u519b\u56e2\u65a9\u83b7<em class=\"highlight\">\u5927\u6a21\u578b</em>\u667a\u80fd\u4f53\u56fd\u8d5b\u591a\u9879\u5927\u5956", "comment": "Source: WeChat, Published: 2025-12-11 11:02:08", "summary": "12\u67089\u65e5-10\u65e5\uff0c\u7b2c\u4e00\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u5168\u56fd\u603b\u51b3\u8d5b\u5728\u798f\u5efa\u53a6\u95e8\u5706\u6ee1\u843d\u5e55\u3002\u5e7f\u4e1c\u7701\u667a\u80fd\u4ea4\u901a\u534f\u4f1a\u51ed\u501f\u5728\u8d5b\u4e8b\u7ec4\u7ec7\u3001\u884c\u4e1a\u534f\u540c\u4e2d\u7684\u7a81\u51fa\u8868\u73b0\uff0c\u8363\u83b7\u201c\u6700\u4f73\u7ec4\u7ec7\u5956\u201d\u3002", "AI": {"tldr": "12\u67089\u65e5-10\u65e5\uff0c\u7b2c\u4e00\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u5168\u56fd\u603b\u51b3\u8d5b\u5728\u798f\u5efa\u53a6\u95e8\u5706\u6ee1\u843d\u5e55\u3002\u5e7f\u4e1c\u7701\u667a\u80fd\u4ea4\u901a\u534f\u4f1a\u51ed\u501f\u5728\u8d5b\u4e8b\u7ec4\u7ec7\u3001\u884c\u4e1a\u534f\u540c\u4e2d\u7684\u7a81\u51fa\u8868\u73b0\uff0c\u8363\u83b7\u201c\u6700\u4f73\u7ec4\u7ec7\u5956\u201d\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.04cae9b2", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI5Mzg1NTk3MA==&mid=2247503529&idx=1&sn=0db78fee27b67c3bee08a6ec9e6f3c91&chksm=ed258a91f2875a8b2858d49270042a91a6d50b3b440717ef999b0cd61520608c33dab29c7095#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI5Mzg1NTk3MA==&mid=2247503529&idx=1&sn=0db78fee27b67c3bee08a6ec9e6f3c91&chksm=ed258a91f2875a8b2858d49270042a91a6d50b3b440717ef999b0cd61520608c33dab29c7095#rd", "authors": ["\u79d1\u6280\u5934\u7248"], "title": "\u9a6c\u4e91\u5927\u53d1\u795e\u5a01\uff0c\u963f\u91cc<em class=\"highlight\">\u5927\u6a21\u578b</em>\u62ff\u4e0b\u7f8e\u56fd\u7845\u8c37\u5de8\u5934", "comment": "Source: WeChat, Published: 2025-12-11 10:29:04", "summary": "\u8fd9\u662f\u56fd\u5185\u5927\u6a21\u578b\u5728\u8be5\u7c7b\u8bc4\u6d4b\u4e2d\u7684\u6700\u4f73\u7eaa\u5f55\u3002\u9664\u4e86\u5f3a\u5927\u7684\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u963f\u91cc\u8fd8\u6784\u5efa\u4e86\u5168\u6808AI\u6280\u672f\u4f53\u7cfb\u3002\u4ece\u5e95\u5c42\u82af\u7247\u3001\u8d85\u8282\u70b9\u670d\u52a1\u5668\u3001\u9ad8\u6027\u80fd\u7f51\u7edc\u3001\u5206\u5e03\u5f0f\u5b58\u50a8\u3001\u667a\u7b97\u96c6\u7fa4\u5230\u4eba\u5de5\u667a\u80fd\u5e73\u53f0\uff0c\u963f\u91cc\u4e91\u5df2\u5f62\u6210\u5b8c\u6574\u7684\u6280\u672f\u95ed\u73af\u3002", "AI": {"tldr": "\u8fd9\u662f\u56fd\u5185\u5927\u6a21\u578b\u5728\u8be5\u7c7b\u8bc4\u6d4b\u4e2d\u7684\u6700\u4f73\u7eaa\u5f55\u3002\u9664\u4e86\u5f3a\u5927\u7684\u57fa\u7840\u6a21\u578b\u80fd\u529b\uff0c\u963f\u91cc\u8fd8\u6784\u5efa\u4e86\u5168\u6808AI\u6280\u672f\u4f53\u7cfb\u3002\u4ece\u5e95\u5c42\u82af\u7247\u3001\u8d85\u8282\u70b9\u670d\u52a1\u5668\u3001\u9ad8\u6027\u80fd\u7f51\u7edc\u3001\u5206\u5e03\u5f0f\u5b58\u50a8\u3001\u667a\u7b97\u96c6\u7fa4\u5230\u4eba\u5de5\u667a\u80fd\u5e73\u53f0\uff0c\u963f\u91cc\u4e91\u5df2\u5f62\u6210\u5b8c\u6574\u7684\u6280\u672f\u95ed\u73af\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.6adfe2e0", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3OTM5MDQ4Nw==&mid=2247499190&idx=1&sn=c89a9a0f32d768d1b17bfab124e18f17&chksm=9ecc188a9bbcdecbbd432e507c2654a0f317aece11d0b78685957fa9c1463a2765b8c211d100#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3OTM5MDQ4Nw==&mid=2247499190&idx=1&sn=c89a9a0f32d768d1b17bfab124e18f17&chksm=9ecc188a9bbcdecbbd432e507c2654a0f317aece11d0b78685957fa9c1463a2765b8c211d100#rd", "authors": ["\u6b27\u6587\u6295\u7814"], "title": "OpenAI<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7684\u4ef7\u503c\u6b63\u5728\u88ab\u5782\u76f4\u9886\u57df\u7684\u5e94\u7528\u541e\u566c", "comment": "Source: WeChat, Published: 2025-12-11 10:24:24", "summary": "1. \u901a\u7528\u5927\u6a21\u578b\u7684\u201c\u62a4\u57ce\u6cb3\u201d\u5df2\u5f7b\u5e95\u5d29\u584c\uff1a\u5782\u76f4\u5e94\u7528\u7684\u201c\u53cd\u566c\u201d \u79d8\u5bc6\uff1a \u8fc7\u53bb\u4e09\u5e74\uff0cOpenAI \u66fe\u8ba9\u6240\u6709 SaaS \u516c\u53f8\u745f\u745f\u53d1\u6296\uff0c\u8ba4\u4e3a GPT-5 \u4f1a\u541e\u566c\u4e00\u5207\u8f6f\u4ef6\u3002\u4f46 2025 \u5e74 12 \u6708 10 \u65e5 Zoom \u5728 \"Humanity's Last Exam\" \uff08HLE\uff09 \u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5c60\u699c\uff0c\u63ed\u793a\u4e86\u4e00", "AI": {"tldr": "1. \u901a\u7528\u5927\u6a21\u578b\u7684\u201c\u62a4\u57ce\u6cb3\u201d\u5df2\u5f7b\u5e95\u5d29\u584c\uff1a\u5782\u76f4\u5e94\u7528\u7684\u201c\u53cd\u566c\u201d \u79d8\u5bc6\uff1a \u8fc7\u53bb\u4e09\u5e74\uff0cOpenAI \u66fe\u8ba9\u6240\u6709 SaaS \u516c\u53f8\u745f\u745f\u53d1\u6296\uff0c\u8ba4\u4e3a GPT-5 \u4f1a\u541e\u566c\u4e00\u5207\u8f6f\u4ef6\u3002\u4f46 2025 \u5e74 12 \u6708 10 \u65e5 Zoom \u5728 \"Humanity's Last Exam\" \uff08HLE\uff09 \u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5c60\u699c\uff0c\u63ed\u793a\u4e86\u4e00", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.b54c21b2", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI4Njg4MTgxMA==&mid=2247508050&idx=1&sn=ee3087c91ee1f59fc1342ff04818c33b&chksm=ea009927054e9ee2551fb826af2781884e24d7ea302a67eb05243086606d7d811f0964865066#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI4Njg4MTgxMA==&mid=2247508050&idx=1&sn=ee3087c91ee1f59fc1342ff04818c33b&chksm=ea009927054e9ee2551fb826af2781884e24d7ea302a67eb05243086606d7d811f0964865066#rd", "authors": ["\u516c\u8def\u9662"], "title": "\u52a8\u6001 | \u516c\u8def\u9662\u6458\u5f97\u9996\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93<em class=\"highlight\">\u5927\u6a21\u578b</em>\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u4e03\u4e2a\u5956\u9879", "comment": "Source: WeChat, Published: 2025-12-11 09:40:54", "summary": "12\u67089\u65e5\u81f310\u65e5\uff0c\u7b2c\u4e00\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u5168\u56fd\u603b\u51b3\u8d5b\u5728\u53a6\u95e8\u4e3e\u884c\u3002\u516c\u8def\u9662\u5728\u6b64\u6b21\u5927\u8d5b\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4e00\u4e3e\u65a9\u83b77\u9879\u5927\u5956\uff0c\u5305\u62ec\u4e00\u7b49\u59562\u9879\u3001\u4e8c\u7b49\u59561\u9879\u3001\u4e09\u7b49\u59562\u9879\u3001\u4f18\u80dc\u5956\u548c\u6700\u4f73\u4eba\u6c14\u5956\u54041\u9879\uff0c\u5c55\u73b0\u4e86\u9662\u4eba\u5de5\u667a\u80fd", "AI": {"tldr": "12\u67089\u65e5\u81f310\u65e5\uff0c\u7b2c\u4e00\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u5168\u56fd\u603b\u51b3\u8d5b\u5728\u53a6\u95e8\u4e3e\u884c\u3002\u516c\u8def\u9662\u5728\u6b64\u6b21\u5927\u8d5b\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4e00\u4e3e\u65a9\u83b77\u9879\u5927\u5956\uff0c\u5305\u62ec\u4e00\u7b49\u59562\u9879\u3001\u4e8c\u7b49\u59561\u9879\u3001\u4e09\u7b49\u59562\u9879\u3001\u4f18\u80dc\u5956\u548c\u6700\u4f73\u4eba\u6c14\u5956\u54041\u9879\uff0c\u5c55\u73b0\u4e86\u9662\u4eba\u5de5\u667a\u80fd", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.ccba3f71", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4Mzk2Njc4Mw==&mid=2247523587&idx=1&sn=31cf40c05c5332a0fdab99f27d53e603&chksm=ce52ac98320f7084814d9897842772cc86ecff04d8056fa12fce9e3415c1b65ec9b6850774b5#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4Mzk2Njc4Mw==&mid=2247523587&idx=1&sn=31cf40c05c5332a0fdab99f27d53e603&chksm=ce52ac98320f7084814d9897842772cc86ecff04d8056fa12fce9e3415c1b65ec9b6850774b5#rd", "authors": ["\u7518\u8083\u4ea4\u901a\u79d1\u6280\u901a\u4fe1"], "title": "\u9996\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93<em class=\"highlight\">\u5927\u6a21\u578b</em>\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u767e\u4f59\u5956\u9879\u6b63\u5f0f\u63ed\u6653", "comment": "Source: WeChat, Published: 2025-12-11 09:29:41", "summary": "03\u4e8c\u7b49\u595604\u4e09\u7b49\u595605\u4f18\u80dc\u595606\u6700\u4f73\u4eba\u6c14\u595607\u5927\u5b66\u751f\u4f18\u79c0\u521b\u610f\u595608\u6700\u4f73\u7ec4\u7ec7\u5956", "AI": {"tldr": "03\u4e8c\u7b49\u595604\u4e09\u7b49\u595605\u4f18\u80dc\u595606\u6700\u4f73\u4eba\u6c14\u595607\u5927\u5b66\u751f\u4f18\u79c0\u521b\u610f\u595608\u6700\u4f73\u7ec4\u7ec7\u5956", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
