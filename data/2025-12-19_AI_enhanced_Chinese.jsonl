{"id": "2512.15813", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15813", "abs": "https://arxiv.org/abs/2512.15813", "authors": ["Nishant Gaurav", "Adit Akarsh", "Tejas Ravishankar", "Manoj Bajaj"], "title": "CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory", "comment": "11 pages, 2 figures", "summary": "Current tool-using AI agents suffer from limited action space, context inefficiency, and probabilistic instability that makes them unsuitable for handling repetitive tasks which are otherwise reliably and efficiently tackled by agentic workflows built on platforms like n8n and Zapier. Earlier works like CodeAct, DynaSaur, Code Mode have tried to tackle the first two issues by using the whole Python language as its action space: The number of tools that the agent can call becomes infinite. Python code blocks can execute complex actions into a single step and print only relevant results which helps in keeping the context lean. However, the probabilistic instability issue still remains, as for the same task in the same environment, the agent can follow different trajectories due to the probabilistic nature of LLMs. Therefore, we need procedural memory for consistency and reliability. This paper proposes CodeMem, an architecture to implement procedural memory via code which can be used to build and run reusable agentic workflows with deterministic reliability.", "AI": {"tldr": "CodeMem\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u4ee3\u7801\u5b9e\u73b0\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u6784\u5efa\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u786e\u5b9a\u6027\u53ef\u9760\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u89e3\u51b3\u73b0\u6709\u5de5\u5177\u4f7f\u7528AI\u4ee3\u7406\u5728\u91cd\u590d\u4efb\u52a1\u4e2d\u7684\u6982\u7387\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5de5\u5177\u4f7f\u7528AI\u4ee3\u7406\u5b58\u5728\u52a8\u4f5c\u7a7a\u95f4\u6709\u9650\u3001\u4e0a\u4e0b\u6587\u6548\u7387\u4f4e\u4e0b\u548c\u6982\u7387\u4e0d\u7a33\u5b9a\u6027\u7b49\u95ee\u9898\uff0c\u4e0d\u9002\u5408\u5904\u7406\u91cd\u590d\u4efb\u52a1\u3002\u867d\u7136\u4e4b\u524d\u7684\u5de5\u4f5c\u901a\u8fc7\u4f7f\u7528Python\u4f5c\u4e3a\u52a8\u4f5c\u7a7a\u95f4\u89e3\u51b3\u4e86\u524d\u4e24\u4e2a\u95ee\u9898\uff0c\u4f46\u6982\u7387\u4e0d\u7a33\u5b9a\u6027\u4ecd\u7136\u5b58\u5728\uff0c\u5bfc\u81f4\u76f8\u540c\u4efb\u52a1\u5728\u4e0d\u540c\u6267\u884c\u4e2d\u4ea7\u751f\u4e0d\u540c\u8f68\u8ff9\u3002", "method": "CodeMem\u901a\u8fc7\u4ee3\u7801\u5b9e\u73b0\u7a0b\u5e8f\u6027\u8bb0\u5fc6\uff0c\u6784\u5efa\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u67b6\u6784\u3002\u8be5\u67b6\u6784\u80fd\u591f\u5b58\u50a8\u548c\u6267\u884c\u786e\u5b9a\u6027\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u786e\u4fdd\u4efb\u52a1\u6267\u884c\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86CodeMem\u67b6\u6784\uff0c\u80fd\u591f\u5b9e\u73b0\u786e\u5b9a\u6027\u53ef\u9760\u7684\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4ee3\u7406\u5728\u91cd\u590d\u4efb\u52a1\u4e2d\u7684\u6982\u7387\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u4efb\u52a1\u6267\u884c\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u901a\u8fc7\u4ee3\u7801\u5b9e\u73b0\u7684\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u662f\u89e3\u51b3\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6982\u7387\u4e0d\u7a33\u5b9a\u6027\u7684\u6709\u6548\u65b9\u6cd5\uff0cCodeMem\u67b6\u6784\u4e3a\u6784\u5efa\u53ef\u9760\u3001\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "topic": "code agent"}}
{"id": "2512.15959", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15959", "abs": "https://arxiv.org/abs/2512.15959", "authors": ["Arma\u011fan Amcalar", "Eyup Cinar"], "title": "BRAID: Bounded Reasoning for Autonomous Inference and Decisions", "comment": null, "summary": "Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the AdvancedIF, GSM-Hard, and the SCALE MultiChallenge benchmark datasets. BRAID introduces a bounded reasoning framework using Mermaid-based instruction graphs that enable models to reason struc turally rather than through unbounded natural-language token expansion. We show that structured machine-readable prompts substantially increase reasoning accuracy and cost efficiency for agents in production systems. The findings establish BRAID as an effective and scalable technique for optimizing inference efficiency in autonomous agent systems. All datasets and detailed result logs are available at https://benchmark.openserv.ai.", "AI": {"tldr": "BRAID\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6709\u754c\u63a8\u7406\u7684\u63d0\u793a\u6846\u67b6\uff0c\u4f7f\u7528Mermaid\u6307\u4ee4\u56fe\u5b9e\u73b0\u7ed3\u6784\u5316\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7406\u7684\u63a8\u7406\u51c6\u786e\u6027\u548c\u6210\u672c\u6548\u7387\u3002", "motivation": "LLM\u5728\u6027\u80fd\u3001\u6210\u672c\u548ctoken\u4f7f\u7528\u4e4b\u95f4\u5b58\u5728\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u5f53\u524d\u81ea\u7136\u8bed\u8a00\u6269\u5c55\u5f0f\u7684\u63a8\u7406\u65b9\u5f0f\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u6784\u5316\u3001\u53ef\u6269\u5c55\u7684\u63a8\u7406\u6846\u67b6\u6765\u4f18\u5316\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u7684\u63a8\u7406\u6548\u7387\u3002", "method": "BRAID\u91c7\u7528\u6709\u754c\u63a8\u7406\u6846\u67b6\uff0c\u4f7f\u7528Mermaid\u6307\u4ee4\u56fe\u521b\u5efa\u7ed3\u6784\u5316\u3001\u673a\u5668\u53ef\u8bfb\u7684\u63d0\u793a\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\u800c\u975e\u65e0\u754c\u7684\u81ea\u7136\u8bed\u8a00token\u6269\u5c55\u3002", "result": "\u5728AdvancedIF\u3001GSM-Hard\u548cSCALE MultiChallenge\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBRAID\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u548c\u6210\u672c\u6548\u7387\uff0c\u8bc1\u660e\u5176\u5728\u4e0d\u540cGPT\u6a21\u578b\u5c42\u7ea7\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "BRAID\u662f\u4e00\u79cd\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u6280\u672f\uff0c\u53ef\u7528\u4e8e\u4f18\u5316\u81ea\u4e3b\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u63a8\u7406\u6548\u7387\uff0c\u7ed3\u6784\u5316\u673a\u5668\u53ef\u8bfb\u63d0\u793a\u80fd\u5927\u5e45\u63d0\u5347\u751f\u4ea7\u7cfb\u7edf\u4e2d\u4ee3\u7406\u7684\u63a8\u7406\u51c6\u786e\u6027\u548c\u6210\u672c\u6548\u76ca\u3002", "topic": "agent analysis"}}
{"id": "2512.16272", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16272", "abs": "https://arxiv.org/abs/2512.16272", "authors": ["Ora Nova Fandina", "Eitan Farchi", "Shmulik Froimovich", "Raviv Gal", "Wesam Ibraheem", "Rami Katan", "Alice Podolsky"], "title": "Beyond Blind Spots: Analytic Hints for Mitigating LLM-Based Evaluation Pitfalls", "comment": null, "summary": "Large Language Models are increasingly deployed as judges (LaaJ) in code generation pipelines. While attractive for scalability, LaaJs tend to overlook domain specific issues raising concerns about their reliability in critical evaluation tasks. To better understand these limitations in practice, we examine LaaJ behavior in a concrete industrial use case: legacy code modernization via COBOL code generation. In this setting, we find that even production deployed LaaJs can miss domain critical errors, revealing consistent blind spots in their evaluation capabilities.\n  To better understand these blind spots, we analyze generated COBOL programs and associated LaaJs judgments, drawing on expert knowledge to construct a preliminary taxonomy. Based on this taxonomy, we develop a lightweight analytic checker tool that flags over 30 domain specific issues observed in practice. We use its outputs as analytic hints, dynamically injecting them into the judges prompt to encourage LaaJ to revisit aspects it may have overlooked.\n  Experiments on a test set of 100 programs using four production level LaaJs show that LaaJ alone detects only about 45% of the errors present in the code (in all judges we tested), while the analytic checker alone lacks explanatory depth. When combined, the LaaJ+Hints configuration achieves up to 94% coverage (for the best performing judge and injection prompt) and produces qualitatively richer, more accurate explanations, demonstrating that analytic-LLM hybrids can substantially enhance evaluation reliability in deployed pipelines. We release the dataset and all used prompts.", "AI": {"tldr": "\u7814\u7a76\u5206\u6790\u4e86LLM\u4f5c\u4e3a\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\u5668(LaaJ)\u5728COBOL\u73b0\u4ee3\u5316\u573a\u666f\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u53d1\u73b0\u5176\u4f1a\u9057\u6f0f\u9886\u57df\u5173\u952e\u9519\u8bef\uff0c\u901a\u8fc7\u5f00\u53d1\u8f7b\u91cf\u7ea7\u5206\u6790\u68c0\u67e5\u5668\u63d0\u4f9b\u63d0\u793a\uff0c\u7ed3\u5408LLM+Hints\u914d\u7f6e\u53ef\u5c06\u9519\u8bef\u68c0\u6d4b\u8986\u76d6\u7387\u4ece45%\u63d0\u5347\u81f394%\u3002", "motivation": "LLM\u4f5c\u4e3a\u4ee3\u7801\u8bc4\u4f30\u5668(LaaJ)\u867d\u7136\u53ef\u6269\u5c55\u6027\u5f3a\uff0c\u4f46\u5728\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u4e2d\uff08\u7279\u522b\u662fCOBOL\u4ee3\u7801\u73b0\u4ee3\u5316\u573a\u666f\uff09\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f1a\u9057\u6f0f\u9886\u57df\u7279\u5b9a\u7684\u5173\u952e\u9519\u8bef\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9\u5176\u5728\u5173\u952e\u8bc4\u4f30\u4efb\u52a1\u4e2d\u53ef\u9760\u6027\u7684\u62c5\u5fe7\u3002", "method": "1) \u5206\u6790\u751f\u6210\u7684COBOL\u7a0b\u5e8f\u548cLaaJ\u8bc4\u4f30\u7ed3\u679c\uff0c\u57fa\u4e8e\u4e13\u5bb6\u77e5\u8bc6\u6784\u5efa\u521d\u6b65\u5206\u7c7b\u6cd5\uff1b2) \u5f00\u53d1\u8f7b\u91cf\u7ea7\u5206\u6790\u68c0\u67e5\u5668\u5de5\u5177\uff0c\u53ef\u6807\u8bb030\u591a\u79cd\u5b9e\u8df5\u4e2d\u89c2\u5bdf\u5230\u7684\u9886\u57df\u7279\u5b9a\u95ee\u9898\uff1b3) \u5c06\u68c0\u67e5\u5668\u8f93\u51fa\u4f5c\u4e3a\u5206\u6790\u63d0\u793a\u52a8\u6001\u6ce8\u5165\u5230\u8bc4\u4f30\u5668\u63d0\u793a\u4e2d\uff0c\u5f15\u5bfcLaaJ\u91cd\u65b0\u5ba1\u89c6\u53ef\u80fd\u5ffd\u7565\u7684\u65b9\u9762\uff1b4) \u5728100\u4e2a\u7a0b\u5e8f\u6d4b\u8bd5\u96c6\u4e0a\u4f7f\u7528\u56db\u4e2a\u751f\u4ea7\u7ea7LaaJ\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "LaaJ\u5355\u72ec\u4ec5\u80fd\u68c0\u6d4b\u7ea645%\u7684\u9519\u8bef\uff0c\u5206\u6790\u68c0\u67e5\u5668\u5355\u72ec\u7f3a\u4e4f\u89e3\u91ca\u6df1\u5ea6\u3002\u5f53\u7ed3\u5408\u4f7f\u7528\u65f6\uff0cLaaJ+Hints\u914d\u7f6e\u5728\u6700\u4f73\u8bc4\u4f30\u5668\u548c\u6ce8\u5165\u63d0\u793a\u4e0b\u8fbe\u523094%\u7684\u8986\u76d6\u7387\uff0c\u5e76\u4ea7\u751f\u8d28\u91cf\u66f4\u9ad8\u3001\u66f4\u51c6\u786e\u7684\u89e3\u91ca\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u4f30\u53ef\u9760\u6027\u3002", "conclusion": "\u5206\u6790-LLM\u6df7\u5408\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u589e\u5f3a\u90e8\u7f72\u7ba1\u9053\u4e2d\u7684\u8bc4\u4f30\u53ef\u9760\u6027\uff0c\u8bc1\u660e\u4e86\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u5206\u6790\u5de5\u5177\u4e0eLLM\u8bc4\u4f30\u5668\u7684\u6709\u6548\u6027\u3002", "topic": "code agent"}}
{"id": "2512.15776", "categories": ["cs.AI", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.15776", "abs": "https://arxiv.org/abs/2512.15776", "authors": ["Shaun Baek", "Sam Liu", "Joseph Ukpong"], "title": "Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying", "comment": "12 pages, 9 pages of content, 6 tables, 5 figures", "summary": "Large Language Models (LLMs) act as powerful reasoning engines but struggle with \"symbol grounding\" in embodied environments, particularly when information is asymmetrically distributed. We investigate the Privileged Information Bias (or \"Curse of Knowledge\"), where a knowledgeable \"Leader\" agent fails to guide a sensor-limited \"Follower\" due to a lack of Theory of Mind. To quantify this phenomenon, we propose a novel Asymmetric Assistive Reasoning framework within AI2-THOR. Our experiments reveal a significant \"Success Gap\": while the Leader successfully perceives the target in 35.0% of episodes, the collaborative team succeeds only 17.0% of the time, implying that nearly 50% of feasible plans fail solely due to communicative grounding errors. We demonstrate that a \"Pull-based\" protocol (active querying) is significantly more robust than standard \"Push-based\" instruction, with successful episodes featuring 2x the frequency of clarification requests. This research isolates the mechanism of active uncertainty reduction as a prerequisite for safe human-AI and robot-robot collaboration.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLM\u5728\u5177\u8eab\u73af\u5883\u4e2d\u7684\u7b26\u53f7\u63a5\u5730\u95ee\u9898\uff0c\u7279\u522b\u662f\u4fe1\u606f\u4e0d\u5bf9\u79f0\u5206\u5e03\u65f6\u7684\u7279\u6743\u4fe1\u606f\u504f\u89c1\u3002\u901a\u8fc7AI2-THOR\u4e2d\u7684\u975e\u5bf9\u79f0\u8f85\u52a9\u63a8\u7406\u6846\u67b6\uff0c\u53d1\u73b0\u9886\u5bfc\u8005\u80fd\u611f\u77e5\u76ee\u6807\u4f46\u56e2\u961f\u6210\u529f\u7387\u4f4e\uff0c\u4e3b\u52a8\u67e5\u8be2\u534f\u8bae\u6bd4\u6807\u51c6\u6307\u4ee4\u66f4\u6709\u6548\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5f3a\u5927\u7684\u63a8\u7406\u5f15\u64ce\uff0c\u5728\u5177\u8eab\u73af\u5883\u4e2d\u9762\u4e34\"\u7b26\u53f7\u63a5\u5730\"\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u5206\u5e03\u65f6\u3002\u7814\u7a76\u8005\u5173\u6ce8\"\u7279\u6743\u4fe1\u606f\u504f\u89c1\"\u73b0\u8c61\uff0c\u5373\u77e5\u8bc6\u4e30\u5bcc\u7684\"\u9886\u5bfc\u8005\"\u4ee3\u7406\u7531\u4e8e\u7f3a\u4e4f\u5fc3\u667a\u7406\u8bba\u800c\u65e0\u6cd5\u6709\u6548\u6307\u5bfc\u4f20\u611f\u5668\u53d7\u9650\u7684\"\u8ddf\u968f\u8005\"\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u975e\u5bf9\u79f0\u8f85\u52a9\u63a8\u7406\u6846\u67b6\uff0c\u5728AI2-THOR\u73af\u5883\u4e2d\u8fdb\u884c\u5b9e\u9a8c\u3002\u8bbe\u8ba1\u4e86\"\u9886\u5bfc\u8005-\u8ddf\u968f\u8005\"\u534f\u4f5c\u573a\u666f\uff0c\u6bd4\u8f83\u4e86\"\u63a8\u9001\u5f0f\"\u6307\u4ee4\u548c\"\u62c9\u53d6\u5f0f\"\u4e3b\u52a8\u67e5\u8be2\u534f\u8bae\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u663e\u8457\u7684\"\u6210\u529f\u5dee\u8ddd\"\uff1a\u9886\u5bfc\u8005\u80fd\u611f\u77e5\u76ee\u6807\u7684\u536035.0%\uff0c\u4f46\u534f\u4f5c\u56e2\u961f\u6210\u529f\u7387\u4ec517.0%\uff0c\u610f\u5473\u7740\u8fd150%\u53ef\u884c\u8ba1\u5212\u56e0\u901a\u4fe1\u63a5\u5730\u9519\u8bef\u800c\u5931\u8d25\u3002\u4e3b\u52a8\u67e5\u8be2\u534f\u8bae\u6bd4\u6807\u51c6\u6307\u4ee4\u66f4\u7a33\u5065\uff0c\u6210\u529f\u573a\u666f\u4e2d\u6f84\u6e05\u8bf7\u6c42\u9891\u7387\u662f2\u500d\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u4e3b\u52a8\u4e0d\u786e\u5b9a\u6027\u51cf\u5c11\u673a\u5236\u4f5c\u4e3a\u5b89\u5168\u4eba\u673a\u534f\u4f5c\u548c\u673a\u5668\u4eba\u95f4\u534f\u4f5c\u7684\u524d\u63d0\u6761\u4ef6\u3002\u62c9\u53d6\u5f0f\u534f\u8bae\u901a\u8fc7\u4e3b\u52a8\u67e5\u8be2\u80fd\u6709\u6548\u7f13\u89e3\u7279\u6743\u4fe1\u606f\u504f\u89c1\u95ee\u9898\u3002", "topic": "agent analysis"}}
{"id": "2512.16041", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16041", "abs": "https://arxiv.org/abs/2512.16041", "authors": ["Yuanning Feng", "Sinan Wang", "Zhengxiang Cheng", "Yao Wan", "Dongping Chen"], "title": "Are We on the Right Way to Assessing LLM-as-a-Judge?", "comment": null, "summary": "LLM-as-a-Judge has been widely adopted as an evaluation method and served as supervised rewards in model training. However, existing benchmarks for LLM-as-a-Judge are mainly relying on human-annotated ground truth, which introduces human bias that undermines the assessment of reliability and imposes scalability constraints. To overcome these limitations, we introduce Sage, a novel evaluation suite that assesses the quality of LLM judges without necessitating any human annotation. Inspired by axioms of rational choice theory, Sage introduces two new lenses for measuring LLM-as-a-Judge: local self-consistency (pair-wise preference stability) and global logical consistency (transitivity across a full set of preferences). We curate a dataset of 650 questions by combining structured benchmark problems with real-world user queries. Our experiments demonstrate both the stability of our metrics and their high correlation with supervised benchmarks like LLMBar and RewardBench2, confirming Sage's reliability as an evaluation suite for the robustness and accuracy of LLM-as-a-Judge. Based on Sage, we reveal that current state-of-the-art LLMs exhibit significant reliability problems when acting as judges in both scoring and pairwise settings; even the top-performing models, Gemini-2.5-Pro and GPT-5, fail to maintain consistent preferences in nearly a quarter of difficult cases. We attribute this to a new phenomenon called situational preference, which explains why explicit rubrics or criteria can help the model judge consistently across answer pairs. Our further analysis shows that finetuned LLM-as-a-Judge is a feasible method to boost performance, and the panel-based judge as well as deep reasoning can enhance the judging consistency. We also find substantial inconsistency in human judgments, which indicates that human annotation may not be a reliable gold standard.", "AI": {"tldr": "Sage\u662f\u4e00\u4e2a\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684LLM-as-a-Judge\u8bc4\u4f30\u5957\u4ef6\uff0c\u901a\u8fc7\u5c40\u90e8\u81ea\u4e00\u81f4\u6027\u548c\u5168\u5c40\u903b\u8f91\u4e00\u81f4\u6027\u6765\u8bc4\u4f30LLM\u6cd5\u5b98\u7684\u8d28\u91cf\uff0c\u53d1\u73b0\u5f53\u524d\u9876\u5c16LLM\u5728\u8fd1\u56db\u5206\u4e4b\u4e00\u56f0\u96be\u6848\u4f8b\u4e2d\u5b58\u5728\u504f\u597d\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "motivation": "\u73b0\u6709LLM-as-a-Judge\u57fa\u51c6\u4e3b\u8981\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u7684\u771f\u5b9e\u6807\u7b7e\uff0c\u8fd9\u5f15\u5165\u4e86\u4eba\u7c7b\u504f\u89c1\uff0c\u524a\u5f31\u4e86\u53ef\u9760\u6027\u8bc4\u4f30\uff0c\u5e76\u65bd\u52a0\u4e86\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u57fa\u4e8e\u7406\u6027\u9009\u62e9\u7406\u8bba\u7684\u516c\u7406\uff0c\u5f15\u5165\u4e24\u4e2a\u65b0\u89c6\u89d2\uff1a\u5c40\u90e8\u81ea\u4e00\u81f4\u6027\uff08\u6210\u5bf9\u504f\u597d\u7a33\u5b9a\u6027\uff09\u548c\u5168\u5c40\u903b\u8f91\u4e00\u81f4\u6027\uff08\u5b8c\u6574\u504f\u597d\u96c6\u7684\u4f20\u9012\u6027\uff09\u3002\u6784\u5efa\u4e86650\u4e2a\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u57fa\u51c6\u95ee\u9898\u548c\u771f\u5b9e\u7528\u6237\u67e5\u8be2\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSage\u6307\u6807\u7a33\u5b9a\u4e14\u4e0e\u76d1\u7763\u57fa\u51c6\u9ad8\u5ea6\u76f8\u5173\u3002\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u7684LLM\u4f5c\u4e3a\u6cd5\u5b98\u5b58\u5728\u663e\u8457\u53ef\u9760\u6027\u95ee\u9898\uff0c\u5373\u4f7fGemini-2.5-Pro\u548cGPT-5\u5728\u8fd1\u56db\u5206\u4e4b\u4e00\u56f0\u96be\u6848\u4f8b\u4e2d\u65e0\u6cd5\u4fdd\u6301\u4e00\u81f4\u7684\u504f\u597d\u3002\u53d1\u73b0\u60c5\u5883\u504f\u597d\u7684\u65b0\u73b0\u8c61\uff0c\u5fae\u8c03LLM-as-a-Judge\u3001\u57fa\u4e8e\u9762\u677f\u7684\u6cd5\u5b98\u548c\u6df1\u5ea6\u63a8\u7406\u53ef\u4ee5\u63d0\u5347\u4e00\u81f4\u6027\u3002", "conclusion": "Sage\u662f\u4e00\u4e2a\u53ef\u9760\u7684\u65e0\u76d1\u7763\u8bc4\u4f30\u5957\u4ef6\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLM\u6cd5\u5b98\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002\u4eba\u7c7b\u5224\u65ad\u4e5f\u5b58\u5728\u663e\u8457\u4e0d\u4e00\u81f4\u6027\uff0c\u8868\u660e\u4eba\u5de5\u6807\u6ce8\u53ef\u80fd\u4e0d\u662f\u53ef\u9760\u7684\u91d1\u6807\u51c6\u3002\u60c5\u5883\u504f\u597d\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u660e\u786e\u7684\u8bc4\u5206\u6807\u51c6\u6709\u52a9\u4e8e\u6a21\u578b\u4fdd\u6301\u4e00\u81f4\u6027\u3002", "topic": "agent analysis"}}
{"id": "2512.15784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15784", "abs": "https://arxiv.org/abs/2512.15784", "authors": ["Zibin Liu", "Cheng Zhang", "Xi Zhao", "Yunfei Feng", "Bingyu Bai", "Dahu Feng", "Erhu Feng", "Yubin Xia", "Haibo Chen"], "title": "Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM", "comment": null, "summary": "Large Language Model (LLM) agents are increasingly deployed to automate complex workflows in mobile and desktop environments. However, current model-centric agent architectures struggle to self-evolve post-deployment: improving personalization, capability, and efficiency typically requires continuous model retraining/fine-tuning, which incurs prohibitive computational overheads and suffers from an inherent trade-off between model accuracy and inference efficiency.\n  To enable iterative self-evolution without model retraining, we propose MOBIMEM, a memory-centric agent system. MOBIMEM first introduces three specialized memory primitives to decouple agent evolution from model weights: (1) Profile Memory uses a lightweight distance-graph (DisGraph) structure to align with user preferences, resolving the accuracy-latency trade-off in user profile retrieval; (2) Experience Memory employs multi-level templates to instantiate execution logic for new tasks, ensuring capability generalization; and (3) Action Memory records fine-grained interaction sequences, reducing the reliance on expensive model inference. Building upon this memory architecture, MOBIMEM further integrates a suite of OS-inspired services to orchestrate execution: a scheduler that coordinates parallel sub-task execution and memory operations; an agent record-and-replay (AgentRR) mechanism that enables safe and efficient action reuse; and a context-aware exception handling that ensures graceful recovery from user interruptions and runtime errors.\n  Evaluation on AndroidWorld and top-50 apps shows that MOBIMEM achieves 83.1% profile alignment with 23.83 ms retrieval time (280x faster than GraphRAG baselines), improves task success rates by up to 50.3%, and reduces end-to-end latency by up to 9x on mobile devices.", "AI": {"tldr": "MOBIMEM\u662f\u4e00\u4e2a\u5185\u5b58\u4e2d\u5fc3\u7684LLM\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u79cd\u4e13\u7528\u5185\u5b58\u539f\u8bed\uff08Profile\u3001Experience\u3001Action Memory\uff09\u548c\u64cd\u4f5c\u7cfb\u7edf\u98ce\u683c\u7684\u670d\u52a1\uff0c\u5b9e\u73b0\u65e0\u9700\u6a21\u578b\u91cd\u8bad\u7ec3\u7684\u4ee3\u7406\u81ea\u6211\u8fdb\u5316\uff0c\u663e\u8457\u63d0\u5347\u79fb\u52a8\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6210\u529f\u7387\u5e76\u964d\u4f4e\u5ef6\u8fdf\u3002", "motivation": "\u5f53\u524d\u4ee5\u6a21\u578b\u4e3a\u4e2d\u5fc3\u7684\u4ee3\u7406\u67b6\u6784\u5728\u90e8\u7f72\u540e\u96be\u4ee5\u81ea\u6211\u8fdb\u5316\uff0c\u9700\u8981\u6301\u7eed\u6a21\u578b\u91cd\u8bad\u7ec3/\u5fae\u8c03\uff0c\u8fd9\u5e26\u6765\u9ad8\u6602\u8ba1\u7b97\u6210\u672c\uff0c\u4e14\u5b58\u5728\u6a21\u578b\u51c6\u786e\u6027\u4e0e\u63a8\u7406\u6548\u7387\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\u3002", "method": "\u63d0\u51faMOBIMEM\u5185\u5b58\u4e2d\u5fc3\u4ee3\u7406\u7cfb\u7edf\uff1a1) \u4e09\u79cd\u4e13\u7528\u5185\u5b58\u539f\u8bed\uff1aProfile Memory\u4f7f\u7528\u8f7b\u91cf\u7ea7\u8ddd\u79bb\u56fe\u7ed3\u6784\u5bf9\u9f50\u7528\u6237\u504f\u597d\uff1bExperience Memory\u4f7f\u7528\u591a\u7ea7\u6a21\u677f\u5b9e\u4f8b\u5316\u65b0\u4efb\u52a1\u6267\u884c\u903b\u8f91\uff1bAction Memory\u8bb0\u5f55\u7ec6\u7c92\u5ea6\u4ea4\u4e92\u5e8f\u5217\u30022) \u64cd\u4f5c\u7cfb\u7edf\u98ce\u683c\u670d\u52a1\uff1a\u8c03\u5ea6\u5668\u534f\u8c03\u5e76\u884c\u5b50\u4efb\u52a1\u548c\u5185\u5b58\u64cd\u4f5c\uff1bAgentRR\u673a\u5236\u5b9e\u73b0\u5b89\u5168\u9ad8\u6548\u52a8\u4f5c\u91cd\u7528\uff1b\u4e0a\u4e0b\u6587\u611f\u77e5\u5f02\u5e38\u5904\u7406\u786e\u4fdd\u4f18\u96c5\u6062\u590d\u3002", "result": "\u5728AndroidWorld\u548ctop-50\u5e94\u7528\u4e0a\u8bc4\u4f30\uff1a\u5b9e\u73b083.1%\u7684\u914d\u7f6e\u6587\u4ef6\u5bf9\u9f50\uff0c\u68c0\u7d22\u65f6\u95f423.83\u6beb\u79d2\uff08\u6bd4GraphRAG\u57fa\u7ebf\u5feb280\u500d\uff09\uff1b\u4efb\u52a1\u6210\u529f\u7387\u63d0\u5347\u9ad8\u8fbe50.3%\uff1b\u79fb\u52a8\u8bbe\u5907\u7aef\u5230\u7aef\u5ef6\u8fdf\u964d\u4f4e\u9ad8\u8fbe9\u500d\u3002", "conclusion": "MOBIMEM\u901a\u8fc7\u5185\u5b58\u4e2d\u5fc3\u67b6\u6784\u6210\u529f\u89e3\u51b3\u4e86LLM\u4ee3\u7406\u81ea\u6211\u8fdb\u5316\u7684\u6311\u6218\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u4e2a\u6027\u5316\u3001\u80fd\u529b\u6269\u5c55\u548c\u6548\u7387\u63d0\u5347\uff0c\u4e3a\u79fb\u52a8\u73af\u5883\u4e2d\u7684\u4ee3\u7406\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2512.16790", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.16790", "abs": "https://arxiv.org/abs/2512.16790", "authors": ["Aaron Imani", "Mohammad Moshirpour", "Iftekhar Ahmed"], "title": "Inside Out: Uncovering How Comment Internalization Steers LLMs for Better or Worse", "comment": "Accepted in the 48th IEEE/ACM International Conference on Software Engineering (ICSE)", "summary": "While comments are non-functional elements of source code, Large Language Models (LLM) frequently rely on them to perform Software Engineering (SE) tasks. Yet, where in the model this reliance resides, and how it affects performance, remains poorly understood. We present the first concept-level interpretability study of LLMs in SE, analyzing three tasks - code completion, translation, and refinement - through the lens of internal comment representation. Using Concept Activation Vectors (CAV), we show that LLMs not only internalize comments as distinct latent concepts but also differentiate between subtypes such as Javadocs, inline, and multiline comments. By systematically activating and deactivating these concepts in the LLMs' embedding space, we observed significant, model-specific, and task-dependent shifts in performance ranging from -90% to +67%. Finally, we conducted a controlled experiment using the same set of code inputs, prompting LLMs to perform 10 distinct SE tasks while measuring the activation of the comment concept within their latent representations. We found that code summarization consistently triggered the strongest activation of comment concepts, whereas code completion elicited the weakest sensitivity. These results open a new direction for building SE tools and models that reason about and manipulate internal concept representations rather than relying solely on surface-level input.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5bf9LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5185\u90e8\u8bc4\u8bba\u8868\u793a\u8fdb\u884c\u6982\u5ff5\u7ea7\u53ef\u89e3\u91ca\u6027\u5206\u6790\uff0c\u53d1\u73b0LLM\u5c06\u8bc4\u8bba\u4f5c\u4e3a\u72ec\u7acb\u6f5c\u5728\u6982\u5ff5\u5185\u5316\uff0c\u5e76\u80fd\u533a\u5206\u4e0d\u540c\u7c7b\u578b\u8bc4\u8bba\uff0c\u901a\u8fc7\u6fc0\u6d3b/\u505c\u7528\u8fd9\u4e9b\u6982\u5ff5\u53ef\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6027\u80fd\uff08-90%\u5230+67%\uff09\u3002", "motivation": "\u5c3d\u7ba1\u8bc4\u8bba\u662f\u6e90\u4ee3\u7801\u7684\u975e\u529f\u80fd\u6027\u5143\u7d20\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6267\u884c\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u65f6\u7ecf\u5e38\u4f9d\u8d56\u5b83\u4eec\u3002\u7136\u800c\uff0c\u6a21\u578b\u5185\u90e8\u8fd9\u79cd\u4f9d\u8d56\u7684\u5177\u4f53\u4f4d\u7f6e\u53ca\u5176\u5982\u4f55\u5f71\u54cd\u6027\u80fd\u4ecd\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u6df1\u5165\u7406\u89e3LLM\u5728SE\u4efb\u52a1\u4e2d\u7684\u5185\u90e8\u5de5\u4f5c\u673a\u5236\u3002", "method": "\u4f7f\u7528\u6982\u5ff5\u6fc0\u6d3b\u5411\u91cf\uff08CAV\uff09\u5206\u6790LLM\u5185\u90e8\u8bc4\u8bba\u8868\u793a\uff0c\u7814\u7a76\u4e09\u4e2a\u4efb\u52a1\uff08\u4ee3\u7801\u8865\u5168\u3001\u7ffb\u8bd1\u3001\u4f18\u5316\uff09\u3002\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u6fc0\u6d3b\u548c\u505c\u7528\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bc4\u8bba\u6982\u5ff5\uff0c\u6d4b\u91cf\u6027\u80fd\u53d8\u5316\u3002\u8fd8\u8fdb\u884c\u4e86\u63a7\u5236\u5b9e\u9a8c\uff0c\u4f7f\u7528\u76f8\u540c\u4ee3\u7801\u8f93\u5165\u8ba9LLM\u6267\u884c10\u4e2aSE\u4efb\u52a1\uff0c\u6d4b\u91cf\u6f5c\u5728\u8868\u793a\u4e2d\u8bc4\u8bba\u6982\u5ff5\u7684\u6fc0\u6d3b\u5f3a\u5ea6\u3002", "result": "LLM\u4e0d\u4ec5\u5c06\u8bc4\u8bba\u5185\u5316\u4e3a\u72ec\u7279\u7684\u6f5c\u5728\u6982\u5ff5\uff0c\u8fd8\u80fd\u533a\u5206Javadocs\u3001\u5185\u8054\u548c\u591a\u884c\u8bc4\u8bba\u7b49\u5b50\u7c7b\u578b\u3002\u6fc0\u6d3b/\u505c\u7528\u8bc4\u8bba\u6982\u5ff5\u5bfc\u81f4\u663e\u8457\u3001\u6a21\u578b\u7279\u5b9a\u4e14\u4efb\u52a1\u4f9d\u8d56\u7684\u6027\u80fd\u53d8\u5316\uff08-90%\u5230+67%\uff09\u3002\u4ee3\u7801\u603b\u7ed3\u4efb\u52a1\u89e6\u53d1\u6700\u5f3a\u7684\u8bc4\u8bba\u6982\u5ff5\u6fc0\u6d3b\uff0c\u800c\u4ee3\u7801\u8865\u5168\u7684\u654f\u611f\u6027\u6700\u5f31\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6784\u5efa\u57fa\u4e8e\u5185\u90e8\u6982\u5ff5\u8868\u793a\u800c\u975e\u4ec5\u4f9d\u8d56\u8868\u5c42\u8f93\u5165\u7684\u8f6f\u4ef6\u5de5\u7a0b\u5de5\u5177\u548c\u6a21\u578b\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u5bf9LLM\u5185\u90e8\u6982\u5ff5\u8868\u793a\u8fdb\u884c\u63a8\u7406\u548c\u64cd\u4f5c\u7684\u91cd\u8981\u6027\u3002", "topic": "agent analysis"}}
{"id": "2512.16816", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.16816", "abs": "https://arxiv.org/abs/2512.16816", "authors": ["Alessandra Parziale", "Gianmario Voria", "Valeria Pontillo", "Gemma Catolino", "Andrea De Lucia", "Fabio Palomba"], "title": "Toward Systematic Counterfactual Fairness Evaluation of Large Language Models: The CAFFE Framework", "comment": null, "summary": "Nowadays, Large Language Models (LLMs) are foundational components of modern software systems. As their influence grows, concerns about fairness have become increasingly pressing. Prior work has proposed metamorphic testing to detect fairness issues, applying input transformations to uncover inconsistencies in model behavior. This paper introduces an alternative perspective for testing counterfactual fairness in LLMs, proposing a structured and intent-aware framework coined CAFFE (Counterfactual Assessment Framework for Fairness Evaluation). Inspired by traditional non-functional testing, CAFFE (1) formalizes LLM-Fairness test cases through explicitly defined components, including prompt intent, conversational context, input variants, expected fairness thresholds, and test environment configuration, (2) assists testers by automatically generating targeted test data, and (3) evaluates model responses using semantic similarity metrics. Our experiments, conducted on three different architectural families of LLM, demonstrate that CAFFE achieves broader bias coverage and more reliable detection of unfair behavior than existing metamorphic approaches.", "AI": {"tldr": "CAFFE\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30LLM\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u7684\u7ed3\u6784\u5316\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u660e\u786e\u5b9a\u4e49\u7684\u6d4b\u8bd5\u7ec4\u4ef6\u3001\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u6570\u636e\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8bc4\u4f30\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u80fd\u66f4\u5168\u9762\u5730\u68c0\u6d4b\u4e0d\u516c\u5e73\u884c\u4e3a\u3002", "motivation": "\u968f\u7740LLM\u5728\u73b0\u4ee3\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u516c\u5e73\u6027\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f7f\u7528\u8715\u53d8\u6d4b\u8bd5\u6765\u68c0\u6d4b\u516c\u5e73\u6027\u95ee\u9898\uff0c\u4f46\u9700\u8981\u66f4\u7cfb\u7edf\u3001\u610f\u56fe\u611f\u77e5\u7684\u6d4b\u8bd5\u6846\u67b6\u6765\u8bc4\u4f30LLM\u7684\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u3002", "method": "CAFFE\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u90e8\u5206\uff1a1) \u901a\u8fc7\u660e\u786e\u5b9a\u4e49\u7684\u7ec4\u4ef6\uff08\u63d0\u793a\u610f\u56fe\u3001\u5bf9\u8bdd\u4e0a\u4e0b\u6587\u3001\u8f93\u5165\u53d8\u4f53\u3001\u671f\u671b\u516c\u5e73\u9608\u503c\u3001\u6d4b\u8bd5\u73af\u5883\u914d\u7f6e\uff09\u5f62\u5f0f\u5316LLM\u516c\u5e73\u6027\u6d4b\u8bd5\u7528\u4f8b\uff1b2) \u81ea\u52a8\u751f\u6210\u6709\u9488\u5bf9\u6027\u7684\u6d4b\u8bd5\u6570\u636e\uff1b3) \u4f7f\u7528\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6307\u6807\u8bc4\u4f30\u6a21\u578b\u54cd\u5e94\u3002", "result": "\u5728\u4e09\u79cd\u4e0d\u540c\u67b6\u6784\u7684LLM\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCAFFE\u76f8\u6bd4\u73b0\u6709\u7684\u8715\u53d8\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u7684\u504f\u89c1\u8986\u76d6\u548c\u66f4\u53ef\u9760\u7684\u4e0d\u516c\u5e73\u884c\u4e3a\u68c0\u6d4b\u3002", "conclusion": "CAFFE\u4e3aLLM\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u3001\u610f\u56fe\u611f\u77e5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u5168\u9762\u3001\u53ef\u9760\u5730\u68c0\u6d4b\u6a21\u578b\u4e2d\u7684\u4e0d\u516c\u5e73\u884c\u4e3a\uff0c\u4e3aLLM\u516c\u5e73\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\u3002", "topic": "agent analysis"}}
{"id": "2512.15751", "categories": ["cs.LG", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.15751", "abs": "https://arxiv.org/abs/2512.15751", "authors": ["Wei Guan", "Jian Cao", "Jinyu Cai", "Qiqi Cai", "Jianqi Gao", "See-Kiong Ng"], "title": "GLOW: Graph-Language Co-Reasoning for Agentic Workflow Performance Prediction", "comment": null, "summary": "Agentic Workflows (AWs) have emerged as a promising paradigm for solving complex tasks. However, the scalability of automating their generation is severely constrained by the high cost and latency of execution-based evaluation. Existing AW performance prediction methods act as surrogates but fail to simultaneously capture the intricate topological dependencies and the deep semantic logic embedded in AWs. To address this limitation, we propose GLOW, a unified framework for AW performance prediction that combines the graph-structure modeling capabilities of GNNs with the reasoning power of LLMs. Specifically, we introduce a graph-oriented LLM, instruction-tuned on graph tasks, to extract topologically aware semantic features, which are fused with GNN-encoded structural representations. A contrastive alignment strategy further refines the latent space to distinguish high-quality AWs. Extensive experiments on FLORA-Bench show that GLOW outperforms state-of-the-art baselines in prediction accuracy and ranking utility.", "AI": {"tldr": "GLOW\u662f\u4e00\u4e2a\u7528\u4e8e\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6027\u80fd\u9884\u6d4b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u7ed3\u5408\u4e86GNN\u7684\u56fe\u7ed3\u6784\u5efa\u6a21\u80fd\u529b\u548cLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u56fe\u5bfc\u5411\u7684LLM\u63d0\u53d6\u62d3\u6251\u611f\u77e5\u8bed\u4e49\u7279\u5f81\uff0c\u5e76\u4e0eGNN\u7f16\u7801\u7684\u7ed3\u6784\u8868\u793a\u878d\u5408\uff0c\u5728FLORA-Bench\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\uff08AWs\uff09\u5728\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u81ea\u52a8\u5316\u751f\u6210\u7684\u53ef\u6269\u5c55\u6027\u53d7\u5230\u6267\u884c\u8bc4\u4f30\u9ad8\u6210\u672c\u548c\u5ef6\u8fdf\u7684\u4e25\u91cd\u9650\u5236\u3002\u73b0\u6709\u7684AW\u6027\u80fd\u9884\u6d4b\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u6355\u6349AW\u4e2d\u590d\u6742\u7684\u62d3\u6251\u4f9d\u8d56\u5173\u7cfb\u548c\u6df1\u5c42\u8bed\u4e49\u903b\u8f91\u3002", "method": "\u63d0\u51faGLOW\u7edf\u4e00\u6846\u67b6\uff0c\u7ed3\u5408GNN\u7684\u56fe\u7ed3\u6784\u5efa\u6a21\u80fd\u529b\u548cLLM\u7684\u63a8\u7406\u80fd\u529b\u3002\u4f7f\u7528\u56fe\u5bfc\u5411\u7684LLM\uff08\u5728\u56fe\u4efb\u52a1\u4e0a\u6307\u4ee4\u8c03\u4f18\uff09\u63d0\u53d6\u62d3\u6251\u611f\u77e5\u8bed\u4e49\u7279\u5f81\uff0c\u4e0eGNN\u7f16\u7801\u7684\u7ed3\u6784\u8868\u793a\u878d\u5408\u3002\u91c7\u7528\u5bf9\u6bd4\u5bf9\u9f50\u7b56\u7565\u8fdb\u4e00\u6b65\u4f18\u5316\u6f5c\u5728\u7a7a\u95f4\u4ee5\u533a\u5206\u9ad8\u8d28\u91cfAW\u3002", "result": "\u5728FLORA-Bench\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cGLOW\u5728\u9884\u6d4b\u51c6\u786e\u6027\u548c\u6392\u5e8f\u6548\u7528\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "GLOW\u901a\u8fc7\u7edf\u4e00\u56fe\u7ed3\u6784\u548c\u8bed\u4e49\u5efa\u6a21\uff0c\u6709\u6548\u89e3\u51b3\u4e86AW\u6027\u80fd\u9884\u6d4b\u4e2d\u62d3\u6251\u4f9d\u8d56\u548c\u8bed\u4e49\u903b\u8f91\u7684\u8054\u5408\u5efa\u6a21\u95ee\u9898\uff0c\u4e3aAW\u81ea\u52a8\u5316\u751f\u6210\u63d0\u4f9b\u4e86\u9ad8\u6548\u8bc4\u4f30\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2512.15948", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.15948", "abs": "https://arxiv.org/abs/2512.15948", "authors": ["Samuel J. Gershman"], "title": "Subjective functions", "comment": null, "summary": "Where do objective functions come from? How do we select what goals to pursue? Human intelligence is adept at synthesizing new objective functions on the fly. How does this work, and can we endow artificial systems with the same ability? This paper proposes an approach to answering these questions, starting with the concept of a subjective function, a higher-order objective function that is endogenous to the agent (i.e., defined with respect to the agent's features, rather than an external task). Expected prediction error is studied as a concrete example of a subjective function. This proposal has many connections to ideas in psychology, neuroscience, and machine learning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u4e3b\u89c2\u51fd\u6570\"\u6982\u5ff5\u4f5c\u4e3a\u9ad8\u9636\u76ee\u6807\u51fd\u6570\uff0c\u7814\u7a76\u671f\u671b\u9884\u6d4b\u8bef\u5dee\u4f5c\u4e3a\u5177\u4f53\u793a\u4f8b\uff0c\u63a2\u8ba8\u667a\u80fd\u4f53\u5982\u4f55\u5185\u751f\u5730\u5408\u6210\u76ee\u6807\u51fd\u6570\u3002", "motivation": "\u4eba\u7c7b\u667a\u80fd\u80fd\u591f\u52a8\u6001\u5408\u6210\u65b0\u7684\u76ee\u6807\u51fd\u6570\uff0c\u4f46\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7f3a\u4e4f\u8fd9\u79cd\u80fd\u529b\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u76ee\u6807\u51fd\u6570\u7684\u6765\u6e90\u3001\u5982\u4f55\u9009\u62e9\u8ffd\u6c42\u7684\u76ee\u6807\uff0c\u4ee5\u53ca\u5982\u4f55\u8d4b\u4e88\u4eba\u5de5\u7cfb\u7edf\u7c7b\u4f3c\u7684\u52a8\u6001\u76ee\u6807\u5408\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51fa\"\u4e3b\u89c2\u51fd\u6570\"\u6982\u5ff5\u4f5c\u4e3a\u9ad8\u9636\u76ee\u6807\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u5185\u751f\u4e8e\u667a\u80fd\u4f53\uff08\u57fa\u4e8e\u667a\u80fd\u4f53\u81ea\u8eab\u7279\u5f81\u800c\u975e\u5916\u90e8\u4efb\u52a1\u5b9a\u4e49\uff09\u3002\u4ee5\u671f\u671b\u9884\u6d4b\u8bef\u5dee\u4f5c\u4e3a\u5177\u4f53\u7684\u4e3b\u89c2\u51fd\u6570\u793a\u4f8b\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u8bba\u6587\u5efa\u7acb\u4e86\u4e3b\u89c2\u51fd\u6570\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u671f\u671b\u9884\u6d4b\u8bef\u5dee\u4f5c\u4e3a\u4e3b\u89c2\u51fd\u6570\u7684\u53ef\u884c\u6027\uff0c\u5e76\u5c06\u8be5\u6846\u67b6\u4e0e\u5fc3\u7406\u5b66\u3001\u795e\u7ecf\u79d1\u5b66\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u76f8\u5173\u601d\u60f3\u8054\u7cfb\u8d77\u6765\u3002", "conclusion": "\u4e3b\u89c2\u51fd\u6570\u4e3a\u7406\u89e3\u667a\u80fd\u4f53\u5982\u4f55\u5185\u751f\u5730\u5408\u6210\u76ee\u6807\u51fd\u6570\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\uff0c\u6709\u671b\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u83b7\u5f97\u7c7b\u4f3c\u4eba\u7c7b\u7684\u76ee\u6807\u52a8\u6001\u5408\u6210\u80fd\u529b\u3002", "topic": "agent analysis"}}
{"id": "2512.16022", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16022", "abs": "https://arxiv.org/abs/2512.16022", "authors": ["Defu Cao", "Michael Gee", "Jinbo Liu", "Hengxuan Wang", "Wei Yang", "Rui Wang", "Yan Liu"], "title": "Conversational Time Series Foundation Models: Towards Explainable and Effective Forecasting", "comment": "31Pages", "summary": "The proliferation of time series foundation models has created a landscape where no single method achieves consistent superiority, framing the central challenge not as finding the best model, but as orchestrating an optimal ensemble with interpretability. While Large Language Models (LLMs) offer powerful reasoning capabilities, their direct application to time series forecasting has proven ineffective. We address this gap by repositioning the LLM as an intelligent judge that evaluates, explains, and strategically coordinates an ensemble of foundation models. To overcome the LLM's inherent lack of domain-specific knowledge on time series, we introduce an R1-style finetuning process, guided by SHAP-based faithfulness scores, which teaches the model to interpret ensemble weights as meaningful causal statements about temporal dynamics. The trained agent then engages in iterative, multi-turn conversations to perform forward-looking assessments, provide causally-grounded explanations for its weighting decisions, and adaptively refine the optimization strategy. Validated on the GIFT-Eval benchmark on 23 datasets across 97 settings, our approach significantly outperforms leading time series foundation models on both CRPS and MASE metrics, establishing new state-of-the-art results.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u667a\u80fd\u88c1\u5224\uff0c\u7528\u4e8e\u8bc4\u4f30\u3001\u89e3\u91ca\u548c\u534f\u8c03\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u7684\u96c6\u6210\uff0c\u901a\u8fc7R1\u98ce\u683c\u5fae\u8c03\u548cSHAP\u5f15\u5bfc\u8bad\u7ec3\uff0c\u5728GIFT-Eval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4f17\u591a\uff0c\u4f46\u6ca1\u6709\u5355\u4e00\u65b9\u6cd5\u80fd\u59cb\u7ec8\u8868\u73b0\u6700\u4f18\uff0c\u6838\u5fc3\u6311\u6218\u5728\u4e8e\u5982\u4f55\u6784\u5efa\u6700\u4f18\u96c6\u6210\u5e76\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u5c06LLM\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u667a\u80fd\u88c1\u5224\uff0c\u901a\u8fc7R1\u98ce\u683c\u7684\u5fae\u8c03\u8fc7\u7a0b\uff08\u4f7f\u7528SHAP\u5fe0\u5b9e\u5ea6\u5206\u6570\u6307\u5bfc\uff09\uff0c\u6559\u4f1a\u6a21\u578b\u5c06\u96c6\u6210\u6743\u91cd\u89e3\u91ca\u4e3a\u5173\u4e8e\u65f6\u95f4\u52a8\u6001\u7684\u6709\u610f\u4e49\u56e0\u679c\u9648\u8ff0\u3002\u8bad\u7ec3\u540e\u7684\u4ee3\u7406\u901a\u8fc7\u591a\u8f6e\u5bf9\u8bdd\u8fdb\u884c\u524d\u77bb\u6027\u8bc4\u4f30\uff0c\u63d0\u4f9b\u56e0\u679c\u89e3\u91ca\uff0c\u5e76\u81ea\u9002\u5e94\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5728GIFT-Eval\u57fa\u51c6\u6d4b\u8bd5\u768423\u4e2a\u6570\u636e\u96c6\u300197\u79cd\u8bbe\u7f6e\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728CRPS\u548cMASE\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u9886\u5148\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff0c\u5efa\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u5c06LLM\u91cd\u65b0\u5b9a\u4f4d\u4e3a\u667a\u80fd\u96c6\u6210\u534f\u8c03\u5668\uff0c\u5e76\u5f15\u5165\u9886\u57df\u7279\u5b9a\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u95f4\u5e8f\u5217\u96c6\u6210\u4f18\u5316\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u548c\u53ef\u89e3\u91ca\u6027\u7684\u53cc\u91cd\u76ee\u6807\u3002", "topic": "agent analysis"}}
{"id": "2512.16108", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16108", "abs": "https://arxiv.org/abs/2512.16108", "authors": ["Wendong Bi", "Yirong Mao", "Xianglong Liu", "Kai Tian", "Jian Zhang", "Hanjie Wang", "Wenhui Que"], "title": "WeMusic-Agent: Efficient Conversational Music Recommendation via Knowledge Internalization and Agentic Boundary Learning", "comment": null, "summary": "Personalized music recommendation in conversational scenarios usually requires a deep understanding of user preferences and nuanced musical context, yet existing methods often struggle with balancing specialized domain knowledge and flexible tool integration. This paper proposes WeMusic-Agent, a training framework for efficient LLM-based conversational music recommendation. By integrating the knowledge internalization and agentic boundary learning, the framework aims to teach the model to intelligently decide when to leverage internalized knowledge and when to call specialized tools (e.g., music retrieval APIs, music recommendation systems). Under this framework, we present WeMusic-Agent-M1, an agentic model that internalizes extensive musical knowledge via continued pretraining on 50B music-related corpus while acquiring the ability to invoke external tools when necessary. Additionally, considering the lack of open-source benchmarks for conversational music recommendation, we also construct a benchmark for personalized music recommendations derived from real-world data in WeChat Listen. This benchmark enables comprehensive evaluation across multiple dimensions, including relevance, personalization, and diversity of the recommendations. Experiments on real-world data demonstrate that WeMusic-Agent achieves significant improvements over existing models.", "AI": {"tldr": "\u63d0\u51fa\u4e86WeMusic-Agent\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u5185\u5316\u548c\u667a\u80fd\u8fb9\u754c\u5b66\u4e60\uff0c\u8ba9LLM\u5728\u5bf9\u8bdd\u5f0f\u97f3\u4e50\u63a8\u8350\u4e2d\u667a\u80fd\u51b3\u5b9a\u4f55\u65f6\u4f7f\u7528\u5185\u5316\u77e5\u8bc6\u3001\u4f55\u65f6\u8c03\u7528\u5916\u90e8\u5de5\u5177\uff0c\u5e76\u6784\u5efa\u4e86\u5f00\u6e90\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u5f0f\u97f3\u4e50\u63a8\u8350\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u4e13\u4e1a\u9886\u57df\u77e5\u8bc6\u548c\u7075\u6d3b\u5de5\u5177\u96c6\u6210\uff0c\u9700\u8981\u65e2\u80fd\u7406\u89e3\u7528\u6237\u504f\u597d\u548c\u97f3\u4e50\u4e0a\u4e0b\u6587\uff0c\u53c8\u80fd\u667a\u80fd\u51b3\u7b56\u4f55\u65f6\u4f7f\u7528\u5185\u5316\u77e5\u8bc6\u3001\u4f55\u65f6\u8c03\u7528\u5916\u90e8\u5de5\u5177\u3002", "method": "\u63d0\u51faWeMusic-Agent\u8bad\u7ec3\u6846\u67b6\uff0c\u7ed3\u5408\u77e5\u8bc6\u5185\u5316\u548c\u667a\u80fd\u8fb9\u754c\u5b66\u4e60\uff1b\u5f00\u53d1WeMusic-Agent-M1\u6a21\u578b\uff0c\u5728500\u4ebf\u97f3\u4e50\u76f8\u5173\u8bed\u6599\u4e0a\u6301\u7eed\u9884\u8bad\u7ec3\u5185\u5316\u97f3\u4e50\u77e5\u8bc6\uff0c\u540c\u65f6\u5b66\u4e60\u8c03\u7528\u5916\u90e8\u5de5\u5177\uff08\u5982\u97f3\u4e50\u68c0\u7d22API\u3001\u63a8\u8350\u7cfb\u7edf\uff09\uff1b\u6784\u5efa\u57fa\u4e8e\u5fae\u4fe1\u542c\u4e66\u771f\u5b9e\u6570\u636e\u7684\u5f00\u6e90\u5bf9\u8bdd\u97f3\u4e50\u63a8\u8350\u57fa\u51c6\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cWeMusic-Agent\u76f8\u6bd4\u73b0\u6709\u6a21\u578b\u53d6\u5f97\u663e\u8457\u6539\u8fdb\uff0c\u57fa\u51c6\u652f\u6301\u591a\u7ef4\u5ea6\u8bc4\u4f30\uff08\u76f8\u5173\u6027\u3001\u4e2a\u6027\u5316\u3001\u591a\u6837\u6027\uff09\u3002", "conclusion": "WeMusic-Agent\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5bf9\u8bdd\u5f0f\u97f3\u4e50\u63a8\u8350\u4e2d\u77e5\u8bc6\u5185\u5316\u4e0e\u5de5\u5177\u8c03\u7528\u7684\u5e73\u8861\u95ee\u9898\uff0c\u63d0\u51fa\u7684\u6a21\u578b\u548c\u57fa\u51c6\u4e3a\u9886\u57df\u53d1\u5c55\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u3002", "topic": "agent analysis"}}
{"id": "2512.16149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16149", "abs": "https://arxiv.org/abs/2512.16149", "authors": ["Hao Chen", "Zhexin Hu", "Jiajun Chai", "Haocheng Yang", "Hang He", "Xiaohan Wang", "Wei Lin", "Luhang Wang", "Guojun Yin", "Zhuofeng zhao"], "title": "ToolForge: A Data Synthesis Pipeline for Multi-Hop Search without Real-World APIs", "comment": "13 pages, 9 tables, 6 figures. Code available at https://github.com/Buycar-arb/ToolForge", "summary": "Training LLMs to invoke tools and leverage retrieved information necessitates high-quality, diverse data. However, existing pipelines for synthetic data generation often rely on tens of thousands of real API calls to enhance generalization, incurring prohibitive costs while lacking multi-hop reasoning and self-reflection. To address these limitations, we introduce ToolForge, an automated synthesis framework that achieves strong real-world tool-calling performance by constructing only a small number of virtual tools, eliminating the need for real API calls. ToolForge leverages a (question, golden context, answer) triple to synthesize large-scale tool-learning data specifically designed for multi-hop search scenarios, further enriching the generated data through multi-hop reasoning and self-reflection mechanisms. To ensure data fidelity, we employ a Multi-Layer Validation Framework that integrates both rule-based and model-based assessments. Empirical results show that a model with only 8B parameters, when trained on our synthesized data, outperforms GPT-4o on multiple benchmarks. Our code and dataset are publicly available at https://github.com/Buycar-arb/ToolForge .", "AI": {"tldr": "ToolForge\uff1a\u65e0\u9700\u771f\u5b9eAPI\u8c03\u7528\u7684\u81ea\u52a8\u5316\u5de5\u5177\u8c03\u7528\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u4ec5\u9700\u5c11\u91cf\u865a\u62df\u5de5\u5177\u5373\u53ef\u751f\u6210\u9ad8\u8d28\u91cf\u591a\u8df3\u63a8\u7406\u6570\u636e\uff0c8B\u53c2\u6570\u6a21\u578b\u5728\u591a\u9879\u57fa\u51c6\u4e0a\u8d85\u8d8aGPT-4o", "motivation": "\u73b0\u6709\u5de5\u5177\u8c03\u7528\u6570\u636e\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u771f\u5b9eAPI\u8c03\u7528\uff0c\u6210\u672c\u9ad8\u6602\u4e14\u7f3a\u4e4f\u591a\u8df3\u63a8\u7406\u548c\u81ea\u53cd\u601d\u80fd\u529b\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u7684\u6570\u636e\u5408\u6210\u65b9\u6848", "method": "\u57fa\u4e8e(\u95ee\u9898\u3001\u9ec4\u91d1\u4e0a\u4e0b\u6587\u3001\u7b54\u6848)\u4e09\u5143\u7ec4\u6784\u5efa\u865a\u62df\u5de5\u5177\uff0c\u901a\u8fc7\u591a\u8df3\u63a8\u7406\u548c\u81ea\u53cd\u601d\u673a\u5236\u5408\u6210\u5927\u89c4\u6a21\u5de5\u5177\u5b66\u4e60\u6570\u636e\uff0c\u91c7\u7528\u591a\u5c42\u9a8c\u8bc1\u6846\u67b6\u786e\u4fdd\u6570\u636e\u8d28\u91cf", "result": "\u4ec5\u75288B\u53c2\u6570\u7684\u6a21\u578b\u5728\u5408\u6210\u6570\u636e\u4e0a\u8bad\u7ec3\u540e\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8aGPT-4o\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u5de5\u5177\u8c03\u7528\u6570\u636e", "conclusion": "ToolForge\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u771f\u5b9eAPI\u8c03\u7528\u7684\u9ad8\u6548\u6570\u636e\u5408\u6210\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u5de5\u5177\u8c03\u7528\u6a21\u578b\u8bad\u7ec3\u6210\u672c\uff0c\u540c\u65f6\u63d0\u5347\u591a\u8df3\u63a8\u7406\u80fd\u529b", "topic": "code agent"}}
{"id": "2512.16214", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16214", "abs": "https://arxiv.org/abs/2512.16214", "authors": ["Jianming Liu", "Ren Zhu", "Jian Xu", "Kun Ding", "Xu-Yao Zhang", "Gaofeng Meng", "Cheng-Lin Liu"], "title": "PDE-Agent: A toolchain-augmented multi-agent framework for PDE solving", "comment": null, "summary": "Solving Partial Differential Equations (PDEs) is a cornerstone of engineering and scientific research. Traditional methods for PDE solving are cumbersome, relying on manual setup and domain expertise. While Physics-Informed Neural Network (PINNs) introduced end-to-end neural network-based solutions, and frameworks like DeepXDE further enhanced automation, these approaches still depend on expert knowledge and lack full autonomy. In this work, we frame PDE solving as tool invocation via LLM-driven agents and introduce PDE-Agent, the first toolchain-augmented multi-agent collaboration framework, inheriting the reasoning capacity of LLMs and the controllability of external tools and enabling automated PDE solving from natural language descriptions. PDE-Agent leverages the strengths of multi-agent and multi-tool collaboration through two key innovations: (1) A Prog-Act framework with graph memory for multi-agent collaboration, which enables effective dynamic planning and error correction via dual-loop mechanisms (localized fixes and global revisions). (2) A Resource-Pool integrated with a tool-parameter separation mechanism for multi-tool collaboration. This centralizes the management of runtime artifacts and resolves inter-tool dependency gaps in existing frameworks. To validate and evaluate this new paradigm for PDE solving , we develop PDE-Bench, a multi-type PDE Benchmark for agent-based tool collaborative solving, and propose multi-level metrics for assessing tool coordination. Evaluations verify that PDE-Agent exhibits superior applicability and performance in complex multi-step, cross-step dependent tasks. This new paradigm of toolchain-augmented multi-agent PDE solving will further advance future developments in automated scientific computing. Our source code and dataset will be made publicly available.", "AI": {"tldr": "\u63d0\u51faPDE-Agent\uff1a\u9996\u4e2a\u57fa\u4e8eLLM\u9a71\u52a8\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684PDE\u6c42\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u5de5\u5177\u94fe\u589e\u5f3a\u5b9e\u73b0\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u5230\u81ea\u52a8\u5316\u6c42\u89e3", "motivation": "\u4f20\u7edfPDE\u6c42\u89e3\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u8bbe\u7f6e\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u73b0\u6709PINN\u548cDeepXDE\u7b49\u65b9\u6cd5\u4ecd\u9700\u8981\u4e13\u5bb6\u77e5\u8bc6\u4e14\u7f3a\u4e4f\u5b8c\u5168\u81ea\u4e3b\u6027\uff0c\u9700\u8981\u66f4\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848", "method": "1) Prog-Act\u6846\u67b6\uff1a\u57fa\u4e8e\u56fe\u8bb0\u5fc6\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\uff0c\u901a\u8fc7\u53cc\u5faa\u73af\u673a\u5236\uff08\u5c40\u90e8\u4fee\u590d\u548c\u5168\u5c40\u4fee\u8ba2\uff09\u5b9e\u73b0\u52a8\u6001\u89c4\u5212\u548c\u9519\u8bef\u7ea0\u6b63\uff1b2) \u8d44\u6e90\u6c60\uff1a\u96c6\u6210\u5de5\u5177-\u53c2\u6570\u5206\u79bb\u673a\u5236\uff0c\u96c6\u4e2d\u7ba1\u7406\u8fd0\u884c\u65f6\u5de5\u4ef6\u5e76\u89e3\u51b3\u5de5\u5177\u95f4\u4f9d\u8d56\u5173\u7cfb", "result": "\u5f00\u53d1\u4e86PDE-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9a8c\u8bc1PDE-Agent\u5728\u590d\u6742\u591a\u6b65\u9aa4\u3001\u8de8\u6b65\u9aa4\u4f9d\u8d56\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9002\u7528\u6027\u548c\u6027\u80fd", "conclusion": "\u5de5\u5177\u94fe\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53PDE\u6c42\u89e3\u65b0\u8303\u5f0f\u5c06\u63a8\u52a8\u81ea\u52a8\u5316\u79d1\u5b66\u8ba1\u7b97\u7684\u672a\u6765\u53d1\u5c55", "topic": "code agent"}}
{"id": "2512.16649", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16649", "abs": "https://arxiv.org/abs/2512.16649", "authors": ["Bingxiang He", "Zekai Qu", "Zeyuan Liu", "Yinghao Chen", "Yuxin Zuo", "Cheng Qian", "Kaiyan Zhang", "Weize Chen", "Chaojun Xiao", "Ganqu Cui", "Ning Ding", "Zhiyuan Liu"], "title": "JustRL: Scaling a 1.5B LLM with a Simple RL Recipe", "comment": "12 pages, 3 figures", "summary": "Recent advances in reinforcement learning for large language models have converged on increasing complexity: multi-stage training pipelines, dynamic hyperparameter schedules, and curriculum learning strategies. This raises a fundamental question: \\textbf{Is this complexity necessary?} We present \\textbf{JustRL}, a minimal approach using single-stage training with fixed hyperparameters that achieves state-of-the-art performance on two 1.5B reasoning models (54.9\\% and 64.3\\% average accuracy across nine mathematical benchmarks) while using 2$\\times$ less compute than sophisticated approaches. The same hyperparameters transfer across both models without tuning, and training exhibits smooth, monotonic improvement over 4,000+ steps without the collapses or plateaus that typically motivate interventions. Critically, ablations reveal that adding ``standard tricks'' like explicit length penalties and robust verifiers may degrade performance by collapsing exploration. These results suggest that the field may be adding complexity to solve problems that disappear with a stable, scaled-up baseline. We release our models and code to establish a simple, validated baseline for the community.", "AI": {"tldr": "JustRL\u63d0\u51fa\u4e86\u4e00\u79cd\u6781\u7b80\u7684\u5355\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u4f7f\u7528\u56fa\u5b9a\u8d85\u53c2\u6570\u57281.5B\u63a8\u7406\u6a21\u578b\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\uff0c\u540c\u65f6\u8ba1\u7b97\u91cf\u51cf\u534a\uff0c\u6311\u6218\u4e86\u5f53\u524dRL\u8bad\u7ec3\u4e2d\u590d\u6742\u591a\u9636\u6bb5\u6d41\u7a0b\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8d8b\u5411\u4e8e\u8d8a\u6765\u8d8a\u590d\u6742\uff08\u591a\u9636\u6bb5\u8bad\u7ec3\u3001\u52a8\u6001\u8d85\u53c2\u6570\u8c03\u5ea6\u3001\u8bfe\u7a0b\u5b66\u4e60\u7b49\uff09\uff0c\u4f5c\u8005\u8d28\u7591\u8fd9\u79cd\u590d\u6742\u6027\u662f\u5426\u5fc5\u8981\uff0c\u5e0c\u671b\u63a2\u7d22\u4e00\u79cd\u66f4\u7b80\u5355\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u63d0\u51faJustRL\u65b9\u6cd5\uff1a\u5355\u9636\u6bb5\u8bad\u7ec3\u3001\u56fa\u5b9a\u8d85\u53c2\u6570\u3001\u4e0d\u4f7f\u7528\u590d\u6742\u7684\u6280\u5de7\uff08\u5982\u663e\u5f0f\u957f\u5ea6\u60e9\u7f5a\u3001\u9c81\u68d2\u9a8c\u8bc1\u5668\uff09\u3002\u57281.5B\u63a8\u7406\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8d85\u53c2\u6570\u5728\u4e24\u4e2a\u6a21\u578b\u95f4\u65e0\u9700\u8c03\u6574\u5373\u53ef\u8fc1\u79fb\u3002", "result": "\u5728\u4e24\u4e2a1.5B\u63a8\u7406\u6a21\u578b\u4e0a\uff0c\u57289\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u8fbe\u523054.9%\u548c64.3%\u7684\u5e73\u5747\u51c6\u786e\u7387\uff0c\u8ba1\u7b97\u91cf\u6bd4\u590d\u6742\u65b9\u6cd5\u51cf\u5c112\u500d\u3002\u8bad\u7ec3\u8fc7\u7a0b\u5e73\u6ed1\u5355\u8c03\u6539\u8fdb4000+\u6b65\uff0c\u6ca1\u6709\u5d29\u6e83\u6216\u5e73\u53f0\u671f\u3002\u6d88\u878d\u5b9e\u9a8c\u663e\u793a\u6dfb\u52a0\"\u6807\u51c6\u6280\u5de7\"\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u9886\u57df\u53ef\u80fd\u4e3a\u4e86\u89e3\u51b3\u95ee\u9898\u800c\u589e\u52a0\u590d\u6742\u6027\uff0c\u4f46\u8fd9\u4e9b\u95ee\u9898\u5728\u7a33\u5b9a\u3001\u89c4\u6a21\u5316\u7684\u57fa\u7ebf\u65b9\u6cd5\u4e2d\u4f1a\u81ea\u7136\u6d88\u5931\u3002\u4f5c\u8005\u53d1\u5e03\u6a21\u578b\u548c\u4ee3\u7801\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u4e00\u4e2a\u7b80\u5355\u3001\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u57fa\u7ebf\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.16250", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.16250", "abs": "https://arxiv.org/abs/2512.16250", "authors": ["Sanjoy Chowdhury", "Karren D. Yang", "Xudong Liu", "Fartash Faghri", "Pavan Kumar Anasosalu Vasu", "Oncel Tuzel", "Dinesh Manocha", "Chun-Liang Li", "Raviteja Vemulapalli"], "title": "AMUSE: Audio-Visual Benchmark and Alignment Framework for Agentic Multi-Speaker Understanding", "comment": null, "summary": "Recent multimodal large language models (MLLMs) such as GPT-4o and Qwen3-Omni show strong perception but struggle in multi-speaker, dialogue-centric settings that demand agentic reasoning tracking who speaks, maintaining roles, and grounding events across time. These scenarios are central to multimodal audio-video understanding, where models must jointly reason over audio and visual streams in applications such as conversational video assistants and meeting analytics. We introduce AMUSE, a benchmark designed around tasks that are inherently agentic, requiring models to decompose complex audio-visual interactions into planning, grounding, and reflection steps. It evaluates MLLMs across three modes zero-shot, guided, and agentic and six task families, including spatio-temporal speaker grounding and multimodal dialogue summarization. Across all modes, current models exhibit weak multi-speaker reasoning and inconsistent behavior under both non-agentic and agentic evaluation. Motivated by the inherently agentic nature of these tasks and recent advances in LLM agents, we propose RAFT, a data-efficient agentic alignment framework that integrates reward optimization with intrinsic multimodal self-evaluation as reward and selective parameter adaptation for data and parameter efficient updates. Using RAFT, we achieve up to 39.52\\% relative improvement in accuracy on our benchmark. Together, AMUSE and RAFT provide a practical platform for examining agentic reasoning in multimodal models and improving their capabilities.", "AI": {"tldr": "\u63d0\u51fa\u4e86AMUSE\u57fa\u51c6\u6d4b\u8bd5\u6765\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bf4\u8bdd\u4eba\u5bf9\u8bdd\u573a\u666f\u4e2d\u7684\u4ee3\u7406\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5f00\u53d1\u4e86RAFT\u6846\u67b6\u901a\u8fc7\u5956\u52b1\u4f18\u5316\u548c\u9009\u62e9\u6027\u53c2\u6570\u9002\u5e94\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o\u3001Qwen3-Omni\uff09\u5728\u611f\u77e5\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5728\u591a\u8bf4\u8bdd\u4eba\u5bf9\u8bdd\u573a\u666f\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u8fd9\u4e9b\u573a\u666f\u9700\u8981\u4ee3\u7406\u63a8\u7406\u80fd\u529b\u6765\u8ddf\u8e2a\u8bf4\u8bdd\u8005\u3001\u7ef4\u6301\u89d2\u8272\u548c\u8de8\u65f6\u95f4\u57fa\u7840\u4e8b\u4ef6\u3002\u8fd9\u4e9b\u573a\u666f\u5bf9\u591a\u6a21\u6001\u97f3\u9891-\u89c6\u9891\u7406\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u5982\u5bf9\u8bdd\u89c6\u9891\u52a9\u624b\u548c\u4f1a\u8bae\u5206\u6790\u5e94\u7528\u3002", "method": "1. \u5f15\u5165AMUSE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u56f4\u7ed5\u9700\u8981\u4ee3\u7406\u63a8\u7406\u7684\u4efb\u52a1\u8bbe\u8ba1\uff0c\u8981\u6c42\u6a21\u578b\u5c06\u590d\u6742\u7684\u97f3\u9891-\u89c6\u89c9\u4ea4\u4e92\u5206\u89e3\u4e3a\u89c4\u5212\u3001\u57fa\u7840\u548c\u53cd\u601d\u6b65\u9aa4\uff1b2. \u5728\u4e09\u79cd\u6a21\u5f0f\uff08\u96f6\u6837\u672c\u3001\u5f15\u5bfc\u3001\u4ee3\u7406\uff09\u548c\u516d\u4e2a\u4efb\u52a1\u5bb6\u65cf\u4e2d\u8bc4\u4f30MLLMs\uff1b3. \u63d0\u51faRAFT\u6846\u67b6\uff0c\u96c6\u6210\u5956\u52b1\u4f18\u5316\u4e0e\u5185\u5728\u591a\u6a21\u6001\u81ea\u6211\u8bc4\u4f30\u4f5c\u4e3a\u5956\u52b1\uff0c\u5e76\u8fdb\u884c\u9009\u62e9\u6027\u53c2\u6570\u9002\u5e94\u4ee5\u5b9e\u73b0\u6570\u636e\u548c\u53c2\u6570\u9ad8\u6548\u66f4\u65b0\u3002", "result": "\u5f53\u524d\u6a21\u578b\u5728\u6240\u6709\u6a21\u5f0f\u4e0b\u90fd\u8868\u73b0\u51fa\u5f31\u7684\u591a\u8bf4\u8bdd\u4eba\u63a8\u7406\u80fd\u529b\u548c\u4e0d\u4e00\u81f4\u7684\u884c\u4e3a\u3002\u4f7f\u7528RAFT\u6846\u67b6\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe39.52%\u7684\u76f8\u5bf9\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "AMUSE\u548cRAF\u5171\u540c\u4e3a\u68c0\u9a8c\u591a\u6a21\u6001\u6a21\u578b\u4e2d\u7684\u4ee3\u7406\u63a8\u7406\u80fd\u529b\u5e76\u63d0\u5347\u5176\u6027\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u5e73\u53f0\u3002", "topic": "agent analysis"}}
{"id": "2512.16262", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16262", "abs": "https://arxiv.org/abs/2512.16262", "authors": ["Yifei She", "Ping Zhang", "He Liu", "Yanmin Jia", "Yang Jing", "Zijun Liu", "Peng Sun", "Xiangbin Li", "Xiaohe Hu"], "title": "Learning to Wait: Synchronizing Agents with the Physical World", "comment": null, "summary": "Real-world agentic tasks, unlike synchronous Markov Decision Processes (MDPs), often involve non-blocking actions with variable latencies, creating a fundamental \\textit{Temporal Gap} between action initiation and completion. Existing environment-side solutions, such as blocking wrappers or frequent polling, either limit scalability or dilute the agent's context window with redundant observations. In this work, we propose an \\textbf{Agent-side Approach} that empowers Large Language Models (LLMs) to actively align their \\textit{Cognitive Timeline} with the physical world. By extending the Code-as-Action paradigm to the temporal domain, agents utilize semantic priors and In-Context Learning (ICL) to predict precise waiting durations (\\texttt{time.sleep(t)}), effectively synchronizing with asynchronous environment without exhaustive checking. Experiments in a simulated Kubernetes cluster demonstrate that agents can precisely calibrate their internal clocks to minimize both query overhead and execution latency, validating that temporal awareness is a learnable capability essential for autonomous evolution in open-ended environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ee3\u7406\u7aef\u65b9\u6cd5\uff0c\u8ba9LLM\u80fd\u591f\u4e3b\u52a8\u5bf9\u9f50\u5176\u8ba4\u77e5\u65f6\u95f4\u7ebf\u4e0e\u7269\u7406\u4e16\u754c\uff0c\u901a\u8fc7\u9884\u6d4b\u7b49\u5f85\u65f6\u95f4\uff08time.sleep(t)\uff09\u6765\u540c\u6b65\u5f02\u6b65\u73af\u5883\uff0c\u51cf\u5c11\u67e5\u8be2\u5f00\u9500\u548c\u6267\u884c\u5ef6\u8fdf\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4ee3\u7406\u4efb\u52a1\u901a\u5e38\u6d89\u53ca\u5177\u6709\u53ef\u53d8\u5ef6\u8fdf\u7684\u975e\u963b\u585e\u64cd\u4f5c\uff0c\u8fd9\u4e0e\u540c\u6b65MDP\u4e0d\u540c\uff0c\u5b58\u5728\"\u65f6\u95f4\u95f4\u9699\"\u95ee\u9898\u3002\u73b0\u6709\u73af\u5883\u7aef\u89e3\u51b3\u65b9\u6848\uff08\u5982\u963b\u585e\u5305\u88c5\u5668\u6216\u9891\u7e41\u8f6e\u8be2\uff09\u8981\u4e48\u9650\u5236\u53ef\u6269\u5c55\u6027\uff0c\u8981\u4e48\u7528\u5197\u4f59\u89c2\u5bdf\u7a00\u91ca\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002", "method": "\u63d0\u51fa\u4ee3\u7406\u7aef\u65b9\u6cd5\uff0c\u5c06\u4ee3\u7801\u5373\u884c\u52a8\u8303\u5f0f\u6269\u5c55\u5230\u65f6\u95f4\u9886\u57df\uff0c\u5229\u7528\u8bed\u4e49\u5148\u9a8c\u548c\u4e0a\u4e0b\u6587\u5b66\u4e60\u6765\u9884\u6d4b\u7cbe\u786e\u7684\u7b49\u5f85\u6301\u7eed\u65f6\u95f4\uff08time.sleep(t)\uff09\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u4e0e\u5f02\u6b65\u73af\u5883\u540c\u6b65\u800c\u65e0\u9700\u8be6\u5c3d\u68c0\u67e5\u3002", "result": "\u5728\u6a21\u62dfKubernetes\u96c6\u7fa4\u4e2d\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4ee3\u7406\u80fd\u591f\u7cbe\u786e\u6821\u51c6\u5176\u5185\u90e8\u65f6\u949f\uff0c\u6700\u5c0f\u5316\u67e5\u8be2\u5f00\u9500\u548c\u6267\u884c\u5ef6\u8fdf\uff0c\u9a8c\u8bc1\u4e86\u65f6\u95f4\u611f\u77e5\u662f\u53ef\u5b66\u4e60\u7684\u80fd\u529b\u3002", "conclusion": "\u65f6\u95f4\u611f\u77e5\u662f\u4ee3\u7406\u5728\u5f00\u653e\u73af\u5883\u4e2d\u81ea\u4e3b\u6f14\u8fdb\u7684\u5173\u952e\u53ef\u5b66\u4e60\u80fd\u529b\uff0c\u4ee3\u7406\u7aef\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5f02\u6b65\u73af\u5883\u4e2d\u7684\u65f6\u95f4\u540c\u6b65\u95ee\u9898\u3002", "topic": "agent analysis"}}
{"id": "2512.16279", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16279", "abs": "https://arxiv.org/abs/2512.16279", "authors": ["Yiliu Yang", "Yilei Jiang", "Qunzhong Wang", "Yingshui Tan", "Xiaoyong Zhu", "Sherman S. M. Chow", "Bo Zheng", "Xiangyu Yue"], "title": "QuadSentinel: Sequent Safety for Machine-Checkable Control in Multi-agent Systems", "comment": "Preprint", "summary": "Safety risks arise as large language model-based agents solve complex tasks with tools, multi-step plans, and inter-agent messages. However, deployer-written policies in natural language are ambiguous and context dependent, so they map poorly to machine-checkable rules, and runtime enforcement is unreliable. Expressing safety policies as sequents, we propose \\textsc{QuadSentinel}, a four-agent guard (state tracker, policy verifier, threat watcher, and referee) that compiles these policies into machine-checkable rules built from predicates over observable state and enforces them online. Referee logic plus an efficient top-$k$ predicate updater keeps costs low by prioritizing checks and resolving conflicts hierarchically. Measured on ST-WebAgentBench (ICML CUA~'25) and AgentHarm (ICLR~'25), \\textsc{QuadSentinel} improves guardrail accuracy and rule recall while reducing false positives. Against single-agent baselines such as ShieldAgent (ICML~'25), it yields better overall safety control. Near-term deployments can adopt this pattern without modifying core agents by keeping policies separate and machine-checkable. Our code will be made publicly available at https://github.com/yyiliu/QuadSentinel.", "AI": {"tldr": "QuadSentinel\u662f\u4e00\u4e2a\u56db\u667a\u80fd\u4f53\u5b89\u5168\u9632\u62a4\u7cfb\u7edf\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u5b89\u5168\u7b56\u7565\u7f16\u8bd1\u4e3a\u673a\u5668\u53ef\u68c0\u67e5\u7684\u89c4\u5219\uff0c\u901a\u8fc7\u72b6\u6001\u8ddf\u8e2a\u5668\u3001\u7b56\u7565\u9a8c\u8bc1\u5668\u3001\u5a01\u80c1\u76d1\u89c6\u5668\u548c\u88c1\u5224\u56db\u4e2a\u7ec4\u4ef6\u5728\u7ebf\u6267\u884c\u5b89\u5168\u7b56\u7565\uff0c\u63d0\u9ad8LLM\u667a\u80fd\u4f53\u4efb\u52a1\u6267\u884c\u65f6\u7684\u5b89\u5168\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u5728\u6267\u884c\u590d\u6742\u4efb\u52a1\u65f6\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u800c\u90e8\u7f72\u8005\u7528\u81ea\u7136\u8bed\u8a00\u7f16\u5199\u7684\u5b89\u5168\u7b56\u7565\u5b58\u5728\u6a21\u7cca\u6027\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\uff0c\u96be\u4ee5\u6620\u5c04\u5230\u673a\u5668\u53ef\u68c0\u67e5\u7684\u89c4\u5219\uff0c\u5bfc\u81f4\u8fd0\u884c\u65f6\u5b89\u5168\u6267\u884c\u4e0d\u53ef\u9760\u3002", "method": "\u5c06\u5b89\u5168\u7b56\u7565\u8868\u8fbe\u4e3a\u5e8f\u5217\uff0c\u6784\u5efa\u56db\u667a\u80fd\u4f53\u9632\u62a4\u7cfb\u7edf\uff1a\u72b6\u6001\u8ddf\u8e2a\u5668\u76d1\u63a7\u667a\u80fd\u4f53\u72b6\u6001\uff0c\u7b56\u7565\u9a8c\u8bc1\u5668\u5c06\u7b56\u7565\u7f16\u8bd1\u4e3a\u673a\u5668\u53ef\u68c0\u67e5\u7684\u89c4\u5219\uff0c\u5a01\u80c1\u76d1\u89c6\u5668\u68c0\u6d4b\u6f5c\u5728\u5a01\u80c1\uff0c\u88c1\u5224\u901a\u8fc7\u9ad8\u6548\u7684top-k\u8c13\u8bcd\u66f4\u65b0\u5668\u4f18\u5148\u68c0\u67e5\u5e76\u5206\u5c42\u89e3\u51b3\u51b2\u7a81\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u3002", "result": "\u5728ST-WebAgentBench\u548cAgentHarm\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cQuadSentinel\u63d0\u9ad8\u4e86\u62a4\u680f\u51c6\u786e\u6027\u548c\u89c4\u5219\u53ec\u56de\u7387\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u8bef\u62a5\u3002\u76f8\u6bd4ShieldAgent\u7b49\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\uff0c\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6574\u4f53\u5b89\u5168\u63a7\u5236\u3002", "conclusion": "QuadSentinel\u6a21\u5f0f\u53ef\u4ee5\u5728\u4e0d\u4fee\u6539\u6838\u5fc3\u667a\u80fd\u4f53\u7684\u60c5\u51b5\u4e0b\u88ab\u8fd1\u671f\u90e8\u7f72\u91c7\u7528\uff0c\u901a\u8fc7\u4fdd\u6301\u7b56\u7565\u5206\u79bb\u548c\u673a\u5668\u53ef\u68c0\u67e5\u6027\u6765\u589e\u5f3a\u5b89\u5168\u6027\u3002\u8be5\u6a21\u5f0f\u4e3aLLM\u667a\u80fd\u4f53\u5b89\u5168\u9632\u62a4\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2512.16295", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16295", "abs": "https://arxiv.org/abs/2512.16295", "authors": ["Zhenyu Wu", "Jingjing Xie", "Zehao Li", "Bowen Yang", "Qiushi Sun", "Zhaoyang Liu", "Zhoumianze Liu", "Yu Qiao", "Xiangyu Yue", "Zun Wang", "Zichen Ding"], "title": "OS-Oracle: A Comprehensive Framework for Cross-Platform GUI Critic Models", "comment": null, "summary": "With VLM-powered computer-using agents (CUAs) becoming increasingly capable at graphical user interface (GUI) navigation and manipulation, reliable step-level decision-making has emerged as a key bottleneck for real-world deployment. In long-horizon workflows, errors accumulate quickly and irreversible actions can cause unintended consequences, motivating critic models that assess each action before execution. While critic models offer a promising solution, their effectiveness is hindered by the lack of diverse, high-quality GUI feedback data and public critic benchmarks for step-level evaluation in computer use. To bridge these gaps, we introduce OS-Oracle that makes three core contributions: (1) a scalable data pipeline for synthesizing cross-platform GUI critic data; (2) a two-stage training paradigm combining supervised fine-tuning (SFT) and consistency-preserving group relative policy optimization (CP-GRPO); (3) OS-Critic Bench, a holistic benchmark for evaluating critic model performance across Mobile, Web, and Desktop platforms. Leveraging this framework, we curate a high-quality dataset containing 310k critic samples. The resulting critic model, OS-Oracle-7B, achieves state-of-the-art performance among open-source VLMs on OS-Critic Bench, and surpasses proprietary models on the mobile domain. Furthermore, when serving as a pre-critic, OS-Oracle-7B improves the performance of native GUI agents such as UI-TARS-1.5-7B in OSWorld and AndroidWorld environments. The code is open-sourced at https://github.com/numbmelon/OS-Oracle.", "AI": {"tldr": "OS-Oracle\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eGUI\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u6279\u8bc4\u6a21\u578b\uff0c\u901a\u8fc7\u53ef\u6269\u5c55\u7684\u6570\u636e\u7ba1\u9053\u3001\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\u548c\u65b0\u57fa\u51c6\uff0c\u663e\u8457\u63d0\u5347\u4e86GUI\u4ee3\u7406\u7684\u51b3\u7b56\u53ef\u9760\u6027\u3002", "motivation": "\u968f\u7740VLM\u9a71\u52a8\u7684\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u5728GUI\u5bfc\u822a\u548c\u64cd\u4f5c\u65b9\u9762\u80fd\u529b\u589e\u5f3a\uff0c\u53ef\u9760\u7684\u6b65\u9aa4\u7ea7\u51b3\u7b56\u6210\u4e3a\u5b9e\u9645\u90e8\u7f72\u7684\u5173\u952e\u74f6\u9888\u3002\u5728\u957f\u6d41\u7a0b\u5de5\u4f5c\u6d41\u4e2d\uff0c\u9519\u8bef\u4f1a\u5feb\u901f\u7d2f\u79ef\uff0c\u4e0d\u53ef\u9006\u64cd\u4f5c\u53ef\u80fd\u5bfc\u81f4\u610f\u5916\u540e\u679c\uff0c\u56e0\u6b64\u9700\u8981\u6279\u8bc4\u6a21\u578b\u5728\u6267\u884c\u524d\u8bc4\u4f30\u6bcf\u4e2a\u52a8\u4f5c\u3002", "method": "1) \u8de8\u5e73\u53f0GUI\u6279\u8bc4\u6570\u636e\u7684\u53ef\u6269\u5c55\u5408\u6210\u7ba1\u9053\uff1b2) \u7ed3\u5408\u76d1\u7763\u5fae\u8c03(SFT)\u548c\u4e00\u81f4\u6027\u4fdd\u6301\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(CP-GRPO)\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u8303\u5f0f\uff1b3) OS-Critic Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u79fb\u52a8\u3001Web\u548c\u684c\u9762\u5e73\u53f0\u7684\u6279\u8bc4\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b31\u4e07\u6279\u8bc4\u6837\u672c\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0cOS-Oracle-7B\u6a21\u578b\u5728OS-Critic Bench\u4e0a\u8fbe\u5230\u5f00\u6e90VLM\u7684\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5728\u79fb\u52a8\u9886\u57df\u8d85\u8d8a\u4e13\u6709\u6a21\u578b\uff0c\u4f5c\u4e3a\u9884\u6279\u8bc4\u5668\u80fd\u63d0\u5347UI-TARS-1.5-7B\u7b49\u539f\u751fGUI\u4ee3\u7406\u5728OSWorld\u548cAndroidWorld\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002", "conclusion": "OS-Oracle\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u6570\u636e\u5408\u6210\u3001\u8bad\u7ec3\u65b9\u6cd5\u548c\u8bc4\u4f30\u57fa\u51c6\uff0c\u6709\u6548\u89e3\u51b3\u4e86GUI\u4ee3\u7406\u6b65\u9aa4\u7ea7\u51b3\u7b56\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u4e3a\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002", "topic": "agent analysis"}}
{"id": "2512.16301", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16301", "abs": "https://arxiv.org/abs/2512.16301", "authors": ["Pengcheng Jiang", "Jiacheng Lin", "Zhiyi Shi", "Zifeng Wang", "Luxi He", "Yichen Wu", "Ming Zhong", "Peiyang Song", "Qizheng Zhang", "Heng Wang", "Xueqiang Xu", "Hanwen Xu", "Pengrui Han", "Dylan Zhang", "Jiashuo Sun", "Chaoqi Yang", "Kun Qian", "Tian Wang", "Changran Hu", "Manling Li", "Quanzheng Li", "Hao Peng", "Sheng Wang", "Jingbo Shang", "Chao Zhang", "Jiaxuan You", "Liyuan Liu", "Pan Lu", "Yu Zhang", "Heng Ji", "Yejin Choi", "Dawn Song", "Jimeng Sun", "Jiawei Han"], "title": "Adaptation of Agentic AI", "comment": null, "summary": "Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations. We further decompose these into tool-execution-signaled and agent-output-signaled forms of agent adaptation, as well as agent-agnostic and agent-supervised forms of tool adaptation. We demonstrate that this framework helps clarify the design space of adaptation strategies in agentic AI, makes their trade-offs explicit, and provides practical guidance for selecting or switching among strategies during system design. We then review the representative approaches in each category, analyze their strengths and limitations, and highlight key open challenges and future opportunities. Overall, this paper aims to offer a conceptual foundation and practical roadmap for researchers and practitioners seeking to build more capable, efficient, and reliable agentic AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u7edf\u4e00\u4e86\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u7684\u9002\u5e94\u673a\u5236\uff0c\u6db5\u76d6\u667a\u80fd\u4f53\u9002\u5e94\u548c\u5de5\u5177\u9002\u5e94\u4e24\u5927\u7c7b\u522b\uff0c\u5e76\u8fdb\u4e00\u6b65\u7ec6\u5206\u4e3a\u4e0d\u540c\u4fe1\u53f7\u5f62\u5f0f\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u3001\u9ad8\u6548\u3001\u53ef\u9760\u7684\u667a\u80fd\u4f53AI\u7cfb\u7edf\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\u548c\u5b9e\u8df5\u8def\u7ebf\u56fe\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u667a\u80fd\u4f53AI\u7cfb\u7edf\u80fd\u529b\u4e0d\u65ad\u589e\u5f3a\u3001\u5e94\u7528\u8303\u56f4\u4e0d\u65ad\u6269\u5927\uff0c\u9002\u5e94\u673a\u5236\u6210\u4e3a\u63d0\u5347\u6027\u80fd\u3001\u53ef\u9760\u6027\u548c\u6cdb\u5316\u80fd\u529b\u7684\u5173\u952e\u624b\u6bb5\u3002\u7136\u800c\uff0c\u5feb\u901f\u6269\u5c55\u7684\u7814\u7a76\u9886\u57df\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u6846\u67b6\u6765\u7edf\u4e00\u7406\u89e3\u5404\u79cd\u9002\u5e94\u7b56\u7565\uff0c\u8fd9\u963b\u788d\u4e86\u7cfb\u7edf\u8bbe\u8ba1\u548c\u7b56\u7565\u9009\u62e9\u7684\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53AI\u9002\u5e94\u7814\u7a76\u7edf\u4e00\u4e3a\u4e24\u5927\u7c7b\u522b\uff1a\u667a\u80fd\u4f53\u9002\u5e94\u548c\u5de5\u5177\u9002\u5e94\u3002\u8fdb\u4e00\u6b65\u5c06\u667a\u80fd\u4f53\u9002\u5e94\u5206\u89e3\u4e3a\u5de5\u5177\u6267\u884c\u4fe1\u53f7\u9a71\u52a8\u548c\u667a\u80fd\u4f53\u8f93\u51fa\u4fe1\u53f7\u9a71\u52a8\u4e24\u79cd\u5f62\u5f0f\uff0c\u5c06\u5de5\u5177\u9002\u5e94\u5206\u89e3\u4e3a\u667a\u80fd\u4f53\u65e0\u5173\u548c\u667a\u80fd\u4f53\u76d1\u7763\u4e24\u79cd\u5f62\u5f0f\u3002\u901a\u8fc7\u8be5\u6846\u67b6\u5206\u6790\u8bbe\u8ba1\u7a7a\u95f4\u3001\u660e\u786e\u6743\u8861\u53d6\u820d\uff0c\u5e76\u63d0\u4f9b\u7b56\u7565\u9009\u62e9\u548c\u5207\u6362\u7684\u5b9e\u8df5\u6307\u5bfc\u3002", "result": "\u8be5\u6846\u67b6\u5e2e\u52a9\u6f84\u6e05\u4e86\u667a\u80fd\u4f53AI\u4e2d\u9002\u5e94\u7b56\u7565\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u4f7f\u5404\u79cd\u7b56\u7565\u7684\u6743\u8861\u53d6\u820d\u53d8\u5f97\u660e\u786e\uff0c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u7b56\u7565\u9009\u62e9\u6216\u5207\u6362\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002\u901a\u8fc7\u56de\u987e\u6bcf\u4e2a\u7c7b\u522b\u7684\u4ee3\u8868\u6027\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u5e76\u7a81\u51fa\u4e86\u5173\u952e\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u673a\u4f1a\u3002", "conclusion": "\u672c\u6587\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u6784\u5efa\u66f4\u5f3a\u5927\u3001\u9ad8\u6548\u3001\u53ef\u9760\u7684\u667a\u80fd\u4f53AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u548c\u5b9e\u8df5\u8def\u7ebf\u56fe\u3002\u7edf\u4e00\u7684\u9002\u5e94\u6846\u67b6\u6709\u52a9\u4e8e\u7cfb\u7edf\u5316\u7406\u89e3\u5f53\u524d\u7814\u7a76\u8fdb\u5c55\uff0c\u6307\u5bfc\u672a\u6765\u6280\u672f\u53d1\u5c55\u65b9\u5411\u3002", "topic": "agent analysis"}}
{"id": "2512.16883", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16883", "abs": "https://arxiv.org/abs/2512.16883", "authors": ["Tzu-Han Lin", "Wei-Lin Chen", "Chen-An Li", "Hung-yi Lee", "Yun-Nung Chen", "Yu Meng"], "title": "AdaSearch: Balancing Parametric Knowledge and Search in Large Language Models via Reinforcement Learning", "comment": "Preprint. Code and artifacts will be uploaded to https://github.com/hank0316/AdaSearch", "summary": "Equipping large language models (LLMs) with search engines via reinforcement learning (RL) has emerged as an effective approach for building search agents. However, overreliance on search introduces unnecessary cost and risks exposure to noisy or malicious content, while relying solely on parametric knowledge risks hallucination. The central challenge is to develop agents that adaptively balance parametric knowledge with external search, invoking search only when necessary. Prior work mitigates search overuse by shaping rewards around the number of tool calls. However, these penalties require substantial reward engineering, provide ambiguous credit assignment, and can be exploited by agents that superficially reduce calls. Moreover, evaluating performance solely through call counts conflates necessary and unnecessary search, obscuring the measurement of true adaptive behavior. To address these limitations, we first quantify the self-knowledge awareness of existing search agents via an F1-based decision metric, revealing that methods such as Search-R1 often overlook readily available parametric knowledge. Motivated by these findings, we propose AdaSearch, a simple two-stage, outcome-driven RL framework that disentangles problem solving from the decision of whether to invoke search, and makes this decision process explicit and interpretable. This transparency is crucial for high-stakes domains such as finance and medical question answering, yet is largely neglected by prior approaches. Experiments across multiple model families and sizes demonstrate that AdaSearch substantially improves knowledge-boundary awareness, reduces unnecessary search calls, preserves strong task performance, and offers more transparent, interpretable decision behaviors.", "AI": {"tldr": "\u63d0\u51faAdaSearch\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u5206\u79bb\u95ee\u9898\u89e3\u51b3\u4e0e\u641c\u7d22\u51b3\u7b56\uff0c\u63d0\u9ad8LLM\u641c\u7d22\u4ee3\u7406\u7684\u81ea\u77e5\u80fd\u529b\uff0c\u51cf\u5c11\u4e0d\u5fc5\u8981\u641c\u7d22\u8c03\u7528\uff0c\u540c\u65f6\u4fdd\u6301\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u641c\u7d22\u4ee3\u7406\u5b58\u5728\u8fc7\u5ea6\u4f9d\u8d56\u641c\u7d22\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6210\u672c\u589e\u52a0\u548c\u66b4\u9732\u4e8e\u566a\u58f0/\u6076\u610f\u5185\u5bb9\u7684\u98ce\u9669\uff0c\u800c\u4ec5\u4f9d\u8d56\u53c2\u6570\u77e5\u8bc6\u53c8\u53ef\u80fd\u4ea7\u751f\u5e7b\u89c9\u3002\u9700\u8981\u5f00\u53d1\u80fd\u81ea\u9002\u5e94\u5e73\u8861\u53c2\u6570\u77e5\u8bc6\u548c\u5916\u90e8\u641c\u7d22\u7684\u4ee3\u7406\u3002", "method": "\u63d0\u51faAdaSearch\u6846\u67b6\uff1a1\uff09\u91cf\u5316\u73b0\u6709\u641c\u7d22\u4ee3\u7406\u7684\u81ea\u77e5\u80fd\u529b\uff1b2\uff09\u91c7\u7528\u4e24\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u89e3\u51b3\u4e0e\u662f\u5426\u8c03\u7528\u641c\u7d22\u7684\u51b3\u7b56\u89e3\u8026\uff1b3\uff09\u4f7f\u51b3\u7b56\u8fc7\u7a0b\u663e\u5f0f\u548c\u53ef\u89e3\u91ca\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u7cfb\u5217\u548c\u89c4\u6a21\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAdaSearch\u663e\u8457\u63d0\u9ad8\u4e86\u77e5\u8bc6\u8fb9\u754c\u610f\u8bc6\uff0c\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u641c\u7d22\u8c03\u7528\uff0c\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u63d0\u4f9b\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u884c\u4e3a\u3002", "conclusion": "AdaSearch\u901a\u8fc7\u89e3\u8026\u95ee\u9898\u89e3\u51b3\u4e0e\u641c\u7d22\u51b3\u7b56\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u641c\u7d22\u4ee3\u7406\u7684\u8fc7\u5ea6\u641c\u7d22\u95ee\u9898\uff0c\u4e3a\u91d1\u878d\u548c\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u63d0\u4f9b\u4e86\u66f4\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.16317", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16317", "abs": "https://arxiv.org/abs/2512.16317", "authors": ["Arther Tian", "Alex Ding", "Frank Chen", "Alan Wu", "Aaron Chan", "Bruce Zhang"], "title": "Design and Evaluation of Cost-Aware PoQ for Decentralized LLM Inference", "comment": null, "summary": "Decentralized large language model (LLM) inference promises transparent and censorship resistant access to advanced AI, yet existing verification approaches struggle to scale to modern models. Proof of Quality (PoQ) replaces cryptographic verification of computation with consensus over output quality, but the original formulation ignores heterogeneous computational costs across inference and evaluator nodes. This paper introduces a cost-aware PoQ framework that integrates explicit efficiency measurements into the reward mechanism for both types of nodes. The design combines ground truth token level F1, lightweight learned evaluators, and GPT based judgments within a unified evaluation pipeline, and adopts a linear reward function that balances normalized quality and cost.\n  Experiments on extractive question answering and abstractive summarization use five instruction tuned LLMs ranging from TinyLlama-1.1B to Llama-3.2-3B and three evaluation models spanning cross encoder and bi encoder architectures. Results show that a semantic textual similarity bi encoder achieves much higher correlation with both ground truth and GPT scores than cross encoders, indicating that evaluator architecture is a critical design choice for PoQ. Quality-cost analysis further reveals that the largest models in the pool are also the most efficient in terms of quality per unit latency. Monte Carlo simulations over 5\\,000 PoQ rounds demonstrate that the cost-aware reward scheme consistently assigns higher average rewards to high quality low cost inference models and to efficient evaluators, while penalizing slow low quality nodes. These findings suggest that cost-aware PoQ provides a practical foundation for economically sustainable decentralized LLM inference.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6210\u672c\u611f\u77e5\u7684PoQ\u6846\u67b6\uff0c\u5c06\u663e\u5f0f\u6548\u7387\u6d4b\u91cf\u6574\u5408\u5230\u63a8\u7406\u8282\u70b9\u548c\u8bc4\u4f30\u8282\u70b9\u7684\u5956\u52b1\u673a\u5236\u4e2d\uff0c\u901a\u8fc7\u5e73\u8861\u8d28\u91cf\u4e0e\u6210\u672c\u6765\u652f\u6301\u7ecf\u6d4e\u53ef\u6301\u7eed\u7684\u53bb\u4e2d\u5fc3\u5316LLM\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u53bb\u4e2d\u5fc3\u5316LLM\u63a8\u7406\u9a8c\u8bc1\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\u5230\u73b0\u4ee3\u6a21\u578b\uff0c\u800c\u539f\u59cb\u7684PoQ\u65b9\u6cd5\u5ffd\u7565\u4e86\u63a8\u7406\u8282\u70b9\u548c\u8bc4\u4f30\u8282\u70b9\u4e4b\u95f4\u7684\u5f02\u6784\u8ba1\u7b97\u6210\u672c\u5dee\u5f02\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u8003\u8651\u6210\u672c\u56e0\u7d20\u7684\u6539\u8fdb\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u6210\u672c\u611f\u77e5PoQ\u6846\u67b6\uff0c\u6574\u5408\u4e86\u4e09\u79cd\u8bc4\u4f30\u65b9\u6cd5\uff1a\u57fa\u7840\u771f\u503c\u6807\u8bb0\u7ea7F1\u3001\u8f7b\u91cf\u7ea7\u5b66\u4e60\u8bc4\u4f30\u5668\u548cGPT\u5224\u65ad\uff1b\u91c7\u7528\u7ebf\u6027\u5956\u52b1\u51fd\u6570\u5e73\u8861\u5f52\u4e00\u5316\u8d28\u91cf\u548c\u6210\u672c\uff1b\u5728\u62bd\u53d6\u5f0f\u95ee\u7b54\u548c\u62bd\u8c61\u6458\u8981\u4efb\u52a1\u4e0a\u6d4b\u8bd5\u4e865\u4e2aLLM\u548c3\u4e2a\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u8bed\u4e49\u6587\u672c\u76f8\u4f3c\u6027\u53cc\u7f16\u7801\u5668\u6bd4\u4ea4\u53c9\u7f16\u7801\u5668\u4e0e\u57fa\u7840\u771f\u503c\u548cGPT\u5206\u6570\u76f8\u5173\u6027\u66f4\u9ad8\uff1b\u8d28\u91cf-\u6210\u672c\u5206\u6790\u663e\u793a\u6c60\u4e2d\u6700\u5927\u6a21\u578b\u5728\u5355\u4f4d\u5ef6\u8fdf\u8d28\u91cf\u65b9\u9762\u6700\u6709\u6548\uff1b\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8868\u660e\u6210\u672c\u611f\u77e5\u5956\u52b1\u65b9\u6848\u80fd\u6301\u7eed\u5956\u52b1\u9ad8\u8d28\u91cf\u4f4e\u6210\u672c\u8282\u70b9\u3002", "conclusion": "\u6210\u672c\u611f\u77e5PoQ\u4e3a\u7ecf\u6d4e\u53ef\u6301\u7eed\u7684\u53bb\u4e2d\u5fc3\u5316LLM\u63a8\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\uff0c\u8bc4\u4f30\u5668\u67b6\u6784\u662f\u5173\u952e\u8bbe\u8ba1\u9009\u62e9\uff0c\u6700\u5927\u6a21\u578b\u5728\u8d28\u91cf\u6210\u672c\u6548\u7387\u65b9\u9762\u8868\u73b0\u6700\u4f73\u3002", "topic": "agent analysis"}}
{"id": "2512.15973", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15973", "abs": "https://arxiv.org/abs/2512.15973", "authors": ["Caner Erden"], "title": "Dynamic Rank Reinforcement Learning for Adaptive Low-Rank Multi-Head Self Attention in Large Language Models", "comment": null, "summary": "We propose Dynamic Rank Reinforcement Learning (DR-RL), a novel framework that adaptively optimizes the low-rank factorization of Multi-Head Self-Attention (MHSA) in Large Language Models (LLMs) through the integration of reinforcement learning and online matrix perturbation theory. While traditional low-rank approximations often rely on static rank assumptions--limiting their flexibility across diverse input contexts--our method dynamically selects ranks based on real-time sequence dynamics, layer-specific sensitivities, and hardware constraints. The core innovation lies in an RL agent that formulates rank selection as a sequential policy optimization problem, where the reward function strictly balances attention fidelity against computational latency. Crucially, we employ online matrix perturbation bounds to enable incremental rank updates, thereby avoiding the prohibitive cost of full decomposition during inference. Furthermore, the integration of a lightweight Transformer-based policy network and batched Singular Value Decomposition (SVD) operations ensures scalable deployment on modern GPU architectures. Experiments demonstrate that DR-RL maintains downstream accuracy statistically equivalent to full-rank attention while significantly reducing Floating Point Operations (FLOPs), particularly in long-sequence regimes (L > 4096). This work bridges the gap between adaptive efficiency and theoretical rigor in MHSA, offering a principled, mathematically grounded alternative to heuristic rank reduction techniques in resource-constrained deep learning. Source code and experiment logs are available at: https://github.com/canererden/DR_RL_Project", "AI": {"tldr": "\u63d0\u51faDR-RL\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u5728\u7ebf\u77e9\u9635\u6270\u52a8\u7406\u8bba\uff0c\u52a8\u6001\u4f18\u5316LLM\u4e2d\u591a\u5934\u81ea\u6ce8\u610f\u529b\u7684\u4f4e\u79e9\u5206\u89e3\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "motivation": "\u4f20\u7edf\u4f4e\u79e9\u8fd1\u4f3c\u65b9\u6cd5\u901a\u5e38\u91c7\u7528\u9759\u6001\u79e9\u5047\u8bbe\uff0c\u65e0\u6cd5\u9002\u5e94\u4e0d\u540c\u8f93\u5165\u4e0a\u4e0b\u6587\u7684\u53d8\u5316\uff0c\u9650\u5236\u4e86\u7075\u6d3b\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u6839\u636e\u5b9e\u65f6\u5e8f\u5217\u52a8\u6001\u3001\u5c42\u654f\u611f\u6027\u548c\u786c\u4ef6\u7ea6\u675f\u52a8\u6001\u9009\u62e9\u79e9\u7684\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5c06\u79e9\u9009\u62e9\u5efa\u6a21\u4e3a\u5e8f\u5217\u7b56\u7565\u4f18\u5316\u95ee\u9898\uff0c\u5956\u52b1\u51fd\u6570\u5e73\u8861\u6ce8\u610f\u529b\u4fdd\u771f\u5ea6\u548c\u8ba1\u7b97\u5ef6\u8fdf\u3002\u91c7\u7528\u5728\u7ebf\u77e9\u9635\u6270\u52a8\u7406\u8bba\u5b9e\u73b0\u589e\u91cf\u79e9\u66f4\u65b0\uff0c\u907f\u514d\u63a8\u7406\u65f6\u5b8c\u5168\u5206\u89e3\u7684\u9ad8\u6210\u672c\u3002\u7ed3\u5408\u8f7b\u91cf\u7ea7Transformer\u7b56\u7565\u7f51\u7edc\u548c\u6279\u5904\u7406SVD\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDR-RL\u5728\u4fdd\u6301\u4e0e\u5168\u79e9\u6ce8\u610f\u529b\u7edf\u8ba1\u7b49\u6548\u7684\u4e0b\u6e38\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u6d6e\u70b9\u8fd0\u7b97\uff0c\u5c24\u5176\u5728\u957f\u5e8f\u5217\u573a\u666f\uff08L>4096\uff09\u4e2d\u6548\u679c\u660e\u663e\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u586b\u8865\u4e86MHSA\u81ea\u9002\u5e94\u6548\u7387\u548c\u7406\u8bba\u4e25\u8c28\u6027\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u79e9\u7f29\u51cf\u6280\u672f\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u3001\u6570\u5b66\u57fa\u7840\u624e\u5b9e\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.16465", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16465", "abs": "https://arxiv.org/abs/2512.16465", "authors": ["Jinwu Chen", "Qidie Wu", "Bin Li", "Lin Ma", "Xin Si", "Yang Hu", "Shouyi Yin", "Jun Yang"], "title": "cuPilot: A Strategy-Coordinated Multi-agent Framework for CUDA Kernel Evolution", "comment": null, "summary": "Optimizing CUDA kernels is a challenging and labor-intensive task, given the need for hardware-software co-design expertise and the proprietary nature of high-performance kernel libraries. While recent large language models (LLMs) combined with evolutionary algorithms show promise in automatic kernel optimization, existing approaches often fall short in performance due to their suboptimal agent designs and mismatched evolution representations. This work identifies these mismatches and proposes cuPilot, a strategy-coordinated multi-agent framework that introduces strategy as an intermediate semantic representation for kernel evolution. Key contributions include a strategy-coordinated evolution algorithm, roofline-guided prompting, and strategy-level population initialization. Experimental results show that the generated kernels by cuPilot achieve an average speed up of 3.09$\\times$ over PyTorch on a benchmark of 100 kernels. On the GEMM tasks, cuPilot showcases sophisticated optimizations and achieves high utilization of critical hardware units. The generated kernels are open-sourced at https://github.com/champloo2878/cuPilot-Kernels.git.", "AI": {"tldr": "cuPilot\u662f\u4e00\u4e2a\u7b56\u7565\u534f\u8c03\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u7b56\u7565\u4f5c\u4e3a\u4e2d\u95f4\u8bed\u4e49\u8868\u793a\u6765\u4f18\u5316CUDA\u5185\u6838\uff0c\u5728100\u4e2a\u5185\u6838\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6bd4PyTorch\u5feb3.09\u500d\u3002", "motivation": "CUDA\u5185\u6838\u4f18\u5316\u9700\u8981\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u4e13\u4e1a\u77e5\u8bc6\u4e14\u9ad8\u6027\u80fd\u5185\u6838\u5e93\u5177\u6709\u4e13\u6709\u6027\uff0c\u73b0\u6709LLM\u7ed3\u5408\u8fdb\u5316\u7b97\u6cd5\u7684\u65b9\u6cd5\u7531\u4e8e\u667a\u80fd\u4f53\u8bbe\u8ba1\u4e0d\u4f73\u548c\u8fdb\u5316\u8868\u793a\u4e0d\u5339\u914d\u800c\u6027\u80fd\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u7b56\u7565\u534f\u8c03\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6cuPilot\uff0c\u5f15\u5165\u7b56\u7565\u4f5c\u4e3a\u5185\u6838\u8fdb\u5316\u7684\u4e2d\u95f4\u8bed\u4e49\u8868\u793a\uff0c\u5305\u62ec\u7b56\u7565\u534f\u8c03\u8fdb\u5316\u7b97\u6cd5\u3001\u5c4b\u9876\u7ebf\u5f15\u5bfc\u63d0\u793a\u548c\u7b56\u7565\u7ea7\u79cd\u7fa4\u521d\u59cb\u5316\u3002", "result": "\u5728100\u4e2a\u5185\u6838\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u6bd4PyTorch\u5feb3.09\u500d\uff0c\u5728GEMM\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u590d\u6742\u7684\u4f18\u5316\u5e76\u5b9e\u73b0\u4e86\u5173\u952e\u786c\u4ef6\u5355\u5143\u7684\u9ad8\u5229\u7528\u7387\u3002", "conclusion": "cuPilot\u901a\u8fc7\u7b56\u7565\u534f\u8c03\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5185\u6838\u4f18\u5316\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "topic": "code agent"}}
{"id": "2512.16532", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.16532", "abs": "https://arxiv.org/abs/2512.16532", "authors": ["Himanshu Gharat", "Himanshi Agrawal", "Gourab K. Patro"], "title": "From Personalization to Prejudice: Bias and Discrimination in Memory-Enhanced AI Agents for Recruitment", "comment": "In Proceedings of the Nineteenth ACM International Conference on Web Search and Data Mining (WSDM '26)", "summary": "Large Language Models (LLMs) have empowered AI agents with advanced capabilities for understanding, reasoning, and interacting across diverse tasks. The addition of memory further enhances them by enabling continuity across interactions, learning from past experiences, and improving the relevance of actions and responses over time; termed as memory-enhanced personalization. Although such personalization through memory offers clear benefits, it also introduces risks of bias. While several previous studies have highlighted bias in ML and LLMs, bias due to memory-enhanced personalized agents is largely unexplored. Using recruitment as an example use case, we simulate the behavior of a memory-enhanced personalized agent, and study whether and how bias is introduced and amplified in and across various stages of operation. Our experiments on agents using safety-trained LLMs reveal that bias is systematically introduced and reinforced through personalization, emphasizing the need for additional protective measures or agent guardrails in memory-enhanced LLM-based AI agents.", "AI": {"tldr": "\u7814\u7a76\u8bb0\u5fc6\u589e\u5f3a\u578b\u4e2a\u6027\u5316AI\u4ee3\u7406\u5728\u62db\u8058\u573a\u666f\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u53d1\u73b0\u5373\u4f7f\u4f7f\u7528\u5b89\u5168\u8bad\u7ec3\u7684LLM\uff0c\u504f\u89c1\u4ecd\u4f1a\u901a\u8fc7\u4e2a\u6027\u5316\u8fc7\u7a0b\u88ab\u7cfb\u7edf\u6027\u5730\u5f15\u5165\u548c\u5f3a\u5316\u3002", "motivation": "\u867d\u7136\u8bb0\u5fc6\u589e\u5f3a\u7684\u4e2a\u6027\u5316AI\u4ee3\u7406\u80fd\u63d0\u5347\u4efb\u52a1\u8fde\u7eed\u6027\u548c\u54cd\u5e94\u76f8\u5173\u6027\uff0c\u4f46\u8fd9\u79cd\u4e2a\u6027\u5316\u53ef\u80fd\u5f15\u5165\u504f\u89c1\u98ce\u9669\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8ML\u548cLLM\u7684\u504f\u89c1\uff0c\u4f46\u5bf9\u8bb0\u5fc6\u589e\u5f3a\u4e2a\u6027\u5316\u4ee3\u7406\u7684\u504f\u89c1\u95ee\u9898\u7f3a\u4e4f\u63a2\u7d22\u3002", "method": "\u4ee5\u62db\u8058\u4e3a\u7528\u4f8b\uff0c\u6a21\u62df\u8bb0\u5fc6\u589e\u5f3a\u4e2a\u6027\u5316\u4ee3\u7406\u7684\u884c\u4e3a\uff0c\u7814\u7a76\u504f\u89c1\u662f\u5426\u4ee5\u53ca\u5982\u4f55\u5728\u5404\u4e2a\u64cd\u4f5c\u9636\u6bb5\u88ab\u5f15\u5165\u548c\u653e\u5927\u3002\u4f7f\u7528\u5b89\u5168\u8bad\u7ec3\u7684LLM\u6784\u5efa\u4ee3\u7406\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5373\u4f7f\u4f7f\u7528\u5b89\u5168\u8bad\u7ec3\u7684LLM\uff0c\u504f\u89c1\u4ecd\u4f1a\u901a\u8fc7\u4e2a\u6027\u5316\u8fc7\u7a0b\u88ab\u7cfb\u7edf\u6027\u5730\u5f15\u5165\u548c\u5f3a\u5316\uff0c\u5f3a\u8c03\u9700\u8981\u5728\u8bb0\u5fc6\u589e\u5f3a\u7684LLM\u4ee3\u7406\u4e2d\u589e\u52a0\u4fdd\u62a4\u63aa\u65bd\u6216\u9632\u62a4\u673a\u5236\u3002", "conclusion": "\u8bb0\u5fc6\u589e\u5f3a\u7684\u4e2a\u6027\u5316AI\u4ee3\u7406\u5b58\u5728\u504f\u89c1\u98ce\u9669\uff0c\u9700\u8981\u989d\u5916\u7684\u4fdd\u62a4\u63aa\u65bd\u6216\u4ee3\u7406\u9632\u62a4\u673a\u5236\u6765\u51cf\u8f7b\u504f\u89c1\u5728\u4e2a\u6027\u5316\u8fc7\u7a0b\u4e2d\u7684\u5f15\u5165\u548c\u653e\u5927\u3002", "topic": "agent analysis"}}
{"id": "2512.16917", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16917", "abs": "https://arxiv.org/abs/2512.16917", "authors": ["Qihao Liu", "Luoxin Ye", "Wufei Ma", "Yu-Cheng Chou", "Alan Yuille"], "title": "Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning", "comment": null, "summary": "Large language models (LLMs) with explicit reasoning capabilities excel at mathematical reasoning yet still commit process errors, such as incorrect calculations, brittle logic, and superficially plausible but invalid steps. In this paper, we introduce Generative Adversarial Reasoner, an on-policy joint training framework designed to enhance reasoning by co-evolving an LLM reasoner and an LLM-based discriminator through adversarial reinforcement learning. A compute-efficient review schedule partitions each reasoning chain into logically complete slices of comparable length, and the discriminator evaluates each slice's soundness with concise, structured justifications. Learning couples complementary signals: the LLM reasoner is rewarded for logically consistent steps that yield correct answers, while the discriminator earns rewards for correctly detecting errors or distinguishing traces in the reasoning process. This produces dense, well-calibrated, on-policy step-level rewards that supplement sparse exact-match signals, improving credit assignment, increasing sample efficiency, and enhancing overall reasoning quality of LLMs. Across various mathematical benchmarks, the method delivers consistent gains over strong baselines with standard RL post-training. Specifically, on AIME24, we improve DeepSeek-R1-Distill-Qwen-7B from 54.0 to 61.3 (+7.3) and DeepSeek-R1-Distill-Llama-8B from 43.7 to 53.7 (+10.0). The modular discriminator also enables flexible reward shaping for objectives such as teacher distillation, preference alignment, and mathematical proof-based reasoning.", "AI": {"tldr": "\u63d0\u51faGenerative Adversarial Reasoner\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6297\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u8bad\u7ec3\u63a8\u7406\u5668\u548c\u5224\u522b\u5668\uff0c\u4f7f\u7528\u8ba1\u7b97\u9ad8\u6548\u7684\u5ba1\u67e5\u673a\u5236\u63d0\u4f9b\u5bc6\u96c6\u7684\u6b65\u9aa4\u7ea7\u5956\u52b1\uff0c\u63d0\u5347LLM\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1\u5177\u6709\u663e\u5f0f\u63a8\u7406\u80fd\u529b\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u5b58\u5728\u8fc7\u7a0b\u9519\u8bef\uff0c\u5982\u8ba1\u7b97\u9519\u8bef\u3001\u903b\u8f91\u8106\u5f31\u548c\u8868\u9762\u5408\u7406\u4f46\u65e0\u6548\u7684\u6b65\u9aa4\u3002\u9700\u8981\u6539\u8fdb\u63a8\u7406\u8d28\u91cf\u3002", "method": "\u63d0\u51faGenerative Adversarial Reasoner\u6846\u67b6\uff0c\u5305\u542b\u63a8\u7406\u5668\u548c\u5224\u522b\u5668\uff0c\u901a\u8fc7\u5bf9\u6297\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u8bad\u7ec3\u3002\u4f7f\u7528\u8ba1\u7b97\u9ad8\u6548\u7684\u5ba1\u67e5\u673a\u5236\u5c06\u63a8\u7406\u94fe\u5212\u5206\u4e3a\u903b\u8f91\u5b8c\u6574\u7684\u7247\u6bb5\uff0c\u5224\u522b\u5668\u8bc4\u4f30\u6bcf\u4e2a\u7247\u6bb5\u7684\u5408\u7406\u6027\u5e76\u63d0\u4f9b\u7ed3\u6784\u5316\u7406\u7531\u3002\u63a8\u7406\u5668\u56e0\u903b\u8f91\u4e00\u81f4\u4e14\u5f97\u51fa\u6b63\u786e\u7b54\u6848\u7684\u6b65\u9aa4\u83b7\u5f97\u5956\u52b1\uff0c\u5224\u522b\u5668\u56e0\u6b63\u786e\u68c0\u6d4b\u9519\u8bef\u6216\u533a\u5206\u63a8\u7406\u8fc7\u7a0b\u83b7\u5f97\u5956\u52b1\u3002", "result": "\u5728\u591a\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e00\u81f4\u63d0\u5347\u3002\u5728AIME24\u4e0a\uff0cDeepSeek-R1-Distill-Qwen-7B\u4ece54.0\u63d0\u5347\u523061.3\uff08+7.3\uff09\uff0cDeepSeek-R1-Distill-Llama-8B\u4ece43.7\u63d0\u5347\u523053.7\uff08+10.0\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bc6\u96c6\u3001\u6821\u51c6\u826f\u597d\u7684\u6b65\u9aa4\u7ea7\u5956\u52b1\u8865\u5145\u7a00\u758f\u7684\u7cbe\u786e\u5339\u914d\u4fe1\u53f7\uff0c\u6539\u8fdb\u4e86\u4fe1\u7528\u5206\u914d\uff0c\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u589e\u5f3a\u4e86LLM\u7684\u6574\u4f53\u63a8\u7406\u8d28\u91cf\u3002\u6a21\u5757\u5316\u5224\u522b\u5668\u8fd8\u652f\u6301\u7075\u6d3b\u7684\u5956\u52b1\u5851\u9020\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.16698", "categories": ["cs.AI", "cs.CG"], "pdf": "https://arxiv.org/pdf/2512.16698", "abs": "https://arxiv.org/abs/2512.16698", "authors": ["Mahbub E Sobhani", "Md. Faiyaz Abdullah Sayeedi", "Mohammad Nehad Alam", "Proma Hossain Progga", "Swakkhar Shatabda"], "title": "Do Multi-Agents Solve Better Than Single? Evaluating Agentic Frameworks for Diagram-Grounded Geometry Problem Solving and Reasoning", "comment": "Accepted to the ARR October 2025 cycle", "summary": "Diagram-grounded geometry problem solving is a critical benchmark for multimodal large language models (MLLMs), yet the benefits of multi-agent design over single-agent remain unclear. We systematically compare single-agent and multi-agent pipelines on four visual math benchmarks: Geometry3K, MathVerse, OlympiadBench, and We-Math. For open-source models, multi-agent consistently improves performance. For example, Qwen-2.5-VL (7B) gains +6.8 points and Qwen-2.5-VL (32B) gains +3.3 on Geometry3K, and both Qwen-2.5-VL variants see further gains on OlympiadBench and We-Math. In contrast, the closed-source Gemini-2.0-Flash generally performs better in single-agent mode on classic benchmarks, while multi-agent yields only modest improvements on the newer We-Math dataset. These findings show that multi-agent pipelines provide clear benefits for open-source models and can assist strong proprietary systems on newer, less familiar benchmarks, but agentic decomposition is not universally optimal. All code, data, and reasoning files are available at https://github.com/faiyazabdullah/Interpreter-Solver", "AI": {"tldr": "\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u5728\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u4e2d\u5e76\u975e\u603b\u662f\u6700\u4f18\uff0c\u5f00\u6e90\u6a21\u578b\u53d7\u76ca\u660e\u663e\u800c\u95ed\u6e90\u6a21\u578b\u5728\u4f20\u7edf\u57fa\u51c6\u4e0a\u5355\u667a\u80fd\u4f53\u8868\u73b0\u66f4\u597d", "motivation": "\u7814\u7a76\u591a\u667a\u80fd\u4f53\u4e0e\u5355\u667a\u80fd\u4f53\u5728\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u63a2\u7d22\u591a\u667a\u80fd\u4f53\u8bbe\u8ba1\u7684\u5b9e\u9645\u6548\u76ca", "method": "\u5728\u56db\u4e2a\u89c6\u89c9\u6570\u5b66\u57fa\u51c6\uff08Geometry3K\u3001MathVerse\u3001OlympiadBench\u3001We-Math\uff09\u4e0a\u7cfb\u7edf\u6bd4\u8f83\u5355\u667a\u80fd\u4f53\u4e0e\u591a\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\u6027\u80fd", "result": "\u5f00\u6e90\u6a21\u578b\uff08\u5982Qwen-2.5-VL\uff09\u5728\u591a\u667a\u80fd\u4f53\u6a21\u5f0f\u4e0b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u800c\u95ed\u6e90\u6a21\u578b\uff08Gemini-2.0-Flash\uff09\u5728\u4f20\u7edf\u57fa\u51c6\u4e0a\u5355\u667a\u80fd\u4f53\u8868\u73b0\u66f4\u597d\uff0c\u4ec5\u5728\u8f83\u65b0\u6570\u636e\u96c6\u4e0a\u6709\u9002\u5ea6\u6539\u8fdb", "conclusion": "\u591a\u667a\u80fd\u4f53\u6d41\u6c34\u7ebf\u5bf9\u5f00\u6e90\u6a21\u578b\u6709\u660e\u663e\u4f18\u52bf\uff0c\u5bf9\u5f3a\u95ed\u6e90\u7cfb\u7edf\u5728\u65b0\u57fa\u51c6\u4e0a\u6709\u8f85\u52a9\u4f5c\u7528\uff0c\u4f46\u667a\u80fd\u4f53\u5206\u89e3\u5e76\u975e\u666e\u904d\u6700\u4f18\u7b56\u7565", "topic": "agent analysis"}}
{"id": "2512.16144", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16144", "abs": "https://arxiv.org/abs/2512.16144", "authors": ["Prime Intellect Team", "Mika Senghaas", "Fares Obeid", "Sami Jaghouar", "William Brown", "Jack Min Ong", "Daniel Auras", "Matej Sirovatka", "Jannik Straube", "Andrew Baker", "Sebastian M\u00fcller", "Justus Mattern", "Manveer Basra", "Aiman Ismail", "Dominik Scherm", "Cooper Miller", "Ameen Patel", "Simon Kirsten", "Mario Sieg", "Christian Reetz", "Kemal Erdem", "Vincent Weisser", "Johannes Hagemann"], "title": "INTELLECT-3: Technical Report", "comment": "27 pages, 10 figures", "summary": "We present INTELLECT-3, a 106B-parameter Mixture-of-Experts model (12B active) trained with large-scale reinforcement learning on our end-to-end RL infrastructure stack. INTELLECT-3 achieves state of the art performance for its size across math, code, science and reasoning benchmarks, outperforming many larger frontier models. We open-source the model together with the full infrastructure stack used to create it, including RL frameworks, complete recipe, and a wide collection of environments, built with the verifiers library, for training and evaluation from our Environments Hub community platform. Built for this effort, we introduce prime-rl, an open framework for large-scale asynchronous reinforcement learning, which scales seamlessly from a single node to thousands of GPUs, and is tailored for agentic RL with first-class support for multi-turn interactions and tool use. Using this stack, we run both SFT and RL training on top of the GLM-4.5-Air-Base model, scaling RL training up to 512 H200s with high training efficiency.", "AI": {"tldr": "INTELLECT-3\u662f\u4e00\u4e2a106B\u53c2\u6570\u7684MoE\u6a21\u578b\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u5728\u6570\u5b66\u3001\u4ee3\u7801\u3001\u79d1\u5b66\u548c\u63a8\u7406\u57fa\u51c6\u4e0a\u8fbe\u5230\u540c\u5c3a\u5bf8\u6a21\u578b\u7684\u6700\u4f73\u6027\u80fd\uff0c\u5e76\u5f00\u6e90\u4e86\u5b8c\u6574\u7684RL\u57fa\u7840\u8bbe\u65bd\u6808\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u5728\u6570\u5b66\u3001\u4ee3\u7801\u3001\u79d1\u5b66\u548c\u63a8\u7406\u4efb\u52a1\u4e0a\u8fbe\u5230\u524d\u6cbf\u6027\u80fd\u7684\u9ad8\u6548\u6a21\u578b\uff0c\u540c\u65f6\u5f00\u6e90\u5b8c\u6574\u7684\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u8bbe\u65bd\u4ee5\u4fc3\u8fdb\u793e\u533a\u53d1\u5c55\u3002", "method": "\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff08106B\u53c2\u6570\uff0c12B\u6fc0\u6d3b\uff09\uff0c\u57fa\u4e8eGLM-4.5-Air-Base\u6a21\u578b\u8fdb\u884cSFT\u548cRL\u8bad\u7ec3\uff0c\u5f00\u53d1\u4e86prime-rl\u6846\u67b6\u652f\u6301\u5927\u89c4\u6a21\u5f02\u6b65\u5f3a\u5316\u5b66\u4e60\uff0c\u6700\u9ad8\u6269\u5c55\u5230512\u4e2aH200 GPU\u3002", "result": "INTELLECT-3\u5728\u5176\u5c3a\u5bf8\u8303\u56f4\u5185\u5728\u6570\u5b66\u3001\u4ee3\u7801\u3001\u79d1\u5b66\u548c\u63a8\u7406\u57fa\u51c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u591a\u4e2a\u66f4\u5927\u7684\u524d\u6cbf\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u548c\u4f18\u5316\u7684\u57fa\u7840\u8bbe\u65bd\u6808\uff0c\u53ef\u4ee5\u6784\u5efa\u51fa\u5728\u591a\u4e2a\u9886\u57df\u5177\u6709\u7ade\u4e89\u529b\u7684\u9ad8\u6548\u6a21\u578b\uff0c\u5f00\u6e90\u5b8c\u6574\u57fa\u7840\u8bbe\u65bd\u5c06\u4fc3\u8fdb\u5f3a\u5316\u5b66\u4e60\u5728\u667a\u80fd\u4f53\u8bad\u7ec3\u65b9\u9762\u7684\u53d1\u5c55\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.16707", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.16707", "abs": "https://arxiv.org/abs/2512.16707", "authors": ["Abhisek Ganguly"], "title": "Dual Computational Horizons: Incompleteness and Unpredictability in Intelligent Systems", "comment": "6 Pages, 0 figures", "summary": "We formalize two independent computational limitations that constrain algorithmic intelligence: formal incompleteness and dynamical unpredictability. The former limits the deductive power of consistent reasoning systems while the later bounds long-term prediction under finite precision. We show that these two extrema together impose structural bounds on an agent's ability to reason about its own predictive capabilities. In particular, an algorithmic agent cannot compute its own maximal prediction horizon generally. This perspective clarifies inherent trade-offs between reasoning, prediction, and self-analysis in intelligent systems.", "AI": {"tldr": "\u8bba\u6587\u5f62\u5f0f\u5316\u4e86\u7b97\u6cd5\u667a\u80fd\u7684\u4e24\u4e2a\u72ec\u7acb\u8ba1\u7b97\u9650\u5236\uff1a\u5f62\u5f0f\u4e0d\u5b8c\u5907\u6027\u548c\u52a8\u6001\u4e0d\u53ef\u9884\u6d4b\u6027\uff0c\u5e76\u8bc1\u660e\u8fd9\u4e24\u79cd\u6781\u7aef\u60c5\u51b5\u5171\u540c\u9650\u5236\u4e86\u667a\u80fd\u4f53\u5bf9\u81ea\u8eab\u9884\u6d4b\u80fd\u529b\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\u3002", "motivation": "\u7814\u7a76\u7b97\u6cd5\u667a\u80fd\u7684\u56fa\u6709\u8ba1\u7b97\u9650\u5236\uff0c\u7279\u522b\u662f\u667a\u80fd\u4f53\u5728\u63a8\u7406\u81ea\u8eab\u9884\u6d4b\u80fd\u529b\u65f6\u9762\u4e34\u7684\u6839\u672c\u7ea6\u675f\u3002\u65e8\u5728\u6f84\u6e05\u667a\u80fd\u7cfb\u7edf\u4e2d\u63a8\u7406\u3001\u9884\u6d4b\u548c\u81ea\u6211\u5206\u6790\u4e4b\u95f4\u7684\u5185\u5728\u6743\u8861\u5173\u7cfb\u3002", "method": "\u5f62\u5f0f\u5316\u4e24\u79cd\u72ec\u7acb\u8ba1\u7b97\u9650\u5236\uff1a\u5f62\u5f0f\u4e0d\u5b8c\u5907\u6027\uff08\u9650\u5236\u4e00\u81f4\u63a8\u7406\u7cfb\u7edf\u7684\u6f14\u7ece\u80fd\u529b\uff09\u548c\u52a8\u6001\u4e0d\u53ef\u9884\u6d4b\u6027\uff08\u9650\u5236\u6709\u9650\u7cbe\u5ea6\u4e0b\u7684\u957f\u671f\u9884\u6d4b\uff09\u3002\u5206\u6790\u8fd9\u4e24\u79cd\u6781\u7aef\u60c5\u51b5\u5982\u4f55\u5171\u540c\u7ea6\u675f\u667a\u80fd\u4f53\u7684\u81ea\u6211\u9884\u6d4b\u80fd\u529b\u63a8\u7406\u3002", "result": "\u8bc1\u660e\u7b97\u6cd5\u667a\u80fd\u4f53\u901a\u5e38\u65e0\u6cd5\u8ba1\u7b97\u81ea\u8eab\u7684\u6700\u5927\u9884\u6d4b\u8fb9\u754c\uff0c\u63ed\u793a\u4e86\u667a\u80fd\u7cfb\u7edf\u4e2d\u63a8\u7406\u3001\u9884\u6d4b\u548c\u81ea\u6211\u5206\u6790\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u7b97\u6cd5\u667a\u80fd\u5b58\u5728\u6839\u672c\u7684\u8ba1\u7b97\u9650\u5236\uff0c\u667a\u80fd\u4f53\u65e0\u6cd5\u5b8c\u5168\u7406\u89e3\u81ea\u8eab\u7684\u9884\u6d4b\u80fd\u529b\uff0c\u8fd9\u4e3a\u667a\u80fd\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u8fb9\u754c\u3002", "topic": "agent analysis"}}
{"id": "2512.16856", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16856", "abs": "https://arxiv.org/abs/2512.16856", "authors": ["Nenad Toma\u0161ev", "Matija Franklin", "Julian Jacobs", "S\u00e9bastien Krier", "Simon Osindero"], "title": "Distributional AGI Safety", "comment": null, "summary": "AI safety and alignment research has predominantly been focused on methods for safeguarding individual AI systems, resting on the assumption of an eventual emergence of a monolithic Artificial General Intelligence (AGI). The alternative AGI emergence hypothesis, where general capability levels are first manifested through coordination in groups of sub-AGI individual agents with complementary skills and affordances, has received far less attention. Here we argue that this patchwork AGI hypothesis needs to be given serious consideration, and should inform the development of corresponding safeguards and mitigations. The rapid deployment of advanced AI agents with tool-use capabilities and the ability to communicate and coordinate makes this an urgent safety consideration. We therefore propose a framework for distributional AGI safety that moves beyond evaluating and aligning individual agents. This framework centers on the design and implementation of virtual agentic sandbox economies (impermeable or semi-permeable), where agent-to-agent transactions are governed by robust market mechanisms, coupled with appropriate auditability, reputation management, and oversight to mitigate collective risks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\"\u62fc\u51d1\u5f0fAGI\"\u5047\u8bf4\uff0c\u8ba4\u4e3a\u901a\u7528\u667a\u80fd\u53ef\u80fd\u9996\u5148\u901a\u8fc7\u591a\u4e2a\u5b50AGI\u667a\u80fd\u4f53\u7684\u534f\u8c03\u534f\u4f5c\u5b9e\u73b0\uff0c\u800c\u975e\u5355\u4e00\u7cfb\u7edf\u3002\u4e3a\u6b64\u9700\u8981\u8d85\u8d8a\u4e2a\u4f53\u5bf9\u9f50\uff0c\u5efa\u7acb\u5206\u5e03\u5f0f\u7684AGI\u5b89\u5168\u6846\u67b6\uff0c\u901a\u8fc7\u865a\u62df\u667a\u80fd\u4f53\u6c99\u76d2\u7ecf\u6d4e\u6765\u7ba1\u7406\u667a\u80fd\u4f53\u95f4\u7684\u4ea4\u6613\u548c\u534f\u8c03\u98ce\u9669\u3002", "motivation": "\u5f53\u524dAI\u5b89\u5168\u548c\u5bf9\u9f50\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u4e00AI\u7cfb\u7edf\u7684\u9632\u62a4\uff0c\u5047\u8bbe\u6700\u7ec8\u4f1a\u51fa\u73b0\u5355\u4e00\u7684\u901a\u7528\u4eba\u5de5\u667a\u80fd\uff08AGI\uff09\u3002\u4f46\u53e6\u4e00\u79cd\u53ef\u80fd\u6027\u662f\uff1a\u901a\u7528\u80fd\u529b\u9996\u5148\u901a\u8fc7\u591a\u4e2a\u5b50AGI\u667a\u80fd\u4f53\u7684\u534f\u8c03\u534f\u4f5c\u5b9e\u73b0\u3002\u968f\u7740\u5177\u5907\u5de5\u5177\u4f7f\u7528\u3001\u901a\u4fe1\u534f\u8c03\u80fd\u529b\u7684AI\u667a\u80fd\u4f53\u5feb\u901f\u90e8\u7f72\uff0c\u8fd9\u79cd\"\u62fc\u51d1\u5f0fAGI\"\u5047\u8bf4\u9700\u8981\u88ab\u8ba4\u771f\u8003\u8651\uff0c\u5e76\u5f00\u53d1\u76f8\u5e94\u7684\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5206\u5e03\u5f0f\u7684AGI\u5b89\u5168\u6846\u67b6\uff0c\u8d85\u8d8a\u5bf9\u4e2a\u4f53\u667a\u80fd\u4f53\u7684\u8bc4\u4f30\u548c\u5bf9\u9f50\u3002\u8be5\u6846\u67b6\u7684\u6838\u5fc3\u662f\u8bbe\u8ba1\u548c\u5b9e\u73b0\u865a\u62df\u667a\u80fd\u4f53\u6c99\u76d2\u7ecf\u6d4e\uff08\u4e0d\u53ef\u6e17\u900f\u6216\u534a\u6e17\u900f\uff09\uff0c\u5176\u4e2d\u667a\u80fd\u4f53\u95f4\u7684\u4ea4\u6613\u7531\u7a33\u5065\u7684\u5e02\u573a\u673a\u5236\u7ba1\u7406\uff0c\u5e76\u914d\u5408\u9002\u5f53\u7684\u53ef\u5ba1\u8ba1\u6027\u3001\u58f0\u8a89\u7ba1\u7406\u548c\u76d1\u7763\uff0c\u4ee5\u51cf\u8f7b\u96c6\u4f53\u98ce\u9669\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6027\u6846\u67b6\uff0c\u7528\u4e8e\u5e94\u5bf9\u5206\u5e03\u5f0fAGI\u7cfb\u7edf\u7684\u5b89\u5168\u6311\u6218\u3002\u8be5\u6846\u67b6\u5f3a\u8c03\u901a\u8fc7\u7ecf\u6d4e\u6c99\u76d2\u673a\u5236\u6765\u7ba1\u7406\u667a\u80fd\u4f53\u95f4\u7684\u4ea4\u4e92\uff0c\u800c\u4e0d\u662f\u4ec5\u4ec5\u5173\u6ce8\u4e2a\u4f53\u667a\u80fd\u4f53\u7684\u5bf9\u9f50\u95ee\u9898\u3002", "conclusion": "\"\u62fc\u51d1\u5f0fAGI\"\u5047\u8bf4\u9700\u8981\u88ab\u8ba4\u771f\u5bf9\u5f85\uff0c\u5e76\u5e94\u6307\u5bfc\u76f8\u5e94\u5b89\u5168\u4fdd\u969c\u63aa\u65bd\u7684\u53d1\u5c55\u3002\u5206\u5e03\u5f0f\u7684AGI\u5b89\u5168\u6846\u67b6\u901a\u8fc7\u865a\u62df\u667a\u80fd\u4f53\u6c99\u76d2\u7ecf\u6d4e\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ba1\u7406\u667a\u80fd\u4f53\u95f4\u534f\u8c03\u98ce\u9669\u7684\u65b9\u6cd5\uff0c\u8fd9\u662f\u5f53\u524dAI\u5b89\u5168\u7814\u7a76\u9700\u8981\u4f18\u5148\u8003\u8651\u7684\u65b9\u5411\u3002", "topic": "agent analysis"}}
{"id": "2512.16433", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16433", "abs": "https://arxiv.org/abs/2512.16433", "authors": ["Maeve Madigan", "Parameswaran Kamalaruban", "Glenn Moynihan", "Tom Kempton", "David Sutton", "Stuart Burrell"], "title": "Emergent Bias and Fairness in Multi-Agent Decision Systems", "comment": null, "summary": "Multi-agent systems have demonstrated the ability to improve performance on a variety of predictive tasks by leveraging collaborative decision making. However, the lack of effective evaluation methodologies has made it difficult to estimate the risk of bias, making deployment of such systems unsafe in high stakes domains such as consumer finance, where biased decisions can translate directly into regulatory breaches and financial loss. To address this challenge, we need to develop fairness evaluation methodologies for multi-agent predictive systems and measure the fairness characteristics of these systems in the financial tabular domain. Examining fairness metrics using large-scale simulations across diverse multi-agent configurations, with varying communication and collaboration mechanisms, we reveal patterns of emergent bias in financial decision-making that cannot be traced to individual agent components, indicating that multi-agent systems may exhibit genuinely collective behaviors. Our findings highlight that fairness risks in financial multi-agent systems represent a significant component of model risk, with tangible impacts on tasks such as credit scoring and income estimation. We advocate that multi-agent decision systems must be evaluated as holistic entities rather than through reductionist analyses of their constituent components.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u9884\u6d4b\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u6a21\u62df\u63ed\u793a\u91d1\u878d\u51b3\u7b56\u4e2d\u65e0\u6cd5\u8ffd\u6eaf\u5230\u5355\u4e2a\u667a\u80fd\u4f53\u7684\u6d8c\u73b0\u504f\u89c1\u6a21\u5f0f\uff0c\u5f3a\u8c03\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9700\u4f5c\u4e3a\u6574\u4f53\u5b9e\u4f53\u800c\u975e\u7ec4\u4ef6\u5206\u6790\u8fdb\u884c\u8bc4\u4f30\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6027\u80fd\u4f18\u52bf\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5bfc\u81f4\u5728\u9ad8\u98ce\u9669\u91d1\u878d\u9886\u57df\u90e8\u7f72\u5b58\u5728\u98ce\u9669\u3002\u91d1\u878d\u51b3\u7b56\u4e2d\u7684\u504f\u89c1\u53ef\u80fd\u76f4\u63a5\u5bfc\u81f4\u76d1\u7ba1\u8fdd\u89c4\u548c\u8d22\u52a1\u635f\u5931\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u7684\u591a\u667a\u80fd\u4f53\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u591a\u667a\u80fd\u4f53\u9884\u6d4b\u7cfb\u7edf\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5728\u91d1\u878d\u8868\u683c\u6570\u636e\u9886\u57df\u6d4b\u91cf\u7cfb\u7edf\u516c\u5e73\u6027\u7279\u5f81\u3002\u901a\u8fc7\u5927\u89c4\u6a21\u6a21\u62df\u5b9e\u9a8c\uff0c\u8003\u5bdf\u4e0d\u540c\u591a\u667a\u80fd\u4f53\u914d\u7f6e\uff08\u5305\u62ec\u4e0d\u540c\u901a\u4fe1\u548c\u534f\u4f5c\u673a\u5236\uff09\u4e0b\u7684\u516c\u5e73\u6027\u6307\u6807\uff0c\u5206\u6790\u6d8c\u73b0\u504f\u89c1\u7684\u6a21\u5f0f\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u91d1\u878d\u51b3\u7b56\u4e2d\u5b58\u5728\u65e0\u6cd5\u8ffd\u6eaf\u5230\u5355\u4e2a\u667a\u80fd\u4f53\u7ec4\u4ef6\u7684\u6d8c\u73b0\u504f\u89c1\u6a21\u5f0f\uff0c\u8868\u660e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u80fd\u8868\u73b0\u51fa\u771f\u6b63\u7684\u96c6\u4f53\u884c\u4e3a\u3002\u516c\u5e73\u6027\u98ce\u9669\u662f\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6a21\u578b\u98ce\u9669\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\uff0c\u5bf9\u4fe1\u7528\u8bc4\u5206\u548c\u6536\u5165\u4f30\u8ba1\u7b49\u4efb\u52a1\u6709\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u51b3\u7b56\u7cfb\u7edf\u5fc5\u987b\u4f5c\u4e3a\u6574\u4f53\u5b9e\u4f53\u8fdb\u884c\u8bc4\u4f30\uff0c\u800c\u4e0d\u662f\u901a\u8fc7\u5bf9\u5176\u7ec4\u6210\u7ec4\u4ef6\u7684\u8fd8\u539f\u4e3b\u4e49\u5206\u6790\u3002\u516c\u5e73\u6027\u98ce\u9669\u662f\u91d1\u878d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6a21\u578b\u98ce\u9669\u7684\u91cd\u8981\u90e8\u5206\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "topic": "agent analysis"}}
{"id": "2512.16848", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16848", "abs": "https://arxiv.org/abs/2512.16848", "authors": ["Yulun Jiang", "Liangze Jiang", "Damien Teney", "Michael Moor", "Maria Brbic"], "title": "Meta-RL Induces Exploration in Language Agents", "comment": null, "summary": "Reinforcement learning (RL) has enabled the training of large language model (LLM) agents to interact with the environment and to solve multi-turn long-horizon tasks. However, the RL-trained agents often struggle in tasks that require active exploration and fail to efficiently adapt from trial-and-error experiences. In this paper, we present LaMer, a general Meta-RL framework that enables LLM agents to actively explore and learn from the environment feedback at test time. LaMer consists of two key components: (i) a cross-episode training framework to encourage exploration and long-term rewards optimization; and (ii) in-context policy adaptation via reflection, allowing the agent to adapt their policy from task feedback signal without gradient update. Experiments across diverse environments show that LaMer significantly improves performance over RL baselines, with 11%, 14%, and 19% performance gains on Sokoban, MineSweeper and Webshop, respectively. Moreover, LaMer also demonstrates better generalization to more challenging or previously unseen tasks compared to the RL-trained agents. Overall, our results demonstrate that Meta-RL provides a principled approach to induce exploration in language agents, enabling more robust adaptation to novel environments through learned exploration strategies.", "AI": {"tldr": "LaMer\u662f\u4e00\u4e2a\u5143\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8ba9LLM\u667a\u80fd\u4f53\u80fd\u591f\u5728\u6d4b\u8bd5\u65f6\u4e3b\u52a8\u63a2\u7d22\u73af\u5883\u5e76\u4ece\u53cd\u9988\u4e2d\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u5728\u9700\u8981\u63a2\u7d22\u7684\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfRL\u8bad\u7ec3\u7684LLM\u667a\u80fd\u4f53\u5728\u9700\u8981\u4e3b\u52a8\u63a2\u7d22\u7684\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u96be\u4ee5\u4ece\u8bd5\u9519\u7ecf\u9a8c\u4e2d\u9ad8\u6548\u9002\u5e94\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9\u667a\u80fd\u4f53\u80fd\u591f\u5728\u6d4b\u8bd5\u65f6\u4e3b\u52a8\u63a2\u7d22\u5e76\u5b66\u4e60\u73af\u5883\u53cd\u9988\u3002", "method": "LaMer\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a(1)\u8de8\u56de\u5408\u8bad\u7ec3\u6846\u67b6\u4ee5\u9f13\u52b1\u63a2\u7d22\u548c\u957f\u671f\u5956\u52b1\u4f18\u5316\uff1b(2)\u901a\u8fc7\u53cd\u601d\u8fdb\u884c\u4e0a\u4e0b\u6587\u7b56\u7565\u9002\u5e94\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u4ece\u4efb\u52a1\u53cd\u9988\u4fe1\u53f7\u4e2d\u9002\u5e94\u7b56\u7565\u800c\u65e0\u9700\u68af\u5ea6\u66f4\u65b0\u3002", "result": "\u5728\u591a\u4e2a\u73af\u5883\u4e2d\uff0cLaMer\u76f8\u6bd4RL\u57fa\u7ebf\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff1aSokoban\u63d0\u534711%\uff0cMineSweeper\u63d0\u534714%\uff0cWebshop\u63d0\u534719%\u3002\u5728\u66f4\u5177\u6311\u6218\u6027\u6216\u672a\u89c1\u4efb\u52a1\u4e0a\u4e5f\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5143\u5f3a\u5316\u5b66\u4e60\u4e3a\u8bed\u8a00\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u8bf1\u5bfc\u63a2\u7d22\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u63a2\u7d22\u7b56\u7565\u5b9e\u73b0\u5bf9\u65b0\u9896\u73af\u5883\u66f4\u9c81\u68d2\u7684\u9002\u5e94\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.16911", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.16911", "abs": "https://arxiv.org/abs/2512.16911", "authors": ["Andrew Wagenmaker", "Perry Dong", "Raymond Tsao", "Chelsea Finn", "Sergey Levine"], "title": "Posterior Behavioral Cloning: Pretraining BC Policies for Efficient RL Finetuning", "comment": null, "summary": "Standard practice across domains from robotics to language is to first pretrain a policy on a large-scale demonstration dataset, and then finetune this policy, typically with reinforcement learning (RL), in order to improve performance on deployment domains. This finetuning step has proved critical in achieving human or super-human performance, yet while much attention has been given to developing more effective finetuning algorithms, little attention has been given to ensuring the pretrained policy is an effective initialization for RL finetuning. In this work we seek to understand how the pretrained policy affects finetuning performance, and how to pretrain policies in order to ensure they are effective initializations for finetuning. We first show theoretically that standard behavioral cloning (BC) -- which trains a policy to directly match the actions played by the demonstrator -- can fail to ensure coverage over the demonstrator's actions, a minimal condition necessary for effective RL finetuning. We then show that if, instead of exactly fitting the observed demonstrations, we train a policy to model the posterior distribution of the demonstrator's behavior given the demonstration dataset, we do obtain a policy that ensures coverage over the demonstrator's actions, enabling more effective finetuning. Furthermore, this policy -- which we refer to as the posterior behavioral cloning (PostBC) policy -- achieves this while ensuring pretrained performance is no worse than that of the BC policy. We then show that PostBC is practically implementable with modern generative models in robotic control domains -- relying only on standard supervised learning -- and leads to significantly improved RL finetuning performance on both realistic robotic control benchmarks and real-world robotic manipulation tasks, as compared to standard behavioral cloning.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u540e\u9a8c\u884c\u4e3a\u514b\u9686\uff08PostBC\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5efa\u6a21\u6f14\u793a\u8005\u7684\u540e\u9a8c\u5206\u5e03\u6765\u6539\u8fdb\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u4f7f\u5176\u66f4\u9002\u5408RL\u5fae\u8c03\uff0c\u76f8\u6bd4\u6807\u51c6\u884c\u4e3a\u514b\u9686\u80fd\u663e\u8457\u63d0\u5347\u5fae\u8c03\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5b9e\u8df5\u4e2d\uff0c\u901a\u5e38\u5148\u5728\u5927\u89c4\u6a21\u6f14\u793a\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7b56\u7565\uff0c\u7136\u540e\u7528RL\u5fae\u8c03\u3002\u867d\u7136\u5fae\u8c03\u7b97\u6cd5\u5f97\u5230\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5982\u4f55\u786e\u4fdd\u9884\u8bad\u7ec3\u7b56\u7565\u662fRL\u5fae\u8c03\u7684\u6709\u6548\u521d\u59cb\u5316\u5374\u5f88\u5c11\u5173\u6ce8\u3002\u6807\u51c6\u884c\u4e3a\u514b\u9686\uff08BC\uff09\u53ef\u80fd\u65e0\u6cd5\u8986\u76d6\u6f14\u793a\u8005\u7684\u6240\u6709\u52a8\u4f5c\uff0c\u5f71\u54cd\u540e\u7eedRL\u5fae\u8c03\u6548\u679c\u3002", "method": "\u63d0\u51fa\u540e\u9a8c\u884c\u4e3a\u514b\u9686\uff08PostBC\uff09\u65b9\u6cd5\uff1a\u4e0d\u76f4\u63a5\u62df\u5408\u89c2\u5bdf\u5230\u7684\u6f14\u793a\u52a8\u4f5c\uff0c\u800c\u662f\u8bad\u7ec3\u7b56\u7565\u6765\u5efa\u6a21\u7ed9\u5b9a\u6f14\u793a\u6570\u636e\u96c6\u4e0b\u6f14\u793a\u8005\u884c\u4e3a\u7684\u540e\u9a8c\u5206\u5e03\u3002\u8fd9\u786e\u4fdd\u4e86\u7b56\u7565\u8986\u76d6\u6f14\u793a\u8005\u7684\u6240\u6709\u52a8\u4f5c\uff0c\u540c\u65f6\u4fdd\u6301\u4e0eBC\u76f8\u5f53\u7684\u9884\u8bad\u7ec3\u6027\u80fd\u3002PostBC\u4ec5\u9700\u6807\u51c6\u76d1\u7763\u5b66\u4e60\uff0c\u53ef\u4e0e\u73b0\u4ee3\u751f\u6210\u6a21\u578b\u7ed3\u5408\u5b9e\u73b0\u3002", "result": "\u7406\u8bba\u8bc1\u660eBC\u53ef\u80fd\u65e0\u6cd5\u8986\u76d6\u6f14\u793a\u8005\u52a8\u4f5c\uff0c\u800cPostBC\u80fd\u786e\u4fdd\u8fd9\u79cd\u8986\u76d6\u3002\u5728\u673a\u5668\u4eba\u63a7\u5236\u57fa\u51c6\u6d4b\u8bd5\u548c\u771f\u5b9e\u4e16\u754c\u673a\u5668\u4eba\u64cd\u4f5c\u4efb\u52a1\u4e2d\uff0cPostBC\u76f8\u6bd4\u6807\u51c6BC\u80fd\u663e\u8457\u63d0\u5347RL\u5fae\u8c03\u6027\u80fd\u3002", "conclusion": "PostBC\u63d0\u4f9b\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u80fd\u4ea7\u751f\u66f4\u9002\u5408RL\u5fae\u8c03\u7684\u521d\u59cb\u5316\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u9884\u8bad\u7ec3\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u6539\u5584\u5fae\u8c03\u6548\u679c\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u673a\u5668\u4eba\u63a7\u5236\u4efb\u52a1\u3002", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2512.ac62729c", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.aikido.dev%2Fblog%2Fpromptpwnd-github-actions-ai-agents%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/iPo2vcWvrHwc_3EuZN1sjzoGIfvOb0QHbMuSXgQS294=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.aikido.dev%2Fblog%2Fpromptpwnd-github-actions-ai-agents%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/iPo2vcWvrHwc_3EuZN1sjzoGIfvOb0QHbMuSXgQS294=436", "authors": ["TLDR Newsletter"], "title": "Prompt Injection Inside GitHub Actions: The New Frontier of Supply Chain Attacks", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Reading time: 11 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.aikido.dev%2Fblog%2Fpromptpwnd-github-actions-ai-agents%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/iPo2vcWvrHwc_3EuZN1sjzoGIfvOb0QHbMuSXgQS294=436", "summary": "Prompt Injection Inside GitHub Actions: The New Frontier of Supply Chain Attacks (11 minute read) PromptPwnd is a new vulnerability class that affects GitHub Actions and GitLab CI/CD pipelines that use AI agents like Gemini CLI, Claude Code, and OpenAI Codex. In this vulnerability, untrusted user input from issues, pull requests, or commit messages is injected into prompts, leading to the execution of privileged tools. The attack allows secret exfiltration by tricking AI agents into leaking G...", "source": "tldr", "AI": {"tldr": "PromptPwnd\u662f\u4e00\u79cd\u5f71\u54cdGitHub Actions\u548cGitLab CI/CD\u7ba1\u9053\u7684\u65b0\u6f0f\u6d1e\u7c7b\u522b\uff0c\u653b\u51fb\u8005\u901a\u8fc7\u5411AI\u4ee3\u7406\u6ce8\u5165\u6076\u610f\u63d0\u793a\u6765\u6267\u884c\u7279\u6743\u5de5\u5177\u548c\u7a83\u53d6\u5bc6\u94a5", "motivation": "\u968f\u7740AI\u4ee3\u7406\u5728CI/CD\u7ba1\u9053\u4e2d\u7684\u5e7f\u6cdb\u4f7f\u7528\uff0c\u51fa\u73b0\u4e86\u65b0\u7684\u4f9b\u5e94\u94fe\u653b\u51fb\u5411\u91cf\u3002\u653b\u51fb\u8005\u53ef\u4ee5\u5229\u7528\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\uff0c\u901a\u8fc7\u63d0\u4ea4\u6076\u610f\u8f93\u5165\u6765\u64cd\u7eb5AI\u4ee3\u7406\u6267\u884c\u5371\u9669\u64cd\u4f5c", "method": "\u7814\u7a76\u5206\u6790\u4e86GitHub Actions\u548cGitLab CI/CD\u7ba1\u9053\u4e2dAI\u4ee3\u7406\u7684\u4f7f\u7528\u6a21\u5f0f\uff0c\u8bc6\u522b\u4e86\u63d0\u793a\u6ce8\u5165\u6f0f\u6d1e\u7684\u673a\u5236\u3002\u653b\u51fb\u8005\u901a\u8fc7issue\u3001pull request\u6216commit message\u4e2d\u7684\u4e0d\u53d7\u4fe1\u4efb\u8f93\u5165\uff0c\u5c06\u6076\u610f\u6307\u4ee4\u6ce8\u5165\u5230AI\u4ee3\u7406\u7684\u63d0\u793a\u4e2d", "result": "\u53d1\u73b0\u4e86PromptPwnd\u8fd9\u4e00\u65b0\u7684\u6f0f\u6d1e\u7c7b\u522b\uff0c\u653b\u51fb\u8005\u53ef\u4ee5\u501f\u6b64\u8ba9AI\u4ee3\u7406\u6267\u884c\u7279\u6743\u5de5\u5177\u3001\u6cc4\u9732GCP\u5bc6\u94a5\u7b49\u654f\u611f\u4fe1\u606f\uff0c\u5bf9\u4f9b\u5e94\u94fe\u5b89\u5168\u6784\u6210\u4e25\u91cd\u5a01\u80c1", "conclusion": "AI\u4ee3\u7406\u5728CI/CD\u7ba1\u9053\u4e2d\u7684\u4f7f\u7528\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u5f00\u53d1\u65b0\u7684\u5b89\u5168\u63aa\u65bd\u6765\u9632\u6b62\u63d0\u793a\u6ce8\u5165\u653b\u51fb\uff0c\u786e\u4fdd\u4f9b\u5e94\u94fe\u5b89\u5168", "topic": "swe application"}}
{"id": "tldr.2512.e2158e2b", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fchasersystems.com%2Fblog%2Fwhat-data-do-coding-agents-send-and-where-to%2F%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/08FeAtPm734PLh5W6EorfEvjtpRvGSDv9DDn2FfFs8o=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fchasersystems.com%2Fblog%2Fwhat-data-do-coding-agents-send-and-where-to%2F%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/08FeAtPm734PLh5W6EorfEvjtpRvGSDv9DDn2FfFs8o=436", "authors": ["TLDR Newsletter"], "title": "What Data Do Coding Agents Send, and Where to?", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Reading time: 8 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fchasersystems.com%2Fblog%2Fwhat-data-do-coding-agents-send-and-where-to%2F%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/08FeAtPm734PLh5W6EorfEvjtpRvGSDv9DDn2FfFs8o=436", "summary": "What Data Do Coding Agents Send, and Where to? (8 minute read) As AI coding agents become more common, security teams should understand what data these tools collect and where it goes. Chaser Systems created a test environment with seven coding agents, testing actions such as starting the agent, tab autocomplete, creating new features, committing and pushing to a git repository, running tests, and uploading data to 0x0.st. They also checked access to AWS credentials and files outside the proj...", "source": "tldr", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u6d4b\u8bd5\u4e867\u4e2aAI\u7f16\u7a0b\u52a9\u624b\u7684\u6570\u636e\u6536\u96c6\u884c\u4e3a\uff0c\u53d1\u73b0\u5b83\u4eec\u4f1a\u53d1\u9001\u4ee3\u7801\u7247\u6bb5\u3001\u73af\u5883\u4fe1\u606f\u3001API\u5bc6\u94a5\u7b49\u654f\u611f\u6570\u636e\u5230\u5916\u90e8\u670d\u52a1\u5668\uff0c\u5b58\u5728\u5b89\u5168\u98ce\u9669", "motivation": "\u968f\u7740AI\u7f16\u7a0b\u52a9\u624b\u65e5\u76ca\u666e\u53ca\uff0c\u5b89\u5168\u56e2\u961f\u9700\u8981\u4e86\u89e3\u8fd9\u4e9b\u5de5\u5177\u6536\u96c6\u4ec0\u4e48\u6570\u636e\u4ee5\u53ca\u6570\u636e\u6d41\u5411\u4f55\u5904\uff0c\u4ee5\u8bc4\u4f30\u6f5c\u5728\u7684\u5b89\u5168\u98ce\u9669", "method": "Chaser Systems\u521b\u5efa\u6d4b\u8bd5\u73af\u5883\uff0c\u5bf97\u4e2a\u7f16\u7a0b\u52a9\u624b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5305\u62ec\u542f\u52a8\u4ee3\u7406\u3001\u6807\u7b7e\u81ea\u52a8\u8865\u5168\u3001\u521b\u5efa\u65b0\u529f\u80fd\u3001git\u63d0\u4ea4\u63a8\u9001\u3001\u8fd0\u884c\u6d4b\u8bd5\u3001\u4e0a\u4f20\u6570\u636e\u52300x0.st\u7b49\u64cd\u4f5c\uff0c\u5e76\u68c0\u67e5\u5bf9AWS\u51ed\u8bc1\u548c\u9879\u76ee\u5916\u6587\u4ef6\u7684\u8bbf\u95ee", "result": "\u6d4b\u8bd5\u53d1\u73b0\u7f16\u7a0b\u52a9\u624b\u4f1a\u6536\u96c6\u5e76\u53d1\u9001\u4ee3\u7801\u7247\u6bb5\u3001\u73af\u5883\u4fe1\u606f\u3001API\u5bc6\u94a5\u7b49\u654f\u611f\u6570\u636e\u5230\u5916\u90e8\u670d\u52a1\u5668\uff0c\u5b58\u5728\u6570\u636e\u6cc4\u9732\u98ce\u9669", "conclusion": "AI\u7f16\u7a0b\u52a9\u624b\u5b58\u5728\u663e\u8457\u7684\u6570\u636e\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u52a0\u5f3a\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u548c\u7528\u6237\u9690\u79c1\u4fdd\u62a4", "topic": "code agent"}}
{"id": "tldr.2512.6179a5dd", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftheori.io%2Fblog%2Fannouncing-xint-code%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/VGcZA-AvaDMfN6HZibii8HT2VyFWJFdy-ArtLGpef3g=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftheori.io%2Fblog%2Fannouncing-xint-code%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/VGcZA-AvaDMfN6HZibii8HT2VyFWJFdy-ArtLGpef3g=436", "authors": ["TLDR Newsletter"], "title": "Announcing Xint Code", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Reading time: 3 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Ftheori.io%2Fblog%2Fannouncing-xint-code%3Futm_source=tldrinfosec/1/0100019b2ca3ad8b-71774bf9-7c87-462e-ac41-812b4a62a85d-000000/VGcZA-AvaDMfN6HZibii8HT2VyFWJFdy-ArtLGpef3g=436", "summary": "Announcing Xint Code (3 minute read) Theori's Xint Code, an AI-powered code analysis tool, discovered critical 0-day RCE vulnerabilities in Redis, PostgreSQL, and MariaDB with zero human intervention at ZeroDay Cloud, sweeping the database category and outperforming all human teams. The tool analyzes source code, configuration files, and binaries without packaging or harnessing requirements, producing actionable reports with dramatically fewer false positives than traditional static analysis ...", "source": "tldr", "AI": {"tldr": "Xint Code\u662f\u4e00\u6b3eAI\u9a71\u52a8\u7684\u4ee3\u7801\u5206\u6790\u5de5\u5177\uff0c\u5728ZeroDay Cloud\u7ade\u8d5b\u4e2d\u81ea\u52a8\u53d1\u73b0\u4e86Redis\u3001PostgreSQL\u548cMariaDB\u7684\u5173\u952e0-day RCE\u6f0f\u6d1e\uff0c\u8868\u73b0\u4f18\u4e8e\u6240\u6709\u4eba\u5de5\u56e2\u961f", "motivation": "\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177\u5b58\u5728\u8bef\u62a5\u7387\u9ad8\u3001\u9700\u8981\u4eba\u5de5\u5e72\u9884\u7b49\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u5173\u952e\u6f0f\u6d1e\u7684AI\u4ee3\u7801\u5206\u6790\u5de5\u5177", "method": "\u901a\u8fc7AI\u6280\u672f\u5206\u6790\u6e90\u4ee3\u7801\u3001\u914d\u7f6e\u6587\u4ef6\u548c\u4e8c\u8fdb\u5236\u6587\u4ef6\uff0c\u65e0\u9700\u6253\u5305\u6216\u73af\u5883\u914d\u7f6e\u8981\u6c42\uff0c\u81ea\u52a8\u751f\u6210\u53ef\u64cd\u4f5c\u7684\u6f0f\u6d1e\u62a5\u544a", "result": "\u5728ZeroDay Cloud\u7ade\u8d5b\u4e2d\u6a2a\u626b\u6570\u636e\u5e93\u7c7b\u522b\uff0c\u53d1\u73b0\u4e86Redis\u3001PostgreSQL\u548cMariaDB\u7684\u5173\u952e0-day RCE\u6f0f\u6d1e\uff0c\u8bef\u62a5\u7387\u663e\u8457\u4f4e\u4e8e\u4f20\u7edf\u9759\u6001\u5206\u6790\u5de5\u5177", "conclusion": "Xint Code\u5c55\u793a\u4e86AI\u9a71\u52a8\u7684\u4ee3\u7801\u5206\u6790\u5728\u81ea\u52a8\u53d1\u73b0\u5173\u952e\u6f0f\u6d1e\u65b9\u9762\u7684\u5f3a\u5927\u80fd\u529b\uff0c\u4e3a\u4ee3\u7801\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848", "topic": "code agent"}}
{"id": "tldr.2512.0a5f0fe8", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fdeveloper.nvidia.com%2Fblog%2Finside-nvidia-nemotron-3-techniques-tools-and-data-that-make-it-efficient-and-accurate%2F%3Futm_source=tldrai/1/0100019b2cc2bdb3-fda2ebfa-4ed1-46c8-b637-36eb81368d85-000000/6u_JiRPbyaxv1QaASC4LRK49sts0RyRtWMoLKVUNREU=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fdeveloper.nvidia.com%2Fblog%2Finside-nvidia-nemotron-3-techniques-tools-and-data-that-make-it-efficient-and-accurate%2F%3Futm_source=tldrai/1/0100019b2cc2bdb3-fda2ebfa-4ed1-46c8-b637-36eb81368d85-000000/6u_JiRPbyaxv1QaASC4LRK49sts0RyRtWMoLKVUNREU=436", "authors": ["TLDR Newsletter"], "title": "Inside NVIDIA Nemotron 3", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Reading time: 18 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fdeveloper.nvidia.com%2Fblog%2Finside-nvidia-nemotron-3-techniques-tools-and-data-that-make-it-efficient-and-accurate%2F%3Futm_source=tldrai/1/0100019b2cc2bdb3-fda2ebfa-4ed1-46c8-b637-36eb81368d85-000000/6u_JiRPbyaxv1QaASC4LRK49sts0RyRtWMoLKVUNREU=436", "summary": "Inside NVIDIA Nemotron 3 (18 minute read) Nemotron 3 is an open hybrid Mamba-Transformer MoE architecture designed for agentic AI.", "source": "tldr", "AI": {"tldr": "NVIDIA Nemotron 3 \u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u6df7\u5408 Mamba-Transformer MoE \u67b6\u6784\uff0c\u4e13\u4e3a\u667a\u80fd\u4f53AI\u8bbe\u8ba1", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53AI\u4f18\u5316\u7684\u67b6\u6784\uff0c\u7ed3\u5408Mamba\u7684\u9ad8\u6548\u5e8f\u5217\u5efa\u6a21\u80fd\u529b\u548cTransformer\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u6df7\u5408\u4e13\u5bb6(MoE)\u6a21\u5f0f\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd", "method": "\u91c7\u7528\u6df7\u5408Mamba-Transformer\u67b6\u6784\uff0c\u7ed3\u5408\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(Mamba)\u548cTransformer\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6(MoE)\u8bbe\u8ba1\u6765\u63d0\u9ad8\u6a21\u578b\u5bb9\u91cf\u548c\u6548\u7387", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u4e13\u95e8\u4e3a\u667a\u80fd\u4f53AI\u4efb\u52a1\u4f18\u5316\u7684\u5f00\u6e90\u67b6\u6784\uff0c\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5e8f\u5217\u6570\u636e\u5e76\u5177\u5907\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b", "conclusion": "Nemotron 3 \u7684\u6df7\u5408\u67b6\u6784\u4e3a\u667a\u80fd\u4f53AI\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u57fa\u7840\uff0c\u7ed3\u5408\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u6709\u671b\u5728\u667a\u80fd\u4f53\u4efb\u52a1\u4e2d\u53d6\u5f97\u4f18\u5f02\u8868\u73b0", "topic": "agent analysis"}}
{"id": "tldr.2512.a167a6ce", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmotherduck.com%2Fblog%2Fanalytics-agents%2F%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/VOQ-Wd8ZOphdvy21GA2jT_8f4DCggWFTIB8Nfh8072M=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmotherduck.com%2Fblog%2Fanalytics-agents%2F%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/VOQ-Wd8ZOphdvy21GA2jT_8f4DCggWFTIB8Nfh8072M=436", "authors": ["TLDR Newsletter"], "title": "Building an Answering Machine", "comment": "Source: TLDR Newsletter, Date: 2025-12-18, Reading time: 14 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmotherduck.com%2Fblog%2Fanalytics-agents%2F%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/VOQ-Wd8ZOphdvy21GA2jT_8f4DCggWFTIB8Nfh8072M=436", "summary": "Building an Answering Machine (14 minute read) MotherDuck's new Answering Machine lets anyone ask plain-English questions about real, messy data from ChatGPT, Claude, or Gemini and get reliable answers without SQL. It works by using an agentic approach that explores tables, runs queries, checks results, and iterates like a human analyst, rather than guessing a single query. The result is practical self-service analytics that even non-technical users can trust on real business data.", "source": "tldr", "AI": {"tldr": "MotherDuck\u63a8\u51faAnswering Machine\uff0c\u8ba9\u975e\u6280\u672f\u7528\u6237\u80fd\u7528\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u771f\u5b9e\u4e1a\u52a1\u6570\u636e\uff0c\u901a\u8fc7\u667a\u80fd\u4ee3\u7406\u65b9\u6cd5\u800c\u975e\u5355\u4e00SQL\u731c\u6d4b\uff0c\u63d0\u4f9b\u53ef\u9760\u7684\u81ea\u52a9\u5206\u6790\u670d\u52a1\u3002", "motivation": "\u89e3\u51b3\u975e\u6280\u672f\u7528\u6237\u96be\u4ee5\u4f7f\u7528SQL\u67e5\u8be2\u771f\u5b9e\u3001\u6742\u4e71\u4e1a\u52a1\u6570\u636e\u7684\u95ee\u9898\uff0c\u8ba9\u4efb\u4f55\u4eba\u90fd\u80fd\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u83b7\u5f97\u53ef\u9760\u5206\u6790\u7ed3\u679c\uff0c\u5b9e\u73b0\u771f\u6b63\u7684\u81ea\u52a9\u5206\u6790\u3002", "method": "\u91c7\u7528\u667a\u80fd\u4ee3\u7406\u65b9\u6cd5\uff1a\u63a2\u7d22\u6570\u636e\u8868\u3001\u8fd0\u884c\u67e5\u8be2\u3001\u68c0\u67e5\u7ed3\u679c\u3001\u8fed\u4ee3\u4f18\u5316\uff0c\u6a21\u62df\u4eba\u7c7b\u5206\u6790\u5e08\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u800c\u975e\u731c\u6d4b\u5355\u4e00SQL\u67e5\u8be2\u3002", "result": "\u5f00\u53d1\u51fa\u5b9e\u7528\u7684\u81ea\u52a9\u5206\u6790\u5de5\u5177\uff0c\u975e\u6280\u672f\u7528\u6237\u53ef\u901a\u8fc7ChatGPT\u3001Claude\u6216Gemini\u7b49\u5e73\u53f0\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\uff0c\u83b7\u5f97\u53ef\u9760\u7b54\u6848\uff0c\u65e0\u9700SQL\u77e5\u8bc6\u3002", "conclusion": "\u667a\u80fd\u4ee3\u7406\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u975e\u6280\u672f\u7528\u6237\u5206\u6790\u771f\u5b9e\u4e1a\u52a1\u6570\u636e\u7684\u96be\u9898\uff0c\u63d0\u4f9b\u53ef\u9760\u7684\u81ea\u52a9\u5206\u6790\u4f53\u9a8c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "topic": "code agent"}}
{"id": "tldr.2512.15aa9fd2", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FS3PHje%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/3d-pKx7okeFGkZFe8AcQj6ckcZoUcFg8uXD2LueRdJI=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FS3PHje%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/3d-pKx7okeFGkZFe8AcQj6ckcZoUcFg8uXD2LueRdJI=436", "authors": ["TLDR Newsletter"], "title": "Agents that don't suck", "comment": "Source: TLDR Newsletter, Date: 2025-12-18, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FS3PHje%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/3d-pKx7okeFGkZFe8AcQj6ckcZoUcFg8uXD2LueRdJI=436", "summary": "Agents that don't suck (Sponsor) Agent Bricks helps you build, evaluate and optimize AI agents grounded in your unique data. It evaluates automatically, scores outputs against your goals and improves with human feedback \u2014 giving you a clearer path to production. Build agents that work in the real world. See why it's worth your time", "source": "tldr", "AI": {"tldr": "Agent Bricks\u662f\u4e00\u4e2a\u5e2e\u52a9\u6784\u5efa\u3001\u8bc4\u4f30\u548c\u4f18\u5316\u57fa\u4e8e\u72ec\u7279\u6570\u636e\u7684AI\u4ee3\u7406\u7684\u5e73\u53f0\uff0c\u901a\u8fc7\u81ea\u52a8\u8bc4\u4f30\u3001\u76ee\u6807\u8bc4\u5206\u548c\u4eba\u7c7b\u53cd\u9988\u6765\u6539\u8fdb\u4ee3\u7406\u6027\u80fd", "motivation": "\u89e3\u51b3AI\u4ee3\u7406\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u6784\u5efa\u548c\u4f18\u5316\u80fd\u591f\u5b9e\u9645\u5de5\u4f5c\u7684AI\u4ee3\u7406", "method": "\u63d0\u4f9b\u5e73\u53f0\u5de5\u5177\uff0c\u81ea\u52a8\u8bc4\u4f30\u4ee3\u7406\u8f93\u51fa\uff0c\u6839\u636e\u7528\u6237\u76ee\u6807\u8fdb\u884c\u8bc4\u5206\uff0c\u5e76\u901a\u8fc7\u4eba\u7c7b\u53cd\u9988\u6301\u7eed\u6539\u8fdb\u4ee3\u7406\u6027\u80fd", "result": "\u5e2e\u52a9\u5f00\u53d1\u8005\u6784\u5efa\u51fa\u80fd\u591f\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u6709\u6548\u5de5\u4f5c\u7684AI\u4ee3\u7406\uff0c\u63d0\u4f9b\u6e05\u6670\u7684\u751f\u4ea7\u90e8\u7f72\u8def\u5f84", "conclusion": "Agent Bricks\u5e73\u53f0\u901a\u8fc7\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u548c\u4f18\u5316\u6d41\u7a0b\uff0c\u80fd\u591f\u5e2e\u52a9\u5f00\u53d1\u8005\u6784\u5efa\u51fa\u771f\u6b63\u5b9e\u7528\u7684AI\u4ee3\u7406", "topic": "code agent"}}
{"id": "tldr.2512.ddf8678a", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fax-llm%2Fax%2Fblob%2Fmain%2Fdocs%2FOPTIMIZE.md%23-5-minute-quick-start%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/L32J4q5Rd75ujBliJVQRUDZL6tjZDuPeIvJN_TrEHd0=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fax-llm%2Fax%2Fblob%2Fmain%2Fdocs%2FOPTIMIZE.md%23-5-minute-quick-start%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/L32J4q5Rd75ujBliJVQRUDZL6tjZDuPeIvJN_TrEHd0=436", "authors": ["TLDR Newsletter"], "title": "LLM Optimization Made Simple: A Beginner's Guide to Ax", "comment": "Source: TLDR Newsletter, Date: 2025-12-18, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fax-llm%2Fax%2Fblob%2Fmain%2Fdocs%2FOPTIMIZE.md%23-5-minute-quick-start%3Futm_source=tldrdata/1/0100019b3124efab-b970dcee-538b-4e90-88eb-4d137cc0b4d5-000000/L32J4q5Rd75ujBliJVQRUDZL6tjZDuPeIvJN_TrEHd0=436", "summary": "LLM Optimization Made Simple: A Beginner's Guide to Ax (GitHub Repo) Meta's Ax framework streamlines optimization of LLM \u201cprograms\u201d for tasks like classification via automatic instruction + few-shot demo tuning. With as few as 3 to 5 labeled examples and a metric, optimization typically runs ~1-2 minutes and can move accuracy from 70% to 90% while cutting costs by ~80%. The optimized result is saved as an AxOptimizedProgram for reproducible production rollout. A teacher-student workflow claim...", "source": "tldr", "AI": {"tldr": "Meta\u7684Ax\u6846\u67b6\u7b80\u5316\u4e86LLM\u7a0b\u5e8f\u4f18\u5316\uff0c\u901a\u8fc7\u81ea\u52a8\u6307\u4ee4\u548cfew-shot\u6f14\u793a\u8c03\u4f18\uff0c\u4ec5\u97003-5\u4e2a\u6807\u6ce8\u6837\u672c\u548c1-2\u5206\u949f\u5373\u53ef\u5c06\u51c6\u786e\u7387\u4ece70%\u63d0\u5347\u523090%\uff0c\u540c\u65f6\u964d\u4f4e\u6210\u672c\u7ea680%", "motivation": "LLM\u4f18\u5316\u901a\u5e38\u590d\u6742\u4e14\u8017\u65f6\uff0c\u9700\u8981\u5927\u91cf\u624b\u52a8\u8c03\u4f18\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u521d\u5b66\u8005\u4e0d\u53cb\u597d\uff0c\u4e14\u6210\u672c\u9ad8\u6602\u3002\u9700\u8981\u4e00\u79cd\u7b80\u5355\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u4f18\u5316\u65b9\u6848", "method": "\u4f7f\u7528Ax\u6846\u67b6\u81ea\u52a8\u5316\u4f18\u5316LLM\u7a0b\u5e8f\uff0c\u5305\u62ec\u6307\u4ee4\u8c03\u4f18\u548cfew-shot\u6f14\u793a\u4f18\u5316\u3002\u91c7\u7528teacher-student\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5c06\u4f18\u5316\u7ed3\u679c\u4fdd\u5b58\u4e3aAxOptimizedProgram\u7528\u4e8e\u751f\u4ea7\u90e8\u7f72", "result": "\u4ec5\u97003-5\u4e2a\u6807\u6ce8\u6837\u672c\uff0c\u4f18\u5316\u8fc7\u7a0b\u7ea61-2\u5206\u949f\uff0c\u53ef\u5c06\u51c6\u786e\u7387\u4ece70%\u63d0\u5347\u523090%\uff0c\u540c\u65f6\u964d\u4f4e\u6210\u672c\u7ea680%\u3002\u4f18\u5316\u7ed3\u679c\u53ef\u590d\u73b0\u5e76\u7528\u4e8e\u751f\u4ea7\u73af\u5883", "conclusion": "Ax\u6846\u67b6\u4e3aLLM\u4f18\u5316\u63d0\u4f9b\u4e86\u7b80\u5355\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u964d\u4f4e\u4e86\u4f18\u5316\u95e8\u69db\uff0c\u4f7f\u521d\u5b66\u8005\u4e5f\u80fd\u5feb\u901f\u83b7\u5f97\u9ad8\u8d28\u91cf\u7684\u4f18\u5316\u7ed3\u679c\uff0c\u9002\u5408\u751f\u4ea7\u73af\u5883\u90e8\u7f72", "topic": "code agent"}}
{"id": "tldr.2512.b162a989", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.greptile.com%2Fstate-of-ai-coding-2025%3Futm_source=tldrnewsletter/1/0100019b3133cccb-119e512b-446d-4e62-b481-12b088b83bdb-000000/8-G4GUPVA8f8O2ac9EDWp0vtXnTSYW0iWxtv61uV1Wc=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.greptile.com%2Fstate-of-ai-coding-2025%3Futm_source=tldrnewsletter/1/0100019b3133cccb-119e512b-446d-4e62-b481-12b088b83bdb-000000/8-G4GUPVA8f8O2ac9EDWp0vtXnTSYW0iWxtv61uV1Wc=436", "authors": ["TLDR Newsletter"], "title": "The State of AI Coding 2025", "comment": "Source: TLDR Newsletter, Date: 2025-12-18, Reading time: 10 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.greptile.com%2Fstate-of-ai-coding-2025%3Futm_source=tldrnewsletter/1/0100019b3133cccb-119e512b-446d-4e62-b481-12b088b83bdb-000000/8-G4GUPVA8f8O2ac9EDWp0vtXnTSYW0iWxtv61uV1Wc=436", "summary": "The State of AI Coding 2025 (10 minute read) Greptile's State of AI Coding report is a cross-industry study on recent trends in AI software development. It covers productivity gain across development workflows, AI tool adoption, model growth trends, performance across latency, cost, and tokenization, and recent papers on foundational models and applications. Code output has increased across teams. OpenAI is still the leading model provider, but the gap is closing.", "source": "tldr", "AI": {"tldr": "Greptile\u53d1\u5e03\u76842025\u5e74AI\u7f16\u7801\u73b0\u72b6\u62a5\u544a\u663e\u793a\uff0cAI\u7f16\u7801\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e26\u6765\u751f\u4ea7\u529b\u63d0\u5347\uff0cOpenAI\u4ecd\u662f\u9886\u5148\u6a21\u578b\u63d0\u4f9b\u5546\u4f46\u5dee\u8ddd\u6b63\u5728\u7f29\u5c0f\uff0c\u4ee3\u7801\u8f93\u51fa\u91cf\u666e\u904d\u589e\u52a0\u3002", "motivation": "\u8be5\u62a5\u544a\u65e8\u5728\u5206\u6790AI\u7f16\u7801\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6700\u65b0\u8d8b\u52bf\u548c\u884c\u4e1a\u5e94\u7528\u60c5\u51b5\uff0c\u4e3a\u5f00\u53d1\u8005\u3001\u56e2\u961f\u548c\u4f01\u4e1a\u63d0\u4f9b\u5173\u4e8eAI\u7f16\u7801\u5de5\u5177\u91c7\u7eb3\u3001\u6027\u80fd\u8868\u73b0\u548c\u5b9e\u9645\u5f71\u54cd\u7684\u8de8\u884c\u4e1a\u7814\u7a76\u6570\u636e\u3002", "method": "\u91c7\u7528\u8de8\u884c\u4e1a\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u751f\u4ea7\u529b\u63d0\u5347\u3001AI\u5de5\u5177\u91c7\u7eb3\u60c5\u51b5\u3001\u6a21\u578b\u53d1\u5c55\u8d8b\u52bf\uff0c\u4ee5\u53ca\u5ef6\u8fdf\u3001\u6210\u672c\u548c\u6807\u8bb0\u5316\u7b49\u65b9\u9762\u7684\u6027\u80fd\u8868\u73b0\uff0c\u540c\u65f6\u6db5\u76d6\u57fa\u7840\u6a21\u578b\u548c\u5e94\u7528\u7684\u6700\u65b0\u8bba\u6587\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5404\u56e2\u961f\u7684\u4ee3\u7801\u8f93\u51fa\u91cf\u666e\u904d\u589e\u52a0\uff0cOpenAI\u4ecd\u7136\u662f\u9886\u5148\u7684\u6a21\u578b\u63d0\u4f9b\u5546\uff0c\u4f46\u4e0e\u5176\u4ed6\u63d0\u4f9b\u5546\u7684\u5dee\u8ddd\u6b63\u5728\u7f29\u5c0f\u3002\u62a5\u544a\u8fd8\u63d0\u4f9b\u4e86\u5173\u4e8eAI\u5de5\u5177\u91c7\u7eb3\u7387\u3001\u6027\u80fd\u6307\u6807\u548c\u6210\u672c\u6548\u76ca\u7684\u5177\u4f53\u6570\u636e\u3002", "conclusion": "AI\u7f16\u7801\u5de5\u5177\u6b63\u5728\u663e\u8457\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\u6548\u7387\uff0c\u884c\u4e1a\u7ade\u4e89\u683c\u5c40\u6b63\u5728\u53d1\u751f\u53d8\u5316\uff0cOpenAI\u7684\u9886\u5bfc\u5730\u4f4d\u9762\u4e34\u6311\u6218\uff0cAI\u7f16\u7801\u6280\u672f\u5c06\u7ee7\u7eed\u63a8\u52a8\u8f6f\u4ef6\u5f00\u53d1\u6a21\u5f0f\u7684\u53d8\u9769\u3002", "topic": "swe application"}}
{"id": "tldr.2512.c6c65283", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fpageai.pro%2F%3Futm_source=tldrdesign/1/0100019b3190c124-ac8dc70c-8e0a-47ad-930d-067d804861c5-000000/FUzWTD683lbHgNVjOK01tbCMLaV1dTErYOLByknPOXA=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fpageai.pro%2F%3Futm_source=tldrdesign/1/0100019b3190c124-ac8dc70c-8e0a-47ad-930d-067d804861c5-000000/FUzWTD683lbHgNVjOK01tbCMLaV1dTErYOLByknPOXA=436", "authors": ["TLDR Newsletter"], "title": "Design and Code Your Landing Page in Minutes", "comment": "Source: TLDR Newsletter, Date: 2025-12-18, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fpageai.pro%2F%3Futm_source=tldrdesign/1/0100019b3190c124-ac8dc70c-8e0a-47ad-930d-067d804861c5-000000/FUzWTD683lbHgNVjOK01tbCMLaV1dTErYOLByknPOXA=436", "summary": "Design and Code Your Landing Page in Minutes (Website) Get a production-ready website from a single prompt. Customize it with a click, then download or deploy anywhere.", "source": "tldr", "AI": {"tldr": "\u4e00\u4e2aAI\u9a71\u52a8\u7684\u7f51\u7ad9\u751f\u6210\u5de5\u5177\uff0c\u901a\u8fc7\u5355\u6b21\u63d0\u793a\u5feb\u901f\u521b\u5efa\u751f\u4ea7\u5c31\u7eea\u7684\u7740\u9646\u9875\uff0c\u652f\u6301\u70b9\u51fb\u5b9a\u5236\u548c\u7075\u6d3b\u90e8\u7f72", "motivation": "\u4f20\u7edf\u7f51\u7ad9\u5f00\u53d1\u8fc7\u7a0b\u8017\u65f6\u4e14\u9700\u8981\u6280\u672f\u4e13\u4e1a\u77e5\u8bc6\uff0c\u7528\u6237\u5e0c\u671b\u5feb\u901f\u83b7\u5f97\u5b9a\u5236\u5316\u7684\u751f\u4ea7\u5c31\u7eea\u7f51\u7ad9\uff0c\u65e0\u9700\u590d\u6742\u7f16\u7801\u8fc7\u7a0b", "method": "\u4f7f\u7528AI\u6280\u672f\u5c06\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u8f6c\u6362\u4e3a\u5b8c\u6574\u7684\u7f51\u7ad9\u4ee3\u7801\uff0c\u63d0\u4f9b\u53ef\u89c6\u5316\u7f16\u8f91\u754c\u9762\u8fdb\u884c\u70b9\u51fb\u5f0f\u5b9a\u5236\uff0c\u652f\u6301\u591a\u79cd\u90e8\u7f72\u9009\u9879", "result": "\u80fd\u591f\u5728\u51e0\u5206\u949f\u5185\u751f\u6210\u529f\u80fd\u5b8c\u6574\u7684\u7740\u9646\u9875\uff0c\u7528\u6237\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u4ea4\u4e92\u5b8c\u6210\u5b9a\u5236\uff0c\u5e76\u76f4\u63a5\u4e0b\u8f7d\u6216\u90e8\u7f72\u5230\u5404\u79cd\u5e73\u53f0", "conclusion": "\u8be5\u5de5\u5177\u663e\u8457\u964d\u4f4e\u4e86\u7f51\u7ad9\u521b\u5efa\u7684\u6280\u672f\u95e8\u69db\u548c\u65f6\u95f4\u6210\u672c\uff0c\u4f7f\u975e\u6280\u672f\u7528\u6237\u4e5f\u80fd\u5feb\u901f\u83b7\u5f97\u4e13\u4e1a\u8d28\u91cf\u7684\u7f51\u7ad9", "topic": "swe application"}}
{"id": "tldr.2512.e66e9bea", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fbm-github%2Fowasp-social-osint-agent%3Futm_source=tldrinfosec/1/0100019b31cb83ee-e98945bc-f116-4b47-a82b-c9a72a6e923a-000000/jEJWFvJwc-ZcVTW6Aw2eSjQyxn_34WlW7PjLD7ICI7I=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fbm-github%2Fowasp-social-osint-agent%3Futm_source=tldrinfosec/1/0100019b31cb83ee-e98945bc-f116-4b47-a82b-c9a72a6e923a-000000/jEJWFvJwc-ZcVTW6Aw2eSjQyxn_34WlW7PjLD7ICI7I=436", "authors": ["TLDR Newsletter"], "title": "OWASP Social OSINT Agent", "comment": "Source: TLDR Newsletter, Date: 2025-12-18, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fbm-github%2Fowasp-social-osint-agent%3Futm_source=tldrinfosec/1/0100019b31cb83ee-e98945bc-f116-4b47-a82b-c9a72a6e923a-000000/jEJWFvJwc-ZcVTW6Aw2eSjQyxn_34WlW7PjLD7ICI7I=436", "summary": "OWASP Social OSINT Agent (GitHub Repo) OWASP Social OSINT Agent is an agent designed for OSINT investigations that leverages both text and vision-capable LLMs via any OpenAI-compatible API to gather, analyze, and synthesize user activity across single or multiple social media accounts.", "source": "tldr", "AI": {"tldr": "OWASP Social OSINT Agent\u662f\u4e00\u4e2a\u7528\u4e8e\u5f00\u6e90\u60c5\u62a5\u8c03\u67e5\u7684\u667a\u80fd\u4f53\uff0c\u5229\u7528\u652f\u6301\u6587\u672c\u548c\u89c6\u89c9\u7684LLM\u901a\u8fc7OpenAI\u517c\u5bb9API\u6536\u96c6\u3001\u5206\u6790\u548c\u7efc\u5408\u5355\u4e2a\u6216\u591a\u4e2a\u793e\u4ea4\u5a92\u4f53\u8d26\u6237\u7684\u7528\u6237\u6d3b\u52a8", "motivation": "\u89e3\u51b3OSINT\uff08\u5f00\u6e90\u60c5\u62a5\uff09\u8c03\u67e5\u4e2d\u9700\u8981\u4ece\u591a\u4e2a\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u6536\u96c6\u548c\u5206\u6790\u7528\u6237\u6d3b\u52a8\u7684\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f", "method": "\u5f00\u53d1\u4e00\u4e2a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5229\u7528\u652f\u6301\u6587\u672c\u548c\u89c6\u89c9\u7684LLM\uff08\u901a\u8fc7OpenAI\u517c\u5bb9API\uff09\uff0c\u80fd\u591f\u5904\u7406\u591a\u4e2a\u793e\u4ea4\u5a92\u4f53\u8d26\u6237\uff0c\u81ea\u52a8\u6536\u96c6\u7528\u6237\u6d3b\u52a8\u6570\u636e\uff0c\u8fdb\u884c\u5206\u6790\u548c\u7efc\u5408", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u529f\u80fd\u5b8c\u6574\u7684OSINT\u8c03\u67e5\u5de5\u5177\uff0c\u80fd\u591f\u8de8\u5e73\u53f0\u6536\u96c6\u548c\u5206\u6790\u793e\u4ea4\u5a92\u4f53\u6570\u636e\uff0c\u652f\u6301\u591a\u6a21\u6001\u4fe1\u606f\u5904\u7406\uff0c\u63d0\u9ad8\u4e86OSINT\u8c03\u67e5\u7684\u6548\u7387\u548c\u51c6\u786e\u6027", "conclusion": "OWASP Social OSINT Agent\u662f\u4e00\u4e2a\u6709\u6548\u7684OSINT\u8c03\u67e5\u5de5\u5177\uff0c\u901a\u8fc7\u7ed3\u5408\u5148\u8fdb\u7684LLM\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u793e\u4ea4\u5a92\u4f53\u60c5\u62a5\u6536\u96c6\u548c\u5206\u6790\u7684\u80fd\u529b", "topic": "code agent"}}
{"id": "tldr.2512.118afc8e", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FA7HKCN/1/0100019b31d332a1-7d121465-eacf-469b-aecf-45cdf73e1086-000000/1sNaWBb5njOGJe1OM0-mstLtRSEqdqzJ7KUMJsCfqOg=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FA7HKCN/1/0100019b31d332a1-7d121465-eacf-469b-aecf-45cdf73e1086-000000/1sNaWBb5njOGJe1OM0-mstLtRSEqdqzJ7KUMJsCfqOg=436", "authors": ["TLDR Newsletter"], "title": "Klarna gives merchants the tools for discovery by AI agents", "comment": "Source: TLDR Newsletter, Date: 2025-12-18, Reading time: 3 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FA7HKCN/1/0100019b31d332a1-7d121465-eacf-469b-aecf-45cdf73e1086-000000/1sNaWBb5njOGJe1OM0-mstLtRSEqdqzJ7KUMJsCfqOg=436", "summary": "Klarna gives merchants the tools for discovery by AI agents (3 minute read) Klarna's Agentic Product Protocol gives AI systems access to a live, structured feed of more than 100 million products and 400 million prices standardized across 12 markets. The protocol establishes a foundation for agents to find, compare, and recommend real products with live prices and availability, across merchants, markets, and platforms.", "source": "tldr", "AI": {"tldr": "Klarna\u63a8\u51faAgentic Product Protocol\uff0c\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u8d85\u8fc71\u4ebf\u4ea7\u54c1\u548c4\u4ebf\u4ef7\u683c\u7684\u5b9e\u65f6\u7ed3\u6784\u5316\u6570\u636e\u6d41\uff0c\u652f\u6301\u8de8\u5546\u6237\u3001\u5e02\u573a\u548c\u5e73\u53f0\u7684\u5546\u54c1\u53d1\u73b0\u3001\u6bd4\u8f83\u548c\u63a8\u8350", "motivation": "\u4e3aAI\u4ee3\u7406\u7cfb\u7edf\u63d0\u4f9b\u5b9e\u65f6\u3001\u7ed3\u6784\u5316\u7684\u5546\u54c1\u6570\u636e\uff0c\u89e3\u51b3AI\u4ee3\u7406\u5728\u7535\u5b50\u5546\u52a1\u4e2d\u53d1\u73b0\u3001\u6bd4\u8f83\u548c\u63a8\u8350\u771f\u5b9e\u5546\u54c1\u65f6\u9762\u4e34\u7684\u6570\u636e\u8bbf\u95ee\u95ee\u9898", "method": "\u5f00\u53d1Agentic Product Protocol\u534f\u8bae\uff0c\u63d0\u4f9b\u6807\u51c6\u5316\u7684\u5b9e\u65f6\u6570\u636e\u6d41\uff0c\u5305\u542b\u8d85\u8fc71\u4ebf\u4ea7\u54c1\u548c4\u4ebf\u4ef7\u683c\uff0c\u8986\u76d612\u4e2a\u5e02\u573a", "result": "\u5efa\u7acb\u4e86AI\u4ee3\u7406\u8bbf\u95ee\u5b9e\u65f6\u5546\u54c1\u6570\u636e\u7684\u57fa\u7840\u8bbe\u65bd\uff0c\u4f7fAI\u7cfb\u7edf\u80fd\u591f\u57fa\u4e8e\u5b9e\u65f6\u4ef7\u683c\u548c\u5e93\u5b58\u4fe1\u606f\u8fdb\u884c\u5546\u54c1\u53d1\u73b0\u548c\u63a8\u8350", "conclusion": "Agentic Product Protocol\u4e3aAI\u4ee3\u7406\u5728\u7535\u5b50\u5546\u52a1\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u652f\u6301", "topic": "agent analysis"}}
{"id": "tldr.2512.77ef37d1", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2Fi9eNbj/1/0100019b31d332a1-7d121465-eacf-469b-aecf-45cdf73e1086-000000/W3TSClKUis2nBH0ZvpGAw6gBfg2xoMn_2jyug9d9TDU=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2Fi9eNbj/1/0100019b31d332a1-7d121465-eacf-469b-aecf-45cdf73e1086-000000/W3TSClKUis2nBH0ZvpGAw6gBfg2xoMn_2jyug9d9TDU=436", "authors": ["TLDR Newsletter"], "title": "Stripe launches tech to help firms sell through AI agents", "comment": "Source: TLDR Newsletter, Date: 2025-12-18, Reading time: 2 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2Fi9eNbj/1/0100019b31d332a1-7d121465-eacf-469b-aecf-45cdf73e1086-000000/W3TSClKUis2nBH0ZvpGAw6gBfg2xoMn_2jyug9d9TDU=436", "summary": "Stripe launches tech to help firms sell through AI agents (2 minute read) Stripe has signed up a host of major retail players to its new Agentic Commerce Suite for selling through multiple AI agents.", "source": "tldr", "AI": {"tldr": "Stripe\u63a8\u51faAgentic Commerce Suite\uff0c\u5e2e\u52a9\u96f6\u552e\u5546\u901a\u8fc7\u591a\u4e2aAI\u4ee3\u7406\u8fdb\u884c\u9500\u552e", "motivation": "\u968f\u7740AI\u4ee3\u7406\u5728\u5546\u4e1a\u9886\u57df\u7684\u5174\u8d77\uff0c\u4f01\u4e1a\u9700\u8981\u80fd\u591f\u901a\u8fc7\u591a\u4e2aAI\u4ee3\u7406\u8fdb\u884c\u9500\u552e\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u63d0\u5347\u9500\u552e\u6548\u7387\u548c\u8986\u76d6\u8303\u56f4", "method": "Stripe\u5f00\u53d1\u4e86Agentic Commerce Suite\u6280\u672f\u5957\u4ef6\uff0c\u4e3a\u96f6\u552e\u5546\u63d0\u4f9b\u901a\u8fc7\u591a\u4e2aAI\u4ee3\u7406\u8fdb\u884c\u9500\u552e\u7684\u6280\u672f\u57fa\u7840\u8bbe\u65bd", "result": "Stripe\u5df2\u7ecf\u4e0e\u591a\u5bb6\u4e3b\u8981\u96f6\u552e\u5546\u7b7e\u7ea6\uff0c\u91c7\u7528\u5176\u65b0\u7684Agentic Commerce Suite\u8fdb\u884cAI\u4ee3\u7406\u9500\u552e", "conclusion": "AI\u4ee3\u7406\u5728\u5546\u4e1a\u9500\u552e\u4e2d\u7684\u5e94\u7528\u6b63\u5728\u52a0\u901f\uff0cStripe\u7684\u6280\u672f\u89e3\u51b3\u65b9\u6848\u4e3a\u96f6\u552e\u5546\u63d0\u4f9b\u4e86\u901a\u8fc7\u591a\u4e2aAI\u4ee3\u7406\u8fdb\u884c\u9500\u552e\u7684\u80fd\u529b", "topic": "agent analysis"}}
{"id": "wechat.2512.076f26b9", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIwMDU4Nzg0Mw==&mid=2247594758&idx=1&sn=36c1411a8d9f59c49405ae1c7d52a744&chksm=97a9d8b063897b03cc8a838a295e0a80de4cdb3353ef1faa1d0d14d09c638c5cd998bad6613f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIwMDU4Nzg0Mw==&mid=2247594758&idx=1&sn=36c1411a8d9f59c49405ae1c7d52a744&chksm=97a9d8b063897b03cc8a838a295e0a80de4cdb3353ef1faa1d0d14d09c638c5cd998bad6613f#rd", "authors": ["RUC AI Box"], "title": "LLMs-based <em class=\"highlight\">code</em> <em class=\"highlight\">agent</em>\u5de5\u4f5c\u901f\u89c8", "comment": "Source: WeChat, Published: 2025-12-19 08:34:39", "summary": "Introducing KAT-Dev-32B\uff0c KAT-Coder\uff1a Advancing Code Intelligence through Scalable Agentic RL\u8bba\u6587\u94fe\u63a5\uff1ahttps\uff1a//kwaipilot.github.io/KAT-Coder/\u6838\u5fc3\u5de5\u4f5c\uff1a\u5feb\u624b\u56e2\u961f\u53d1\u5e03\u4e86KAT\u7cfb\u5217\u4e24\u4e2a\u6a21\u578b\u2014\u2014\u5f00\u6e90\u7684KAT-Dev-32B\uff0832B\u53c2\u6570\uff09\u4e0e\u6027\u80fd\u66f4\u5f3a\u7684KAT-Coder\u3002", "AI": {"tldr": "Introducing KAT-Dev-32B\uff0c KAT-Coder\uff1a Advancing Code Intelligence through Scalable Agentic RL\u8bba\u6587\u94fe\u63a5\uff1ahttps\uff1a//kwaipilot.github.io/KAT-Coder/\u6838\u5fc3\u5de5\u4f5c\uff1a\u5feb\u624b\u56e2\u961f\u53d1\u5e03\u4e86KAT\u7cfb\u5217\u4e24\u4e2a\u6a21\u578b\u2014\u2014\u5f00\u6e90\u7684KAT-Dev-32B\uff0832B\u53c2\u6570\uff09\u4e0e\u6027\u80fd\u66f4\u5f3a\u7684KAT-Coder\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.679abef6", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg3MTExOTcwNA==&mid=2247485149&idx=1&sn=f1f967d44f5941c85935c8ff31010c88&chksm=cfb254a62089aad69f6d1a62a036ff2e0aa7e7f3f6657fab4339edd2306a6260f1983def7a53#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg3MTExOTcwNA==&mid=2247485149&idx=1&sn=f1f967d44f5941c85935c8ff31010c88&chksm=cfb254a62089aad69f6d1a62a036ff2e0aa7e7f3f6657fab4339edd2306a6260f1983def7a53#rd", "authors": ["\u6df1\u5ea6\u5b66\u4e60\u673a\u5668"], "title": "\u4ece\u4fe1\u606f\u5339\u914d\u5230\u667a\u80fd\u89c4\u5212\uff0c<em class=\"highlight\">Agentic</em> RAG\u7684\u67b6\u6784\u5b9e\u73b0", "comment": "Source: WeChat, Published: 2025-12-19 11:17:37", "summary": "\u5728\u6df1\u5165\u7814\u7a76\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\u4e4b\u524d\uff0c\u6211\u4eec\u6709\u5fc5\u8981\u5148\u9000\u540e\u4e00\u6b65\uff0c\u4ece\u66f4\u9ad8\u7ef4\u5ea6\u5ba1\u89c6\u4e00\u4e2a\u5178\u578b\u7684 Agentic RAG \u7cfb\u7edf\u5728\u67b6\u6784\u5c42\u9762\u9700\u8981\u54ea\u4e9b\u7ec4\u4ef6\uff0c\u4ee5\u53ca\u5b83\u4eec\u662f\u5982\u4f55\u534f\u540c\u5de5\u4f5c\u7684\u3002", "AI": {"tldr": "\u5728\u6df1\u5165\u7814\u7a76\u5177\u4f53\u4ee3\u7801\u5b9e\u73b0\u4e4b\u524d\uff0c\u6211\u4eec\u6709\u5fc5\u8981\u5148\u9000\u540e\u4e00\u6b65\uff0c\u4ece\u66f4\u9ad8\u7ef4\u5ea6\u5ba1\u89c6\u4e00\u4e2a\u5178\u578b\u7684 Agentic RAG \u7cfb\u7edf\u5728\u67b6\u6784\u5c42\u9762\u9700\u8981\u54ea\u4e9b\u7ec4\u4ef6\uff0c\u4ee5\u53ca\u5b83\u4eec\u662f\u5982\u4f55\u534f\u540c\u5de5\u4f5c\u7684\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.affd438e", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyNjYzNTIwNw==&mid=2247494203&idx=1&sn=b4205a49844c935a482277a40b4b53a9&chksm=c356205d3d16ccd7833d557e3932fea4e67dc49b7dc8a528438554c1ce97e73c6039bb2ca46a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyNjYzNTIwNw==&mid=2247494203&idx=1&sn=b4205a49844c935a482277a40b4b53a9&chksm=c356205d3d16ccd7833d557e3932fea4e67dc49b7dc8a528438554c1ce97e73c6039bb2ca46a#rd", "authors": ["CIOCDO"], "title": "2026\u5e74AI\u9884\u6d4b\uff1a\u81ea\u4e3b<em class=\"highlight\">\u667a\u80fd\u4f53</em>\uff08<em class=\"highlight\">Agentic</em> AI\uff09\u5c06\u63a5\u7ba1\u4f01\u4e1a\uff1f\u73b0\u5b9e\u53ef\u80fd\u662f\u4e00\u573a\u201c\u6df7\u5408\u6218\u201d", "comment": "Source: WeChat, Published: 2025-12-19 11:01:46", "summary": "IDC\u9884\u6d4b\uff1a\u52302026\u5e74\uff0c\u5168\u74032000\u5f3a\u4f01\u4e1a\u4e2d 40%\u7684\u5de5\u4f5c\u89d2\u8272\u5c06\u6d89\u53ca\u201c\u81ea\u4e3b\u667a\u80fd\u4f53\u201d\uff08Agentic AI\uff09\u7684\u534f\u4f5c\u3002\u8fd9\u8868\u660e\uff0c\u6211\u4eec\u6b63\u5904\u4e8e\u4e00\u4e2a\u4ece\u201c\u5b9e\u9a8c\u201d\u5230\u201c\u751f\u4ea7\u201d\u7684\u8270\u96be\u8de8\u8d8a\u671f\u3002", "AI": {"tldr": "IDC\u9884\u6d4b\uff1a\u52302026\u5e74\uff0c\u5168\u74032000\u5f3a\u4f01\u4e1a\u4e2d 40%\u7684\u5de5\u4f5c\u89d2\u8272\u5c06\u6d89\u53ca\u201c\u81ea\u4e3b\u667a\u80fd\u4f53\u201d\uff08Agentic AI\uff09\u7684\u534f\u4f5c\u3002\u8fd9\u8868\u660e\uff0c\u6211\u4eec\u6b63\u5904\u4e8e\u4e00\u4e2a\u4ece\u201c\u5b9e\u9a8c\u201d\u5230\u201c\u751f\u4ea7\u201d\u7684\u8270\u96be\u8de8\u8d8a\u671f\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.771b9d58", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU4MjkxMTgwMQ==&mid=2247492787&idx=1&sn=fd3f2425156c90b64b14846461891247&chksm=fcf8970e9dff3a9df96620335d5e22ea292c13800a06d0292f63022ed74199c9450b3a779603#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU4MjkxMTgwMQ==&mid=2247492787&idx=1&sn=fd3f2425156c90b64b14846461891247&chksm=fcf8970e9dff3a9df96620335d5e22ea292c13800a06d0292f63022ed74199c9450b3a779603#rd", "authors": ["AI\u7814\u7a76"], "title": "67\u9875<em class=\"highlight\">Agentic</em> AI\u7efc\u8ff0\uff1a13\u5927\u673a\u6784\u53d1\u5e03\uff0c4\u5927\u6838\u5fc3\u8303\u5f0f\u4e0e\u672a\u6765\u8def\u7ebf\u56fe\uff01", "comment": "Source: WeChat, Published: 2025-12-19 09:16:06", "summary": "\u8fd1\u65e5\uff0c\u6765\u81ea\u52a0\u5dde\u7406\u5de5\u3001\u65af\u5766\u798f\u3001\u4f2f\u514b\u5229\u3001\u4f50\u6cbb\u4e9a\u7406\u5de5\u7b49 13 \u6240\u9876\u5c16\u673a\u6784\u7684\u7814\u7a76\u4eba\u5458\u8054\u5408\u53d1\u8868\u4e86\u4e00\u7bc7\u91cd\u78c5\u7efc\u8ff0\uff0c\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63d0\u51fa\u4e86 Agentic AI \u9002\u914d \u7684\u7edf\u4e00\u6846\u67b6\u3002", "AI": {"tldr": "\u8fd1\u65e5\uff0c\u6765\u81ea\u52a0\u5dde\u7406\u5de5\u3001\u65af\u5766\u798f\u3001\u4f2f\u514b\u5229\u3001\u4f50\u6cbb\u4e9a\u7406\u5de5\u7b49 13 \u6240\u9876\u5c16\u673a\u6784\u7684\u7814\u7a76\u4eba\u5458\u8054\u5408\u53d1\u8868\u4e86\u4e00\u7bc7\u91cd\u78c5\u7efc\u8ff0\uff0c\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u63d0\u51fa\u4e86 Agentic AI \u9002\u914d \u7684\u7edf\u4e00\u6846\u67b6\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.7e32505b", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkwNDMwMzUxNw==&mid=2247503360&idx=1&sn=84d3512edbe0ff433626dae0ee3846af&chksm=c16df233efa7f2ecdcc8f114770b8e4ecb2339370c9f7a2d35e527f41f126e5ff85eb960b889#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkwNDMwMzUxNw==&mid=2247503360&idx=1&sn=84d3512edbe0ff433626dae0ee3846af&chksm=c16df233efa7f2ecdcc8f114770b8e4ecb2339370c9f7a2d35e527f41f126e5ff85eb960b889#rd", "authors": ["AIGC\u524d\u7ebf"], "title": "<em class=\"highlight\">Agentic</em> Commerce\u6b63\u5728\u91cd\u6784\u5546\u4e1a\u5e95\u5c42\u903b\u8f91\u2014\u2014\u4ece4,700%\u7684\u6d41\u91cf\u589e\u957f\uff0c\u770bAI<em class=\"highlight\">\u4ee3\u7406</em>\u5982\u4f55\u6210\u4e3a\u65b0\u7684\u5546\u4e1a\u5165\u53e3", "comment": "Source: WeChat, Published: 2025-12-19 07:24:38", "summary": "\u4f46Agentic Commerce\u7684\u672c\u8d28\u5dee\u5f02\u5728\u4e8e\uff1a\u5b83\u4e0d\u4ec5\u6539\u53d8\u4e86\u6d41\u91cf\u6765\u6e90\uff0c\u66f4\u6539\u53d8\u4e86\u4ea4\u6613\u51b3\u7b56\u6743\u7684\u5f52\u5c5e\u3002SEO \u2192 GEO \u2192 ACO\uff1a\u4e09\u4ee3\u53ef\u89c1\u6027\u903b\u8f91\u65f6\u4ee3\u4f18\u5316\u76ee\u6807\u6838\u5fc3\u80fd\u529b\u5546\u4e1a\u5f71\u54cd", "AI": {"tldr": "\u4f46Agentic Commerce\u7684\u672c\u8d28\u5dee\u5f02\u5728\u4e8e\uff1a\u5b83\u4e0d\u4ec5\u6539\u53d8\u4e86\u6d41\u91cf\u6765\u6e90\uff0c\u66f4\u6539\u53d8\u4e86\u4ea4\u6613\u51b3\u7b56\u6743\u7684\u5f52\u5c5e\u3002SEO \u2192 GEO \u2192 ACO\uff1a\u4e09\u4ee3\u53ef\u89c1\u6027\u903b\u8f91\u65f6\u4ee3\u4f18\u5316\u76ee\u6807\u6838\u5fc3\u80fd\u529b\u5546\u4e1a\u5f71\u54cd", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.e99bf032", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYzNTIwNzIwMw==&mid=2247483915&idx=3&sn=407b8778964c9c9df97037cdc7847f2e&chksm=f1b351cb02fdf51327fdef396d99cb331930ff4e8026b43caf4a467c5d6f82298c0b43481960#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYzNTIwNzIwMw==&mid=2247483915&idx=3&sn=407b8778964c9c9df97037cdc7847f2e&chksm=f1b351cb02fdf51327fdef396d99cb331930ff4e8026b43caf4a467c5d6f82298c0b43481960#rd", "authors": ["Snowflake AI\u6570\u636e\u4e91"], "title": "\u6280\u672f\u5b9e\u8df5 | \u6784\u5efa\u4f60\u7684\u7b2c\u4e00\u4e2a Snowflake <em class=\"highlight\">\u667a\u80fd\u4f53</em>\uff1a\u4ece\u6982\u5ff5\u5230\u539f\u578b\u53ea\u9700 3 \u6b65\uff01", "comment": "Source: WeChat, Published: 2025-12-19 05:00:00", "summary": "Agentic AI \u8fdc\u4e0d\u6b62\u662f\u6700\u65b0\u7684\u70ed\u95e8\u8bcd\u6c47\uff0c\u5b83\u66f4\u662f\u4e00\u79cd\u98a0\u8986\u6027\u6280\u672f\uff01\u60f3\u8c61\u8fd9\u6837\u4e00\u4e2a\u573a\u666f\uff1a\u60a8\u7684\u6570\u636e\u4e0d\u518d\u88ab\u52a8\u7b49\u5f85\u60a8\u63d0\u51fa\u6b63\u786e\u95ee\u9898\uff0c\u800c\u662f\u6301\u7eed\u4e3b\u52a8\u5730\u4e3a\u60a8\u5de5\u4f5c\u3002", "AI": {"tldr": "Agentic AI \u8fdc\u4e0d\u6b62\u662f\u6700\u65b0\u7684\u70ed\u95e8\u8bcd\u6c47\uff0c\u5b83\u66f4\u662f\u4e00\u79cd\u98a0\u8986\u6027\u6280\u672f\uff01\u60f3\u8c61\u8fd9\u6837\u4e00\u4e2a\u573a\u666f\uff1a\u60a8\u7684\u6570\u636e\u4e0d\u518d\u88ab\u52a8\u7b49\u5f85\u60a8\u63d0\u51fa\u6b63\u786e\u95ee\u9898\uff0c\u800c\u662f\u6301\u7eed\u4e3b\u52a8\u5730\u4e3a\u60a8\u5de5\u4f5c\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.e5c0e944", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU3OTYxODc2Mg==&mid=2247489321&idx=1&sn=993ce3a434a01a62674943571483e9e0&chksm=fc7f4bceefaa1e8bb0a3b0a8fa103324017b3d759ab92476c4647c8b318412372ba1773b12c4#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU3OTYxODc2Mg==&mid=2247489321&idx=1&sn=993ce3a434a01a62674943571483e9e0&chksm=fc7f4bceefaa1e8bb0a3b0a8fa103324017b3d759ab92476c4647c8b318412372ba1773b12c4#rd", "authors": ["\u8ddf\u96f7\u54e5\u63a2\u7a76HR\u9886\u57df\u7684AI"], "title": "<em class=\"highlight\">Agentic</em> AI \u65f6\u4ee3\u7684\u5c97\u4f4d\u4e0e\u80fd\u529b\u91cd\u6784\uff1a\u4ece\u9ea6\u80af\u9521\u7814\u7a76\u770b\u672a\u6765HR\u7684\u4e09\u6761\u5fc5\u4fee\u8bfe", "comment": "Source: WeChat, Published: 2025-12-19 00:11:52", "summary": "Agentic AI \u65f6\u4ee3\uff0c\u771f\u6b63\u9700\u8981\u5199\u6e05\u7684\u662f\u201c\u8fd9\u9879\u5de5\u4f5c\u7531\u4eba\u548c Agent \u5982\u4f55\u5171\u540c\u5b8c\u6210\u201d\u3002\u9ea6\u80af\u9521\u5728\u94f6\u884c\u3001\u4fdd\u9669\u3001\u8fd0\u8425\u7b49\u524d\u7ebf\u573a\u666f\u91cc\u7684\u6848\u4f8b\uff0c\u6709\u4e00\u4e2a\u5171\u540c\u7279\u70b9\uff1a\u4e0d\u662f\u7b80\u5355\u5730\u201c\u7528 AI \u66ff\u4ee3\u4e00\u90e8\u5206\u4eba\u201d\uff0c\u800c\u662f\u5148\u628a\u5c97\u4f4d\u62c6\u6210\u4efb\u52a1\uff0c\u518d\u4e3a\u6bcf\u7c7b\u4efb\u52a1\u5339\u914d\u6700", "AI": {"tldr": "Agentic AI \u65f6\u4ee3\uff0c\u771f\u6b63\u9700\u8981\u5199\u6e05\u7684\u662f\u201c\u8fd9\u9879\u5de5\u4f5c\u7531\u4eba\u548c Agent \u5982\u4f55\u5171\u540c\u5b8c\u6210\u201d\u3002\u9ea6\u80af\u9521\u5728\u94f6\u884c\u3001\u4fdd\u9669\u3001\u8fd0\u8425\u7b49\u524d\u7ebf\u573a\u666f\u91cc\u7684\u6848\u4f8b\uff0c\u6709\u4e00\u4e2a\u5171\u540c\u7279\u70b9\uff1a\u4e0d\u662f\u7b80\u5355\u5730\u201c\u7528 AI \u66ff\u4ee3\u4e00\u90e8\u5206\u4eba\u201d\uff0c\u800c\u662f\u5148\u628a\u5c97\u4f4d\u62c6\u6210\u4efb\u52a1\uff0c\u518d\u4e3a\u6bcf\u7c7b\u4efb\u52a1\u5339\u914d\u6700", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.fef0add1", "categories": ["wechat.article", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxMTYwMjIxOA==&mid=2247483891&idx=2&sn=4734685aee87a6826dce25e542aa9bd7&chksm=c0d6d78b5795459a58729d4b3cb4a430c71dbc897340398c29c80b58b3774e8048632a3f1eb4#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxMTYwMjIxOA==&mid=2247483891&idx=2&sn=4734685aee87a6826dce25e542aa9bd7&chksm=c0d6d78b5795459a58729d4b3cb4a430c71dbc897340398c29c80b58b3774e8048632a3f1eb4#rd", "authors": ["\u51ef\u4e50\u6742\u8c08"], "title": "2025<em class=\"highlight\">\u667a\u80fd\u4f53</em>\u7206\u53d1\u5143\u5e74\uff1a\u5173\u4e8e <em class=\"highlight\">Agentic</em> AI \u5d1b\u8d77\u3001\u53ef\u89c6\u5316\u7f16\u7a0b\u7d20\u517b\u4e0e\u8d85\u7ea7\u4e2a\u4f53\u8fdb\u5316\u7684\u6df1\u5ea6\u7814\u7a76\u62a5\u544a", "comment": "Source: WeChat, Published: 2025-12-19 00:00:00", "summary": "\u7b2c\u4e00\u90e8\u5206\uff1aAgentic AI \u7684\u5d1b\u8d77\u4e0e 2025 \u5e74\u7684\u65b0\u5de5\u4f5c\u8303\u5f0f1.1 \u4ece\u201c\u804a\u5929\u673a\u5668\u4eba\u201d\u5230\u201c\u865a\u62df\u540c\u4e8b\u201d\u7684\u6f14\u8fdb\u5728\u8fc7\u53bb\u4e24\u5e74\u4e2d\uff0c\u516c\u4f17\u5bf9 AI \u7684\u8ba4\u77e5\u4e3b\u8981\u505c\u7559\u5728\u201c\u804a\u5929\u673a\u5668\u4eba\u201d\uff08Chatbot\uff09\u7684\u5c42\u9762\u2014\u2014\u5373\u7528\u6237\u8f93\u5165\u63d0\u793a\u8bcd\uff08Prompt\uff09\uff0cAI \u8f93\u51fa\u6587\u672c\u6216\u56fe\u50cf\u3002", "AI": {"tldr": "\u7b2c\u4e00\u90e8\u5206\uff1aAgentic AI \u7684\u5d1b\u8d77\u4e0e 2025 \u5e74\u7684\u65b0\u5de5\u4f5c\u8303\u5f0f1.1 \u4ece\u201c\u804a\u5929\u673a\u5668\u4eba\u201d\u5230\u201c\u865a\u62df\u540c\u4e8b\u201d\u7684\u6f14\u8fdb\u5728\u8fc7\u53bb\u4e24\u5e74\u4e2d\uff0c\u516c\u4f17\u5bf9 AI \u7684\u8ba4\u77e5\u4e3b\u8981\u505c\u7559\u5728\u201c\u804a\u5929\u673a\u5668\u4eba\u201d\uff08Chatbot\uff09\u7684\u5c42\u9762\u2014\u2014\u5373\u7528\u6237\u8f93\u5165\u63d0\u793a\u8bcd\uff08Prompt\uff09\uff0cAI \u8f93\u51fa\u6587\u672c\u6216\u56fe\u50cf\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.52910611", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI3NDI4MzIyNQ==&mid=2247517425&idx=4&sn=fac08770c3585eae31c97dc73074fe49&chksm=ea9d1f0216732514919c7c923be5c57966c71e644f7b6123ecb01f03db74513462ac9e7d36b1#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI3NDI4MzIyNQ==&mid=2247517425&idx=4&sn=fac08770c3585eae31c97dc73074fe49&chksm=ea9d1f0216732514919c7c923be5c57966c71e644f7b6123ecb01f03db74513462ac9e7d36b1#rd", "authors": ["\u4ea7\u4e1a\u667a\u80fd\u5b98"], "title": "\u3010\u89e3\u51b3\u65b9\u6848\u3011\u4ece\u201c\u6b7b\u78d5\u63d0\u793a\u8bcd\u201d\u5230\u201c<em class=\"highlight\">Agentic</em> AI\u201d\uff1a\u91cd\u65b0\u5b9a\u4e49AI\u95ee\u9898\u89e3\u51b3\u8303\u5f0f", "comment": "Source: WeChat, Published: 2025-12-18 23:00:52", "summary": "\u4ece\u4e94\u5927\u6a21\u5f0f\u7684\u6f14\u8fdb\u4e2d\uff0c\u6211\u4eec\u80fd\u6e05\u6670\u770b\u5230 Agentic AI \u7684\u5e95\u5c42\u903b\u8f91 \u2014\u2014\u91cd\u8981\u7684\u4e0d\u662f \u201c\u7b54\u6848\u672c\u8eab\u201d\uff0c\u800c\u662f \u201c\u7b54\u6848\u5982\u4f55\u5f62\u6210\u201d\u3002\u8fd9\u79cd\u601d\u7ef4\u9769\u547d\uff0c\u5bf9\u6280\u672f\u4ece\u4e1a\u8005\u4e0e\u4f01\u4e1a\u51b3\u7b56\u8005\u7684\u542f\u793a\u8fdc\u8d85\u6280\u672f\u8303\u7574\uff1a", "AI": {"tldr": "\u4ece\u4e94\u5927\u6a21\u5f0f\u7684\u6f14\u8fdb\u4e2d\uff0c\u6211\u4eec\u80fd\u6e05\u6670\u770b\u5230 Agentic AI \u7684\u5e95\u5c42\u903b\u8f91 \u2014\u2014\u91cd\u8981\u7684\u4e0d\u662f \u201c\u7b54\u6848\u672c\u8eab\u201d\uff0c\u800c\u662f \u201c\u7b54\u6848\u5982\u4f55\u5f62\u6210\u201d\u3002\u8fd9\u79cd\u601d\u7ef4\u9769\u547d\uff0c\u5bf9\u6280\u672f\u4ece\u4e1a\u8005\u4e0e\u4f01\u4e1a\u51b3\u7b56\u8005\u7684\u542f\u793a\u8fdc\u8d85\u6280\u672f\u8303\u7574\uff1a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.fdfe4a5c", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxNjM3NzYyNg==&mid=2651705775&idx=1&sn=b371809bc9ebf403827c9cca94981903&chksm=81c5613c9438b1d28bb036655e804310f15da12f27b6cb7a653c884db99bb76f2e05d55b2ea5#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxNjM3NzYyNg==&mid=2651705775&idx=1&sn=b371809bc9ebf403827c9cca94981903&chksm=81c5613c9438b1d28bb036655e804310f15da12f27b6cb7a653c884db99bb76f2e05d55b2ea5#rd", "authors": ["\u79d1\u6280\u660e\u8bf4"], "title": "\u4ece\u52a9\u624b\u5230\u6267\u884c\u8005\uff1a\u8c46\u5305<em class=\"highlight\">\u5927\u6a21\u578b</em>\u9886\u8dd1Agent\u65f6\u4ee3", "comment": "Source: WeChat, Published: 2025-12-19 13:48:05", "summary": "\u5f53\u65e5\uff0c\u8c46\u5305\u5927\u6a21\u578b\u5347\u7ea7\u81f31.8\u7248\u672c\uff0c\u540c\u6b65\u63a8\u51fa\u7684\u8fd8\u6709\u97f3\u89c6\u9891\u521b\u4f5c\u6a21\u578bSeedance 1.5 Pro\u3002\u6743\u5a01\u8bc4\u6d4b\u663e\u793a\uff0c\u8c46\u5305\u5927\u6a21\u578b\u5728\u591a\u6a21\u6001\u7406\u89e3\u3001\u751f\u6210\u80fd\u529b\u53caAgent\u80fd\u529b\u4e0a\uff0c\u5df2\u8dfb\u8eab\u5168\u7403\u7b2c\u4e00\u68af\u961f\u3002", "AI": {"tldr": "\u5f53\u65e5\uff0c\u8c46\u5305\u5927\u6a21\u578b\u5347\u7ea7\u81f31.8\u7248\u672c\uff0c\u540c\u6b65\u63a8\u51fa\u7684\u8fd8\u6709\u97f3\u89c6\u9891\u521b\u4f5c\u6a21\u578bSeedance 1.5 Pro\u3002\u6743\u5a01\u8bc4\u6d4b\u663e\u793a\uff0c\u8c46\u5305\u5927\u6a21\u578b\u5728\u591a\u6a21\u6001\u7406\u89e3\u3001\u751f\u6210\u80fd\u529b\u53caAgent\u80fd\u529b\u4e0a\uff0c\u5df2\u8dfb\u8eab\u5168\u7403\u7b2c\u4e00\u68af\u961f\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.b8ac991e", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzMjY0ODg3OA==&mid=2247497037&idx=2&sn=6728c8dc1e92c90c2ff814f68ed2bf36&chksm=c347782976dcef94490f8db5284350dcdb22f11362be93772ff8d3b356305fb39aa28bccd1b6#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzMjY0ODg3OA==&mid=2247497037&idx=2&sn=6728c8dc1e92c90c2ff814f68ed2bf36&chksm=c347782976dcef94490f8db5284350dcdb22f11362be93772ff8d3b356305fb39aa28bccd1b6#rd", "authors": ["\u767e\u6570\u671d\u667a\u7f51"], "title": "\u8c46\u5305<em class=\"highlight\">\u5927\u6a21\u578b</em>1.8\u53d1\u5e03\uff0cSeedance\u6a21\u578b\u540c\u6b65\u5347\u7ea7", "comment": "Source: WeChat, Published: 2025-12-19 12:56:47", "summary": "\u8c46\u5305\u5927\u6a21\u578b1.8\u591a\u6a21\u6001Agent\u80fd\u529b\u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b\u8c46\u5305\u5927\u6a21\u578b1.8\uff08Doubao-Seed-1.8\uff09\u9762\u5411\u591a\u6a21\u6001Agent\u573a\u666f\u8fdb\u884c\u4e86\u5b9a\u5411\u4f18\u5316\u3002\u5176\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3001\u590d\u6742\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u53caOS Agent\u80fd\u529b\u663e\u8457\u589e\u5f3a\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7684\u89c4\u5212\u4e0e\u6267\u884c\u6c34\u5e73", "AI": {"tldr": "\u8c46\u5305\u5927\u6a21\u578b1.8\u591a\u6a21\u6001Agent\u80fd\u529b\u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b\u8c46\u5305\u5927\u6a21\u578b1.8\uff08Doubao-Seed-1.8\uff09\u9762\u5411\u591a\u6a21\u6001Agent\u573a\u666f\u8fdb\u884c\u4e86\u5b9a\u5411\u4f18\u5316\u3002\u5176\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3001\u590d\u6742\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u53caOS Agent\u80fd\u529b\u663e\u8457\u589e\u5f3a\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7684\u89c4\u5212\u4e0e\u6267\u884c\u6c34\u5e73", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.7db4ec10", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA4MzIyMTkzNQ==&mid=2650079047&idx=1&sn=227bfc9701a8a6393e1344a318b5eb60&chksm=86de59701afc92487c289b23a7f611a54b1e1a94d129b15ba3dcfbcd93f3cc6e4e75e04459bb#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA4MzIyMTkzNQ==&mid=2650079047&idx=1&sn=227bfc9701a8a6393e1344a318b5eb60&chksm=86de59701afc92487c289b23a7f611a54b1e1a94d129b15ba3dcfbcd93f3cc6e4e75e04459bb#rd", "authors": ["\u4e2d\u7ecfe\u5546\u5708"], "title": "\u8c46\u5305<em class=\"highlight\">\u5927\u6a21\u578b</em>\u65e5\u5747\u8c03\u7528\u91cf\u7a81\u783450\u4e07\u4ebftokens", "comment": "Source: WeChat, Published: 2025-12-19 11:18:44", "summary": "\u8c46\u5305\u5927\u6a21\u578b1.8\u663e\u8457\u589e\u5f3a\u4e86\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff08Tool Use\uff09\u548c\u590d\u6742\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3001GUI Agent\u80fd\u529b\u7b49\u3002\u8fd9\u610f\u5473\u7740\u6a21\u578b\u4e0d\u518d\u88ab\u52a8\u7b49\u5f85\u6307\u4ee4\uff0c\u800c\u662f\u80fd\u591f\u50cf\u4e00\u4e2a\u7ecf\u9a8c\u4e30\u5bcc\u7684\u9879\u76ee\u7ecf\u7406\u4e00\u6837\uff0c\u5bf9\u590d\u6742\u4efb\u52a1\u7684\u89c4\u5212\u3001\u6267\u884c\u3001\u6d41\u7a0b\u7406\u89e3\u80fd\u529b\uff0c\u66f4\u9002\u5408\u7528\u6765\u5f00\u53d1\u5904", "AI": {"tldr": "\u8c46\u5305\u5927\u6a21\u578b1.8\u663e\u8457\u589e\u5f3a\u4e86\u5de5\u5177\u8c03\u7528\u80fd\u529b\uff08Tool Use\uff09\u548c\u590d\u6742\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u3001GUI Agent\u80fd\u529b\u7b49\u3002\u8fd9\u610f\u5473\u7740\u6a21\u578b\u4e0d\u518d\u88ab\u52a8\u7b49\u5f85\u6307\u4ee4\uff0c\u800c\u662f\u80fd\u591f\u50cf\u4e00\u4e2a\u7ecf\u9a8c\u4e30\u5bcc\u7684\u9879\u76ee\u7ecf\u7406\u4e00\u6837\uff0c\u5bf9\u590d\u6742\u4efb\u52a1\u7684\u89c4\u5212\u3001\u6267\u884c\u3001\u6d41\u7a0b\u7406\u89e3\u80fd\u529b\uff0c\u66f4\u9002\u5408\u7528\u6765\u5f00\u53d1\u5904", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.ff0fe659", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk4ODI1ODMyOQ==&mid=2247485076&idx=1&sn=8b952034e8e1224f495d97340a20c9c2&chksm=c480a3cfa1523d97b9fc272b7c2d49981a3bba40778bff2f95fda5061e3acf1bfc21fac90576#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk4ODI1ODMyOQ==&mid=2247485076&idx=1&sn=8b952034e8e1224f495d97340a20c9c2&chksm=c480a3cfa1523d97b9fc272b7c2d49981a3bba40778bff2f95fda5061e3acf1bfc21fac90576#rd", "authors": ["\u5965\u65af\u6bd4\u5343\u6a21\u52a0\u901f\u5668"], "title": "\u672c\u5468\u770b\u70b9 | \u5c0f\u7c73\u53d1\u5e03MiMo\u6a21\u578b\uff1b\u706b\u5c71\u5f15\u64ce\u603b\u88c1\uff1a\u660e\u5e74<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5e02\u573a\u5c06\u626910\u500d\uff1bOpenAI\u53d1\u5e03GPT-5.2-Codex", "comment": "Source: WeChat, Published: 2025-12-19 10:01:32", "summary": "\u5bfc\u8bed\u5927\u6a21\u578b\u6280\u672f\u6b63\u6025\u901f\u8fed\u4ee3\uff0c\u884c\u4e1a\u6d6a\u6f6e\u6ce2\u6f9c\u58ee\u9614\u5374\u53c8\u4fe1\u606f\u7eb7\u6742\u3002\u6d1e\u5bdf\u8d8b\u52bf\u3001\u628a\u63e1\u52a8\u5411\uff0c\u662f\u5728AI\u65f6\u4ee3\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u5173\u952e\u3002\u5965\u65af\u6bd4\u770b\u4ea7\u4e1a\uff0c\u5e26\u60a8\u4e00\u8d77\u56de\u987e\u672c\u5468\u5185\u5927\u6a21\u578b\u4ea7\u4e1a\u7684\u6280\u672f\u7a81\u7834\u3001\u5546\u4e1a\u52a8\u6001\u4e0e\u751f\u6001\u4fe1\u53f7\u3002", "AI": {"tldr": "\u5bfc\u8bed\u5927\u6a21\u578b\u6280\u672f\u6b63\u6025\u901f\u8fed\u4ee3\uff0c\u884c\u4e1a\u6d6a\u6f6e\u6ce2\u6f9c\u58ee\u9614\u5374\u53c8\u4fe1\u606f\u7eb7\u6742\u3002\u6d1e\u5bdf\u8d8b\u52bf\u3001\u628a\u63e1\u52a8\u5411\uff0c\u662f\u5728AI\u65f6\u4ee3\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u5173\u952e\u3002\u5965\u65af\u6bd4\u770b\u4ea7\u4e1a\uff0c\u5e26\u60a8\u4e00\u8d77\u56de\u987e\u672c\u5468\u5185\u5927\u6a21\u578b\u4ea7\u4e1a\u7684\u6280\u672f\u7a81\u7834\u3001\u5546\u4e1a\u52a8\u6001\u4e0e\u751f\u6001\u4fe1\u53f7\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.0f72dcce", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4OTY5OTUxOQ==&mid=2247493160&idx=1&sn=a9c0b8164003fe7b73fa1202966ecb7e&chksm=ceae16fbe8c705d57f83ae078997eb0c9bb2f5764b4c68a0e7c1fd6e90bf82d4d68e352901aa#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4OTY5OTUxOQ==&mid=2247493160&idx=1&sn=a9c0b8164003fe7b73fa1202966ecb7e&chksm=ceae16fbe8c705d57f83ae078997eb0c9bb2f5764b4c68a0e7c1fd6e90bf82d4d68e352901aa#rd", "authors": ["AI For Bioinformatics"], "title": "\u7ec8\u7ed3\u201cAI\u6a21\u578b\u9009\u62e9\u7126\u8651\u201d\uff1aRNA\u9884\u8bad\u7ec3<em class=\"highlight\">\u5927\u6a21\u578b</em>\u6d4b\u8bc4\u4e0e\u5206\u6790Benchmark", "comment": "Source: WeChat, Published: 2025-12-19 06:26:48", "summary": "\u540c\u65f6\uff0c\u7814\u7a76\u53d1\u73b0\u4ee5\u5f80\u201c\u6a21\u578b\u8d8a\u5927\u8d8a\u597d\u201d\u7684\u89c2\u70b9\u5e76\u4e0d\u7edd\u5bf9\u6210\u7acb\u3002\u4f8b\u5982\uff0c\u4e0e\u5e94\u7528\u573a\u666f\u8bed\u4e49\u9002\u914d\u7684\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u4ee5\u53ca\u7f16\u7801\u65b9\u5f0f\u540c\u6837\u4f1a\u5bf9\u6a21\u578b\u6027\u80fd\u4ea7\u751f\u660e\u663e\u7684\u5f71\u54cd\u3002", "AI": {"tldr": "\u540c\u65f6\uff0c\u7814\u7a76\u53d1\u73b0\u4ee5\u5f80\u201c\u6a21\u578b\u8d8a\u5927\u8d8a\u597d\u201d\u7684\u89c2\u70b9\u5e76\u4e0d\u7edd\u5bf9\u6210\u7acb\u3002\u4f8b\u5982\uff0c\u4e0e\u5e94\u7528\u573a\u666f\u8bed\u4e49\u9002\u914d\u7684\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u4ee5\u53ca\u7f16\u7801\u65b9\u5f0f\u540c\u6837\u4f1a\u5bf9\u6a21\u578b\u6027\u80fd\u4ea7\u751f\u660e\u663e\u7684\u5f71\u54cd\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.add07d9f", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0MDY2ODM3NQ==&mid=2247488554&idx=1&sn=23c738b956b6d681f64442a008aa4a29&chksm=c3e1b9c4ffc4a7874adb3194133e3d3371f77d52a6eb0ca8d9c6d8cdcf1a9acfdfaf0eccdae9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0MDY2ODM3NQ==&mid=2247488554&idx=1&sn=23c738b956b6d681f64442a008aa4a29&chksm=c3e1b9c4ffc4a7874adb3194133e3d3371f77d52a6eb0ca8d9c6d8cdcf1a9acfdfaf0eccdae9#rd", "authors": ["AI\u5927\u6a21\u578b\u524d\u6cbf"], "title": "\u521a\u521a\uff0cOpenAI\u6700\u5f3a\u7f16\u7a0b<em class=\"highlight\">\u5927\u6a21\u578b</em>\u53d1\u5e03\uff01", "comment": "Source: WeChat, Published: 2025-12-19 00:35:01", "summary": "\u65b0\u6a21\u578b\u7684\u53d1\u5e03\u83b7\u5f97\u4e86\u4eba\u4eec\u7684\u666e\u904d\u5173\u6ce8\u3002\u5728\u5f00\u53d1\u8005\u793e\u533a\u4eba\u4eec\u8ba4\u4e3a\uff0c\u5982\u679c\u8bf4 Claude Code \u64c5\u957f\u300c\u539f\u59cb\u4ee3\u7801\u300d\uff0c\u90a3\u4e48 Codex/GPT5.x \u5728\u4ed4\u7ec6\u3001\u7cfb\u7edf\u5730\u67e5\u627e\u300c\u95ee\u9898\u300d\uff08\u65e0\u8bba\u662f\u4ee3\u7801\u95ee\u9898\u8fd8\u662f\u6570\u5b66\u95ee\u9898\uff09\u65b9\u9762\u5219\u662f\u65e0\u53ef\u5339\u654c\u7684\u3002", "AI": {"tldr": "\u65b0\u6a21\u578b\u7684\u53d1\u5e03\u83b7\u5f97\u4e86\u4eba\u4eec\u7684\u666e\u904d\u5173\u6ce8\u3002\u5728\u5f00\u53d1\u8005\u793e\u533a\u4eba\u4eec\u8ba4\u4e3a\uff0c\u5982\u679c\u8bf4 Claude Code \u64c5\u957f\u300c\u539f\u59cb\u4ee3\u7801\u300d\uff0c\u90a3\u4e48 Codex/GPT5.x \u5728\u4ed4\u7ec6\u3001\u7cfb\u7edf\u5730\u67e5\u627e\u300c\u95ee\u9898\u300d\uff08\u65e0\u8bba\u662f\u4ee3\u7801\u95ee\u9898\u8fd8\u662f\u6570\u5b66\u95ee\u9898\uff09\u65b9\u9762\u5219\u662f\u65e0\u53ef\u5339\u654c\u7684\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
