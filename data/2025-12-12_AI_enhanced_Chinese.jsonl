{"id": "2512.10173", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.10173", "abs": "https://arxiv.org/abs/2512.10173", "authors": ["Mantas Baksys", "Stefan Zetzsche", "Olivier Bouissou", "Remi Delmas", "Soonho Kong"], "title": "ATLAS: Automated Toolkit for Large-Scale Verified Code Synthesis", "comment": null, "summary": "Large language models have shown potential for program verification, but progress is hindered by the scarcity of verified code for training. We present ATLAS, an automated pipeline that synthesizes verified programs at scale to address this data bottleneck. ATLAS generates complete Dafny programs with specifications, implementations, and proofs, producing 2.7K verified programs from which we extract over 19K training examples--more than 7 per verified program--by decomposing the synthesis process into multiple specialized tasks. Fine-tuning Qwen 2.5 7B Coder on this dataset produces substantial gains: +23 percentage points on DafnyBench and +50 percentage points on DafnySynthesis. These results demonstrate that synthetic verified code can effectively enhance LLM capabilities for formal verification.", "AI": {"tldr": "ATLAS\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u901a\u8fc7\u5408\u6210\u5e26\u9a8c\u8bc1\u7684Dafny\u7a0b\u5e8f\u6765\u89e3\u51b3LLM\u7a0b\u5e8f\u9a8c\u8bc1\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u751f\u62102700\u4e2a\u9a8c\u8bc1\u7a0b\u5e8f\u548c19000\u591a\u4e2a\u8bad\u7ec3\u793a\u4f8b\uff0c\u663e\u8457\u63d0\u5347\u4e86Qwen 2.5 7B Coder\u5728Dafny\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7a0b\u5e8f\u9a8c\u8bc1\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u4ee3\u7801\u8bad\u7ec3\u6570\u636e\uff0c\u8fdb\u5c55\u53d7\u5230\u963b\u788d\u3002\u73b0\u6709\u7684\u9a8c\u8bc1\u4ee3\u7801\u7a00\u7f3a\uff0c\u9650\u5236\u4e86LLM\u5728\u5f62\u5f0f\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u63d0\u5347\u3002", "method": "ATLAS\u662f\u4e00\u4e2a\u81ea\u52a8\u5316\u7ba1\u9053\uff0c\u80fd\u591f\u5927\u89c4\u6a21\u5408\u6210\u7ecf\u8fc7\u9a8c\u8bc1\u7684Dafny\u7a0b\u5e8f\u3002\u5b83\u751f\u6210\u5b8c\u6574\u7684Dafny\u7a0b\u5e8f\uff0c\u5305\u62ec\u89c4\u8303\u3001\u5b9e\u73b0\u548c\u8bc1\u660e\u3002\u901a\u8fc7\u5c06\u5408\u6210\u8fc7\u7a0b\u5206\u89e3\u4e3a\u591a\u4e2a\u4e13\u95e8\u4efb\u52a1\uff0c\u4ece\u6bcf\u4e2a\u9a8c\u8bc1\u7a0b\u5e8f\u4e2d\u63d0\u53d6\u591a\u4e2a\u8bad\u7ec3\u793a\u4f8b\uff0c\u5171\u751f\u62102700\u4e2a\u9a8c\u8bc1\u7a0b\u5e8f\u548c19000\u591a\u4e2a\u8bad\u7ec3\u793a\u4f8b\u3002", "result": "\u5728ATLAS\u751f\u6210\u7684\u6570\u636e\u96c6\u4e0a\u5fae\u8c03Qwen 2.5 7B Coder\u6a21\u578b\uff0c\u5728DafnyBench\u4e0a\u63d0\u5347\u4e8623\u4e2a\u767e\u5206\u70b9\uff0c\u5728DafnySynthesis\u4e0a\u63d0\u5347\u4e8650\u4e2a\u767e\u5206\u70b9\uff0c\u663e\u793a\u51fa\u5408\u6210\u9a8c\u8bc1\u4ee3\u7801\u80fd\u6709\u6548\u589e\u5f3aLLM\u7684\u5f62\u5f0f\u9a8c\u8bc1\u80fd\u529b\u3002", "conclusion": "\u5408\u6210\u9a8c\u8bc1\u4ee3\u7801\u53ef\u4ee5\u6709\u6548\u89e3\u51b3LLM\u7a0b\u5e8f\u9a8c\u8bc1\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u5f62\u5f0f\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u7a0b\u5e8f\u9a8c\u8bc1\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u3002", "topic": "code agent"}}
{"id": "2512.10218", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.10218", "abs": "https://arxiv.org/abs/2512.10218", "authors": ["Thanosan Prathifkumar", "Noble Saji Mathews", "Meiyappan Nagappan"], "title": "Does SWE-Bench-Verified Test Agent Ability or Model Memory?", "comment": null, "summary": "SWE-Bench-Verified, a dataset comprising 500 issues, serves as a de facto benchmark for evaluating various large language models (LLMs) on their ability to resolve GitHub issues. But this benchmark may overlap with model training data. If that is true, scores may reflect training recall, not issue-solving skill. To study this, we test two Claude models that frequently appear in top-performing agents submitted to the benchmark. We ask them to find relevant files using only issue text, and then issue text plus file paths. We then run the same setup on BeetleBox and SWE-rebench. Despite both benchmarks involving popular open-source Python projects, models performed 3 times better on SWE-Bench-Verified. They were also 6 times better at finding edited files, without any additional context about the projects themselves. This gap suggests the models may have seen many SWE-Bench-Verified tasks during training. As a result, scores on this benchmark may not reflect an agent's ability to handle real software issues, yet it continues to be used in ways that can misrepresent progress and lead to choices that favour agents that use certain models over strong agent design. Our setup tests the localization step with minimal context to the extent that the task should be logically impossible to solve. Our results show the risk of relying on older popular benchmarks and support the shift toward newer datasets built with contamination in mind.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0SWE-Bench-Verified\u57fa\u51c6\u6d4b\u8bd5\u53ef\u80fd\u88ab\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\uff0c\u6a21\u578b\u8868\u73b0\u4f18\u5f02\u66f4\u591a\u6e90\u4e8e\u8bad\u7ec3\u8bb0\u5fc6\u800c\u975e\u771f\u5b9e\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u8fd9\u8bef\u5bfc\u4e86\u5bf9\u4ee3\u7801\u4ee3\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u3002", "motivation": "SWE-Bench-Verified\u4f5c\u4e3a\u8bc4\u4f30LLM\u89e3\u51b3GitHub\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53ef\u80fd\u5b58\u5728\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u5bfc\u81f4\u5206\u6570\u53cd\u6620\u7684\u662f\u8bad\u7ec3\u8bb0\u5fc6\u800c\u975e\u771f\u5b9e\u6280\u80fd\uff0c\u8fd9\u4f1a\u5f71\u54cd\u5bf9\u4ee3\u7801\u4ee3\u7406\u80fd\u529b\u7684\u51c6\u786e\u8bc4\u4f30\u3002", "method": "\u6d4b\u8bd5\u4e24\u4e2a\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u7684Claude\u6a21\u578b\uff0c\u8ba9\u5b83\u4eec\u4ec5\u4f7f\u7528\u95ee\u9898\u6587\u672c\u5b9a\u4f4d\u76f8\u5173\u6587\u4ef6\uff0c\u7136\u540e\u4f7f\u7528\u95ee\u9898\u6587\u672c\u52a0\u6587\u4ef6\u8def\u5f84\u3002\u5728BeetleBox\u548cSWE-rebench\u4e0a\u8fdb\u884c\u76f8\u540c\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u6a21\u578b\u5728\u4e0d\u540c\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u6a21\u578b\u5728SWE-Bench-Verified\u4e0a\u7684\u8868\u73b0\u6bd4\u5728\u5176\u4ed6\u57fa\u51c6\u4e0a\u597d3\u500d\uff0c\u5b9a\u4f4d\u7f16\u8f91\u6587\u4ef6\u7684\u80fd\u529b\u597d6\u500d\uff0c\u5c3d\u7ba1\u6ca1\u6709\u989d\u5916\u9879\u76ee\u4e0a\u4e0b\u6587\u3002\u8fd9\u8868\u660e\u6a21\u578b\u53ef\u80fd\u5728\u8bad\u7ec3\u4e2d\u89c1\u8fc7SWE-Bench-Verified\u4efb\u52a1\u3002", "conclusion": "SWE-Bench-Verified\u57fa\u51c6\u6d4b\u8bd5\u53ef\u80fd\u88ab\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\uff0c\u5206\u6570\u4e0d\u80fd\u53cd\u6620\u4ee3\u7406\u5904\u7406\u771f\u5b9e\u8f6f\u4ef6\u95ee\u9898\u7684\u80fd\u529b\uff0c\u7ee7\u7eed\u4f7f\u7528\u4f1a\u8bef\u5bfc\u8fdb\u5c55\u8bc4\u4f30\u548c\u4ee3\u7406\u8bbe\u8ba1\u9009\u62e9\uff0c\u9700\u8981\u8f6c\u5411\u8003\u8651\u6c61\u67d3\u95ee\u9898\u7684\u65b0\u6570\u636e\u96c6\u3002", "topic": "swe benchmark"}}
{"id": "2512.10238", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.10238", "abs": "https://arxiv.org/abs/2512.10238", "authors": ["Antu Saha"], "title": "Studying and Automating Issue Resolution for Software Quality", "comment": "3 pages", "summary": "Effective issue resolution is crucial for maintaining software quality. Yet developers frequently encounter challenges such as low-quality issue reports, limited understanding of real-world workflows, and a lack of automated support. This research aims to address these challenges through three complementary directions. First, we enhance issue report quality by proposing techniques that leverage LLM reasoning and application-specific information. Second, we empirically characterize developer workflows in both traditional and AI-augmented systems. Third, we automate cognitively demanding resolution tasks, including buggy UI localization and solution identification, through ML, DL, and LLM-based approaches. Together, our work delivers empirical insights, practical tools, and automated methods to advance AI-driven issue resolution, supporting more maintainable and high-quality software systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e09\u4e2a\u4e92\u8865\u65b9\u5411\u63d0\u5347\u8f6f\u4ef6\u95ee\u9898\u89e3\u51b3\u6548\u7387\uff1a1) \u5229\u7528LLM\u63a8\u7406\u548c\u5e94\u7528\u7279\u5b9a\u4fe1\u606f\u63d0\u9ad8\u95ee\u9898\u62a5\u544a\u8d28\u91cf\uff1b2) \u5b9e\u8bc1\u5206\u6790\u4f20\u7edf\u548cAI\u589e\u5f3a\u7cfb\u7edf\u4e2d\u7684\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u7a0b\uff1b3) \u901a\u8fc7ML\u3001DL\u548cLLM\u65b9\u6cd5\u81ea\u52a8\u5316bug\u5b9a\u4f4d\u548c\u89e3\u51b3\u65b9\u6848\u8bc6\u522b\u7b49\u8ba4\u77e5\u5bc6\u96c6\u578b\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e38\u89c1\u7684\u95ee\u9898\u89e3\u51b3\u6311\u6218\uff1a\u4f4e\u8d28\u91cf\u7684\u95ee\u9898\u62a5\u544a\u3001\u5bf9\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u7406\u89e3\u6709\u9650\u3001\u7f3a\u4e4f\u81ea\u52a8\u5316\u652f\u6301\u3002\u8fd9\u4e9b\u95ee\u9898\u5f71\u54cd\u8f6f\u4ef6\u8d28\u91cf\u548c\u7ef4\u62a4\u6548\u7387\u3002", "method": "\u91c7\u7528\u4e09\u4e2a\u4e92\u8865\u7684\u7814\u7a76\u65b9\u5411\uff1a1) \u5229\u7528LLM\u63a8\u7406\u548c\u5e94\u7528\u7279\u5b9a\u4fe1\u606f\u7684\u6280\u672f\u63d0\u5347\u95ee\u9898\u62a5\u544a\u8d28\u91cf\uff1b2) \u5b9e\u8bc1\u5206\u6790\u4f20\u7edf\u548cAI\u589e\u5f3a\u7cfb\u7edf\u4e2d\u7684\u5f00\u53d1\u8005\u5de5\u4f5c\u6d41\u7a0b\uff1b3) \u7ed3\u5408\u673a\u5668\u5b66\u4e60\u3001\u6df1\u5ea6\u5b66\u4e60\u548cLLM\u65b9\u6cd5\uff0c\u81ea\u52a8\u5316bug\u5b9a\u4f4d\u548c\u89e3\u51b3\u65b9\u6848\u8bc6\u522b\u7b49\u8ba4\u77e5\u5bc6\u96c6\u578b\u4efb\u52a1\u3002", "result": "\u5f00\u53d1\u4e86\u5b9e\u8bc1\u6d1e\u5bdf\u3001\u5b9e\u7528\u5de5\u5177\u548c\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u63a8\u8fdbAI\u9a71\u52a8\u7684\u95ee\u9898\u89e3\u51b3\uff0c\u652f\u6301\u66f4\u53ef\u7ef4\u62a4\u548c\u9ad8\u8d28\u91cf\u7684\u8f6f\u4ef6\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7\u7efc\u5408\u65b9\u6cd5\u63d0\u5347\u8f6f\u4ef6\u95ee\u9898\u89e3\u51b3\u6548\u7387\uff0c\u4e3aAI\u9a71\u52a8\u7684\u8f6f\u4ef6\u7ef4\u62a4\u63d0\u4f9b\u5b9e\u8bc1\u57fa\u7840\u3001\u5de5\u5177\u652f\u6301\u548c\u6280\u672f\u65b9\u6848\u3002", "topic": "swe application"}}
{"id": "2512.10393", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10393", "abs": "https://arxiv.org/abs/2512.10393", "authors": ["Guoqiang Chen", "Lingyun Ying", "Ziyang Song", "Daguang Liu", "Qiang Wang", "Zhiqi Wang", "Li Hu", "Shaoyin Cheng", "Weiming Zhang", "Nenghai Yu"], "title": "Cross-modal Retrieval Models for Stripped Binary Analysis", "comment": null, "summary": "LLM-agent based binary code analysis has demonstrated significant potential across a wide range of software security scenarios, including vulnerability detection, malware analysis, etc. In agent workflow, however, retrieving the positive from thousands of stripped binary functions based on user query remains under-studied and challenging, as the absence of symbolic information distinguishes it from source code retrieval. In this paper, we introduce, BinSeek, the first two-stage cross-modal retrieval framework for stripped binary code analysis. It consists of two models: BinSeekEmbedding is trained on large-scale dataset to learn the semantic relevance of the binary code and the natural language description, furthermore, BinSeek-Reranker learns to carefully judge the relevance of the candidate code to the description with context augmentation. To this end, we built an LLM-based data synthesis pipeline to automate training construction, also deriving a domain benchmark for future research. Our evaluation results show that BinSeek achieved the state-of-the-art performance, surpassing the the same scale models by 31.42% in Rec@3 and 27.17% in MRR@3, as well as leading the advanced general-purpose models that have 16 times larger parameters.", "AI": {"tldr": "BinSeek\uff1a\u9996\u4e2a\u4e24\u9636\u6bb5\u8de8\u6a21\u6001\u68c0\u7d22\u6846\u67b6\uff0c\u7528\u4e8e\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u4ee3\u7801\u5206\u6790\uff0c\u901a\u8fc7\u5d4c\u5165\u6a21\u578b\u548c\u91cd\u6392\u5e8f\u6a21\u578b\u5b9e\u73b0\u4e8c\u8fdb\u5236\u4ee3\u7801\u4e0e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u76f8\u5173\u6027\u5339\u914d\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u5728\u4e8c\u8fdb\u5236\u4ee3\u7801\u5206\u6790\u4e2d\u9762\u4e34\u6311\u6218\uff1a\u4ece\u6570\u5343\u4e2a\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u51fd\u6570\u4e2d\u68c0\u7d22\u76f8\u5173\u4ee3\u7801\u7247\u6bb5\u5f88\u56f0\u96be\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u7b26\u53f7\u4fe1\u606f\u4f7f\u5176\u4e0e\u6e90\u4ee3\u7801\u68c0\u7d22\u4e0d\u540c\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1) BinSeekEmbedding\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u5b66\u4e60\u4e8c\u8fdb\u5236\u4ee3\u7801\u4e0e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u8bed\u4e49\u76f8\u5173\u6027\uff1b2) BinSeek-Reranker\u901a\u8fc7\u4e0a\u4e0b\u6587\u589e\u5f3a\u4ed4\u7ec6\u5224\u65ad\u5019\u9009\u4ee3\u7801\u4e0e\u63cf\u8ff0\u7684\u76f8\u5173\u6027\u3002\u4f7f\u7528LLM\u6570\u636e\u5408\u6210\u7ba1\u9053\u81ea\u52a8\u5316\u8bad\u7ec3\u6570\u636e\u6784\u5efa\u3002", "result": "BinSeek\u53d6\u5f97\u6700\u5148\u8fdb\u6027\u80fd\uff1a\u5728Rec@3\u4e0a\u8d85\u8d8a\u540c\u89c4\u6a21\u6a21\u578b31.42%\uff0c\u5728MRR@3\u4e0a\u8d85\u8d8a27.17%\uff0c\u4e14\u9886\u5148\u53c2\u6570\u89c4\u6a21\u592716\u500d\u7684\u901a\u7528\u6a21\u578b\u3002", "conclusion": "BinSeek\u662f\u9996\u4e2a\u9488\u5bf9\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u4ee3\u7801\u5206\u6790\u7684\u4e24\u9636\u6bb5\u8de8\u6a21\u6001\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u5d4c\u5165\u548c\u91cd\u6392\u5e8f\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u4e8c\u8fdb\u5236\u4ee3\u7801\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u9886\u57df\u57fa\u51c6\u3002", "topic": "agent analysis"}}
{"id": "2512.10415", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10415", "abs": "https://arxiv.org/abs/2512.10415", "authors": ["Devanshu Sahoo", "Vasudev Majhi", "Arjun Neekhra", "Yash Sinha", "Murari Mandal", "Dhruv Kumar"], "title": "How to Trick Your AI TA: A Systematic Study of Academic Jailbreaking in LLM Code Evaluation", "comment": "Under Review", "summary": "The use of Large Language Models (LLMs) as automatic judges for code evaluation is becoming increasingly prevalent in academic environments. But their reliability can be compromised by students who may employ adversarial prompting strategies in order to induce misgrading and secure undeserved academic advantages. In this paper, we present the first large-scale study of jailbreaking LLM-based automated code evaluators in academic context. Our contributions are: (i) We systematically adapt 20+ jailbreaking strategies for jailbreaking AI code evaluators in the academic context, defining a new class of attacks termed academic jailbreaking. (ii) We release a poisoned dataset of 25K adversarial student submissions, specifically designed for the academic code-evaluation setting, sourced from diverse real-world coursework and paired with rubrics and human-graded references, and (iii) In order to capture the multidimensional impact of academic jailbreaking, we systematically adapt and define three jailbreaking metrics (Jailbreak Success Rate, Score Inflation, and Harmfulness). (iv) We comprehensively evalulate the academic jailbreaking attacks using six LLMs. We find that these models exhibit significant vulnerability, particularly to persuasive and role-play-based attacks (up to 97% JSR). Our adversarial dataset and benchmark suite lay the groundwork for next-generation robust LLM-based evaluators in academic code assessment.", "AI": {"tldr": "\u9996\u6b21\u5927\u89c4\u6a21\u7814\u7a76\u5b66\u672f\u73af\u5883\u4e2d\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u8bc4\u4f30\u5668\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u63d0\u51fa\u5b66\u672f\u8d8a\u72f1\u6982\u5ff5\uff0c\u53d1\u5e03\u5305\u542b2.5\u4e07\u5bf9\u6297\u6027\u63d0\u4ea4\u7684\u6570\u636e\u96c6\uff0c\u8bc4\u4f306\u4e2aLLM\u7684\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u8bf4\u670d\u6027\u548c\u89d2\u8272\u626e\u6f14\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe97%", "motivation": "LLM\u4f5c\u4e3a\u4ee3\u7801\u8bc4\u4f30\u81ea\u52a8\u8bc4\u5224\u5668\u5728\u5b66\u672f\u73af\u5883\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5b66\u751f\u53ef\u80fd\u4f7f\u7528\u5bf9\u6297\u6027\u63d0\u793a\u7b56\u7565\u8bf1\u5bfc\u8bef\u5224\u4ee5\u83b7\u53d6\u4e0d\u5f53\u5b66\u672f\u4f18\u52bf\uff0c\u9700\u8981\u7814\u7a76\u8fd9\u79cd\u5b66\u672f\u8d8a\u72f1\u653b\u51fb\u7684\u53ef\u9760\u6027\u548c\u5f71\u54cd", "method": "\u7cfb\u7edf\u6027\u5730\u5c0620\u591a\u79cd\u8d8a\u72f1\u7b56\u7565\u9002\u914d\u5230\u5b66\u672f\u4ee3\u7801\u8bc4\u4f30\u573a\u666f\uff0c\u5b9a\u4e49\u5b66\u672f\u8d8a\u72f1\u653b\u51fb\u7c7b\u522b\uff1b\u53d1\u5e03\u5305\u542b2.5\u4e07\u5bf9\u6297\u6027\u5b66\u751f\u63d0\u4ea4\u7684\u6bd2\u5316\u6570\u636e\u96c6\uff1b\u5b9a\u4e49\u4e09\u4e2a\u8d8a\u72f1\u5ea6\u91cf\u6307\u6807\uff08\u8d8a\u72f1\u6210\u529f\u7387\u3001\u5206\u6570\u81a8\u80c0\u3001\u5371\u5bb3\u6027\uff09\uff1b\u4f7f\u75286\u4e2aLLM\u5168\u9762\u8bc4\u4f30\u5b66\u672f\u8d8a\u72f1\u653b\u51fb", "result": "\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u8868\u73b0\u51fa\u663e\u8457\u8106\u5f31\u6027\uff0c\u7279\u522b\u662f\u5bf9\u8bf4\u670d\u6027\u548c\u89d2\u8272\u626e\u6f14\u653b\u51fb\uff08\u8d8a\u72f1\u6210\u529f\u7387\u9ad8\u8fbe97%\uff09\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u9c81\u68d2\u7684\u57fa\u4e8eLLM\u7684\u5b66\u672f\u4ee3\u7801\u8bc4\u4f30\u5668\u5960\u5b9a\u57fa\u7840", "conclusion": "\u5b66\u672f\u73af\u5883\u4e2dLLM\u4ee3\u7801\u8bc4\u4f30\u5668\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u8bc4\u4f30\u7cfb\u7edf\uff0c\u53d1\u5e03\u7684\u5bf9\u6297\u6027\u6570\u636e\u96c6\u548c\u57fa\u51c6\u5957\u4ef6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840", "topic": "agent analysis"}}
{"id": "2512.10121", "categories": ["cs.CL", "cs.AI", "cs.CY", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2512.10121", "abs": "https://arxiv.org/abs/2512.10121", "authors": ["Zhongjie Jiang"], "title": "Workflow is All You Need: Escaping the \"Statistical Smoothing Trap\" via High-Entropy Information Foraging and Adversarial Pacing", "comment": "22 pages, 8 figures. Includes an ecological validity blind test where the Agentic Workflow achieved a 25% acceptance rate in top-tier media, decisively outperforming the SOTA Zero-shot baseline (0%). Features the DNFO-v5 ontology", "summary": "Central to long-form text generation in vertical domains is the \"impossible trinity\" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).", "AI": {"tldr": "DeepNews\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u91d1\u878d\u8bb0\u8005\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff0c\u91c7\u7528\u53cc\u7c92\u5ea6\u68c0\u7d22\u3001\u6a21\u5f0f\u5f15\u5bfc\u6218\u7565\u89c4\u5212\u548c\u5bf9\u6297\u7ea6\u675f\u63d0\u793a\uff0c\u89e3\u51b3\u4e86\u957f\u6587\u672c\u751f\u6210\u4e2d\u7684\"\u4e0d\u53ef\u80fd\u4e09\u89d2\"\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u91d1\u878d\u62a5\u9053\u7684\u771f\u5b9e\u6027\u548c\u903b\u8f91\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5782\u76f4\u9886\u57df\u957f\u6587\u672c\u751f\u6210\u4e2d\u5b58\u5728\"\u4e0d\u53ef\u80fd\u4e09\u89d2\"\u74f6\u9888\uff1a\u96be\u4ee5\u540c\u65f6\u5b9e\u73b0\u4f4e\u5e7b\u89c9\u3001\u6df1\u5ea6\u903b\u8f91\u8fde\u8d2f\u6027\u548c\u4e2a\u6027\u5316\u8868\u8fbe\u3002\u7814\u7a76\u53d1\u73b0\u8fd9\u662f\u7531\u4e8e\u73b0\u6709\u751f\u6210\u8303\u5f0f\u9677\u5165\"\u7edf\u8ba1\u5e73\u6ed1\u9677\u9631\"\uff0c\u5ffd\u89c6\u4e86\u4e13\u5bb6\u5199\u4f5c\u6240\u9700\u7684\u9ad8\u71b5\u4fe1\u606f\u83b7\u53d6\u548c\u7ed3\u6784\u5316\u8ba4\u77e5\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faDeepNews\u6846\u67b6\uff0c\u6a21\u62df\u8d44\u6df1\u91d1\u878d\u8bb0\u8005\u7684\u8ba4\u77e5\u8fc7\u7a0b\uff1a1)\u57fa\u4e8e\u4fe1\u606f\u89c5\u98df\u7406\u8bba\u7684\u53cc\u7c92\u5ea6\u68c0\u7d22\u673a\u5236\uff0c\u5f3a\u5236\u6267\u884c10:1\u9971\u548c\u4fe1\u606f\u8f93\u5165\u6bd4\uff1b2)\u6a21\u5f0f\u5f15\u5bfc\u6218\u7565\u89c4\u5212\uff0c\u5229\u7528\u9886\u57df\u4e13\u5bb6\u77e5\u8bc6\u5e93\u548c\u539f\u5b50\u5757\u6784\u5efa\u903b\u8f91\u9aa8\u67b6\uff1b3)\u5bf9\u6297\u7ea6\u675f\u63d0\u793a\uff0c\u4f7f\u7528\u8282\u594f\u6253\u7834\u548c\u903b\u8f91\u8ff7\u96fe\u7b49\u6280\u672f\u7834\u574f\u6a21\u578b\u751f\u6210\u6587\u672c\u7684\u6982\u7387\u5e73\u6ed1\u6027\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u91d1\u878d\u6df1\u5ea6\u62a5\u9053\u4e2d\u5b58\u5728\"\u77e5\u8bc6\u60ac\u5d16\"\uff1a\u5f53\u68c0\u7d22\u4e0a\u4e0b\u6587\u4f4e\u4e8e15,000\u5b57\u7b26\u65f6\u5185\u5bb9\u771f\u5b9e\u6027\u5d29\u6e83\uff0c\u800c\u8d85\u8fc730,000\u5b57\u7b26\u7684\u9ad8\u5197\u4f59\u8f93\u5165\u53ef\u5c06\u65e0\u5e7b\u89c9\u7387\u7a33\u5b9a\u572885%\u4ee5\u4e0a\u3002\u5728\u76f2\u6d4b\u4e2d\uff0c\u57fa\u4e8e\u65e7\u6a21\u578b\u6784\u5efa\u7684DeepNews\u7cfb\u7edf\u83b7\u5f9725%\u7684\u63d0\u4ea4\u63a5\u53d7\u7387\uff0c\u663e\u8457\u4f18\u4e8eSOTA\u6a21\u578b\u7684\u96f6\u6837\u672c\u751f\u6210(0%)\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u4e13\u5bb6\u8ba4\u77e5\u8fc7\u7a0b\uff0cDeepNews\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u957f\u6587\u672c\u751f\u6210\u7684\"\u4e0d\u53ef\u80fd\u4e09\u89d2\"\u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u5728\u63d0\u5347\u5782\u76f4\u9886\u57df\u6587\u672c\u751f\u6210\u8d28\u91cf\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "topic": "agent analysis"}}
{"id": "2512.10016", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10016", "abs": "https://arxiv.org/abs/2512.10016", "authors": ["Marvin Alles", "Xingyuan Zhang", "Patrick van der Smagt", "Philip Becker-Ehmck"], "title": "Latent Action World Models for Control with Unlabeled Trajectories", "comment": null, "summary": "Inspired by how humans combine direct interaction with action-free experience (e.g., videos), we study world models that learn from heterogeneous data. Standard world models typically rely on action-conditioned trajectories, which limits effectiveness when action labels are scarce. We introduce a family of latent-action world models that jointly use action-conditioned and action-free data by learning a shared latent action representation. This latent space aligns observed control signals with actions inferred from passive observations, enabling a single dynamics model to train on large-scale unlabeled trajectories while requiring only a small set of action-labeled ones. We use the latent-action world model to learn a latent-action policy through offline reinforcement learning (RL), thereby bridging two traditionally separate domains: offline RL, which typically relies on action-conditioned data, and action-free training, which is rarely used with subsequent RL. On the DeepMind Control Suite, our approach achieves strong performance while using about an order of magnitude fewer action-labeled samples than purely action-conditioned baselines. These results show that latent actions enable training on both passive and interactive data, which makes world models learn more efficiently.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6f5c\u5728\u52a8\u4f5c\u4e16\u754c\u6a21\u578b\uff0c\u901a\u8fc7\u8054\u5408\u4f7f\u7528\u52a8\u4f5c\u6761\u4ef6\u6570\u636e\u548c\u65e0\u52a8\u4f5c\u6570\u636e\uff0c\u5b66\u4e60\u5171\u4eab\u7684\u6f5c\u5728\u52a8\u4f5c\u8868\u793a\uff0c\u4ece\u800c\u5728\u5c11\u91cf\u52a8\u4f5c\u6807\u7b7e\u6837\u672c\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684\u4e16\u754c\u6a21\u578b\u5b66\u4e60\u3002", "motivation": "\u4f20\u7edf\u4e16\u754c\u6a21\u578b\u4f9d\u8d56\u52a8\u4f5c\u6761\u4ef6\u8f68\u8ff9\uff0c\u5f53\u52a8\u4f5c\u6807\u7b7e\u7a00\u7f3a\u65f6\u6548\u679c\u53d7\u9650\u3002\u53d7\u4eba\u7c7b\u7ed3\u5408\u76f4\u63a5\u4ea4\u4e92\u548c\u65e0\u52a8\u4f5c\u7ecf\u9a8c\uff08\u5982\u89c6\u9891\uff09\u7684\u542f\u53d1\uff0c\u9700\u8981\u80fd\u591f\u5229\u7528\u5f02\u6784\u6570\u636e\u7684\u4e16\u754c\u6a21\u578b\u3002", "method": "\u5f15\u5165\u6f5c\u5728\u52a8\u4f5c\u4e16\u754c\u6a21\u578b\u5bb6\u65cf\uff0c\u5b66\u4e60\u5171\u4eab\u7684\u6f5c\u5728\u52a8\u4f5c\u8868\u793a\uff0c\u5c06\u89c2\u5bdf\u5230\u7684\u63a7\u5236\u4fe1\u53f7\u4e0e\u88ab\u52a8\u89c2\u5bdf\u63a8\u65ad\u7684\u52a8\u4f5c\u5bf9\u9f50\u3002\u4f7f\u7528\u8be5\u6a21\u578b\u901a\u8fc7\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u6f5c\u5728\u52a8\u4f5c\u7b56\u7565\u3002", "result": "\u5728DeepMind Control Suite\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4f7f\u7528\u6bd4\u7eaf\u52a8\u4f5c\u6761\u4ef6\u57fa\u7ebf\u5c11\u7ea6\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u52a8\u4f5c\u6807\u7b7e\u6837\u672c\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u3002", "conclusion": "\u6f5c\u5728\u52a8\u4f5c\u4f7f\u4e16\u754c\u6a21\u578b\u80fd\u591f\u540c\u65f6\u5229\u7528\u88ab\u52a8\u548c\u4ea4\u4e92\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\uff0c\u5f25\u5408\u4e86\u79bb\u7ebfRL\u548c\u65e0\u52a8\u4f5c\u8bad\u7ec3\u8fd9\u4e24\u4e2a\u4f20\u7edf\u4e0a\u5206\u79bb\u7684\u9886\u57df\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.10452", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.10452", "abs": "https://arxiv.org/abs/2512.10452", "authors": ["Yang Yang", "Li Kuang", "Jiakun Liu", "Zhongxin Liu", "Yingjie Xia", "David Lo"], "title": "UniCoR: Modality Collaboration for Robust Cross-Language Hybrid Code Retrieval", "comment": "Accepted by the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026)", "summary": "Effective code retrieval is indispensable and it has become an important paradigm to search code in hybrid mode using both natural language and code snippets. Nevertheless, it remains unclear whether existing approaches can effectively leverage such hybrid queries, particularly in cross-language contexts. We conduct a comprehensive empirical study of representative code models and reveal three challenges: (1) insufficient semantic understanding; (2) inefficient fusion in hybrid code retrieval; and (3) weak generalization in cross-language scenarios. To address these challenges, we propose UniCoR, a novel self-supervised framework that learns Unified Code Representations framework designed to learn unified and robust code representations. Firstly, we design a multi-perspective supervised contrastive learning module to enhance semantic understanding and modality fusion. It aligns representations from multiple perspectives, including code-to-code, natural language-to-code, and natural language-to-natural language, enforcing the model to capture a semantic essence among modalities. Secondly, we introduce a representation distribution consistency learning module to improve cross-language generalization, which explicitly aligns the feature distributions of different programming languages, enabling language-agnostic representation learning. Extensive experiments on both empirical benchmark and large-scale benchmark show that UniCoR outperforms all baseline models, achieving an average improvement of 8.64% in MRR and 11.54% in MAP over the best-performing baseline. Furthermore, UniCoR exhibits stability in hybrid code retrieval and generalization capability in cross-language scenarios.", "AI": {"tldr": "UniCoR\u662f\u4e00\u4e2a\u81ea\u76d1\u7763\u7684\u7edf\u4e00\u4ee3\u7801\u8868\u793a\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u5bf9\u6bd4\u5b66\u4e60\u548c\u5206\u5e03\u4e00\u81f4\u6027\u5b66\u4e60\uff0c\u89e3\u51b3\u4e86\u6df7\u5408\u4ee3\u7801\u68c0\u7d22\u4e2d\u7684\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3\u3001\u6a21\u6001\u878d\u5408\u6548\u7387\u4f4e\u548c\u8de8\u8bed\u8a00\u6cdb\u5316\u5f31\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u68c0\u7d22\u65b9\u6cd5\u5728\u6df7\u5408\u67e5\u8be2\uff08\u81ea\u7136\u8bed\u8a00+\u4ee3\u7801\u7247\u6bb5\uff09\u548c\u8de8\u8bed\u8a00\u573a\u666f\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u8bed\u4e49\u7406\u89e3\u4e0d\u8db3\u3001\u6a21\u6001\u878d\u5408\u6548\u7387\u4f4e\u3001\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u5f31\u3002", "method": "\u63d0\u51faUniCoR\u6846\u67b6\uff1a1\uff09\u591a\u89c6\u89d2\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6a21\u5757\uff0c\u4ece\u4ee3\u7801-\u4ee3\u7801\u3001\u81ea\u7136\u8bed\u8a00-\u4ee3\u7801\u3001\u81ea\u7136\u8bed\u8a00-\u81ea\u7136\u8bed\u8a00\u591a\u4e2a\u89c6\u89d2\u5bf9\u9f50\u8868\u793a\uff1b2\uff09\u8868\u793a\u5206\u5e03\u4e00\u81f4\u6027\u5b66\u4e60\u6a21\u5757\uff0c\u663e\u5f0f\u5bf9\u9f50\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u7684\u7279\u5f81\u5206\u5e03\u3002", "result": "\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUniCoR\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u6a21\u578b\uff0cMRR\u5e73\u5747\u63d0\u53478.64%\uff0cMAP\u5e73\u5747\u63d0\u534711.54%\uff0c\u5728\u6df7\u5408\u4ee3\u7801\u68c0\u7d22\u4e2d\u8868\u73b0\u7a33\u5b9a\uff0c\u5728\u8de8\u8bed\u8a00\u573a\u666f\u4e2d\u5177\u6709\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "UniCoR\u901a\u8fc7\u7edf\u4e00\u8868\u793a\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u6df7\u5408\u4ee3\u7801\u68c0\u7d22\u7684\u6311\u6218\uff0c\u4e3a\u8de8\u8bed\u8a00\u4ee3\u7801\u641c\u7d22\u63d0\u4f9b\u4e86\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "code agent"}}
{"id": "2512.10493", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.10493", "abs": "https://arxiv.org/abs/2512.10493", "authors": ["Binquan Zhang", "Li Zhang", "Haoyuan Zhang", "Fang Liu", "Song Wang", "Bo Shen", "An Fu", "Lin Shi"], "title": "Decoding Human-LLM Collaboration in Coding: An Empirical Study of Multi-Turn Conversations in the Wild", "comment": null, "summary": "Large language models (LLMs) are increasingly acting as dynamic conversational interfaces, supporting multi-turn interactions that mimic human-like conversation and facilitate complex tasks like coding. While datasets such as LMSYS-Chat-1M and WildChat capture real-world user-LLM conversations, few studies systematically explore the mechanisms of human-LLM collaboration in coding scenarios. What tortuous paths do users experience during the interaction process? How well do the LLMs follow instructions? Are users satisfied? In this paper, we conduct an empirical analysis on human-LLM coding collaboration using LMSYS-Chat-1M and WildChat datasets to explore the human-LLM collaboration mechanism, LLMs' instruction following ability, and human satisfaction. This study yields interesting findings: 1) Task types shape interaction patterns(linear, star and tree), with code quality optimization favoring linear patterns, design-driven tasks leaning toward tree structures, and queries preferring star patterns; 2) Bug fixing and code refactoring pose greater challenges to LLMs' instruction following, with non-compliance rates notably higher than in information querying; 3) Code quality optimization and requirements-driven development tasks show lower user satisfaction, whereas structured knowledge queries and algorithm designs yield higher levels. These insights offer recommendations for improving LLM interfaces and user satisfaction in coding collaborations, while highlighting avenues for future research on adaptive dialogue systems. We believe this work broadens understanding of human-LLM synergies and supports more effective AI-assisted development.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9LMSYS-Chat-1M\u548cWildChat\u6570\u636e\u96c6\u4e2d\u4eba\u7c7b\u4e0eLLM\u5728\u7f16\u7801\u534f\u4f5c\u4e2d\u7684\u4ea4\u4e92\u6a21\u5f0f\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5206\u6790\uff0c\u7814\u7a76\u4e86\u4ea4\u4e92\u673a\u5236\u3001\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "motivation": "\u5c3d\u7ba1\u5b58\u5728LMSYS-Chat-1M\u548cWildChat\u7b49\u771f\u5b9e\u4e16\u754c\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u7cfb\u7edf\u63a2\u7d22\u7f16\u7801\u573a\u666f\u4e2d\u4eba\u7c7b\u4e0eLLM\u534f\u4f5c\u7684\u673a\u5236\uff0c\u5305\u62ec\u7528\u6237\u4ea4\u4e92\u8def\u5f84\u3001LLM\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u548c\u7528\u6237\u6ee1\u610f\u5ea6\u3002", "method": "\u4f7f\u7528LMSYS-Chat-1M\u548cWildChat\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u63a2\u7d22\u4eba\u7c7b-LLM\u534f\u4f5c\u673a\u5236\u3001LLM\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u548c\u4eba\u7c7b\u6ee1\u610f\u5ea6\u3002", "result": "1) \u4efb\u52a1\u7c7b\u578b\u5851\u9020\u4ea4\u4e92\u6a21\u5f0f\uff08\u7ebf\u6027\u3001\u661f\u5f62\u548c\u6811\u5f62\uff09\uff1b2) \u9519\u8bef\u4fee\u590d\u548c\u4ee3\u7801\u91cd\u6784\u5bf9LLM\u6307\u4ee4\u9075\u5faa\u66f4\u5177\u6311\u6218\u6027\uff1b3) \u4ee3\u7801\u8d28\u91cf\u4f18\u5316\u548c\u9700\u6c42\u9a71\u52a8\u5f00\u53d1\u4efb\u52a1\u7528\u6237\u6ee1\u610f\u5ea6\u8f83\u4f4e\uff0c\u800c\u7ed3\u6784\u5316\u77e5\u8bc6\u67e5\u8be2\u548c\u7b97\u6cd5\u8bbe\u8ba1\u6ee1\u610f\u5ea6\u8f83\u9ad8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6539\u8fdbLLM\u754c\u9762\u548c\u7f16\u7801\u534f\u4f5c\u4e2d\u7684\u7528\u6237\u6ee1\u610f\u5ea6\u63d0\u4f9b\u4e86\u5efa\u8bae\uff0c\u540c\u65f6\u4e3a\u81ea\u9002\u5e94\u5bf9\u8bdd\u7cfb\u7edf\u7684\u672a\u6765\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\uff0c\u6709\u52a9\u4e8e\u66f4\u6709\u6548\u7684AI\u8f85\u52a9\u5f00\u53d1\u3002", "topic": "agent analysis"}}
{"id": "2512.10195", "categories": ["cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.10195", "abs": "https://arxiv.org/abs/2512.10195", "authors": ["Gyutaek Oh", "Sangjoon Park", "Byung-Hoon Kim"], "title": "AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding", "comment": null, "summary": "Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.", "AI": {"tldr": "AutoMedic\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u4e34\u5e8a\u5bf9\u8bdd\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u5c06\u9759\u6001\u533b\u7597\u95ee\u7b54\u6570\u636e\u96c6\u8f6c\u6362\u4e3a\u865a\u62df\u60a3\u8005\u6863\u6848\uff0c\u901a\u8fc7CARE\u6307\u6807\u8fdb\u884c\u591a\u7ef4\u5ea6\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u533b\u7597\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5b58\u5728\u5c40\u9650\uff1a\u9759\u6001\u95ee\u7b54\u57fa\u51c6\u65e0\u6cd5\u8bc4\u4f30\u52a8\u6001\u4ea4\u4e92\u5f0f\u4e34\u5e8a\u5bf9\u8bdd\u573a\u666f\uff0c\u4e14\u7f3a\u4e4f\u591a\u7ef4\u5ea6\u8bc4\u4f30\u7b56\u7565\u3002\u52a8\u6001\u4e34\u5e8a\u60c5\u5883\u8bc4\u4f30\u9762\u4e34\u7ec4\u5408\u7a7a\u95f4\u5e9e\u5927\u3001\u96be\u4ee5\u6807\u51c6\u5316\u548c\u5b9a\u91cf\u6d4b\u91cf\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faAutoMedic\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff0c\u5c06\u73b0\u6210\u7684\u9759\u6001\u533b\u7597\u95ee\u7b54\u6570\u636e\u96c6\u8f6c\u6362\u4e3a\u865a\u62df\u60a3\u8005\u6863\u6848\uff0c\u5b9e\u73b0LLM\u667a\u80fd\u4f53\u4e4b\u95f4\u771f\u5b9e\u3001\u4e34\u5e8a\u57fa\u7840\u7684\u591a\u8f6e\u4e34\u5e8a\u5bf9\u8bdd\u3002\u4f7f\u7528CARE\u6307\u6807\uff08\u4e34\u5e8a\u5bf9\u8bdd\u51c6\u786e\u6027\u3001\u6548\u7387/\u7b56\u7565\u3001\u540c\u7406\u5fc3\u3001\u9c81\u68d2\u6027\uff09\u8fdb\u884c\u591a\u7ef4\u5ea6\u8bc4\u4f30\u3002", "result": "AutoMedic\u88ab\u9a8c\u8bc1\u4e3a\u4e34\u5e8a\u5bf9\u8bdd\u4ee3\u7406\u7684\u6709\u6548\u81ea\u52a8\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a\u5bf9\u8bdd\u5f0f\u533b\u7597\u5e94\u7528\u4e2dLLM\u7684\u6709\u6548\u5f00\u53d1\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u3002\u4eba\u7c7b\u4e13\u5bb6\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "AutoMedic\u89e3\u51b3\u4e86\u533b\u7597\u9886\u57dfLLM\u8bc4\u4f30\u7684\u5173\u952e\u6311\u6218\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6a21\u62df\u548cCARE\u591a\u7ef4\u5ea6\u6307\u6807\uff0c\u4e3a\u4e34\u5e8a\u5bf9\u8bdd\u4ee3\u7406\u7684\u6807\u51c6\u5316\u3001\u5b9a\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2512.10713", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10713", "abs": "https://arxiv.org/abs/2512.10713", "authors": ["Itay Dreyfuss", "Antonio Abu Nassar", "Samuel Ackerman", "Axel Ben David", "Rami Katan", "Orna Raz", "Marcel Zalmanovici"], "title": "PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code", "comment": null, "summary": "Large Language Model (LLM)-based code assistants have emerged as a powerful application of generative AI, demonstrating impressive capabilities in code generation and comprehension. A key requirement for these systems is their ability to accurately follow user instructions. We present Precise Automatically Checked Instruction Following In Code (PACIFIC), a novel framework designed to automatically generate benchmarks that rigorously assess sequential instruction-following and code dry-running capabilities in LLMs, while allowing control over benchmark difficulty. PACIFIC produces benchmark variants with clearly defined expected outputs, enabling straightforward and reliable evaluation through simple output comparisons. In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM's intrinsic ability to reason through code behavior step-by-step without execution (dry running) and to follow instructions. Furthermore, our framework mitigates training data contamination by facilitating effortless generation of novel benchmark variations. We validate our framework by generating a suite of benchmarks spanning a range of difficulty levels and evaluating multiple state-of-the-art LLMs. Our results demonstrate that PACIFIC can produce increasingly challenging benchmarks that effectively differentiate instruction-following and dry running capabilities, even among advanced models. Overall, our framework offers a scalable, contamination-resilient methodology for assessing core competencies of LLMs in code-related tasks.", "AI": {"tldr": "PACIFIC\u6846\u67b6\u81ea\u52a8\u751f\u6210\u8bc4\u4f30LLM\u4ee3\u7801\u52a9\u624b\u987a\u5e8f\u6307\u4ee4\u8ddf\u968f\u548c\u4ee3\u7801\u5e72\u8fd0\u884c\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u63a7\u5236\u96be\u5ea6\u751f\u6210\u53d8\u4f53\uff0c\u907f\u514d\u6570\u636e\u6c61\u67d3\uff0c\u6709\u6548\u533a\u5206\u4e0d\u540c\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5f80\u5f80\u4f9d\u8d56\u5de5\u5177\u4f7f\u7528\u6216\u4ee3\u7406\u884c\u4e3a\uff0c\u96be\u4ee5\u9694\u79bb\u8bc4\u4f30LLM\u5185\u5728\u7684\u4ee3\u7801\u5e72\u8fd0\u884c\uff08\u4e0d\u6267\u884c\u4ee3\u7801\u7684\u9010\u6b65\u63a8\u7406\uff09\u548c\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u4e14\u5b58\u5728\u8bad\u7ec3\u6570\u636e\u6c61\u67d3\u95ee\u9898\u3002", "method": "\u63d0\u51faPACIFIC\u6846\u67b6\uff0c\u81ea\u52a8\u751f\u6210\u5177\u6709\u660e\u786e\u5b9a\u4e49\u671f\u671b\u8f93\u51fa\u7684\u57fa\u51c6\u6d4b\u8bd5\u53d8\u4f53\uff0c\u63a7\u5236\u96be\u5ea6\u7ea7\u522b\uff0c\u901a\u8fc7\u7b80\u5355\u8f93\u51fa\u6bd4\u8f83\u8fdb\u884c\u53ef\u9760\u8bc4\u4f30\uff0c\u907f\u514d\u5de5\u5177\u4f7f\u7528\u6216\u4ee3\u7406\u884c\u4e3a\u5e72\u6270\u3002", "result": "\u751f\u6210\u6db5\u76d6\u4e0d\u540c\u96be\u5ea6\u7ea7\u522b\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u8bc4\u4f30\u591a\u4e2aSOTA LLM\uff0c\u7ed3\u679c\u663e\u793aPACIFIC\u80fd\u4ea7\u751f\u8d8a\u6765\u8d8a\u5177\u6311\u6218\u6027\u7684\u57fa\u51c6\uff0c\u6709\u6548\u533a\u5206\u4e0d\u540c\u6a21\u578b\u5728\u6307\u4ee4\u8ddf\u968f\u548c\u5e72\u8fd0\u884c\u65b9\u9762\u7684\u80fd\u529b\u5dee\u5f02\u3002", "conclusion": "PACIFIC\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u6297\u6c61\u67d3\u7684\u65b9\u6cd5\u8bba\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\u4e2d\u7684\u6838\u5fc3\u80fd\u529b\uff0c\u7279\u522b\u662f\u987a\u5e8f\u6307\u4ee4\u8ddf\u968f\u548c\u4ee3\u7801\u5e72\u8fd0\u884c\u80fd\u529b\u3002", "topic": "agent analysis"}}
{"id": "2512.10034", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2512.10034", "abs": "https://arxiv.org/abs/2512.10034", "authors": ["Salom\u00e9 Guilbert", "Cassandra Masschelein", "Jeremy Goumaz", "Bohdan Naida", "Philippe Schwaller"], "title": "DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations", "comment": null, "summary": "Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD setup, encompassing parameterization, input preparation, and software configuration, remains a major barrier for widespread and efficient usage. Agentic LLMs have demonstrated their capacity to autonomously execute multi-step scientific processes, and to date, they have not successfully been used to automate protein-ligand MD workflows. Here, we present DynaMate, a modular multi-agent framework that autonomously designs and executes complete MD workflows for both protein and protein-ligand systems, and offers free energy binding affinity calculations with the MM/PB(GB)SA method. The framework integrates dynamic tool use, web search, PaperQA, and a self-correcting behavior. DynaMate comprises three specialized modules, interacting to plan the experiment, perform the simulation, and analyze the results. We evaluated its performance across twelve benchmark systems of varying complexity, assessing success rate, efficiency, and adaptability. DynaMate reliably performed full MD simulations, corrected runtime errors through iterative reasoning, and produced meaningful analyses of protein-ligand interactions. This automated framework paves the way toward standardized, scalable, and time-efficient molecular modeling pipelines for future biomolecular and drug design applications.", "AI": {"tldr": "DynaMate\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53LLM\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u4e3b\u8bbe\u8ba1\u548c\u6267\u884c\u86cb\u767d\u8d28\u53ca\u86cb\u767d\u8d28-\u914d\u4f53\u590d\u5408\u7269\u7684\u5b8c\u6574\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ec\u81ea\u7531\u80fd\u7ed3\u5408\u4eb2\u548c\u529b\u8ba1\u7b97\u3002", "motivation": "\u5c3d\u7ba1\u5206\u5b50\u52a8\u529b\u5b66\u6a21\u62df\u5728\u836f\u7269\u53d1\u73b0\u548c\u86cb\u767d\u8d28\u5de5\u7a0b\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5176\u6280\u672f\u590d\u6742\u6027\uff08\u53c2\u6570\u5316\u3001\u8f93\u5165\u51c6\u5907\u3001\u8f6f\u4ef6\u914d\u7f6e\uff09\u6210\u4e3a\u5e7f\u6cdb\u9ad8\u6548\u4f7f\u7528\u7684\u4e3b\u8981\u969c\u788d\u3002\u76ee\u524d\u5c1a\u672a\u6709\u6210\u529f\u7684\u57fa\u4e8e\u667a\u80fd\u4f53LLM\u7684\u81ea\u52a8\u5316\u86cb\u767d\u8d28-\u914d\u4f53MD\u5de5\u4f5c\u6d41\u7a0b\u89e3\u51b3\u65b9\u6848\u3002", "method": "DynaMate\u91c7\u7528\u6a21\u5757\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u4e13\u95e8\u6a21\u5757\uff1a\u5b9e\u9a8c\u89c4\u5212\u3001\u6a21\u62df\u6267\u884c\u548c\u7ed3\u679c\u5206\u6790\u3002\u6846\u67b6\u96c6\u6210\u4e86\u52a8\u6001\u5de5\u5177\u4f7f\u7528\u3001\u7f51\u7edc\u641c\u7d22\u3001PaperQA\u548c\u81ea\u6821\u6b63\u884c\u4e3a\uff0c\u80fd\u591f\u81ea\u4e3b\u8bbe\u8ba1\u5e76\u6267\u884c\u5b8c\u6574\u7684MD\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5305\u62ecMM/PB(GB)SA\u65b9\u6cd5\u7684\u81ea\u7531\u80fd\u7ed3\u5408\u4eb2\u548c\u529b\u8ba1\u7b97\u3002", "result": "\u572812\u4e2a\u4e0d\u540c\u590d\u6742\u5ea6\u7684\u57fa\u51c6\u7cfb\u7edf\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cDynaMate\u80fd\u591f\u53ef\u9760\u5730\u6267\u884c\u5b8c\u6574\u7684MD\u6a21\u62df\uff0c\u901a\u8fc7\u8fed\u4ee3\u63a8\u7406\u7ea0\u6b63\u8fd0\u884c\u65f6\u9519\u8bef\uff0c\u5e76\u4ea7\u751f\u6709\u610f\u4e49\u7684\u86cb\u767d\u8d28-\u914d\u4f53\u76f8\u4e92\u4f5c\u7528\u5206\u6790\u3002", "conclusion": "\u8be5\u81ea\u52a8\u5316\u6846\u67b6\u4e3a\u672a\u6765\u751f\u7269\u5206\u5b50\u548c\u836f\u7269\u8bbe\u8ba1\u5e94\u7528\u4e2d\u7684\u6807\u51c6\u5316\u3001\u53ef\u6269\u5c55\u548c\u65f6\u95f4\u9ad8\u6548\u7684\u5206\u5b50\u5efa\u6a21\u6d41\u7a0b\u94fa\u5e73\u4e86\u9053\u8def\u3002", "topic": "code agent"}}
{"id": "2512.10042", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10042", "abs": "https://arxiv.org/abs/2512.10042", "authors": ["Jongmin Lee", "Meiqi Sun", "Pieter Abbeel"], "title": "SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation", "comment": "ICLR 2025", "summary": "In the unsupervised pre-training for reinforcement learning, the agent aims to learn a prior policy for downstream tasks without relying on task-specific reward functions. We focus on state entropy maximization (SEM), where the goal is to learn a policy that maximizes the entropy of the state stationary distribution. In this paper, we introduce SEMDICE, a principled off-policy algorithm that computes an SEM policy from an arbitrary off-policy dataset, which optimizes the policy directly within the space of stationary distributions. SEMDICE computes a single, stationary Markov state-entropy-maximizing policy from an arbitrary off-policy dataset. Experimental results demonstrate that SEMDICE outperforms baseline algorithms in maximizing state entropy while achieving the best adaptation efficiency for downstream tasks among SEM-based unsupervised RL pre-training methods.", "AI": {"tldr": "\u63d0\u51faSEMDICE\u7b97\u6cd5\uff0c\u7528\u4e8e\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u9884\u8bad\u7ec3\uff0c\u901a\u8fc7\u6700\u5927\u5316\u72b6\u6001\u71b5\u4ece\u4efb\u610f\u79bb\u7ebf\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u5148\u9a8c\u7b56\u7565\uff0c\u5728\u72b6\u6001\u71b5\u6700\u5927\u5316\u548c\u4e0b\u6e38\u4efb\u52a1\u9002\u5e94\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5728\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u9884\u8bad\u7ec3\u4e2d\uff0c\u667a\u80fd\u4f53\u9700\u8981\u5728\u4e0d\u4f9d\u8d56\u4efb\u52a1\u7279\u5b9a\u5956\u52b1\u51fd\u6570\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u9002\u7528\u4e8e\u4e0b\u6e38\u4efb\u52a1\u7684\u5148\u9a8c\u7b56\u7565\u3002\u72b6\u6001\u71b5\u6700\u5927\u5316\uff08SEM\uff09\u662f\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u4ece\u79bb\u7ebf\u6570\u636e\u96c6\u4e2d\u5b66\u4e60SEM\u7b56\u7565\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faSEMDICE\u7b97\u6cd5\uff0c\u4e00\u79cd\u57fa\u4e8e\u539f\u7406\u7684\u79bb\u7ebf\u7b56\u7565\u7b97\u6cd5\uff0c\u76f4\u63a5\u4ece\u4efb\u610f\u79bb\u7ebf\u6570\u636e\u96c6\u4e2d\u8ba1\u7b97SEM\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u5728\u5e73\u7a33\u5206\u5e03\u7a7a\u95f4\u4e2d\u76f4\u63a5\u4f18\u5316\u7b56\u7565\uff0c\u8ba1\u7b97\u5355\u4e00\u3001\u5e73\u7a33\u7684\u9a6c\u5c14\u53ef\u592b\u72b6\u6001\u71b5\u6700\u5927\u5316\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSEMDICE\u5728\u6700\u5927\u5316\u72b6\u6001\u71b5\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u7b97\u6cd5\uff0c\u540c\u65f6\u5728\u57fa\u4e8eSEM\u7684\u65e0\u76d1\u7763RL\u9884\u8bad\u7ec3\u65b9\u6cd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u4f73\u7684\u4e0b\u6e38\u4efb\u52a1\u9002\u5e94\u6548\u7387\u3002", "conclusion": "SEMDICE\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u80fd\u591f\u4ece\u79bb\u7ebf\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u9ad8\u8d28\u91cf\u7684\u5148\u9a8c\u7b56\u7565\uff0c\u4e3a\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u826f\u597d\u7684\u521d\u59cb\u5316\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.10398", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.10398", "abs": "https://arxiv.org/abs/2512.10398", "authors": ["Zhaodong Wang", "Zhenting Qi", "Sherman Wong", "Nathan Hu", "Samuel Lin", "Jun Ge", "Erwin Gao", "Yining Yang", "Ben Maurer", "Wenlin Chen", "David Recordon", "Yilun Du", "Minlan Yu", "Ying Zhang"], "title": "Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale", "comment": null, "summary": "Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.", "AI": {"tldr": "Confucius Code Agent (CCA) \u662f\u4e00\u4e2a\u5f00\u6e90AI\u8f6f\u4ef6\u5de5\u7a0b\u5e08\uff0c\u5728\u5de5\u4e1a\u89c4\u6a21\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5728SWE-Bench-Pro\u4e0a\u8fbe\u523054.3%\u7684Resolve@1\u6027\u80fd\uff0c\u901a\u8fc7Confucius SDK\u5e73\u53f0\u5b9e\u73b0\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u3001\u8de8\u4f1a\u8bdd\u6301\u7eed\u5b66\u4e60\u548c\u6a21\u5757\u5316\u5de5\u5177\u4f7f\u7528\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684AI\u8f6f\u4ef6\u5de5\u7a0b\u9700\u8981\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21\u4ee3\u7801\u5e93\u3001\u4fdd\u6301\u957f\u671f\u8bb0\u5fc6\u5e76\u534f\u8c03\u590d\u6742\u5de5\u5177\u94fe\u7684\u7f16\u7801\u4ee3\u7406\u3002\u73b0\u6709\u5f00\u6e90\u4ee3\u7406\u5728\u5de5\u4e1a\u89c4\u6a21\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u800c\u4e13\u6709\u4ee3\u7406\u867d\u7136\u6027\u80fd\u5f3a\u4f46\u53ef\u6269\u5c55\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u63a7\u6027\u6709\u9650\u3002", "method": "\u57fa\u4e8eConfucius SDK\u5e73\u53f0\u6784\u5efa\uff0c\u5305\u542b\u7edf\u4e00\u7f16\u6392\u5668\uff08\u5206\u5c42\u5de5\u4f5c\u8bb0\u5fc6\u7528\u4e8e\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\uff09\u3001\u6301\u4e45\u7b14\u8bb0\u7cfb\u7edf\uff08\u8de8\u4f1a\u8bdd\u6301\u7eed\u5b66\u4e60\uff09\u3001\u6a21\u5757\u5316\u6269\u5c55\u6a21\u5757\uff08\u9c81\u68d2\u5de5\u5177\u4f7f\u7528\uff09\uff0c\u4ee5\u53ca\u901a\u8fc7\u6784\u5efa-\u6d4b\u8bd5-\u6539\u8fdb\u5faa\u73af\u81ea\u52a8\u5316\u914d\u7f6e\u5408\u6210\u7684\u5143\u4ee3\u7406\u3002", "result": "\u5728SWE-Bench-Pro\u4e0a\u8fbe\u523054.3%\u7684Resolve@1\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7f16\u7801\u4ee3\u7406\uff0c\u5b9e\u73b0\u4e86\u5de5\u4e1a\u89c4\u6a21\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u5904\u7406\u80fd\u529b\u3002", "conclusion": "Confucius SDK\u548cCCA\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u6269\u5c55\u548c\u53ef\u590d\u73b0\u7684\u57fa\u7840\uff0c\u5f25\u5408\u4e86\u7814\u7a76\u539f\u578b\u4e0e\u751f\u4ea7\u7ea7\u7cfb\u7edf\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u652f\u6301\u5de5\u4e1a\u89c4\u6a21\u7684\u4ee3\u7406\u5f00\u53d1\u548c\u90e8\u7f72\u3002", "topic": "code agent"}}
{"id": "2512.10047", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "nlin.AO", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2512.10047", "abs": "https://arxiv.org/abs/2512.10047", "authors": ["Zhuo-Yang Song", "Qing-Hong Cao", "Ming-xing Luo", "Hua Xing Zhu"], "title": "Detailed balance in large language model-driven agents", "comment": "20 pages, 12 figures, 5 tables", "summary": "Large language model (LLM)-driven agents are emerging as a powerful new paradigm for solving complex problems. Despite the empirical success of these practices, a theoretical framework to understand and unify their macroscopic dynamics remains lacking. This Letter proposes a method based on the least action principle to estimate the underlying generative directionality of LLMs embedded within agents. By experimentally measuring the transition probabilities between LLM-generated states, we statistically discover a detailed balance in LLM-generated transitions, indicating that LLM generation may not be achieved by generally learning rule sets and strategies, but rather by implicitly learning a class of underlying potential functions that may transcend different LLM architectures and prompt templates. To our knowledge, this is the first discovery of a macroscopic physical law in LLM generative dynamics that does not depend on specific model details. This work is an attempt to establish a macroscopic dynamics theory of complex AI systems, aiming to elevate the study of AI agents from a collection of engineering practices to a science built on effective measurements that are predictable and quantifiable.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5728\u72b6\u6001\u8f6c\u79fb\u4e2d\u5b58\u5728\u7ec6\u81f4\u5e73\u8861\uff0c\u8868\u660eLLM\u751f\u6210\u53ef\u80fd\u4e0d\u662f\u901a\u8fc7\u5b66\u4e60\u89c4\u5219\u96c6\u548c\u7b56\u7565\uff0c\u800c\u662f\u901a\u8fc7\u9690\u5f0f\u5b66\u4e60\u4e00\u7c7b\u6f5c\u5728\u51fd\u6570\u5b9e\u73b0\u7684\uff0c\u8fd9\u53ef\u80fd\u662f\u9996\u4e2a\u4e0d\u4f9d\u8d56\u5177\u4f53\u6a21\u578b\u7ec6\u8282\u7684LLM\u751f\u6210\u52a8\u529b\u5b66\u5b8f\u89c2\u7269\u7406\u5b9a\u5f8b\u3002", "motivation": "\u5c3d\u7ba1LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65b9\u9762\u53d6\u5f97\u4e86\u7ecf\u9a8c\u6027\u6210\u529f\uff0c\u4f46\u7f3a\u4e4f\u7406\u89e3\u5176\u5b8f\u89c2\u52a8\u529b\u5b66\u7684\u7406\u8bba\u6846\u67b6\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u590d\u6742AI\u7cfb\u7edf\u7684\u5b8f\u89c2\u52a8\u529b\u5b66\u7406\u8bba\uff0c\u5c06AI\u667a\u80fd\u4f53\u7814\u7a76\u4ece\u5de5\u7a0b\u5b9e\u8df5\u63d0\u5347\u5230\u53ef\u9884\u6d4b\u3001\u53ef\u91cf\u5316\u7684\u79d1\u5b66\u3002", "method": "\u57fa\u4e8e\u6700\u5c0f\u4f5c\u7528\u91cf\u539f\u7406\uff0c\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u91cfLLM\u751f\u6210\u72b6\u6001\u4e4b\u95f4\u7684\u8f6c\u79fb\u6982\u7387\uff0c\u7edf\u8ba1\u53d1\u73b0LLM\u751f\u6210\u8f6c\u6362\u4e2d\u5b58\u5728\u7ec6\u81f4\u5e73\u8861\u3002\u8fd9\u8868\u660eLLM\u751f\u6210\u53ef\u80fd\u901a\u8fc7\u9690\u5f0f\u5b66\u4e60\u6f5c\u5728\u51fd\u6570\u5b9e\u73b0\uff0c\u800c\u975e\u4e00\u822c\u6027\u5730\u5b66\u4e60\u89c4\u5219\u96c6\u548c\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u4e86LLM\u751f\u6210\u8f6c\u6362\u4e2d\u7684\u7ec6\u81f4\u5e73\u8861\u73b0\u8c61\uff0c\u8868\u660eLLM\u751f\u6210\u53ef\u80fd\u901a\u8fc7\u9690\u5f0f\u5b66\u4e60\u4e00\u7c7b\u6f5c\u5728\u51fd\u6570\u5b9e\u73b0\uff0c\u8fd9\u7c7b\u51fd\u6570\u53ef\u80fd\u8d85\u8d8a\u4e0d\u540c\u7684LLM\u67b6\u6784\u548c\u63d0\u793a\u6a21\u677f\u3002\u8fd9\u662f\u9996\u4e2a\u4e0d\u4f9d\u8d56\u5177\u4f53\u6a21\u578b\u7ec6\u8282\u7684LLM\u751f\u6210\u52a8\u529b\u5b66\u5b8f\u89c2\u7269\u7406\u5b9a\u5f8b\u7684\u53d1\u73b0\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u662f\u5efa\u7acb\u590d\u6742AI\u7cfb\u7edf\u5b8f\u89c2\u52a8\u529b\u5b66\u7406\u8bba\u7684\u5c1d\u8bd5\uff0c\u65e8\u5728\u5c06AI\u667a\u80fd\u4f53\u7814\u7a76\u4ece\u5de5\u7a0b\u5b9e\u8df5\u96c6\u5408\u63d0\u5347\u5230\u57fa\u4e8e\u53ef\u9884\u6d4b\u3001\u53ef\u91cf\u5316\u6709\u6548\u6d4b\u91cf\u7684\u79d1\u5b66\u3002\u53d1\u73b0\u7684\u7ec6\u81f4\u5e73\u8861\u73b0\u8c61\u4e3a\u7406\u89e3LLM\u751f\u6210\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\u3002", "topic": "agent analysis"}}
{"id": "2512.10206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10206", "abs": "https://arxiv.org/abs/2512.10206", "authors": ["Yakun Zhu", "Zhongzhen Huang", "Qianhan Feng", "Linjie Mu", "Yannian Gu", "Shaoting Zhang", "Qi Dou", "Xiaofan Zhang"], "title": "CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment", "comment": null, "summary": "Medical care follows complex clinical pathways that extend beyond isolated physician-patient encounters, emphasizing decision-making and transitions between different stages. Current benchmarks focusing on static exams or isolated dialogues inadequately evaluate large language models (LLMs) in dynamic clinical scenarios. We introduce CP-Env, a controllable agentic hospital environment designed to evaluate LLMs across end-to-end clinical pathways. CP-Env simulates a hospital ecosystem with patient and physician agents, constructing scenarios ranging from triage and specialist consultation to diagnostic testing and multidisciplinary team meetings for agent interaction. Following real hospital adaptive flow of healthcare, it enables branching, long-horizon task execution. We propose a three-tiered evaluation framework encompassing Clinical Efficacy, Process Competency, and Professional Ethics. Results reveal that most models struggle with pathway complexity, exhibiting hallucinations and losing critical diagnostic details. Interestingly, excessive reasoning steps can sometimes prove counterproductive, while top models tend to exhibit reduced tool dependency through internalized knowledge. CP-Env advances medical AI agents development through comprehensive end-to-end clinical evaluation. We provide the benchmark and evaluation tools for further research and development at https://github.com/SPIRAL-MED/CP-Env.", "AI": {"tldr": "CP-Env\u662f\u4e00\u4e2a\u53ef\u63a7\u7684\u667a\u80fd\u4f53\u533b\u9662\u73af\u5883\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u7aef\u5230\u7aef\u4e34\u5e8a\u8def\u5f84\u4e2d\u7684\u8868\u73b0\uff0c\u6a21\u62df\u533b\u9662\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u542b\u60a3\u8005\u548c\u533b\u751f\u667a\u80fd\u4f53\uff0c\u652f\u6301\u4ece\u5206\u8bca\u5230\u591a\u5b66\u79d1\u4f1a\u8bca\u7684\u590d\u6742\u4e34\u5e8a\u573a\u666f\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u9759\u6001\u8003\u8bd5\u6216\u5b64\u7acb\u5bf9\u8bdd\uff0c\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30LLM\u5728\u52a8\u6001\u4e34\u5e8a\u573a\u666f\u4e2d\u7684\u8868\u73b0\u3002\u533b\u7597\u62a4\u7406\u9075\u5faa\u590d\u6742\u7684\u4e34\u5e8a\u8def\u5f84\uff0c\u6d89\u53ca\u591a\u4e2a\u9636\u6bb5\u7684\u51b3\u7b56\u548c\u8f6c\u6362\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u5f00\u53d1CP-Env\u53ef\u63a7\u667a\u80fd\u4f53\u533b\u9662\u73af\u5883\uff0c\u6a21\u62df\u533b\u9662\u751f\u6001\u7cfb\u7edf\uff0c\u5305\u542b\u60a3\u8005\u548c\u533b\u751f\u667a\u80fd\u4f53\u3002\u6784\u5efa\u4ece\u5206\u8bca\u3001\u4e13\u79d1\u4f1a\u8bca\u5230\u8bca\u65ad\u6d4b\u8bd5\u548c\u591a\u5b66\u79d1\u56e2\u961f\u4f1a\u8bae\u7684\u573a\u666f\u3002\u91c7\u7528\u4e09\u5c42\u8bc4\u4f30\u6846\u67b6\uff1a\u4e34\u5e8a\u6548\u80fd\u3001\u6d41\u7a0b\u80fd\u529b\u548c\u4e13\u4e1a\u4f26\u7406\u3002", "result": "\u5927\u591a\u6570\u6a21\u578b\u5728\u8def\u5f84\u590d\u6742\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u51fa\u73b0\u5e7b\u89c9\u5e76\u4e22\u5931\u5173\u952e\u8bca\u65ad\u7ec6\u8282\u3002\u6709\u8da3\u7684\u662f\uff0c\u8fc7\u591a\u7684\u63a8\u7406\u6b65\u9aa4\u6709\u65f6\u4f1a\u9002\u5f97\u5176\u53cd\uff0c\u800c\u9876\u7ea7\u6a21\u578b\u503e\u5411\u4e8e\u901a\u8fc7\u5185\u5316\u77e5\u8bc6\u51cf\u5c11\u5de5\u5177\u4f9d\u8d56\u3002", "conclusion": "CP-Env\u901a\u8fc7\u5168\u9762\u7684\u7aef\u5230\u7aef\u4e34\u5e8a\u8bc4\u4f30\u63a8\u8fdb\u533b\u7597AI\u667a\u80fd\u4f53\u53d1\u5c55\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u4f30\u5de5\u5177\u5df2\u5f00\u6e90\uff0c\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u5f00\u53d1\u4f7f\u7528\u3002", "topic": "agent analysis"}}
{"id": "2512.10304", "categories": ["cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.10304", "abs": "https://arxiv.org/abs/2512.10304", "authors": ["Byeong Ho Kang", "Wenli Yang", "Muhammad Bilal Amin"], "title": "Trustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance", "comment": null, "summary": "As Artificial Intelligence (AI) systems increasingly assume consequential decision-making roles, a widening gap has emerged between technical capabilities and institutional accountability. Ethical guidance alone is insufficient to counter this challenge; it demands architectures that embed governance into the execution fabric of the ecosystem. This paper presents the Ten Criteria for Trustworthy Orchestration AI, a comprehensive assurance framework that integrates human input, semantic coherence, audit and provenance integrity into a unified Control-Panel architecture. Unlike conventional agentic AI initiatives that primarily focus on AI-to-AI coordination, the proposed framework provides an umbrella of governance to the entire AI components, their consumers and human participants. By taking aspiration from international standards and Australia's National Framework for AI Assurance initiative, this work demonstrates that trustworthiness can be systematically incorporated (by engineering) into AI systems, ensuring the execution fabric remains verifiable, transparent, reproducible and under meaningful human control.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\"\u53ef\u4fe1\u7f16\u6392AI\u7684\u5341\u5927\u6807\u51c6\"\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u9762\u677f\u67b6\u6784\u5c06\u6cbb\u7406\u5d4c\u5165AI\u751f\u6001\u7cfb\u7edf\u6267\u884c\u5c42\u9762\uff0c\u786e\u4fddAI\u7cfb\u7edf\u53ef\u9a8c\u8bc1\u3001\u900f\u660e\u3001\u53ef\u91cd\u73b0\u4e14\u53d7\u6709\u610f\u4e49\u7684\u4eba\u7c7b\u63a7\u5236\u3002", "motivation": "\u968f\u7740AI\u7cfb\u7edf\u5728\u5173\u952e\u51b3\u7b56\u4e2d\u626e\u6f14\u8d8a\u6765\u8d8a\u91cd\u8981\u7684\u89d2\u8272\uff0c\u6280\u672f\u80fd\u529b\u4e0e\u5236\u5ea6\u95ee\u8d23\u4e4b\u95f4\u51fa\u73b0\u4e86\u65e5\u76ca\u6269\u5927\u7684\u5dee\u8ddd\u3002\u4ec5\u9760\u4f26\u7406\u6307\u5bfc\u4e0d\u8db3\u4ee5\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u9700\u8981\u5c06\u6cbb\u7406\u5d4c\u5165\u751f\u6001\u7cfb\u7edf\u6267\u884c\u5c42\u9762\u7684\u67b6\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u53ef\u4fe1\u7f16\u6392AI\u7684\u5341\u5927\u6807\u51c6\u6846\u67b6\uff0c\u91c7\u7528\u63a7\u5236\u9762\u677f\u67b6\u6784\uff0c\u6574\u5408\u4eba\u7c7b\u8f93\u5165\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u3001\u5ba1\u8ba1\u548c\u6eaf\u6e90\u5b8c\u6574\u6027\u3002\u8be5\u6846\u67b6\u4e3a\u6574\u4e2aAI\u7ec4\u4ef6\u3001\u5176\u6d88\u8d39\u8005\u548c\u4eba\u7c7b\u53c2\u4e0e\u8005\u63d0\u4f9b\u6cbb\u7406\u4fdd\u969c\uff0c\u501f\u9274\u56fd\u9645\u6807\u51c6\u548c\u6fb3\u5927\u5229\u4e9a\u56fd\u5bb6AI\u4fdd\u969c\u6846\u67b6\u3002", "result": "\u5c55\u793a\u4e86\u53ef\u4fe1\u6027\u53ef\u4ee5\u901a\u8fc7\u5de5\u7a0b\u65b9\u6cd5\u7cfb\u7edf\u5730\u878d\u5165AI\u7cfb\u7edf\uff0c\u786e\u4fdd\u6267\u884c\u5c42\u9762\u4fdd\u6301\u53ef\u9a8c\u8bc1\u3001\u900f\u660e\u3001\u53ef\u91cd\u73b0\u4e14\u53d7\u6709\u610f\u4e49\u7684\u4eba\u7c7b\u63a7\u5236\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u89e3\u51b3AI\u7cfb\u7edf\u6cbb\u7406\u4e0e\u95ee\u8d23\u95ee\u9898\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u5de5\u7a0b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6cbb\u7406\u5d4c\u5165\u6267\u884c\u67b6\u6784\uff0c\u5f25\u5408\u4e86\u6280\u672f\u80fd\u529b\u4e0e\u5236\u5ea6\u95ee\u8d23\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "topic": "agent analysis"}}
{"id": "2512.10350", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10350", "abs": "https://arxiv.org/abs/2512.10350", "authors": ["Nicolas Tacheny"], "title": "Dynamics of Agentic Loops in Large Language Models: A Geometric Theory of Trajectories", "comment": null, "summary": "Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u5206\u6790\u667a\u80fd\u4f53\u5faa\u73af\u5728\u8bed\u4e49\u5d4c\u5165\u7a7a\u95f4\u4e2d\u51e0\u4f55\u884c\u4e3a\u7684\u6846\u67b6\uff0c\u533a\u5206\u4e86\u8bed\u8a00\u53d8\u6362\u7684\u5de5\u4ef6\u7a7a\u95f4\u548c\u51e0\u4f55\u6d4b\u91cf\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u901a\u8fc7\u7b49\u6e17\u6821\u51c6\u6d88\u9664\u4f59\u5f26\u76f8\u4f3c\u5ea6\u504f\u5dee\uff0c\u8bc6\u522b\u4e86\u6536\u7f29\u91cd\u5199\u5faa\u73af\u548c\u63a2\u7d22\u6027\u603b\u7ed3\u5426\u5b9a\u5faa\u73af\u4e24\u79cd\u57fa\u672c\u673a\u5236\u3002", "motivation": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u8fc7\u9012\u5f52\u53cd\u9988\u5faa\u73af\u8fd0\u884c\uff0c\u4f46\u4eba\u4eec\u5bf9\u8fd9\u4e9b\u667a\u80fd\u4f53\u5faa\u73af\u7684\u51e0\u4f55\u884c\u4e3a\uff08\u6536\u655b\u3001\u53d1\u6563\u6216\u66f4\u590d\u6742\u52a8\u6001\uff09\u7406\u89e3\u4e0d\u8db3\uff0c\u9700\u8981\u5efa\u7acb\u5206\u6790\u6846\u67b6\u6765\u7406\u89e3\u5176\u52a8\u6001\u7279\u6027\u3002", "method": "\u5f15\u5165\u5728\u8bed\u4e49\u5d4c\u5165\u7a7a\u95f4\u4e2d\u5206\u6790\u667a\u80fd\u4f53\u8f68\u8ff9\u7684\u51e0\u4f55\u6846\u67b6\uff0c\u5c06\u8fed\u4ee3\u53d8\u6362\u89c6\u4e3a\u79bb\u6563\u52a8\u529b\u7cfb\u7edf\uff1b\u533a\u5206\u5de5\u4ef6\u7a7a\u95f4\uff08\u8bed\u8a00\u53d8\u6362\uff09\u548c\u5d4c\u5165\u7a7a\u95f4\uff08\u51e0\u4f55\u6d4b\u91cf\uff09\uff1b\u63d0\u51fa\u7b49\u6e17\u6821\u51c6\u6d88\u9664\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u5404\u5411\u5f02\u6027\u504f\u5dee\uff1b\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u7814\u7a76\u5355\u4e00\u667a\u80fd\u4f53\u5faa\u73af\u3002", "result": "\u8bc6\u522b\u4e86\u4e24\u79cd\u57fa\u672c\u673a\u5236\uff1a\u6536\u7f29\u91cd\u5199\u5faa\u73af\u6536\u655b\u4e8e\u7a33\u5b9a\u5438\u5f15\u5b50\u4e14\u5206\u6563\u5ea6\u9012\u51cf\uff0c\u63a2\u7d22\u6027\u603b\u7ed3\u5426\u5b9a\u5faa\u73af\u4ea7\u751f\u65e0\u754c\u53d1\u6563\u4e14\u65e0\u805a\u7c7b\u5f62\u6210\uff1b\u8fd9\u4e9b\u673a\u5236\u663e\u793a\u51fa\u6536\u7f29\u548c\u6269\u5f20\u7684\u5b9a\u6027\u4e0d\u540c\u51e0\u4f55\u7279\u5f81\uff1b\u63d0\u793a\u8bbe\u8ba1\u76f4\u63a5\u63a7\u5236\u667a\u80fd\u4f53\u5faa\u73af\u7684\u52a8\u6001\u673a\u5236\u3002", "conclusion": "\u667a\u80fd\u4f53\u5faa\u73af\u7684\u51e0\u4f55\u884c\u4e3a\u53ef\u4ee5\u901a\u8fc7\u7cfb\u7edf\u6846\u67b6\u8fdb\u884c\u5206\u6790\uff0c\u63d0\u793a\u8bbe\u8ba1\u80fd\u591f\u76f4\u63a5\u63a7\u5236\u5faa\u73af\u7684\u52a8\u6001\u673a\u5236\uff0c\u4e3a\u8fed\u4ee3LLM\u53d8\u6362\u4e2d\u7684\u6536\u655b\u3001\u53d1\u6563\u548c\u8f68\u8ff9\u7ed3\u6784\u63d0\u4f9b\u4e86\u7cfb\u7edf\u63a7\u5236\u65b9\u6cd5\u3002", "topic": "agent analysis"}}
{"id": "2512.10371", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10371", "abs": "https://arxiv.org/abs/2512.10371", "authors": ["Shizuo Tian", "Hao Wen", "Yuxuan Chen", "Jiacheng Liu", "Shanhui Zhao", "Guohong Liu", "Ju Ren", "Yunxin Liu", "Yuanchun Li"], "title": "AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management", "comment": "16 pages, 8 figures", "summary": "The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.", "AI": {"tldr": "AgentProg\uff1a\u4e00\u79cd\u7a0b\u5e8f\u5f15\u5bfc\u7684\u79fb\u52a8GUI\u4ee3\u7406\u4e0a\u4e0b\u6587\u7ba1\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u4ea4\u4e92\u5386\u53f2\u91cd\u6784\u4e3a\u5e26\u53d8\u91cf\u548c\u63a7\u5236\u6d41\u7684\u7a0b\u5e8f\u6765\u51cf\u5c11\u4e0a\u4e0b\u6587\u5f00\u9500\uff0c\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "motivation": "\u79fb\u52a8GUI\u4ee3\u7406\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u81ea\u52a8\u5316\u4e2d\u9762\u4e34\u5173\u952e\u74f6\u9888\uff1a\u4f9d\u8d56\u4e0d\u65ad\u6269\u5c55\u7684\u4ea4\u4e92\u5386\u53f2\u4f1a\u5bfc\u81f4\u5927\u91cf\u4e0a\u4e0b\u6587\u5f00\u9500\uff0c\u73b0\u6709\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u538b\u7f29\u6280\u672f\u5f80\u5f80\u65e0\u6cd5\u4fdd\u7559\u91cd\u8981\u8bed\u4e49\u4fe1\u606f\uff0c\u5bfc\u81f4\u4efb\u52a1\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faAgentProg\uff0c\u4e00\u79cd\u7a0b\u5e8f\u5f15\u5bfc\u7684\u4ee3\u7406\u4e0a\u4e0b\u6587\u7ba1\u7406\u65b9\u6cd5\uff1a1) \u5c06\u4ea4\u4e92\u5386\u53f2\u91cd\u6784\u4e3a\u5e26\u6709\u53d8\u91cf\u548c\u63a7\u5236\u6d41\u7684\u7a0b\u5e8f\uff1b2) \u57fa\u4e8e\u7a0b\u5e8f\u7ed3\u6784\u786e\u5b9a\u54ea\u4e9b\u4fe1\u606f\u5e94\u4fdd\u7559\u6216\u4e22\u5f03\uff1b3) \u96c6\u6210\u53d7\u4fe1\u5ff5MDP\u6846\u67b6\u542f\u53d1\u7684\u5168\u5c40\u4fe1\u5ff5\u72b6\u6001\u673a\u5236\u6765\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u9002\u5e94\u73af\u5883\u53d8\u5316\u3002", "result": "\u5728AndroidWorld\u548c\u6269\u5c55\u7684\u957f\u65f6\u7a0b\u4efb\u52a1\u5957\u4ef6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAgentProg\u5728\u8fd9\u4e9b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6210\u529f\u7387\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5b83\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u4fdd\u6301\u7a33\u5065\u6027\u80fd\uff0c\u800c\u57fa\u7ebf\u65b9\u6cd5\u5219\u51fa\u73b0\u707e\u96be\u6027\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "AgentProg\u901a\u8fc7\u7a0b\u5e8f\u5316\u91cd\u6784\u4ea4\u4e92\u5386\u53f2\u6709\u6548\u89e3\u51b3\u4e86\u79fb\u52a8GUI\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u95ee\u9898\uff0c\u5728\u957f\u65f6\u7a0b\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u79fb\u52a8\u81ea\u52a8\u5316\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2512.10414", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10414", "abs": "https://arxiv.org/abs/2512.10414", "authors": ["Yang Yu", "Zhuangzhuang Chen", "Siqi Wang", "Lanqing Li", "Xiaomeng Li"], "title": "Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention", "comment": null, "summary": "Recently, reinforcement learning (RL) has become a common choice in enhancing the reasoning capabilities of vision-language models (VLMs). Considering existing RL- based finetuning methods, entropy intervention turns out to be an effective way to benefit exploratory ability, thereby improving policy performance. Notably, most existing stud- ies intervene in entropy by simply controlling the update of specific tokens during policy optimization of RL. They ig- nore the entropy intervention during the RL sampling that can boost the performance of GRPO by improving the di- versity of responses. In this paper, we propose Selective- adversarial Entropy Intervention, namely SaEI, which en- hances policy entropy by distorting the visual input with the token-selective adversarial objective coming from the en- tropy of sampled responses. Specifically, we first propose entropy-guided adversarial sampling (EgAS) that formu- lates the entropy of sampled responses as an adversarial ob- jective. Then, the corresponding adversarial gradient can be used to attack the visual input for producing adversarial samples, allowing the policy model to explore a larger an- swer space during RL sampling. Then, we propose token- selective entropy computation (TsEC) to maximize the ef- fectiveness of adversarial attack in EgAS without distorting factual knowledge within VLMs. Extensive experiments on both in-domain and out-of-domain datasets show that our proposed method can greatly improve policy exploration via entropy intervention, to boost reasoning capabilities. Code will be released once the paper is accepted.", "AI": {"tldr": "\u63d0\u51faSaEI\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5bf9\u6297\u71b5\u5e72\u9884\u589e\u5f3a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728RL\u91c7\u6837\u9636\u6bb5\u5f15\u5165\u71b5\u5e72\u9884\u6765\u63d0\u5347\u54cd\u5e94\u591a\u6837\u6027", "motivation": "\u73b0\u6709\u57fa\u4e8eRL\u7684\u5fae\u8c03\u65b9\u6cd5\u901a\u5e38\u53ea\u5728\u7b56\u7565\u4f18\u5316\u9636\u6bb5\u5bf9\u7279\u5b9atoken\u8fdb\u884c\u71b5\u5e72\u9884\uff0c\u5ffd\u7565\u4e86\u5728RL\u91c7\u6837\u9636\u6bb5\u7684\u71b5\u5e72\u9884\u53ef\u4ee5\u63d0\u5347\u54cd\u5e94\u591a\u6837\u6027\uff0c\u4ece\u800c\u6539\u5584GRPO\u6027\u80fd", "method": "\u63d0\u51fa\u9009\u62e9\u6027\u5bf9\u6297\u71b5\u5e72\u9884(SaEI)\uff1a1) \u71b5\u5f15\u5bfc\u5bf9\u6297\u91c7\u6837(EgAS)\uff0c\u5c06\u91c7\u6837\u54cd\u5e94\u7684\u71b5\u4f5c\u4e3a\u5bf9\u6297\u76ee\u6807\uff0c\u751f\u6210\u5bf9\u6297\u6837\u672c\u6765\u6269\u5927\u7b54\u6848\u7a7a\u95f4\u63a2\u7d22\uff1b2) token\u9009\u62e9\u6027\u71b5\u8ba1\u7b97(TsEC)\uff0c\u5728\u4e0d\u626d\u66f2\u4e8b\u5b9e\u77e5\u8bc6\u7684\u524d\u63d0\u4e0b\u6700\u5927\u5316\u5bf9\u6297\u653b\u51fb\u6548\u679c", "result": "\u5728\u9886\u57df\u5185\u548c\u9886\u57df\u5916\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u901a\u8fc7\u71b5\u5e72\u9884\u663e\u8457\u63d0\u5347\u7b56\u7565\u63a2\u7d22\u80fd\u529b\uff0c\u4ece\u800c\u589e\u5f3a\u63a8\u7406\u80fd\u529b", "conclusion": "\u5728RL\u91c7\u6837\u9636\u6bb5\u5f15\u5165\u9009\u62e9\u6027\u5bf9\u6297\u71b5\u5e72\u9884\u80fd\u6709\u6548\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u589e\u5f3a\u54cd\u5e94\u591a\u6837\u6027\u6765\u6539\u5584\u7b56\u7565\u63a2\u7d22", "topic": "agentic reinforcement learning"}}
{"id": "2512.10501", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10501", "abs": "https://arxiv.org/abs/2512.10501", "authors": ["Lim Chien Her", "Ming Yan", "Yunshu Bai", "Ruihao Li", "Hao Zhang"], "title": "Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation", "comment": null, "summary": "Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u67b6\u6784\uff0c\u5229\u7528LLM\u4ee3\u7406\u8fdb\u884c\u96f6\u6837\u672cPCG\u53c2\u6570\u914d\u7f6e\uff0c\u901a\u8fc7Actor-Critic\u53cc\u4ee3\u7406\u8fed\u4ee3\u5de5\u4f5c\u6d41\uff0c\u5c06\u62bd\u8c61\u7528\u6237\u6307\u4ee4\u8f6c\u5316\u4e3a\u7cbe\u786e\u53c2\u6570\u89c4\u8303", "motivation": "PCG\u9700\u8981\u7cbe\u786e\u914d\u7f6e\u4e0d\u900f\u660e\u7684\u6280\u672f\u53c2\u6570\uff0c\u800c\u73b0\u6210\u7684LLM\u96be\u4ee5\u5f25\u5408\u62bd\u8c61\u7528\u6237\u6307\u4ee4\u4e0e\u4e25\u683c\u53c2\u6570\u89c4\u8303\u4e4b\u95f4\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u9700\u8981\u66f4\u597d\u7684\u63a7\u5236\u65b9\u6cd5", "method": "\u91c7\u7528Actor-Critic\u53cc\u4ee3\u7406\u67b6\u6784\uff0cActor\u8d1f\u8d23\u751f\u6210\u53c2\u6570\u914d\u7f6e\uff0cCritic\u8fdb\u884c\u8bc4\u4f30\u548c\u53cd\u9988\uff0c\u5f62\u6210\u8fed\u4ee3\u5de5\u4f5c\u6d41\uff0c\u81ea\u4e3b\u63a8\u7406\u5de5\u5177\u53c2\u6570\u5e76\u9010\u6b65\u4f18\u5316\u914d\u7f6e\u4ee5\u7b26\u5408\u4eba\u7c7b\u8bbe\u8ba1\u504f\u597d", "result": "\u57283D\u5730\u56fe\u751f\u6210\u4efb\u52a1\u4e0a\u9a8c\u8bc1\uff0c\u4f18\u4e8e\u5355\u4ee3\u7406\u57fa\u7ebf\uff0c\u80fd\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u591a\u6837\u4e14\u7ed3\u6784\u6709\u6548\u7684\u73af\u5883\uff0c\u5efa\u7acb\u4e86PCG\u6307\u4ee4\u8ddf\u968f\u7684\u65b0\u57fa\u51c6", "conclusion": "\u73b0\u6210LLM\u53ef\u6709\u6548\u91cd\u65b0\u7528\u4f5c\u901a\u7528PCG\u5de5\u5177\u4ee3\u7406\uff0c\u901a\u8fc7\u5c06\u8d1f\u62c5\u4ece\u6a21\u578b\u8bad\u7ec3\u8f6c\u5411\u67b6\u6784\u63a8\u7406\uff0c\u4e3a\u65e0\u9700\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u800c\u638c\u63e1\u590d\u6742\u8f6f\u4ef6\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u6846\u67b6", "topic": "agent analysis"}}
{"id": "2512.10534", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10534", "abs": "https://arxiv.org/abs/2512.10534", "authors": ["Haiteng Zhao", "Junhao Shen", "Yiming Zhang", "Songyang Gao", "Kuikun Liu", "Tianyou Ma", "Fan Zheng", "Dahua Lin", "Wenwei Zhang", "Kai Chen"], "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning", "comment": null, "summary": "Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.", "AI": {"tldr": "InternGeometry\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u8fed\u4ee3\u63d0\u51fa\u547d\u9898\u548c\u8f85\u52a9\u6784\u9020\u3001\u7b26\u53f7\u5f15\u64ce\u9a8c\u8bc1\u548c\u53cd\u9988\u53cd\u601d\uff0c\u7ed3\u5408\u52a8\u6001\u5185\u5b58\u673a\u5236\u548c\u590d\u6742\u5ea6\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\uff0c\u4ec5\u7528\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u5c31\u5728IMO\u51e0\u4f55\u95ee\u9898\u4e0a\u8fbe\u5230\u91d1\u724c\u6c34\u5e73\u3002", "motivation": "\u5f53\u524dLLM\u5728\u51e0\u4f55\u95ee\u9898\u6c42\u89e3\u65b9\u9762\u53d7\u9650\u4e8e\u8f85\u52a9\u6784\u9020\u7684\u542f\u53d1\u5f0f\u80fd\u529b\u4e0d\u8db3\uff0c\u800c\u4e13\u5bb6\u6a21\u578b\u5982AlphaGeometry 2\u9700\u8981\u5927\u89c4\u6a21\u6570\u636e\u5408\u6210\u548c\u641c\u7d22\u3002\u672c\u6587\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u8fbe\u5230\u91d1\u724c\u6c34\u5e73\u7684LLM\u51e0\u4f55\u667a\u80fd\u4f53\uff0c\u514b\u670d\u51e0\u4f55\u95ee\u9898\u4e2d\u7684\u542f\u53d1\u5f0f\u9650\u5236\u3002", "method": "1. \u8fed\u4ee3\u5f0f\u95ee\u9898\u6c42\u89e3\uff1a\u63d0\u51fa\u547d\u9898\u548c\u8f85\u52a9\u6784\u9020\uff0c\u7528\u7b26\u53f7\u5f15\u64ce\u9a8c\u8bc1\uff0c\u6839\u636e\u53cd\u9988\u6307\u5bfc\u540e\u7eed\u63d0\u6848\uff1b2. \u52a8\u6001\u5185\u5b58\u673a\u5236\uff1a\u652f\u6301\u6bcf\u4e2a\u95ee\u9898\u4e0e\u7b26\u53f7\u5f15\u64ce\u8fdb\u884c200\u591a\u6b21\u4ea4\u4e92\uff1b3. \u590d\u6742\u5ea6\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\uff1a\u5728\u8bad\u7ec3\u9636\u6bb5\u9010\u6e10\u589e\u52a0\u5408\u6210\u95ee\u9898\u7684\u590d\u6742\u5ea6\uff1b4. \u57fa\u4e8eInternThinker-32B\u6a21\u578b\u6784\u5efa\u3002", "result": "\u57282000-2024\u5e74\u768450\u4e2aIMO\u51e0\u4f55\u95ee\u9898\u4e2d\u89e3\u51b3\u4e8644\u4e2a\uff0c\u8d85\u8fc7\u91d1\u724c\u9009\u624b\u5e73\u5747\u5206\uff0840.9\uff09\uff0c\u4ec5\u4f7f\u752813K\u8bad\u7ec3\u6837\u672c\uff08AlphaGeometry 2\u6570\u636e\u91cf\u76840.004%\uff09\u3002\u8fd8\u80fd\u4e3aIMO\u95ee\u9898\u63d0\u51fa\u4eba\u7c7b\u89e3\u6cd5\u4e2d\u672a\u51fa\u73b0\u7684\u65b0\u9896\u8f85\u52a9\u6784\u9020\u3002", "conclusion": "InternGeometry\u5c55\u793a\u4e86LLM\u667a\u80fd\u4f53\u5728\u4e13\u5bb6\u7ea7\u51e0\u4f55\u4efb\u52a1\u4e0a\u7684\u6f5c\u529b\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8fed\u4ee3\u6c42\u89e3\u6846\u67b6\u548c\u9ad8\u6548\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7528\u6781\u5c11\u6570\u636e\u8fbe\u5230\u91d1\u724c\u6c34\u5e73\uff0c\u4e3a\u51e0\u4f55AI\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002", "topic": "agent analysis"}}
{"id": "2512.10563", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10563", "abs": "https://arxiv.org/abs/2512.10563", "authors": ["Xin Guan"], "title": "NormCode: A Semi-Formal Language for Context-Isolated AI Planning", "comment": null, "summary": "Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode's own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.", "AI": {"tldr": "NormCode\u662f\u4e00\u79cd\u534a\u5f62\u5f0f\u5316\u8bed\u8a00\uff0c\u7528\u4e8e\u6784\u5efa\u63a8\u7406\u8ba1\u5212\uff0c\u901a\u8fc7\u4e25\u683c\u5206\u79bb\u8bed\u4e49\u64cd\u4f5c\u548c\u8bed\u6cd5\u64cd\u4f5c\uff0c\u6d88\u9664\u591a\u6b65LLM\u5de5\u4f5c\u6d41\u4e2d\u7684\u4e0a\u4e0b\u6587\u6c61\u67d3\u95ee\u9898\u3002", "motivation": "\u591a\u6b65LLM\u5de5\u4f5c\u6d41\u5b58\u5728\u4e0a\u4e0b\u6587\u6c61\u67d3\u95ee\u9898\uff1a\u968f\u7740\u4fe1\u606f\u5728\u6b65\u9aa4\u95f4\u79ef\u7d2f\uff0c\u6a21\u578b\u4f1a\u4ea7\u751f\u5e7b\u89c9\u3001\u6df7\u6dc6\u4e2d\u95f4\u8f93\u51fa\u3001\u4e22\u5931\u4efb\u52a1\u7ea6\u675f\u3002\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6d88\u9664\u8de8\u6b65\u9aa4\u6c61\u67d3\uff0c\u5b9e\u73b0\u53ef\u5ba1\u8ba1\u7684AI\u5de5\u4f5c\u6d41\u3002", "method": "NormCode\u662f\u4e00\u79cd\u534a\u5f62\u5f0f\u5316\u8bed\u8a00\uff0c\u5305\u542b\u4e09\u79cd\u540c\u6784\u683c\u5f0f\uff1a.ncds\u7528\u4e8e\u4eba\u5de5\u7f16\u5199\uff0c.ncd\u7528\u4e8e\u673a\u5668\u6267\u884c\uff0c.ncn\u7528\u4e8e\u4eba\u5de5\u9a8c\u8bc1\u3002\u5b83\u4e25\u683c\u5206\u79bb\u8bed\u4e49\u64cd\u4f5c\uff08LLM\u9a71\u52a8\u7684\u63a8\u7406\uff0c\u975e\u786e\u5b9a\u6027\uff09\u548c\u8bed\u6cd5\u64cd\u4f5c\uff08\u786e\u5b9a\u6027\u6570\u636e\u91cd\u7ec4\uff09\uff0c\u652f\u6301\u4ece\u8349\u56fe\u5230\u751f\u4ea7\u7684\u6e10\u8fdb\u5f62\u5f0f\u5316\u3002", "result": "\u901a\u8fc7\u4e24\u4e2a\u6f14\u793a\u9a8c\u8bc1\uff1a1\uff09\u57fa\u7840X\u52a0\u6cd5\u7b97\u6cd5\u5728\u4efb\u610f\u957f\u5ea6\u8f93\u5165\u4e0a\u5b9e\u73b0100%\u51c6\u786e\u7387\uff1b2\uff09\u81ea\u6258\u7ba1\u6267\u884cNormCode\u81ea\u8eab\u7684\u4e94\u9636\u6bb5\u7f16\u8bd1\u5668\u6d41\u6c34\u7ebf\u3002\u5de5\u4f5c\u7f16\u6392\u5668\u63d0\u4f9b\u4f9d\u8d56\u9a71\u52a8\u8c03\u5ea6\u3001SQLite\u652f\u6301\u7684\u68c0\u67e5\u70b9\u548c\u5faa\u73af\u7ba1\u7406\u3002", "conclusion": "NormCode\u901a\u8fc7\u8bbe\u8ba1\u6d88\u9664\u8de8\u6b65\u9aa4\u6c61\u67d3\uff0c\u4f7fAI\u5de5\u4f5c\u6d41\u53ef\u5ba1\u8ba1\uff0c\u6ee1\u8db3\u6cd5\u5f8b\u63a8\u7406\u3001\u533b\u7597\u51b3\u7b56\u548c\u91d1\u878d\u5206\u6790\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u5bf9\u900f\u660e\u5ea6\u7684\u5173\u952e\u9700\u6c42\u3002", "topic": "code agent"}}
{"id": "2512.10696", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10696", "abs": "https://arxiv.org/abs/2512.10696", "authors": ["Zouying Cao", "Jiaji Deng", "Li Yu", "Weikang Zhou", "Zhaoyang Liu", "Bolin Ding", "Hai Zhao"], "title": "Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution", "comment": "16 pages, 9 figures, 9 tables", "summary": "Procedural memory enables large language model (LLM) agents to internalize \"how-to\" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a \"passive accumulation\" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\\textbf{ReMe}$ ($\\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\\texttt{reme.library}$ dataset to facilitate further research.", "AI": {"tldr": "ReMe\u662f\u4e00\u4e2a\u8bb0\u5fc6\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u8fdb\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ef4\u5ea6\u84b8\u998f\u3001\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u91cd\u7528\u548c\u57fa\u4e8e\u6548\u7528\u7684\u7cbe\u70bc\u673a\u5236\uff0c\u5b9e\u73b0\u4ece\u9759\u6001\u5b58\u50a8\u5230\u52a8\u6001\u63a8\u7406\u7684\u8f6c\u53d8\uff0c\u5728BFCL-V3\u548cAppWorld\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u667a\u80fd\u4f53\u7684\u7a0b\u5e8f\u6027\u8bb0\u5fc6\u6846\u67b6\u4e3b\u8981\u91c7\u7528\"\u88ab\u52a8\u79ef\u7d2f\"\u8303\u5f0f\uff0c\u5c06\u8bb0\u5fc6\u89c6\u4e3a\u9759\u6001\u7684\u53ea\u8ffd\u52a0\u6863\u6848\uff0c\u7f3a\u4e4f\u52a8\u6001\u63a8\u7406\u80fd\u529b\u3002\u9700\u8981\u5f25\u5408\u9759\u6001\u5b58\u50a8\u4e0e\u52a8\u6001\u63a8\u7406\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5b9e\u73b0\u7ecf\u9a8c\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u8fdb\u5316\u3002", "method": "\u63d0\u51faReMe\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u521b\u65b0\u673a\u5236\uff1a1) \u591a\u7ef4\u5ea6\u84b8\u998f\uff1a\u901a\u8fc7\u8bc6\u522b\u6210\u529f\u6a21\u5f0f\u3001\u5206\u6790\u5931\u8d25\u89e6\u53d1\u56e0\u7d20\u548c\u751f\u6210\u6bd4\u8f83\u6027\u89c1\u89e3\u6765\u63d0\u53d6\u7ec6\u7c92\u5ea6\u7ecf\u9a8c\uff1b2) \u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u91cd\u7528\uff1a\u901a\u8fc7\u573a\u666f\u611f\u77e5\u7d22\u5f15\u5c06\u5386\u53f2\u89c1\u89e3\u9002\u914d\u5230\u65b0\u4e0a\u4e0b\u6587\uff1b3) \u57fa\u4e8e\u6548\u7528\u7684\u7cbe\u70bc\uff1a\u81ea\u4e3b\u6dfb\u52a0\u6709\u6548\u8bb0\u5fc6\u5e76\u4fee\u526a\u8fc7\u65f6\u8bb0\u5fc6\uff0c\u7ef4\u62a4\u7d27\u51d1\u9ad8\u8d28\u91cf\u7684\u7ecf\u9a8c\u6c60\u3002", "result": "\u5728BFCL-V3\u548cAppWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReMe\u5efa\u7acb\u4e86\u667a\u80fd\u4f53\u8bb0\u5fc6\u7cfb\u7edf\u7684\u65b0SOTA\u3002\u5173\u952e\u53d1\u73b0\uff1a\u914d\u5907ReMe\u7684Qwen3-8B\u8d85\u8d8a\u4e86\u66f4\u5927\u7684\u65e0\u8bb0\u5fc6Qwen3-14B\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u5185\u5b58\u7f29\u653e\u6548\u5e94\uff0c\u8868\u660e\u81ea\u8fdb\u5316\u8bb0\u5fc6\u4e3a\u7ec8\u8eab\u5b66\u4e60\u63d0\u4f9b\u4e86\u8ba1\u7b97\u9ad8\u6548\u7684\u9014\u5f84\u3002", "conclusion": "ReMe\u901a\u8fc7\u52a8\u6001\u8bb0\u5fc6\u751f\u547d\u5468\u671f\u7ba1\u7406\uff0c\u5b9e\u73b0\u4e86\u4ece\u88ab\u52a8\u79ef\u7d2f\u5230\u4e3b\u52a8\u8fdb\u5316\u7684\u8f6c\u53d8\uff0c\u4e3aLLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u7ecf\u9a8c\u5b66\u4e60\u548c\u7ec8\u8eab\u5b66\u4e60\u80fd\u529b\u3002\u91ca\u653e\u7684\u4ee3\u7801\u548creme.library\u6570\u636e\u96c6\u5c06\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "topic": "agent analysis"}}
{"id": "2512.10492", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10492", "abs": "https://arxiv.org/abs/2512.10492", "authors": ["Jiaxi Wu", "Tiantian Zhang", "Yuxing Wang", "Yongzhe Chang", "Xueqian Wang"], "title": "UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning", "comment": null, "summary": "Robust adversarial reinforcement learning has emerged as an effective paradigm for training agents to handle uncertain disturbance in real environments, with critical applications in sequential decision-making domains such as autonomous driving and robotic control. Within this paradigm, agent training is typically formulated as a zero-sum Markov game between a protagonist and an adversary to enhance policy robustness. However, the trainable nature of the adversary inevitably induces non-stationarity in the learning dynamics, leading to exacerbated training instability and convergence difficulties, particularly in high-dimensional complex environments. In this paper, we propose a novel approach, Uncertainty-Aware Critic Ensemble for robust adversarial Reinforcement learning (UACER), which consists of two strategies: 1) Diversified critic ensemble: a diverse set of K critic networks is exploited in parallel to stabilize Q-value estimation rather than conventional single-critic architectures for both variance reduction and robustness enhancement. 2) Time-varying Decay Uncertainty (TDU) mechanism: advancing beyond simple linear combinations, we develop a variance-derived Q-value aggregation strategy that explicitly incorporates epistemic uncertainty to dynamically regulate the exploration-exploitation trade-off while simultaneously stabilizing the training process. Comprehensive experiments across several MuJoCo control problems validate the superior effectiveness of UACER, outperforming state-of-the-art methods in terms of overall performance, stability, and efficiency.", "AI": {"tldr": "\u63d0\u51faUACER\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6837\u5316\u8bc4\u8bba\u5bb6\u96c6\u6210\u548c\u65f6\u95f4\u53d8\u5316\u8870\u51cf\u4e0d\u786e\u5b9a\u6027\u673a\u5236\uff0c\u89e3\u51b3\u9c81\u68d2\u5bf9\u6297\u5f3a\u5316\u5b66\u4e60\u4e2d\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6536\u655b\u56f0\u96be\u7684\u95ee\u9898\u3002", "motivation": "\u9c81\u68d2\u5bf9\u6297\u5f3a\u5316\u5b66\u4e60\u5728\u81ea\u52a8\u9a7e\u9a76\u548c\u673a\u5668\u4eba\u63a7\u5236\u7b49\u5e8f\u5217\u51b3\u7b56\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\uff0c\u4f46\u53ef\u8bad\u7ec3\u7684\u5bf9\u6297\u8005\u4f1a\u5bfc\u81f4\u5b66\u4e60\u52a8\u6001\u7684\u975e\u5e73\u7a33\u6027\uff0c\u52a0\u5267\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6536\u655b\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u9ad8\u7ef4\u590d\u6742\u73af\u5883\u4e2d\u3002", "method": "UACER\u5305\u542b\u4e24\u4e2a\u7b56\u7565\uff1a1\uff09\u591a\u6837\u5316\u8bc4\u8bba\u5bb6\u96c6\u6210\uff1a\u4f7f\u7528K\u4e2a\u5e76\u884c\u8bc4\u8bba\u5bb6\u7f51\u7edc\u7a33\u5b9aQ\u503c\u4f30\u8ba1\uff0c\u51cf\u5c11\u65b9\u5dee\u5e76\u589e\u5f3a\u9c81\u68d2\u6027\uff1b2\uff09\u65f6\u95f4\u53d8\u5316\u8870\u51cf\u4e0d\u786e\u5b9a\u6027\u673a\u5236\uff1a\u57fa\u4e8e\u65b9\u5dee\u63a8\u5bfc\u7684Q\u503c\u805a\u5408\u7b56\u7565\uff0c\u663e\u5f0f\u7ed3\u5408\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u52a8\u6001\u8c03\u8282\u63a2\u7d22-\u5229\u7528\u6743\u8861\u5e76\u7a33\u5b9a\u8bad\u7ec3\u8fc7\u7a0b\u3002", "result": "\u5728\u591a\u4e2aMuJoCo\u63a7\u5236\u95ee\u9898\u4e0a\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86UACER\u7684\u4f18\u8d8a\u6709\u6548\u6027\uff0c\u5728\u6574\u4f53\u6027\u80fd\u3001\u7a33\u5b9a\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "UACER\u901a\u8fc7\u521b\u65b0\u7684\u8bc4\u8bba\u5bb6\u96c6\u6210\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u9c81\u68d2\u5bf9\u6297\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4e3a\u590d\u6742\u73af\u5883\u4e2d\u7684\u5e8f\u5217\u51b3\u7b56\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.10510", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10510", "abs": "https://arxiv.org/abs/2512.10510", "authors": ["Chihyeon Song", "Jaewoo Lee", "Jinkyoo Park"], "title": "Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning", "comment": "15 pages, 3 figures, 7 tables", "summary": "Offline-to-Online Reinforcement Learning (O2O RL) faces a critical dilemma in balancing the use of a fixed offline dataset with newly collected online experiences. Standard methods, often relying on a fixed data-mixing ratio, struggle to manage the trade-off between early learning stability and asymptotic performance. To overcome this, we introduce the Adaptive Replay Buffer (ARB), a novel approach that dynamically prioritizes data sampling based on a lightweight metric we call 'on-policyness'. Unlike prior methods that rely on complex learning procedures or fixed ratios, ARB is designed to be learning-free and simple to implement, seamlessly integrating into existing O2O RL algorithms. It assesses how closely collected trajectories align with the current policy's behavior and assigns a proportional sampling weight to each transition within that trajectory. This strategy effectively leverages offline data for initial stability while progressively focusing learning on the most relevant, high-rewarding online experiences. Our extensive experiments on D4RL benchmarks demonstrate that ARB consistently mitigates early performance degradation and significantly improves the final performance of various O2O RL algorithms, highlighting the importance of an adaptive, behavior-aware replay buffer design.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u56de\u653e\u7f13\u51b2\u533a(ARB)\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u79bb\u7ebf\u4e0e\u5728\u7ebf\u6570\u636e\u91c7\u6837\u6bd4\u4f8b\uff0c\u89e3\u51b3\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u7a33\u5b9a\u6027\u4e0e\u6027\u80fd\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u5173\u952e\u56f0\u5883\uff1a\u9700\u8981\u5728\u56fa\u5b9a\u79bb\u7ebf\u6570\u636e\u96c6\u548c\u65b0\u6536\u96c6\u7684\u5728\u7ebf\u7ecf\u9a8c\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u6807\u51c6\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u56fa\u5b9a\u7684\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\uff0c\u96be\u4ee5\u5728\u65e9\u671f\u5b66\u4e60\u7a33\u5b9a\u6027\u548c\u6e10\u8fdb\u6027\u80fd\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002", "method": "\u5f15\u5165\u81ea\u9002\u5e94\u56de\u653e\u7f13\u51b2\u533a(ARB)\uff0c\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u6307\u6807\"on-policyness\"\u52a8\u6001\u4f18\u5148\u91c7\u6837\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u590d\u6742\u5b66\u4e60\u8fc7\u7a0b\uff0c\u7b80\u5355\u6613\u5b9e\u73b0\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709O2O RL\u7b97\u6cd5\u4e2d\u3002\u8bc4\u4f30\u6536\u96c6\u7684\u8f68\u8ff9\u4e0e\u5f53\u524d\u7b56\u7565\u884c\u4e3a\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u5e76\u4e3a\u8be5\u8f68\u8ff9\u4e2d\u7684\u6bcf\u4e2a\u8f6c\u79fb\u5206\u914d\u76f8\u5e94\u7684\u91c7\u6837\u6743\u91cd\u3002", "result": "\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cARB\u80fd\u6301\u7eed\u7f13\u89e3\u65e9\u671f\u6027\u80fd\u4e0b\u964d\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u5404\u79cdO2O RL\u7b97\u6cd5\u7684\u6700\u7ec8\u6027\u80fd\u3002", "conclusion": "\u81ea\u9002\u5e94\u3001\u884c\u4e3a\u611f\u77e5\u7684\u56de\u653e\u7f13\u51b2\u533a\u8bbe\u8ba1\u5bf9\u4e8e\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u81f3\u5173\u91cd\u8981\uff0cARB\u901a\u8fc7\u52a8\u6001\u6570\u636e\u91c7\u6837\u7b56\u7565\u6709\u6548\u5e73\u8861\u4e86\u79bb\u7ebf\u6570\u636e\u7684\u521d\u59cb\u7a33\u5b9a\u6027\u548c\u5728\u7ebf\u7ecf\u9a8c\u7684\u5b66\u4e60\u6548\u7387\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.10931", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10931", "abs": "https://arxiv.org/abs/2512.10931", "authors": ["George Yakushev", "Nataliia Babina", "Masoud Vahid Dastgerdi", "Vyacheslav Zhdanovskiy", "Alina Shutova", "Denis Kuznedelev"], "title": "Asynchronous Reasoning: Training-Free Interactive Thinking LLMs", "comment": "Preprint, work in progress", "summary": "Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to <= 5s. and the overall real-time delays by 6-11x.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u65cb\u8f6c\u5d4c\u5165\u7279\u6027\u4f7fLLM\u80fd\u591f\u540c\u65f6\u601d\u8003\u3001\u76d1\u542c\u548c\u751f\u6210\u8f93\u51fa\uff0c\u5b9e\u73b0\u5b9e\u65f6\u63a8\u7406\u54cd\u5e94\u3002", "motivation": "\u5f53\u524dLLM\u63a8\u7406\u9700\u8981\u5148\u601d\u8003\u518d\u56de\u7b54\uff0c\u5bfc\u81f4\u4ea4\u4e92\u5ef6\u8fdf\uff0c\u4e0d\u9002\u5408\u8bed\u97f3\u52a9\u624b\u7b49\u9700\u8981\u5b9e\u65f6\u54cd\u5e94\u7684\u5e94\u7528\u573a\u666f\u3002\u4eba\u7c7b\u53ef\u4ee5\u5f02\u6b65\u601d\u8003\u3001\u503e\u542c\u548c\u884c\u52a8\uff0c\u800c\u73b0\u6709LLM\u53ea\u80fd\u987a\u5e8f\u4ea4\u4e92\u3002", "method": "\u5229\u7528\u65cb\u8f6c\u5d4c\u5165\u7684\u7279\u6027\uff0c\u4f7f\u539f\u672c\u8bbe\u8ba1\u7528\u4e8e\u987a\u5e8f\u4ea4\u4e92\u7684LLM\u80fd\u591f\u540c\u65f6\u8fdb\u884c\u601d\u8003\u3001\u76d1\u542c\u548c\u751f\u6210\u8f93\u51fa\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5728\u6570\u5b66\u3001\u5e38\u8bc6\u548c\u5b89\u5168\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u51c6\u786e\u7684\u601d\u8003\u589e\u5f3a\u7b54\u6848\uff0c\u5c06\u9996\u4e2a\u975e\u601d\u8003token\u7684\u751f\u6210\u65f6\u95f4\u4ece\u5206\u949f\u7ea7\u51cf\u5c11\u5230\u22645\u79d2\uff0c\u6574\u4f53\u5b9e\u65f6\u5ef6\u8fdf\u964d\u4f4e6-11\u500d\u3002", "conclusion": "\u901a\u8fc7\u65cb\u8f6c\u5d4c\u5165\u5b9e\u73b0LLM\u7684\u5f02\u6b65\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u6539\u5584\u4e86\u5b9e\u65f6\u4ea4\u4e92\u6027\u80fd\uff0c\u4f7fLLM\u66f4\u9002\u5408\u8bed\u97f3\u52a9\u624b\u7b49\u9700\u8981\u5b9e\u65f6\u54cd\u5e94\u7684\u5e94\u7528\u573a\u666f\u3002", "topic": "agent analysis"}}
{"id": "2512.10665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10665", "abs": "https://arxiv.org/abs/2512.10665", "authors": ["Muhua Huang", "Qinlin Zhao", "Xiaoyuan Yi", "Xing Xie"], "title": "On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity", "comment": "Working Paper", "summary": "As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz's Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4ef7\u503c\u591a\u6837\u6027\u5982\u4f55\u5f71\u54cd\u96c6\u4f53\u884c\u4e3a\uff0c\u53d1\u73b0\u4ef7\u503c\u591a\u6837\u6027\u589e\u5f3a\u4e86\u4ef7\u503c\u7a33\u5b9a\u6027\u3001\u4fc3\u8fdb\u4e86\u6d8c\u73b0\u884c\u4e3a\uff0c\u4f46\u6781\u7aef\u5f02\u8d28\u6027\u4f1a\u5bfc\u81f4\u4e0d\u7a33\u5b9a\u6027\u3002", "motivation": "\u968f\u7740\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u65e5\u76ca\u666e\u53ca\uff0c\u8fd9\u4e9b\u4eba\u5de5\u793e\u533a\u7684\u96c6\u4f53\u884c\u4e3a\uff08\u5982\u96c6\u4f53\u667a\u80fd\uff09\u53d7\u5230\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\u3002\u672c\u7814\u7a76\u65e8\u5728\u56de\u7b54\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\uff1a\u4ef7\u503c\u591a\u6837\u6027\u5982\u4f55\u5851\u9020AI\u793e\u533a\u7684\u96c6\u4f53\u884c\u4e3a\uff1f", "method": "\u4f7f\u7528\u57fa\u4e8e\u65bd\u74e6\u8328\u57fa\u672c\u4eba\u7c7b\u4ef7\u503c\u7406\u8bba\u7684\u81ea\u7136\u4e3b\u4e49\u4ef7\u503c\u542f\u53d1\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u591a\u667a\u80fd\u4f53\u6a21\u62df\uff0c\u8ba9\u4e0d\u540c\u89c4\u6a21\u7684\u793e\u533a\u53c2\u4e0e\u5f00\u653e\u5f0f\u4e92\u52a8\u548c\u5baa\u6cd5\u5236\u5b9a\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff1a\u4ef7\u503c\u591a\u6837\u6027\u589e\u5f3a\u4e86\u4ef7\u503c\u7a33\u5b9a\u6027\uff0c\u4fc3\u8fdb\u4e86\u6d8c\u73b0\u884c\u4e3a\uff0c\u5e76\u5e26\u6765\u4e86\u66f4\u591a\u7531\u667a\u80fd\u4f53\u81ea\u8eab\u5f00\u53d1\uff08\u65e0\u9700\u5916\u90e8\u6307\u5bfc\uff09\u7684\u521b\u9020\u6027\u539f\u5219\u3002\u4f46\u8fd9\u4e9b\u6548\u5e94\u4e5f\u5448\u73b0\u8fb9\u9645\u9012\u51cf\uff1a\u6781\u7aef\u5f02\u8d28\u6027\u4f1a\u5f15\u53d1\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c06\u4ef7\u503c\u591a\u6837\u6027\u5b9a\u4f4d\u4e3a\u672a\u6765AI\u80fd\u529b\u7684\u65b0\u7ef4\u5ea6\uff0c\u8fde\u63a5\u4e86AI\u80fd\u529b\u4e0e\u793e\u4f1a\u5b66\u4e2d\u7684\u5236\u5ea6\u6d8c\u73b0\u7814\u7a76\u3002", "topic": "agent analysis"}}
{"id": "2512.10687", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.10687", "abs": "https://arxiv.org/abs/2512.10687", "authors": ["Manon Kempermann", "Sai Suresh Macharla Vasu", "Mahalakshmi Raveenthiran", "Theo Farrell", "Ingmar Weber"], "title": "Challenges of Evaluating LLM Safety for User Welfare", "comment": "Paper accepted at IASEAI'26; please cite that peer-reviewed version instead", "summary": "Safety evaluations of large language models (LLMs) typically focus on universal risks like dangerous capabilities or undesirable propensities. However, millions use LLMs for personal advice on high-stakes topics like finance and health, where harms are context-dependent rather than universal. While frameworks like the OECD's AI classification recognize the need to assess individual risks, user-welfare safety evaluations remain underdeveloped. We argue that developing such evaluations is non-trivial due to fundamental questions about accounting for user context in evaluation design. In this exploratory study, we evaluated advice on finance and health from GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across user profiles of varying vulnerability. First, we demonstrate that evaluators must have access to rich user context: identical LLM responses were rated significantly safer by context-blind evaluators than by those aware of user circumstances, with safety scores for high-vulnerability users dropping from safe (5/7) to somewhat unsafe (3/7). One might assume this gap could be addressed by creating realistic user prompts containing key contextual information. However, our second study challenges this: we rerun the evaluation on prompts containing context users report they would disclose, finding no significant improvement. Our work establishes that effective user-welfare safety evaluation requires evaluators to assess responses against diverse user profiles, as realistic user context disclosure alone proves insufficient, particularly for vulnerable populations. By demonstrating a methodology for context-aware evaluation, this study provides both a starting point for such assessments and foundational evidence that evaluating individual welfare demands approaches distinct from existing universal-risk frameworks. We publish our code and dataset to aid future developments.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86LLM\u5b89\u5168\u8bc4\u4f30\u7684\u65b0\u65b9\u5411\uff1a\u4ece\u901a\u7528\u98ce\u9669\u8bc4\u4f30\u8f6c\u5411\u8003\u8651\u7528\u6237\u5177\u4f53\u60c5\u5883\u7684\u4e2a\u4eba\u798f\u5229\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u91d1\u878d\u548c\u5065\u5eb7\u5efa\u8bae\u9886\u57df\uff0c\u53d1\u73b0\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u4f1a\u9ad8\u4f30\u5b89\u5168\u6027\uff0c\u800c\u7528\u6237\u81ea\u6211\u62ab\u9732\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e0d\u8db3\u4ee5\u5f25\u8865\u8bc4\u4f30\u5dee\u8ddd\u3002", "motivation": "\u5f53\u524dLLM\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u98ce\u9669\uff08\u5982\u5371\u9669\u80fd\u529b\uff09\uff0c\u4f46\u6570\u767e\u4e07\u7528\u6237\u5728\u5b9e\u9645\u4f7f\u7528LLM\u83b7\u53d6\u91d1\u878d\u548c\u5065\u5eb7\u7b49\u9ad8\u98ce\u9669\u5efa\u8bae\u65f6\uff0c\u5371\u5bb3\u662f\u60c5\u5883\u4f9d\u8d56\u7684\u800c\u975e\u901a\u7528\u7684\u3002\u867d\u7136OECD\u7b49\u6846\u67b6\u8ba4\u8bc6\u5230\u9700\u8981\u8bc4\u4f30\u4e2a\u4eba\u98ce\u9669\uff0c\u4f46\u7528\u6237\u798f\u5229\u5b89\u5168\u8bc4\u4f30\u4ecd\u4e0d\u6210\u719f\uff0c\u4e14\u5982\u4f55\u5c06\u7528\u6237\u60c5\u5883\u7eb3\u5165\u8bc4\u4f30\u8bbe\u8ba1\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\u3002", "method": "\u63a2\u7d22\u6027\u7814\u7a76\uff1a1\uff09\u8bc4\u4f30GPT-5\u3001Claude Sonnet 4\u548cGemini 2.5 Pro\u5728\u91d1\u878d\u548c\u5065\u5eb7\u9886\u57df\u7684\u5efa\u8bae\uff1b2\uff09\u4f7f\u7528\u4e0d\u540c\u8106\u5f31\u7a0b\u5ea6\u7684\u7528\u6237\u6863\u6848\uff1b3\uff09\u6bd4\u8f83\u6709\u65e0\u7528\u6237\u60c5\u5883\u4fe1\u606f\u7684\u8bc4\u4f30\u8005\u8bc4\u5206\uff1b4\uff09\u6d4b\u8bd5\u7528\u6237\u81ea\u6211\u62ab\u9732\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u662f\u5426\u80fd\u6539\u5584\u8bc4\u4f30\u6548\u679c\u3002", "result": "1\uff09\u60c5\u5883\u76f2\u8bc4\u4f30\u8005\u6bd4\u4e86\u89e3\u7528\u6237\u60c5\u5883\u7684\u8bc4\u4f30\u8005\u663e\u8457\u9ad8\u4f30\u5b89\u5168\u6027\uff08\u9ad8\u8106\u5f31\u7528\u6237\u5b89\u5168\u8bc4\u5206\u4ece3/7\u4e0a\u5347\u52305/7\uff09\uff1b2\uff09\u5373\u4f7f\u7528\u6237\u5728\u63d0\u793a\u4e2d\u62ab\u9732\u81ea\u8ba4\u4e3a\u5173\u952e\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u8bc4\u4f30\u6548\u679c\u4e5f\u65e0\u663e\u8457\u6539\u5584\uff1b3\uff09\u6709\u6548\u7684\u7528\u6237\u798f\u5229\u8bc4\u4f30\u9700\u8981\u8bc4\u4f30\u8005\u57fa\u4e8e\u591a\u6837\u5316\u7528\u6237\u6863\u6848\u8bc4\u4f30\u54cd\u5e94\u3002", "conclusion": "\u7528\u6237\u798f\u5229\u5b89\u5168\u8bc4\u4f30\u9700\u8981\u4e0e\u73b0\u6709\u901a\u7528\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\u4e0d\u540c\u7684\u65b9\u6cd5\uff0c\u5fc5\u987b\u8ba9\u8bc4\u4f30\u8005\u8bc4\u4f30\u54cd\u5e94\u4e0e\u591a\u6837\u5316\u7528\u6237\u6863\u6848\u7684\u5339\u914d\u5ea6\uff0c\u4ec5\u9760\u7528\u6237\u81ea\u6211\u62ab\u9732\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5bf9\u8106\u5f31\u4eba\u7fa4\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u60c5\u5883\u611f\u77e5\u8bc4\u4f30\u7684\u65b9\u6cd5\u8bba\u8d77\u70b9\u3002", "topic": "agent analysis"}}
{"id": "2512.10601", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10601", "abs": "https://arxiv.org/abs/2512.10601", "authors": ["Akhil Agnihotri"], "title": "Multi-Objective Reward and Preference Optimization: Theory and Algorithms", "comment": "PhD thesis", "summary": "This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion through the Average-Constrained Policy Optimization (ACPO) algorithm. ACPO integrates sensitivity analysis with trust-region updates to ensure stable constraint handling, achieving state-of-the-art empirical performance with theoretical guarantees. Constrained RL is then extended to finite-horizon settings via e-COP, the first policy optimization method for episodic CMDPs. Built on an episodic policy difference lemma, e-COP offers provable performance, simplicity, and scalability in safety-critical environments. The thesis then investigates reinforcement learning from human preferences. warmPref-PS introduces a posterior sampling strategy for linear bandits that integrates offline preference data from heterogeneous raters into online learning. Explicit modeling of rater competence yields substantial regret reduction and more efficient data collection for RLHF. The PSPL algorithm further advances preference-based RL by jointly sampling reward models and transition dynamics from pairwise trajectory comparisons, providing Bayesian simple-regret guarantees and robust empirical identification of optimal policies. The final contribution applies these methods to large-scale model alignment. A multi-objective constrained optimization view yields MOPO, an iterative algorithm with closed-form updates that scales to multi-billion-parameter language models and remains robust across alignment settings. Collectively, the thesis unifies constrained RL across average-cost, episodic, and preference-driven paradigms, delivering theoretical advances and practical tools for safe and aligned decision-making.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5728\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u505a\u51fa\u4e86\u7cfb\u7edf\u6027\u8d21\u732e\uff0c\u5305\u62ec\u5e73\u5747\u6210\u672cCMDP\u7684ACPO\u7b97\u6cd5\u3001\u6709\u9650\u65f6\u57dfCMDP\u7684e-COP\u7b97\u6cd5\u3001\u57fa\u4e8e\u4eba\u7c7b\u504f\u597d\u7684warmPref-PS\u548cPSPL\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5927\u89c4\u6a21\u6a21\u578b\u5bf9\u9f50\u7684MOPO\u7b97\u6cd5\uff0c\u4e3a\u5b89\u5168\u5bf9\u9f50\u7684\u51b3\u7b56\u63d0\u4f9b\u7406\u8bba\u548c\u5b9e\u8df5\u5de5\u5177\u3002", "motivation": "\u5f53\u524d\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u5728\u63a7\u5236\u3001\u504f\u597d\u5b66\u4e60\u548c\u5927\u6a21\u578b\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u7406\u8bba\u548c\u65b9\u6cd5\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u5f00\u53d1\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5904\u7406\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u7ea6\u675f\u95ee\u9898\uff0c\u786e\u4fdd\u51b3\u7b56\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u5bf9\u9f50\u6027\u3002", "method": "1) \u9488\u5bf9\u5e73\u5747\u6210\u672cCMDP\u5f00\u53d1ACPO\u7b97\u6cd5\uff0c\u7ed3\u5408\u654f\u611f\u6027\u5206\u6790\u548c\u4fe1\u4efb\u57df\u66f4\u65b0\uff1b2) \u9488\u5bf9\u6709\u9650\u65f6\u57dfCMDP\u63d0\u51fae-COP\u7b97\u6cd5\uff0c\u57fa\u4e8e\u65f6\u57df\u7b56\u7565\u5dee\u5f02\u5f15\u7406\uff1b3) \u63d0\u51fawarmPref-PS\u7528\u4e8e\u7ebf\u6027\u8d4c\u535a\u673a\uff0c\u6574\u5408\u5f02\u8d28\u8bc4\u5206\u8005\u7684\u79bb\u7ebf\u504f\u597d\u6570\u636e\uff1b4) \u5f00\u53d1PSPL\u7b97\u6cd5\u4ece\u6210\u5bf9\u8f68\u8ff9\u6bd4\u8f83\u4e2d\u8054\u5408\u91c7\u6837\u5956\u52b1\u6a21\u578b\u548c\u8f6c\u79fb\u52a8\u6001\uff1b5) \u63d0\u51faMOPO\u7b97\u6cd5\u7528\u4e8e\u5927\u89c4\u6a21\u6a21\u578b\u5bf9\u9f50\uff0c\u91c7\u7528\u591a\u76ee\u6807\u7ea6\u675f\u4f18\u5316\u89c6\u89d2\u3002", "result": "ACPO\u5728\u5e73\u5747\u6210\u672cCMDP\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u5b9e\u8bc1\u6027\u80fd\u5e76\u5177\u6709\u7406\u8bba\u4fdd\u8bc1\uff1be-COP\u5728\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u6027\u80fd\u3001\u7b80\u5355\u6027\u548c\u53ef\u6269\u5c55\u6027\uff1bwarmPref-PS\u663e\u8457\u51cf\u5c11\u9057\u61be\u5e76\u63d0\u9ad8\u6570\u636e\u6536\u96c6\u6548\u7387\uff1bPSPL\u63d0\u4f9b\u8d1d\u53f6\u65af\u7b80\u5355\u9057\u61be\u4fdd\u8bc1\u5e76\u7a33\u5065\u8bc6\u522b\u6700\u4f18\u7b56\u7565\uff1bMOPO\u53ef\u6269\u5c55\u5230\u6570\u5341\u4ebf\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\u5e76\u5728\u5404\u79cd\u5bf9\u9f50\u8bbe\u7f6e\u4e2d\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u7edf\u4e00\u4e86\u5e73\u5747\u6210\u672c\u3001\u65f6\u57df\u548c\u504f\u597d\u9a71\u52a8\u7684\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u8303\u5f0f\uff0c\u4e3a\u5b89\u5168\u548c\u5bf9\u9f50\u7684\u51b3\u7b56\u63d0\u4f9b\u4e86\u7406\u8bba\u8fdb\u5c55\u548c\u5b9e\u7528\u5de5\u5177\uff0c\u5728\u63a7\u5236\u3001\u504f\u597d\u5b66\u4e60\u548c\u6a21\u578b\u5bf9\u9f50\u7b49\u591a\u4e2a\u9886\u57df\u505a\u51fa\u4e86\u7cfb\u7edf\u6027\u8d21\u732e\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.10822", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.10822", "abs": "https://arxiv.org/abs/2512.10822", "authors": ["Mumuksh Tayal", "Manan Tayal", "Aditya Singh", "Shishir Kolathaya", "Ravi Prakash"], "title": "V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions", "comment": "23 pages, 8 figure, 7 tables", "summary": "Ensuring safety in autonomous systems requires controllers that satisfy hard, state-wise constraints without relying on online interaction. While existing Safe Offline RL methods typically enforce soft expected-cost constraints, they do not guarantee forward invariance. Conversely, Control Barrier Functions (CBFs) provide rigorous safety guarantees but usually depend on expert-designed barrier functions or full knowledge of the system dynamics. We introduce Value-Guided Offline Control Barrier Functions (V-OCBF), a framework that learns a neural CBF entirely from offline demonstrations. Unlike prior approaches, V-OCBF does not assume access to the dynamics model; instead, it derives a recursive finite-difference barrier update, enabling model-free learning of a barrier that propagates safety information over time. Moreover, V-OCBF incorporates an expectile-based objective that avoids querying the barrier on out-of-distribution actions and restricts updates to the dataset-supported action set. The learned barrier is then used with a Quadratic Program (QP) formulation to synthesize real-time safe control. Across multiple case studies, V-OCBF yields substantially fewer safety violations than baseline methods while maintaining strong task performance, highlighting its scalability for offline synthesis of safety-critical controllers without online interaction or hand-engineered barriers.", "AI": {"tldr": "V-OCBF\uff1a\u4e00\u79cd\u4ece\u79bb\u7ebf\u6f14\u793a\u4e2d\u5b66\u4e60\u795e\u7ecf\u63a7\u5236\u5c4f\u969c\u51fd\u6570\u7684\u6846\u67b6\uff0c\u65e0\u9700\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\uff0c\u901a\u8fc7\u9012\u5f52\u6709\u9650\u5dee\u5206\u5c4f\u969c\u66f4\u65b0\u5b9e\u73b0\u6a21\u578b\u65e0\u5173\u7684\u5b89\u5168\u5b66\u4e60\uff0c\u7ed3\u5408\u671f\u671b\u5206\u4f4d\u6570\u76ee\u6807\u907f\u514d\u5206\u5e03\u5916\u52a8\u4f5c\u67e5\u8be2\uff0c\u6700\u7ec8\u901a\u8fc7\u4e8c\u6b21\u89c4\u5212\u5408\u6210\u5b9e\u65f6\u5b89\u5168\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5f3a\u5236\u6267\u884c\u8f6f\u671f\u671b\u6210\u672c\u7ea6\u675f\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u524d\u5411\u4e0d\u53d8\u6027\uff1b\u800c\u63a7\u5236\u5c4f\u969c\u51fd\u6570\uff08CBFs\uff09\u867d\u7136\u63d0\u4f9b\u4e25\u683c\u5b89\u5168\u4fdd\u8bc1\uff0c\u4f46\u901a\u5e38\u4f9d\u8d56\u4e13\u5bb6\u8bbe\u8ba1\u7684\u5c4f\u969c\u51fd\u6570\u6216\u5b8c\u6574\u7684\u7cfb\u7edf\u52a8\u529b\u5b66\u77e5\u8bc6\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u4ece\u79bb\u7ebf\u6570\u636e\u4e2d\u5b66\u4e60\u5b89\u5168\u63a7\u5236\u5668\u7684\u65b9\u6cd5\uff0c\u65e2\u4e0d\u9700\u8981\u5728\u7ebf\u4ea4\u4e92\uff0c\u4e5f\u4e0d\u9700\u8981\u624b\u52a8\u8bbe\u8ba1\u7684\u5c4f\u969c\u51fd\u6570\u3002", "method": "\u63d0\u51faV-OCBF\u6846\u67b6\uff1a1\uff09\u4ece\u79bb\u7ebf\u6f14\u793a\u4e2d\u5b66\u4e60\u795e\u7ecfCBF\uff0c\u65e0\u9700\u52a8\u529b\u5b66\u6a21\u578b\uff1b2\uff09\u63a8\u5bfc\u9012\u5f52\u6709\u9650\u5dee\u5206\u5c4f\u969c\u66f4\u65b0\uff0c\u5b9e\u73b0\u6a21\u578b\u65e0\u5173\u7684\u5b89\u5168\u4fe1\u606f\u65f6\u95f4\u4f20\u64ad\uff1b3\uff09\u91c7\u7528\u671f\u671b\u5206\u4f4d\u6570\u76ee\u6807\uff0c\u907f\u514d\u5728\u5206\u5e03\u5916\u52a8\u4f5c\u4e0a\u67e5\u8be2\u5c4f\u969c\u51fd\u6570\uff0c\u5e76\u5c06\u66f4\u65b0\u9650\u5236\u5728\u6570\u636e\u96c6\u652f\u6301\u7684\u52a8\u4f5c\u96c6\u5185\uff1b4\uff09\u4f7f\u7528\u5b66\u4e60\u7684\u5c4f\u969c\u51fd\u6570\u901a\u8fc7\u4e8c\u6b21\u89c4\u5212\uff08QP\uff09\u5408\u6210\u5b9e\u65f6\u5b89\u5168\u63a7\u5236\u3002", "result": "\u5728\u591a\u4e2a\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cV-OCBF\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u5b89\u5168\u8fdd\u89c4\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u4efb\u52a1\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u5728\u65e0\u9700\u5728\u7ebf\u4ea4\u4e92\u6216\u624b\u5de5\u8bbe\u8ba1\u5c4f\u969c\u7684\u60c5\u51b5\u4e0b\u79bb\u7ebf\u5408\u6210\u5b89\u5168\u5173\u952e\u63a7\u5236\u5668\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "V-OCBF\u4e3a\u81ea\u4e3b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u79bb\u7ebf\u5b89\u5168\u63a7\u5236\u5668\u5408\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u795e\u7ecfCBF\u5b9e\u73b0\u4e86\u4e25\u683c\u7684\u5b89\u5168\u4fdd\u8bc1\uff0c\u65e0\u9700\u7cfb\u7edf\u52a8\u529b\u5b66\u6a21\u578b\u6216\u4e13\u5bb6\u8bbe\u8ba1\u7684\u5c4f\u969c\u51fd\u6570\uff0c\u5728\u5b89\u5168\u6027\u548c\u4efb\u52a1\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.10937", "categories": ["cs.AI", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.10937", "abs": "https://arxiv.org/abs/2512.10937", "authors": ["Matt Wilson"], "title": "On Decision-Making Agents and Higher-Order Causal Processes", "comment": null, "summary": "We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDP\uff09\u4e2d\u7684\u51b3\u7b56\u667a\u80fd\u4f53\u4e0e\u5355\u8f93\u5165\u8fc7\u7a0b\u51fd\u6570\uff08\u9ad8\u9636\u91cf\u5b50\u64cd\u4f5c\u7684\u7ecf\u5178\u6781\u9650\uff09\u4e4b\u95f4\u7684\u7cbe\u786e\u5bf9\u5e94\u5173\u7cfb", "motivation": "\u5efa\u7acb\u4eba\u5de5\u667a\u80fd\u51b3\u7b56\u7406\u8bba\u4e0e\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u901a\u8fc7\u8fc7\u7a0b\u51fd\u6570\u6846\u67b6\u7edf\u4e00\u63cf\u8ff0\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4e4b\u95f4\u7684\u4ea4\u4e92\u5173\u7cfb", "method": "\u5c06\u667a\u80fd\u4f53\u7684\u7b56\u7565\u548c\u8bb0\u5fc6\u66f4\u65b0\u7ed3\u5408\u6210\u8fc7\u7a0b\u51fd\u6570w\uff0c\u901a\u8fc7\u94fe\u63a5\u79ef\u4e0ePOMDP\u73af\u5883\u4ea4\u4e92\uff1b\u5efa\u7acb\u7269\u7406\u89c6\u56fe\uff08\u8fc7\u7a0b\u51fd\u6570\u4f5c\u4e3a\u73af\u5883\uff09\u4e0eAI\u89c6\u56fe\uff08\u8fc7\u7a0b\u51fd\u6570\u7f16\u7801\u667a\u80fd\u4f53\uff09\u7684\u5bf9\u5076\u89e3\u91ca\uff1b\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5c06\u89c2\u6d4b\u65e0\u5173\u7684\u5206\u6563\u5f0fPOMDP\u8bc6\u522b\u4e3a\u591a\u8f93\u5165\u8fc7\u7a0b\u51fd\u6570\u7684\u81ea\u7136\u9886\u57df", "result": "\u5efa\u7acb\u4e86POMDP\u667a\u80fd\u4f53\u4e0e\u8fc7\u7a0b\u51fd\u6570\u4e4b\u95f4\u7684\u7cbe\u786e\u5bf9\u5e94\u5173\u7cfb\uff0c\u63d0\u4f9b\u4e86\u667a\u80fd\u4f53-\u73af\u5883\u4ea4\u4e92\u7684\u7edf\u4e00\u6570\u5b66\u6846\u67b6\uff0c\u5e76\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u7cfb\u7edf", "conclusion": "\u8be5\u5bf9\u5e94\u5173\u7cfb\u4e3a\u7406\u89e3\u667a\u80fd\u4f53\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u8fde\u63a5\u4e86\u4eba\u5de5\u667a\u80fd\u548c\u91cf\u5b50\u4fe1\u606f\u7406\u8bba\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u5206\u6790\u5960\u5b9a\u4e86\u57fa\u7840", "topic": "agent analysis"}}
{"id": "2512.10805", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.10805", "abs": "https://arxiv.org/abs/2512.10805", "authors": ["Akshay Kulkarni", "Tsui-Wei Weng", "Vivek Narayanaswamy", "Shusen Liu", "Wesam A. Sakla", "Kowshik Thopalli"], "title": "Interpretable and Steerable Concept Bottleneck Sparse Autoencoders", "comment": null, "summary": "Sparse autoencoders (SAEs) promise a unified approach for mechanistic interpretability, concept discovery, and model steering in LLMs and LVLMs. However, realizing this potential requires that the learned features be both interpretable and steerable. To that end, we introduce two new computationally inexpensive interpretability and steerability metrics and conduct a systematic analysis on LVLMs. Our analysis uncovers two observations; (i) a majority of SAE neurons exhibit either low interpretability or low steerability or both, rendering them ineffective for downstream use; and (ii) due to the unsupervised nature of SAEs, user-desired concepts are often absent in the learned dictionary, thus limiting their practical utility. To address these limitations, we propose Concept Bottleneck Sparse Autoencoders (CB-SAE) - a novel post-hoc framework that prunes low-utility neurons and augments the latent space with a lightweight concept bottleneck aligned to a user-defined concept set. The resulting CB-SAE improves interpretability by +32.1% and steerability by +14.5% across LVLMs and image generation tasks. We will make our code and model weights available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCB-SAE\u6846\u67b6\uff0c\u901a\u8fc7\u526a\u679d\u4f4e\u6548\u7528\u795e\u7ecf\u5143\u5e76\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u6982\u5ff5\u74f6\u9888\u5c42\uff0c\u663e\u8457\u63d0\u5347\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u63a7\u6027\u3002", "motivation": "\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728LLM/LVM\u7684\u673a\u5236\u53ef\u89e3\u91ca\u6027\u3001\u6982\u5ff5\u53d1\u73b0\u548c\u6a21\u578b\u64cd\u63a7\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u95ee\u9898\uff1a1\uff09\u591a\u6570\u795e\u7ecf\u5143\u53ef\u89e3\u91ca\u6027\u6216\u53ef\u64cd\u63a7\u6027\u4f4e\uff1b2\uff09\u65e0\u76d1\u7763\u5b66\u4e60\u5bfc\u81f4\u7528\u6237\u6240\u9700\u6982\u5ff5\u7f3a\u5931\u3002", "method": "\u63d0\u51faCB-SAE\u6846\u67b6\uff1a1\uff09\u5f15\u5165\u4e24\u4e2a\u8ba1\u7b97\u6210\u672c\u4f4e\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u64cd\u63a7\u6027\u5ea6\u91cf\u6307\u6807\uff1b2\uff09\u526a\u679d\u4f4e\u6548\u7528\u795e\u7ecf\u5143\uff1b3\uff09\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u6982\u5ff5\u74f6\u9888\u5c42\uff0c\u4e0e\u7528\u6237\u5b9a\u4e49\u7684\u6982\u5ff5\u96c6\u5bf9\u9f50\u3002", "result": "\u5728LVLM\u548c\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e2d\uff0cCB-SAE\u5c06\u53ef\u89e3\u91ca\u6027\u63d0\u534732.1%\uff0c\u53ef\u64cd\u63a7\u6027\u63d0\u534714.5%\u3002", "conclusion": "CB-SAE\u901a\u8fc7\u540e\u5904\u7406\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u758f\u81ea\u7f16\u7801\u5668\u7684\u5b9e\u7528\u6027\u95ee\u9898\uff0c\u4e3a\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u64cd\u63a7\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2512.10835", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10835", "abs": "https://arxiv.org/abs/2512.10835", "authors": ["Atahan Cilan", "Atay \u00d6zg\u00f6vde"], "title": "Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments", "comment": "Submitted to IEEE Transactions on Games", "summary": "This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping between interpretable behavioral parameters and the learned policy, limiting their scalability and controllability. We define player behavior in an N-dimensional continuous space and uniformly sample target behavior vectors from a region that encompasses the subset representing real human styles. During training, each agent receives both its current and target behavior vectors as input, and the reward is based on the normalized reduction in distance between them. This allows the policy to learn how actions influence behavioral statistics, enabling smooth control over attributes such as aggressiveness, mobility, and cooperativeness. A single PPO-based multi-agent policy can reproduce new or unseen play styles without retraining. Experiments conducted in a custom multi-player Unity game show that the proposed framework produces significantly greater behavioral diversity than a win-only baseline and reliably matches specified behavior vectors across diverse targets. The method offers a scalable solution for automated playtesting, game balancing, human-like behavior simulation, and replacing disconnected players in online games.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u65e0\u9700\u4eba\u7c7b\u6e38\u620f\u6570\u636e\u5373\u53ef\u751f\u6210\u53ef\u63a7\u4e14\u591a\u6837\u5316\u7684\u73a9\u5bb6\u884c\u4e3a\uff0c\u901a\u8fc7\u884c\u4e3a\u5411\u91cf\u7a7a\u95f4\u5b9e\u73b0\u5e73\u6ed1\u63a7\u5236", "motivation": "\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u73a9\u5bb6\u8f68\u8ff9\u6570\u636e\u3001\u4e3a\u4e0d\u540c\u73a9\u5bb6\u7c7b\u578b\u8bad\u7ec3\u5355\u72ec\u6a21\u578b\uff0c\u6216\u7f3a\u4e4f\u53ef\u89e3\u91ca\u884c\u4e3a\u53c2\u6570\u4e0e\u5b66\u4e60\u7b56\u7565\u7684\u76f4\u63a5\u6620\u5c04\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u53ef\u63a7\u6027", "method": "\u5c06\u73a9\u5bb6\u884c\u4e3a\u5b9a\u4e49\u4e3aN\u7ef4\u8fde\u7eed\u7a7a\u95f4\uff0c\u5747\u5300\u91c7\u6837\u76ee\u6807\u884c\u4e3a\u5411\u91cf\uff0c\u8bad\u7ec3\u65f6\u8f93\u5165\u5f53\u524d\u548c\u76ee\u6807\u884c\u4e3a\u5411\u91cf\uff0c\u5956\u52b1\u57fa\u4e8e\u4e24\u8005\u8ddd\u79bb\u7684\u5f52\u4e00\u5316\u51cf\u5c11\uff0c\u4f7f\u7528PPO\u591a\u667a\u80fd\u4f53\u7b56\u7565", "result": "\u5728\u81ea\u5b9a\u4e49\u591a\u73a9\u5bb6Unity\u6e38\u620f\u4e2d\uff0c\u76f8\u6bd4\u4ec5\u8ffd\u6c42\u80dc\u5229\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u4ea7\u751f\u663e\u8457\u66f4\u5927\u7684\u884c\u4e3a\u591a\u6837\u6027\uff0c\u5e76\u80fd\u53ef\u9760\u5339\u914d\u6307\u5b9a\u7684\u884c\u4e3a\u5411\u91cf", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u81ea\u52a8\u5316\u6e38\u620f\u6d4b\u8bd5\u3001\u6e38\u620f\u5e73\u8861\u3001\u4eba\u7c7b\u884c\u4e3a\u6a21\u62df\u548c\u5728\u7ebf\u6e38\u620f\u4e2d\u65ad\u7ebf\u73a9\u5bb6\u66ff\u6362\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2512.fe0e9b79", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Fdocker-joins-the-agentic-ai-foundation%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/VKzx6kVyQTN27bo9e6I6T6l0Rmy_UeQruNF1S6NbIR8=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Fdocker-joins-the-agentic-ai-foundation%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/VKzx6kVyQTN27bo9e6I6T6l0Rmy_UeQruNF1S6NbIR8=435", "authors": ["TLDR Newsletter"], "title": "Docker Joins the Agentic AI Foundation", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 3 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Fdocker-joins-the-agentic-ai-foundation%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/VKzx6kVyQTN27bo9e6I6T6l0Rmy_UeQruNF1S6NbIR8=435", "summary": "Docker Joins the Agentic AI Foundation (3 minute read) The Linux Foundation has launched the Agentic AI Foundation to standardize infrastructure protocols for AI agents, bringing together major tech companies like Amazon, Google, Microsoft, and OpenAI. This initiative unifies projects like Anthropic's Model Context Protocol (MCP), Block's goose agent framework, and OpenAI's AGENTS.md standard to ensure transparent evolution and interoperability, with Docker joining as a Gold member.", "source": "tldr", "AI": {"tldr": "Linux\u57fa\u91d1\u4f1a\u6210\u7acbAgentic AI\u57fa\u91d1\u4f1a\uff0c\u65e8\u5728\u6807\u51c6\u5316AI\u4ee3\u7406\u57fa\u7840\u8bbe\u65bd\u534f\u8bae\uff0cDocker\u4f5c\u4e3a\u9ec4\u91d1\u6210\u5458\u52a0\u5165\uff0c\u8054\u5408\u591a\u5bb6\u79d1\u6280\u5de8\u5934\u63a8\u52a8AI\u4ee3\u7406\u4e92\u64cd\u4f5c\u6027\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u9886\u57df\u7f3a\u4e4f\u7edf\u4e00\u7684\u57fa\u7840\u8bbe\u65bd\u6807\u51c6\u548c\u534f\u8bae\uff0c\u4e0d\u540c\u516c\u53f8\u7684AI\u4ee3\u7406\u6846\u67b6\u4e92\u4e0d\u517c\u5bb9\uff0c\u963b\u788d\u4e86AI\u4ee3\u7406\u6280\u672f\u7684\u89c4\u6a21\u5316\u53d1\u5c55\u548c\u751f\u6001\u7cfb\u7edf\u5efa\u8bbe\u3002", "method": "Linux\u57fa\u91d1\u4f1a\u7275\u5934\u6210\u7acbAgentic AI\u57fa\u91d1\u4f1a\uff0c\u6574\u5408Anthropic\u7684MCP\u534f\u8bae\u3001Block\u7684goose\u6846\u67b6\u548cOpenAI\u7684AGENTS.md\u6807\u51c6\u7b49\u73b0\u6709\u9879\u76ee\uff0c\u5efa\u7acb\u7edf\u4e00\u7684AI\u4ee3\u7406\u57fa\u7840\u8bbe\u65bd\u534f\u8bae\u6807\u51c6\u3002", "result": "\u6210\u529f\u5438\u5f15\u4e86Amazon\u3001Google\u3001Microsoft\u3001OpenAI\u7b49\u4e3b\u8981\u79d1\u6280\u516c\u53f8\u53c2\u4e0e\uff0cDocker\u4f5c\u4e3a\u9ec4\u91d1\u6210\u5458\u52a0\u5165\uff0c\u5f62\u6210\u4e86\u884c\u4e1a\u8054\u76df\u6765\u63a8\u52a8AI\u4ee3\u7406\u57fa\u7840\u8bbe\u65bd\u7684\u6807\u51c6\u5316\u3002", "conclusion": "Agentic AI\u57fa\u91d1\u4f1a\u7684\u6210\u7acb\u6807\u5fd7\u7740AI\u4ee3\u7406\u57fa\u7840\u8bbe\u65bd\u6807\u51c6\u5316\u8fc8\u51fa\u91cd\u8981\u4e00\u6b65\uff0c\u6709\u671b\u4fc3\u8fdbAI\u4ee3\u7406\u6280\u672f\u7684\u900f\u660e\u6f14\u8fdb\u548c\u8de8\u5e73\u53f0\u4e92\u64cd\u4f5c\u6027\uff0c\u52a0\u901fAI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u6210\u719f\u3002", "topic": "agent analysis"}}
{"id": "tldr.2512.6ce3d972", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fabout.gitlab.com%2Fblog%2Fcontinuously-deploying-the-largest-gitlab-instance%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/2nGvuIj73VkpxSAH7g0N0k2nLuv824_MV-ojImVjVus=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fabout.gitlab.com%2Fblog%2Fcontinuously-deploying-the-largest-gitlab-instance%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/2nGvuIj73VkpxSAH7g0N0k2nLuv824_MV-ojImVjVus=435", "authors": ["TLDR Newsletter"], "title": "How we deploy the largest GitLab instance 12 times daily", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 12 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fabout.gitlab.com%2Fblog%2Fcontinuously-deploying-the-largest-gitlab-instance%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/2nGvuIj73VkpxSAH7g0N0k2nLuv824_MV-ojImVjVus=435", "summary": "How we deploy the largest GitLab instance 12 times daily (12 minute read) GitLab deploys code to GitLab.com up to 12 times daily using its own CI/CD platform, leveraging Canary deployments, progressive rollouts, and multiversion compatibility to ensure zero downtime. The deployment pipeline manages both containerized and traditional services, runs backward-compatible database migrations in Canary before post-deploy changes, and validates every stage through automated tests to maintain stabili...", "source": "tldr", "AI": {"tldr": "GitLab\u4f7f\u7528\u81ea\u5df1\u7684CI/CD\u5e73\u53f0\u6bcf\u5929\u90e8\u7f72\u4ee3\u7801\u6700\u591a12\u6b21\uff0c\u91c7\u7528\u91d1\u4e1d\u96c0\u90e8\u7f72\u3001\u6e10\u8fdb\u5f0f\u53d1\u5e03\u548c\u591a\u7248\u672c\u517c\u5bb9\u6027\u786e\u4fdd\u96f6\u505c\u673a\u65f6\u95f4\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u6d4b\u8bd5\u9a8c\u8bc1\u6bcf\u4e2a\u9636\u6bb5\u4ee5\u4fdd\u6301\u7a33\u5b9a\u6027\u3002", "motivation": "GitLab\u9700\u8981\u9891\u7e41\u3001\u53ef\u9760\u5730\u90e8\u7f72\u4ee3\u7801\u5230GitLab.com\uff0c\u540c\u65f6\u786e\u4fdd\u670d\u52a1\u7a33\u5b9a\u6027\u548c\u96f6\u505c\u673a\u65f6\u95f4\uff0c\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u7528\u6237\u4f7f\u7528\u3002", "method": "\u4f7f\u7528GitLab\u81ea\u5df1\u7684CI/CD\u5e73\u53f0\uff0c\u91c7\u7528\u91d1\u4e1d\u96c0\u90e8\u7f72\u3001\u6e10\u8fdb\u5f0f\u53d1\u5e03\u3001\u591a\u7248\u672c\u517c\u5bb9\u6027\u7b56\u7565\uff0c\u7ba1\u7406\u5bb9\u5668\u5316\u548c\u4f20\u7edf\u670d\u52a1\uff0c\u5728\u90e8\u7f72\u524d\u8fd0\u884c\u5411\u540e\u517c\u5bb9\u7684\u6570\u636e\u5e93\u8fc1\u79fb\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u5316\u6d4b\u8bd5\u9a8c\u8bc1\u6bcf\u4e2a\u9636\u6bb5\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u6bcf\u5929\u6700\u591a12\u6b21\u4ee3\u7801\u90e8\u7f72\uff0c\u786e\u4fdd\u96f6\u505c\u673a\u65f6\u95f4\uff0c\u4fdd\u6301\u670d\u52a1\u7a33\u5b9a\u6027\uff0c\u5e76\u80fd\u591f\u9ad8\u6548\u7ba1\u7406\u5927\u89c4\u6a21\u90e8\u7f72\u6d41\u7a0b\u3002", "conclusion": "GitLab\u901a\u8fc7\u81ea\u6709\u7684CI/CD\u5e73\u53f0\u548c\u5148\u8fdb\u7684\u90e8\u7f72\u7b56\u7565\uff0c\u80fd\u591f\u5b9e\u73b0\u9ad8\u9891\u3001\u53ef\u9760\u7684\u4ee3\u7801\u90e8\u7f72\uff0c\u4e3a\u5927\u89c4\u6a21\u670d\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u90e8\u7f72\u89e3\u51b3\u65b9\u6848\u3002", "topic": "swe application"}}
{"id": "tldr.2512.9ad38b4e", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2FFission-AI%2FOpenSpec%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/l60kid57IFtUlqehHiVWskX2TZDeYYyY21bwC-xtEzE=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2FFission-AI%2FOpenSpec%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/l60kid57IFtUlqehHiVWskX2TZDeYYyY21bwC-xtEzE=435", "authors": ["TLDR Newsletter"], "title": "OpenSpec", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2FFission-AI%2FOpenSpec%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/l60kid57IFtUlqehHiVWskX2TZDeYYyY21bwC-xtEzE=435", "summary": "OpenSpec (GitHub Repo) OpenSpec is a spec-driven development workflow for AI coding assistants that aims to make their outputs more predictable and reviewable by locking intent before any code is written. This lightweight specification process enables deterministic code generation from agreed-upon requirements, addressing the common issue of vague prompts.", "source": "tldr", "AI": {"tldr": "OpenSpec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u8303\u7684AI\u7f16\u7801\u52a9\u624b\u5f00\u53d1\u5de5\u4f5c\u6d41\uff0c\u901a\u8fc7\u5148\u9501\u5b9a\u610f\u56fe\u518d\u751f\u6210\u4ee3\u7801\uff0c\u4f7fAI\u8f93\u51fa\u66f4\u53ef\u9884\u6d4b\u548c\u53ef\u5ba1\u67e5", "motivation": "\u89e3\u51b3\u5f53\u524dAI\u7f16\u7801\u52a9\u624b\u4e2d\u5e38\u89c1\u7684\u6a21\u7cca\u63d0\u793a\u95ee\u9898\uff0c\u4f7f\u4ee3\u7801\u751f\u6210\u66f4\u52a0\u786e\u5b9a\u6027\u548c\u53ef\u9884\u6d4b\uff0c\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u7684\u53ef\u5ba1\u67e5\u6027", "method": "\u91c7\u7528\u89c4\u8303\u9a71\u52a8\u7684\u5f00\u53d1\u5de5\u4f5c\u6d41\uff0c\u5728\u7f16\u5199\u4efb\u4f55\u4ee3\u7801\u4e4b\u524d\u5148\u901a\u8fc7\u8f7b\u91cf\u7ea7\u89c4\u8303\u6d41\u7a0b\u9501\u5b9a\u610f\u56fe\uff0c\u4ece\u5df2\u8fbe\u6210\u5171\u8bc6\u7684\u9700\u6c42\u4e2d\u751f\u6210\u786e\u5b9a\u6027\u4ee3\u7801", "result": "\u901a\u8fc7\u89c4\u8303\u9a71\u52a8\u7684\u65b9\u6cd5\u4f7fAI\u7f16\u7801\u52a9\u624b\u7684\u8f93\u51fa\u66f4\u52a0\u53ef\u9884\u6d4b\u548c\u53ef\u5ba1\u67e5\uff0c\u89e3\u51b3\u4e86\u6a21\u7cca\u63d0\u793a\u5bfc\u81f4\u7684\u4ee3\u7801\u751f\u6210\u4e0d\u786e\u5b9a\u6027\u95ee\u9898", "conclusion": "OpenSpec\u5de5\u4f5c\u6d41\u901a\u8fc7\u5148\u89c4\u8303\u540e\u4ee3\u7801\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86AI\u7f16\u7801\u52a9\u624b\u7684\u8f93\u51fa\u8d28\u91cf\u548c\u53ef\u9884\u6d4b\u6027", "topic": "code agent"}}
{"id": "tldr.2512.6712f51d", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fmicrosoft%2Fagent-lightning%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/fzXkOSoygpahOVWAjA44ek9Lq5ydCCDWQGM-W-8A9Yo=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fmicrosoft%2Fagent-lightning%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/fzXkOSoygpahOVWAjA44ek9Lq5ydCCDWQGM-W-8A9Yo=435", "authors": ["TLDR Newsletter"], "title": "Agent Lightning", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fmicrosoft%2Fagent-lightning%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/fzXkOSoygpahOVWAjA44ek9Lq5ydCCDWQGM-W-8A9Yo=435", "summary": "Agent Lightning (GitHub Repo) Agent Lightning is a new trainer designed to streamline the development and improvement of AI agents. It allows developers to focus on their ideas by minimizing implementation complexities. The trainer integrates with any existing agent framework, collecting prompt, tool call, and reward events into a central \"LightningStore\" which then feeds an algorithm to continuously refine agent performance.", "source": "tldr", "AI": {"tldr": "Agent Lightning\u662f\u4e00\u4e2a\u65b0\u7684\u8bad\u7ec3\u5668\uff0c\u65e8\u5728\u7b80\u5316AI\u667a\u80fd\u4f53\u7684\u5f00\u53d1\u548c\u6539\u8fdb\uff0c\u901a\u8fc7\u96c6\u4e2d\u6536\u96c6\u63d0\u793a\u3001\u5de5\u5177\u8c03\u7528\u548c\u5956\u52b1\u4e8b\u4ef6\u6765\u6301\u7eed\u4f18\u5316\u667a\u80fd\u4f53\u6027\u80fd", "motivation": "\u5f00\u53d1AI\u667a\u80fd\u4f53\u65f6\u9762\u4e34\u5b9e\u73b0\u590d\u6742\u6027\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u8ba9\u5f00\u53d1\u8005\u80fd\u591f\u4e13\u6ce8\u4e8e\u521b\u610f\u800c\u975e\u6280\u672f\u7ec6\u8282\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u8bad\u7ec3\u6846\u67b6\u6765\u6301\u7eed\u6539\u8fdb\u667a\u80fd\u4f53\u6027\u80fd", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e0e\u73b0\u6709\u667a\u80fd\u4f53\u6846\u67b6\u96c6\u6210\u7684\u8bad\u7ec3\u5668\uff0c\u901a\u8fc7\"LightningStore\"\u96c6\u4e2d\u6536\u96c6\u63d0\u793a\u3001\u5de5\u5177\u8c03\u7528\u548c\u5956\u52b1\u4e8b\u4ef6\uff0c\u7136\u540e\u4f7f\u7528\u7b97\u6cd5\u6301\u7eed\u4f18\u5316\u667a\u80fd\u4f53\u6027\u80fd", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u7b80\u5316\u667a\u80fd\u4f53\u5f00\u53d1\u6d41\u7a0b\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u652f\u6301\u4e0e\u73b0\u6709\u667a\u80fd\u4f53\u6846\u67b6\u96c6\u6210\uff0c\u5b9e\u73b0\u4e86\u667a\u80fd\u4f53\u6027\u80fd\u7684\u6301\u7eed\u6539\u8fdb\u673a\u5236", "conclusion": "Agent Lightning\u4e3aAI\u667a\u80fd\u4f53\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u96c6\u4e2d\u5316\u7684\u4e8b\u4ef6\u6536\u96c6\u548c\u4f18\u5316\u7b97\u6cd5\uff0c\u964d\u4f4e\u4e86\u5f00\u53d1\u590d\u6742\u5ea6\u5e76\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u6027\u80fd", "topic": "agent analysis"}}
{"id": "tldr.2512.ac6407cd", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Fdocker-sandboxes-a-new-approach-for-coding-agent-safety%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/n-4qo6TUSqwajR_V88HmWwDIvOkBTGboQBImq1lGZqQ=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Fdocker-sandboxes-a-new-approach-for-coding-agent-safety%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/n-4qo6TUSqwajR_V88HmWwDIvOkBTGboQBImq1lGZqQ=435", "authors": ["TLDR Newsletter"], "title": "A New Approach for Coding Agent Safety", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Fdocker-sandboxes-a-new-approach-for-coding-agent-safety%2F%3Futm_source=tldrdevops/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/n-4qo6TUSqwajR_V88HmWwDIvOkBTGboQBImq1lGZqQ=435", "summary": "A New Approach for Coding Agent Safety (4 minute read) Coding agents are gaining autonomy and need controlled access, prompting Docker to introduce experimental container-based sandboxes that isolate agent workflows while mirroring local workspaces. The preview supports Claude Code and Gemini CLI and will evolve toward microVM isolation, stronger controls, and broader agent compatibility.", "source": "tldr", "AI": {"tldr": "Docker\u63a8\u51fa\u5b9e\u9a8c\u6027\u5bb9\u5668\u6c99\u7bb1\uff0c\u4e3a\u65e5\u76ca\u81ea\u4e3b\u7684\u7f16\u7801\u4ee3\u7406\u63d0\u4f9b\u9694\u79bb\u73af\u5883\uff0c\u652f\u6301Claude Code\u548cGemini CLI\uff0c\u672a\u6765\u5c06\u5411\u5fae\u865a\u62df\u673a\u9694\u79bb\u548c\u66f4\u5f3a\u63a7\u5236\u53d1\u5c55", "motivation": "\u968f\u7740\u7f16\u7801\u4ee3\u7406\u81ea\u4e3b\u6027\u589e\u5f3a\uff0c\u9700\u8981\u5bf9\u5176\u8bbf\u95ee\u8fdb\u884c\u63a7\u5236\uff0c\u786e\u4fdd\u5b89\u5168\u6027\u548c\u9694\u79bb\u6027", "method": "Docker\u5f15\u5165\u5b9e\u9a8c\u6027\u5bb9\u5668\u6c99\u7bb1\uff0c\u9694\u79bb\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u540c\u65f6\u955c\u50cf\u672c\u5730\u5de5\u4f5c\u73af\u5883", "result": "\u9884\u89c8\u7248\u652f\u6301Claude Code\u548cGemini CLI\uff0c\u672a\u6765\u5c06\u6269\u5c55\u4e3a\u5fae\u865a\u62df\u673a\u9694\u79bb\u3001\u66f4\u5f3a\u63a7\u5236\u673a\u5236\u548c\u66f4\u5e7f\u6cdb\u7684\u4ee3\u7406\u517c\u5bb9\u6027", "conclusion": "\u5bb9\u5668\u6c99\u7bb1\u4e3a\u7f16\u7801\u4ee3\u7406\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\uff0c\u662f\u5411\u66f4\u5b89\u5168\u3001\u53ef\u63a7\u7684\u4ee3\u7406\u5de5\u4f5c\u73af\u5883\u6f14\u8fdb\u7684\u91cd\u8981\u4e00\u6b65", "topic": "code agent"}}
{"id": "tldr.2512.b7afd2e7", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.codacy.com%2Fai-reviewer%2F%3Futm_campaign=31129159-AI%2520Risk%2520Hub%2520%2526%2520AI%2520Reviewer%2520Launch%2520%257C%2520Newsletters%26utm_source=TLDR%26utm_medium=newsletter%26utm_content=RiskHub_AIReviewer/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/bA4otMFXJq8881PW9O38jywYzGJaLzndkoJKyFpc0-o=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.codacy.com%2Fai-reviewer%2F%3Futm_campaign=31129159-AI%2520Risk%2520Hub%2520%2526%2520AI%2520Reviewer%2520Launch%2520%257C%2520Newsletters%26utm_source=TLDR%26utm_medium=newsletter%26utm_content=RiskHub_AIReviewer/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/bA4otMFXJq8881PW9O38jywYzGJaLzndkoJKyFpc0-o=435", "authors": ["TLDR Newsletter"], "title": "Codacy's new AI Reviewer helps devs regain control of Pull Requests", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.codacy.com%2Fai-reviewer%2F%3Futm_campaign=31129159-AI%2520Risk%2520Hub%2520%2526%2520AI%2520Reviewer%2520Launch%2520%257C%2520Newsletters%26utm_source=TLDR%26utm_medium=newsletter%26utm_content=RiskHub_AIReviewer/1/0100019b0827d676-6a211884-1a71-4c64-aae2-b5632bd8f95a-000000/bA4otMFXJq8881PW9O38jywYzGJaLzndkoJKyFpc0-o=435", "summary": "Codacy's new AI Reviewer helps devs regain control of Pull Requests (Sponsor) GenAI is rewriting your codebase faster than your devs can review it. Codacy's new AI Reviewer pairs deterministic static analysis with context-aware code reviews that catch issues missed by legacy scanners. See how it works", "source": "tldr", "AI": {"tldr": "Codacy\u63a8\u51faAI Reviewer\u5de5\u5177\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u4e0e\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\u5ba1\u67e5\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u66f4\u597d\u5730\u7ba1\u7406Pull Requests\u4e2d\u7684AI\u751f\u6210\u4ee3\u7801", "motivation": "GenAI\u6b63\u5728\u4ee5\u8d85\u8fc7\u5f00\u53d1\u8005\u5ba1\u67e5\u901f\u5ea6\u7684\u65b9\u5f0f\u91cd\u5199\u4ee3\u7801\u5e93\uff0c\u4f20\u7edf\u626b\u63cf\u5de5\u5177\u65e0\u6cd5\u6709\u6548\u68c0\u6d4bAI\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u5ba1\u67e5\u5de5\u5177", "method": "\u5c06\u786e\u5b9a\u6027\u9759\u6001\u5206\u6790\u4e0e\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u4ee3\u7801\u5ba1\u67e5\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u6bd4\u4f20\u7edf\u626b\u63cf\u5de5\u5177\u66f4\u5168\u9762\u7684\u4ee3\u7801\u8d28\u91cf\u68c0\u6d4b", "result": "\u5f00\u53d1\u4e86AI Reviewer\u5de5\u5177\uff0c\u80fd\u591f\u6355\u83b7\u4f20\u7edf\u626b\u63cf\u5668\u9057\u6f0f\u7684\u95ee\u9898\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u91cd\u65b0\u638c\u63a7Pull Requests\u7684\u5ba1\u67e5\u8fc7\u7a0b", "conclusion": "AI Reviewer\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u5ba1\u67e5\uff0c\u6709\u6548\u89e3\u51b3\u4e86AI\u751f\u6210\u4ee3\u7801\u5ba1\u67e5\u7684\u6311\u6218\uff0c\u63d0\u5347\u4e86\u4ee3\u7801\u8d28\u91cf\u548c\u5f00\u53d1\u6548\u7387", "topic": "swe application"}}
{"id": "tldr.2512.8d8ec0ae", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fengineering.atspotify.com%2F2025%2F12%2Ffeedback-loops-background-coding-agents-part-3%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/ZwxhugminsfrYzep9kBMSFh6yo8RgRiHshuu8xxtLoU=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fengineering.atspotify.com%2F2025%2F12%2Ffeedback-loops-background-coding-agents-part-3%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/ZwxhugminsfrYzep9kBMSFh6yo8RgRiHshuu8xxtLoU=434", "authors": ["TLDR Newsletter"], "title": "Background Coding Agents: Predictable Results Through Strong Feedback Loops", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 8 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fengineering.atspotify.com%2F2025%2F12%2Ffeedback-loops-background-coding-agents-part-3%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/ZwxhugminsfrYzep9kBMSFh6yo8RgRiHshuu8xxtLoU=434", "summary": "Background Coding Agents: Predictable Results Through Strong Feedback Loops (8 minute read) Spotify's background coding agents use verification loops to stay on track. Independent verifiers, like Maven, build systems and tests that run automatically and give incremental feedback. An LLM judge also vetoes PRs when agents get too creative and drift from their prompts.", "source": "tldr", "AI": {"tldr": "Spotify\u5f00\u53d1\u4e86\u540e\u53f0\u7f16\u7801\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5faa\u73af\uff08\u5305\u62ec\u6784\u5efa\u7cfb\u7edf\u3001\u6d4b\u8bd5\u548cLLM\u8bc4\u5ba1\uff09\u6765\u786e\u4fdd\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9884\u6d4b\u6027\u548c\u8d28\u91cf\uff0c\u9632\u6b62\u4ee3\u7406\u504f\u79bb\u63d0\u793a\u8981\u6c42\u3002", "motivation": "\u89e3\u51b3\u7f16\u7801\u4ee3\u7406\u5728\u751f\u6210\u4ee3\u7801\u65f6\u53ef\u80fd\u504f\u79bb\u539f\u59cb\u63d0\u793a\u3001\u4ea7\u751f\u4e0d\u53ef\u9884\u6d4b\u7ed3\u679c\u7684\u95ee\u9898\uff0c\u786e\u4fdd\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u53ef\u63a7\u4e14\u53ef\u9760\u3002", "method": "\u91c7\u7528\u591a\u5c42\u9a8c\u8bc1\u5faa\u73af\uff1a1) \u72ec\u7acb\u9a8c\u8bc1\u5668\uff08\u5982Maven\uff09\u8fd0\u884c\u81ea\u52a8\u6784\u5efa\u548c\u6d4b\u8bd5\u63d0\u4f9b\u589e\u91cf\u53cd\u9988\uff1b2) LLM\u8bc4\u5ba1\u5728\u4ee3\u7801\u63d0\u4ea4\u524d\u5ba1\u67e5PR\uff0c\u5f53\u4ee3\u7406\u8fc7\u4e8e\"\u521b\u9020\u6027\"\u504f\u79bb\u63d0\u793a\u65f6\u884c\u4f7f\u5426\u51b3\u6743\u3002", "result": "\u901a\u8fc7\u5f3a\u53cd\u9988\u5faa\u73af\u673a\u5236\uff0c\u7f16\u7801\u4ee3\u7406\u80fd\u591f\u4fdd\u6301\u4efb\u52a1\u8f68\u8ff9\uff0c\u751f\u6210\u66f4\u53ef\u9884\u6d4b\u3001\u7b26\u5408\u8981\u6c42\u7684\u4ee3\u7801\uff0c\u51cf\u5c11\u4e86\u4eba\u5de5\u5e72\u9884\u9700\u6c42\u3002", "conclusion": "\u5f3a\u53cd\u9988\u5faa\u73af\u662f\u786e\u4fdd\u7f16\u7801\u4ee3\u7406\u53ef\u9760\u6027\u7684\u5173\u952e\uff0c\u9a8c\u8bc1\u673a\u5236\u80fd\u6709\u6548\u9632\u6b62\u4ee3\u7406\u504f\u79bb\uff0c\u5b9e\u73b0\u66f4\u53ef\u63a7\u7684\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u3002", "topic": "code agent"}}
{"id": "tldr.2512.5c2771a6", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmistral.ai%2Fnews%2Fdevstral-2-vibe-cli%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/rfIwTqcZwX4UDYwgvXd2h7-09DJJaEq34QDmBoqHnks=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmistral.ai%2Fnews%2Fdevstral-2-vibe-cli%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/rfIwTqcZwX4UDYwgvXd2h7-09DJJaEq34QDmBoqHnks=434", "authors": ["TLDR Newsletter"], "title": "Introducing: Devstral 2 and Mistral Vibe CLI", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 6 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmistral.ai%2Fnews%2Fdevstral-2-vibe-cli%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/rfIwTqcZwX4UDYwgvXd2h7-09DJJaEq34QDmBoqHnks=434", "summary": "Introducing: Devstral 2 and Mistral Vibe CLI (6 minute read) Mistral AI has launched Devstral 2 and Devstral Small 2, its next-generation open-source agentic coding models, along with the Mistral Vibe CLI for end-to-end code automation. Devstral 2 (123B) is a state-of-the-art model establishing new benchmarks for open-weight code agents. The Mistral Vibe CLI provides an open-source command-line interface that uses Devstral models to autonomously explore, modify, and execute changes across ent...", "source": "tldr", "AI": {"tldr": "Mistral AI\u53d1\u5e03\u4e86\u65b0\u4e00\u4ee3\u5f00\u6e90\u4ee3\u7801\u4ee3\u7406\u6a21\u578bDevstral 2\u548cDevstral Small 2\uff0c\u4ee5\u53ca\u7528\u4e8e\u7aef\u5230\u7aef\u4ee3\u7801\u81ea\u52a8\u5316\u7684Mistral Vibe CLI\u5de5\u5177", "motivation": "\u63a8\u52a8\u5f00\u6e90\u4ee3\u7801\u4ee3\u7406\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u63d0\u4f9b\u66f4\u5f3a\u5927\u7684\u4ee3\u7801\u751f\u6210\u548c\u81ea\u52a8\u5316\u80fd\u529b\uff0c\u964d\u4f4e\u5f00\u53d1\u8005\u7684\u7f16\u7801\u8d1f\u62c5", "method": "\u5f00\u53d1\u4e86123B\u53c2\u6570\u7684Devstral 2\u6a21\u578b\u4f5c\u4e3a\u5f00\u6e90\u6743\u91cd\u4ee3\u7801\u4ee3\u7406\uff0c\u540c\u65f6\u521b\u5efa\u4e86Mistral Vibe CLI\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u80fd\u591f\u81ea\u4e3b\u63a2\u7d22\u3001\u4fee\u6539\u548c\u6267\u884c\u4ee3\u7801\u53d8\u66f4", "result": "Devstral 2\u5728\u4ee3\u7801\u4ee3\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5efa\u7acb\u4e86\u65b0\u7684\u6807\u51c6\uff0cMistral Vibe CLI\u63d0\u4f9b\u4e86\u7aef\u5230\u7aef\u7684\u4ee3\u7801\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848", "conclusion": "Mistral AI\u7684\u65b0\u4e00\u4ee3\u4ee3\u7801\u4ee3\u7406\u6a21\u578b\u548c\u5de5\u5177\u663e\u8457\u63d0\u5347\u4e86\u5f00\u6e90\u4ee3\u7801\u81ea\u52a8\u5316\u7684\u80fd\u529b\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u8f85\u52a9\u5de5\u5177", "topic": "code agent"}}
{"id": "tldr.2512.64f16e42", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fvercel%2Fstreamdown%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/tzivSK2mG95k_xwpZjrudD3B88BURIUKzaULB1PrdaA=434", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fvercel%2Fstreamdown%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/tzivSK2mG95k_xwpZjrudD3B88BURIUKzaULB1PrdaA=434", "authors": ["TLDR Newsletter"], "title": "Streamdown", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fvercel%2Fstreamdown%3Futm_source=tldrdev/1/0100019b083d999a-f3936cdc-fbaf-4971-83db-628bf95bb4bd-000000/tzivSK2mG95k_xwpZjrudD3B88BURIUKzaULB1PrdaA=434", "summary": "Streamdown (GitHub Repo) Streamdown is a drop-in replacement for `react-markdown` specifically engineered to handle the unique challenges of streaming Markdown content from AI models. It fixes issues like incomplete or unterminated Markdown blocks. Streamdown supports GitHub Flavored Markdown, LaTeX math rendering, Mermaid diagrams, and Shiki code highlighting.", "source": "tldr", "AI": {"tldr": "Streamdown\u662freact-markdown\u7684\u66ff\u4ee3\u5e93\uff0c\u4e13\u95e8\u5904\u7406AI\u6a21\u578b\u6d41\u5f0fMarkdown\u5185\u5bb9\u7684\u72ec\u7279\u6311\u6218\uff0c\u4fee\u590d\u4e0d\u5b8c\u6574\u6216\u672a\u7ec8\u6b62\u7684Markdown\u5757\u95ee\u9898", "motivation": "\u73b0\u6709react-markdown\u5728\u5904\u7406AI\u6a21\u578b\u6d41\u5f0fMarkdown\u5185\u5bb9\u65f6\u5b58\u5728\u7f3a\u9677\uff0c\u7279\u522b\u662f\u65e0\u6cd5\u6b63\u786e\u5904\u7406\u4e0d\u5b8c\u6574\u6216\u672a\u7ec8\u6b62\u7684Markdown\u5757\uff0c\u9700\u8981\u4e13\u95e8\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5f00\u53d1\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u6d41\u5f0fMarkdown\u5904\u7406\u7684\u5e93\uff0c\u4f5c\u4e3areact-markdown\u7684\u66ff\u4ee3\u54c1\uff0c\u652f\u6301GitHub\u98ce\u683cMarkdown\u3001LaTeX\u6570\u5b66\u6e32\u67d3\u3001Mermaid\u56fe\u8868\u548cShiki\u4ee3\u7801\u9ad8\u4eae", "result": "\u521b\u5efa\u4e86Streamdown\u5e93\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406AI\u6a21\u578b\u751f\u6210\u7684\u6d41\u5f0fMarkdown\u5185\u5bb9\uff0c\u89e3\u51b3\u4e86\u4e0d\u5b8c\u6574Markdown\u5757\u7684\u95ee\u9898", "conclusion": "Streamdown\u4e3a\u5904\u7406AI\u6a21\u578b\u6d41\u5f0fMarkdown\u5185\u5bb9\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u4e86\u73b0\u6709\u5de5\u5177\u5728\u5904\u7406\u6b64\u7c7b\u573a\u666f\u65f6\u7684\u4e0d\u8db3", "topic": "swe application"}}
{"id": "tldr.2512.df106c42", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fevilmartians.com%2Fchronicles%2Fvibe-coding-in-style-dot-md%3Futm_source=tldrdesign/1/0100019b085e4328-f4d2c5e5-8d8d-4b8e-b1b1-1743f38a9753-000000/qYp45TbfvtCbn5DXkWJVjgwkQh712jROHeFESsdf8Wo=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fevilmartians.com%2Fchronicles%2Fvibe-coding-in-style-dot-md%3Futm_source=tldrdesign/1/0100019b085e4328-f4d2c5e5-8d8d-4b8e-b1b1-1743f38a9753-000000/qYp45TbfvtCbn5DXkWJVjgwkQh712jROHeFESsdf8Wo=435", "authors": ["TLDR Newsletter"], "title": "Vibe Coding in style.md", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 5 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fevilmartians.com%2Fchronicles%2Fvibe-coding-in-style-dot-md%3Futm_source=tldrdesign/1/0100019b085e4328-f4d2c5e5-8d8d-4b8e-b1b1-1743f38a9753-000000/qYp45TbfvtCbn5DXkWJVjgwkQh712jROHeFESsdf8Wo=435", "summary": "Vibe Coding in style.md (5 minute read) Evil Martians developed a style guide that encodes engineering best practices into a reusable file for AI code generation tools. The guide emerged from comparing a hastily AI-generated Rails app with its expert-refactored version, capturing patterns such as domain-specific naming, enum usage, and the extraction of logic into namespaced classes. This approach transforms expensive code cleanup into a scalable asset that helps non-engineers produce more ma...", "source": "tldr", "AI": {"tldr": "Evil Martians\u5f00\u53d1\u4e86\u4e00\u4e2a\u7f16\u7801\u98ce\u683c\u6307\u5357\uff0c\u5c06\u5de5\u7a0b\u6700\u4f73\u5b9e\u8df5\u7f16\u7801\u5230\u53ef\u91cd\u7528\u7684\u6587\u4ef6\u4e2d\uff0c\u4f9bAI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u4f7f\u7528\uff0c\u5e2e\u52a9\u975e\u5de5\u7a0b\u5e08\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u4ee3\u7801\u3002", "motivation": "\u6bd4\u8f83AI\u5feb\u901f\u751f\u6210\u7684Rails\u5e94\u7528\u4e0e\u4e13\u5bb6\u91cd\u6784\u7248\u672c\u540e\uff0c\u53d1\u73b0\u9700\u8981\u5c06\u5de5\u7a0b\u6700\u4f73\u5b9e\u8df5\u7cfb\u7edf\u5316\uff0c\u4ee5\u89e3\u51b3AI\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u4e0d\u9ad8\u3001\u9700\u8981\u6602\u8d35\u6e05\u7406\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7f16\u7801\u98ce\u683c\u6307\u5357\u6587\u4ef6\uff0c\u6355\u83b7\u4e86\u9886\u57df\u7279\u5b9a\u547d\u540d\u3001\u679a\u4e3e\u4f7f\u7528\u3001\u5c06\u903b\u8f91\u63d0\u53d6\u5230\u547d\u540d\u7a7a\u95f4\u7c7b\u7b49\u6a21\u5f0f\uff0c\u4f5c\u4e3a\u53ef\u91cd\u7528\u7684\u8d44\u4ea7\u4f9bAI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u4f7f\u7528\u3002", "result": "\u5c06\u6602\u8d35\u7684\u4ee3\u7801\u6e05\u7406\u5de5\u4f5c\u8f6c\u5316\u4e3a\u53ef\u6269\u5c55\u7684\u8d44\u4ea7\uff0c\u5e2e\u52a9\u975e\u5de5\u7a0b\u5e08\u751f\u6210\u66f4\u53ef\u7ef4\u62a4\u3001\u66f4\u7b26\u5408\u6700\u4f73\u5b9e\u8df5\u7684\u4ee3\u7801\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5de5\u7a0b\u6700\u4f73\u5b9e\u8df5\u7f16\u7801\u5230\u53ef\u91cd\u7528\u7684\u98ce\u683c\u6307\u5357\u4e2d\uff0c\u53ef\u4ee5\u89c4\u6a21\u5316\u5730\u63d0\u9ad8AI\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\uff0c\u964d\u4f4e\u540e\u671f\u6e05\u7406\u6210\u672c\u3002", "topic": "code agent"}}
{"id": "tldr.2512.9dde988e", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.dynatrace.com%2Finfo%2Freports%2Fbring-clarity-to-your-ai-systems%2F%3Futm_medium=email%26utm_source=tldr%26utm_campaign=cloud-ai-observability-hyperframe-observability-for-ai%26utm_term=111425/2/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/FVipBKrlYxmAFLN6dL2WVILoX682hJt11uK9_gz7bn8=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.dynatrace.com%2Finfo%2Freports%2Fbring-clarity-to-your-ai-systems%2F%3Futm_medium=email%26utm_source=tldr%26utm_campaign=cloud-ai-observability-hyperframe-observability-for-ai%26utm_term=111425/2/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/FVipBKrlYxmAFLN6dL2WVILoX682hJt11uK9_gz7bn8=435", "authors": ["TLDR Newsletter"], "title": "Observability for agentic AI and LLMs: 6 recommendations", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.dynatrace.com%2Finfo%2Freports%2Fbring-clarity-to-your-ai-systems%2F%3Futm_medium=email%26utm_source=tldr%26utm_campaign=cloud-ai-observability-hyperframe-observability-for-ai%26utm_term=111425/2/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/FVipBKrlYxmAFLN6dL2WVILoX682hJt11uK9_gz7bn8=435", "summary": "Observability for agentic AI and LLMs: 6 recommendations (Sponsor) Agentic AI and GenAI are powerful but unpredictable. It's not just hallucination - they regularly take entirely new paths through established workflows.This Dynatrace report lays out six pragmatic observability recommendations for practitioners managing agentic AI and GenAI workloads. Learn to look beyond monitoring, spot escalating costs, and catch critical issues early. Read the report Want to check it out firsthand? Experim...", "source": "tldr", "AI": {"tldr": "Dynatrace\u62a5\u544a\u63d0\u51fa6\u9879\u5b9e\u7528\u53ef\u89c2\u6d4b\u6027\u5efa\u8bae\uff0c\u5e2e\u52a9\u7ba1\u7406\u4ee3\u7406\u5f0fAI\u548c\u751f\u6210\u5f0fAI\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u89e3\u51b3\u5176\u4e0d\u53ef\u9884\u6d4b\u6027\u95ee\u9898", "motivation": "\u4ee3\u7406\u5f0fAI\u548c\u751f\u6210\u5f0fAI\u867d\u7136\u5f3a\u5927\u4f46\u4e0d\u53ef\u9884\u6d4b\uff0c\u4e0d\u4ec5\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u8fd8\u4f1a\u5728\u65e2\u5b9a\u5de5\u4f5c\u6d41\u4e2d\u91c7\u53d6\u5168\u65b0\u8def\u5f84\uff0c\u9700\u8981\u66f4\u597d\u7684\u53ef\u89c2\u6d4b\u6027\u7ba1\u7406", "method": "\u62a5\u544a\u63d0\u51fa6\u9879\u5b9e\u7528\u53ef\u89c2\u6d4b\u6027\u5efa\u8bae\uff0c\u5305\u62ec\u8d85\u8d8a\u4f20\u7edf\u76d1\u63a7\u3001\u53d1\u73b0\u6210\u672c\u4e0a\u5347\u3001\u53ca\u65e9\u53d1\u73b0\u5173\u952e\u95ee\u9898\u7b49\u65b9\u6cd5", "result": "\u63d0\u4f9b\u4e86\u9488\u5bf9\u4ee3\u7406\u5f0fAI\u548c\u751f\u6210\u5f0fAI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5b9e\u7528\u53ef\u89c2\u6d4b\u6027\u6846\u67b6\u548c\u6700\u4f73\u5b9e\u8df5", "conclusion": "\u9700\u8981\u91c7\u7528\u4e13\u95e8\u7684\u53ef\u89c2\u6d4b\u6027\u65b9\u6cd5\u6765\u6709\u6548\u7ba1\u7406\u4ee3\u7406\u5f0fAI\u548c\u751f\u6210\u5f0fAI\u7684\u4e0d\u53ef\u9884\u6d4b\u6027\uff0c\u786e\u4fdd\u5176\u53ef\u9760\u8fd0\u884c", "topic": "agent analysis"}}
{"id": "tldr.2512.394a9521", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmistral.ai%2Fnews%2Fdevstral-2-vibe-cli%3Futm_source=tldrai/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/kzdAKJb2GxZBGMzoozP7afR5rwJVHXioIM6o1562VRY=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmistral.ai%2Fnews%2Fdevstral-2-vibe-cli%3Futm_source=tldrai/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/kzdAKJb2GxZBGMzoozP7afR5rwJVHXioIM6o1562VRY=435", "authors": ["TLDR Newsletter"], "title": "Introducing Devstral2 and Mistral Vibe CLI", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 5 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmistral.ai%2Fnews%2Fdevstral-2-vibe-cli%3Futm_source=tldrai/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/kzdAKJb2GxZBGMzoozP7afR5rwJVHXioIM6o1562VRY=435", "summary": "Introducing Devstral2 and Mistral Vibe CLI (5 minute read) Devstral 2 hits 72.2% on SWE-bench Verified with 123B parameters, making it one of the best open-weight coding models despite being a fraction of the size of its peers. The 24B Devstral Small 2 scores 68.0% and runs on consumer hardware. Mistral also launched Vibe CLI, an open-source terminal agent that orchestrates multi-file changes across codebases.", "source": "tldr", "AI": {"tldr": "Devstral2\u5728SWE-bench\u4e0a\u8fbe\u523072.2%\u51c6\u786e\u7387\uff0c\u6210\u4e3a\u6700\u4f73\u5f00\u6e90\u7f16\u7801\u6a21\u578b\u4e4b\u4e00\uff1b\u540c\u65f6\u63a8\u51faVibe CLI\u7ec8\u7aef\u4ee3\u7406\u5de5\u5177", "motivation": "\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u66f4\u5c0f\u89c4\u6a21\u7684\u4ee3\u7801\u751f\u6210\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fd0\u884c\uff0c\u540c\u65f6\u63d0\u4f9b\u591a\u6587\u4ef6\u4ee3\u7801\u5e93\u7ba1\u7406\u7684\u7ec8\u7aef\u4ee3\u7406\u5de5\u5177", "method": "\u5f00\u53d1\u4e86123B\u53c2\u6570\u7684Devstral2\u6a21\u578b\u548c24B\u7684Devstral Small 2\u6a21\u578b\uff0c\u5e76\u521b\u5efa\u4e86\u5f00\u6e90\u7684Vibe CLI\u7ec8\u7aef\u4ee3\u7406\u5de5\u5177", "result": "Devstral2\u5728SWE-bench Verified\u4e0a\u8fbe\u523072.2%\u51c6\u786e\u7387\uff0cDevstral Small 2\u8fbe\u523068.0%\u4e14\u80fd\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fd0\u884c", "conclusion": "Devstral2\u6210\u4e3a\u6700\u4f73\u5f00\u6e90\u7f16\u7801\u6a21\u578b\u4e4b\u4e00\uff0cVibe CLI\u4e3a\u4ee3\u7801\u5e93\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u7ec8\u7aef\u4ee3\u7406\u5de5\u5177", "topic": "code agent"}}
{"id": "tldr.2512.b110a074", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FEDxRfQ/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/Xo_vQNIvhz_yHJckFugOFpky_bhmI33RKUc6CXh4_ds=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FEDxRfQ/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/Xo_vQNIvhz_yHJckFugOFpky_bhmI33RKUc6CXh4_ds=435", "authors": ["TLDR Newsletter"], "title": "How People Use AI Agents", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 7 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2FEDxRfQ/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/Xo_vQNIvhz_yHJckFugOFpky_bhmI33RKUc6CXh4_ds=435", "summary": "How People Use AI Agents (7 minute read) A large-scale usage study from Perplexity and Harvard reveals that over half of AI agent tasks involve deep cognitive work like research and productivity, challenging the stereotype of agents as simple task-doers.", "source": "tldr", "AI": {"tldr": "\u54c8\u4f5b\u4e0ePerplexity\u7684\u5927\u89c4\u6a21\u4f7f\u7528\u7814\u7a76\u8868\u660e\uff0c\u8d85\u8fc7\u4e00\u534a\u7684AI\u4ee3\u7406\u4efb\u52a1\u6d89\u53ca\u7814\u7a76\u548c\u751f\u4ea7\u529b\u7b49\u6df1\u5ea6\u8ba4\u77e5\u5de5\u4f5c\uff0c\u6311\u6218\u4e86AI\u4ee3\u7406\u4ec5\u5904\u7406\u7b80\u5355\u4efb\u52a1\u7684\u523b\u677f\u5370\u8c61", "motivation": "\u7814\u7a76\u65e8\u5728\u4e86\u89e3\u4eba\u4eec\u5b9e\u9645\u5982\u4f55\u4f7f\u7528AI\u4ee3\u7406\uff0c\u6311\u6218AI\u4ee3\u7406\u4ec5\u7528\u4e8e\u7b80\u5355\u4efb\u52a1\u7684\u666e\u904d\u770b\u6cd5\uff0c\u63a2\u7d22\u5176\u5728\u6df1\u5ea6\u8ba4\u77e5\u5de5\u4f5c\u4e2d\u7684\u771f\u5b9e\u5e94\u7528\u573a\u666f", "method": "\u57fa\u4e8ePerplexity\u548c\u54c8\u4f5b\u7684\u5927\u89c4\u6a21\u4f7f\u7528\u7814\u7a76\uff0c\u5206\u6790\u7528\u6237\u4e0eAI\u4ee3\u7406\u7684\u4ea4\u4e92\u6570\u636e\uff0c\u7edf\u8ba1\u4e0d\u540c\u7c7b\u578b\u4efb\u52a1\u7684\u6bd4\u4f8b\u548c\u7279\u5f81", "result": "\u7814\u7a76\u53d1\u73b0\u8d85\u8fc750%\u7684AI\u4ee3\u7406\u4efb\u52a1\u6d89\u53ca\u7814\u7a76\u3001\u751f\u4ea7\u529b\u7b49\u6df1\u5ea6\u8ba4\u77e5\u5de5\u4f5c\uff0c\u8868\u660eAI\u4ee3\u7406\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\u66f4\u591a\u7528\u4e8e\u590d\u6742\u601d\u8003\u4efb\u52a1\u800c\u975e\u7b80\u5355\u64cd\u4f5c", "conclusion": "AI\u4ee3\u7406\u7684\u5b9e\u9645\u5e94\u7528\u5df2\u8d85\u8d8a\u7b80\u5355\u4efb\u52a1\u8303\u7574\uff0c\u6b63\u6210\u4e3a\u652f\u6301\u6df1\u5ea6\u8ba4\u77e5\u5de5\u4f5c\u7684\u91cd\u8981\u5de5\u5177\uff0c\u9700\u8981\u91cd\u65b0\u8bc4\u4f30\u5bf9AI\u4ee3\u7406\u80fd\u529b\u7684\u4f20\u7edf\u8ba4\u77e5", "topic": "agent analysis"}}
{"id": "tldr.2512.563ed586", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwandb.ai%2Fsite%2Fresources%2Fwhitepapers%2Freinforcement-learning-ebook%3Futm_source=tldr-ai%26utm_medium=cpc%26utm_campaign=weave%26utm_content=RL%26utm_term=newsletter/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/0VsRAv-uSo2dCEYsPtcStcR2Fi8R1SG_TUUlQFjTHls=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwandb.ai%2Fsite%2Fresources%2Fwhitepapers%2Freinforcement-learning-ebook%3Futm_source=tldr-ai%26utm_medium=cpc%26utm_campaign=weave%26utm_content=RL%26utm_term=newsletter/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/0VsRAv-uSo2dCEYsPtcStcR2Fi8R1SG_TUUlQFjTHls=435", "authors": ["TLDR Newsletter"], "title": "Practitioner's guide to reinforcement learning, from Weights & Biases", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwandb.ai%2Fsite%2Fresources%2Fwhitepapers%2Freinforcement-learning-ebook%3Futm_source=tldr-ai%26utm_medium=cpc%26utm_campaign=weave%26utm_content=RL%26utm_term=newsletter/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/0VsRAv-uSo2dCEYsPtcStcR2Fi8R1SG_TUUlQFjTHls=435", "summary": "Practitioner's guide to reinforcement learning, from Weights & Biases (Sponsor) RL has been touted as the direct path to AGI, while others dismiss it as a dead end. Learn how and when RL works best, where SFT, LoRA, and GRPO fit in, and about the benefits of new Serverless RL from Weights & Biases. Get the guide here.", "source": "tldr", "AI": {"tldr": "Weights & Biases\u63d0\u4f9b\u7684\u5f3a\u5316\u5b66\u4e60\u5b9e\u8df5\u6307\u5357\uff0c\u4ecb\u7ecdRL\u5e94\u7528\u573a\u666f\u3001\u4e0e\u5176\u4ed6\u6280\u672f\u7684\u5173\u7cfb\u4ee5\u53ca\u5176Serverless RL\u670d\u52a1", "motivation": "\u9488\u5bf9\u5f3a\u5316\u5b66\u4e60\u5728AGI\u8def\u5f84\u4e0a\u7684\u4e89\u8bae\uff0c\u63d0\u4f9b\u5b9e\u8df5\u6307\u5bfc\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u7406\u89e3RL\u7684\u6700\u4f73\u5e94\u7528\u573a\u666f\u548c\u4e0e\u5176\u4ed6\u6280\u672f\u7684\u5173\u7cfb", "method": "\u63d0\u4f9b\u5b9e\u8df5\u6307\u5357\uff0c\u6db5\u76d6RL\u5de5\u4f5c\u539f\u7406\u3001SFT\u3001LoRA\u3001GRPO\u7b49\u6280\u672f\u5728RL\u4e2d\u7684\u89d2\u8272\uff0c\u4ee5\u53caWeights & Biases\u7684Serverless RL\u670d\u52a1", "result": "\u63d0\u4f9b\u4e86\u4e00\u4efd\u5168\u9762\u7684RL\u5b9e\u8df5\u6307\u5357\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u7406\u89e3\u4f55\u65f6\u4f7f\u7528RL\u4ee5\u53ca\u5982\u4f55\u7ed3\u5408\u5176\u4ed6\u6280\u672f\uff0c\u5e76\u63a8\u5e7f\u4e86Weights & Biases\u7684Serverless RL\u670d\u52a1", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u662f\u590d\u6742\u4f46\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u9700\u8981\u6839\u636e\u5177\u4f53\u573a\u666f\u9009\u62e9\u4f7f\u7528\uff0cWeights & Biases\u7684Serverless RL\u53ef\u4ee5\u7b80\u5316RL\u5e94\u7528\u5f00\u53d1", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2512.e247fc20", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fai-machine-learning%2Falphaevolve-on-google-cloud%3Futm_source=tldrai/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/YD2LJzab2DMMjEEcSAALmT9rHD94uOlg1C2e7SE3d58=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fai-machine-learning%2Falphaevolve-on-google-cloud%3Futm_source=tldrai/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/YD2LJzab2DMMjEEcSAALmT9rHD94uOlg1C2e7SE3d58=435", "authors": ["TLDR Newsletter"], "title": "AlphaEvolve on Google Cloud: AI for agentic discovery and optimization", "comment": "Source: TLDR Newsletter, Date: 2025-12-10, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcloud.google.com%2Fblog%2Fproducts%2Fai-machine-learning%2Falphaevolve-on-google-cloud%3Futm_source=tldrai/1/0100019b08a0d363-13b01862-7b7f-4091-8d0a-a18507b5d782-000000/YD2LJzab2DMMjEEcSAALmT9rHD94uOlg1C2e7SE3d58=435", "summary": "AlphaEvolve on Google Cloud: AI for agentic discovery and optimization (4 minute read) AlphaEvolve, now on Google Cloud in private preview, leverages Gemini models to optimize complex problems by evolving algorithms through mutation and evaluation. The technology has improved data center efficiency, reduced Gemini's training time, and accelerated TPU design at Google. Various industries, including biotech and logistics, can use it to solve proprietary optimization challenges.", "source": "tldr", "AI": {"tldr": "AlphaEvolve\u5728Google Cloud\u4e0a\u63a8\u51fa\uff0c\u5229\u7528Gemini\u6a21\u578b\u901a\u8fc7\u7b97\u6cd5\u8fdb\u5316\uff08\u53d8\u5f02\u548c\u8bc4\u4f30\uff09\u6765\u4f18\u5316\u590d\u6742\u95ee\u9898\uff0c\u5df2\u5728Google\u5185\u90e8\u63d0\u5347\u6570\u636e\u4e2d\u5fc3\u6548\u7387\u3001\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u5e76\u52a0\u901fTPU\u8bbe\u8ba1\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u4f18\u5316\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u6570\u636e\u4e2d\u5fc3\u6548\u7387\u3001AI\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u548c\u786c\u4ef6\u8bbe\u8ba1\u7b49\u9886\u57df\u7684\u6311\u6218\uff0c\u4e3a\u5404\u884c\u4e1a\u63d0\u4f9b\u4e13\u6709\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8eGemini\u6a21\u578b\uff0c\u91c7\u7528\u7b97\u6cd5\u8fdb\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5f02\u548c\u8bc4\u4f30\u8fc7\u7a0b\u6765\u6f14\u5316\u7b97\u6cd5\uff0c\u5728Google Cloud\u5e73\u53f0\u4e0a\u5b9e\u73b0\u3002", "result": "\u5728Google\u5185\u90e8\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff1a\u63d0\u9ad8\u4e86\u6570\u636e\u4e2d\u5fc3\u6548\u7387\uff0c\u51cf\u5c11\u4e86Gemini\u6a21\u578b\u7684\u8bad\u7ec3\u65f6\u95f4\uff0c\u52a0\u901f\u4e86TPU\u8bbe\u8ba1\u8fc7\u7a0b\u3002", "conclusion": "AlphaEvolve\u6280\u672f\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u751f\u7269\u6280\u672f\u548c\u7269\u6d41\u7b49\u884c\u4e1a\u53ef\u4ee5\u5229\u7528\u5b83\u6765\u89e3\u51b3\u4e13\u6709\u7684\u4f18\u5316\u6311\u6218\u3002", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2512.382876e1", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.infoworld.com%2Farticle%2F4101981%2Fai-memory-is-just-another-database-problem.html%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/pUUOqqR4DaDu1kh3E0eXy5gympeUU8YYX9hRQfUJW8Q=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.infoworld.com%2Farticle%2F4101981%2Fai-memory-is-just-another-database-problem.html%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/pUUOqqR4DaDu1kh3E0eXy5gympeUU8YYX9hRQfUJW8Q=435", "authors": ["TLDR Newsletter"], "title": "AI Memory is Really a Database Problem", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: 7 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.infoworld.com%2Farticle%2F4101981%2Fai-memory-is-just-another-database-problem.html%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/pUUOqqR4DaDu1kh3E0eXy5gympeUU8YYX9hRQfUJW8Q=435", "summary": "AI Memory is Really a Database Problem (7 minute read) AI agent memory must be treated with the same rigor as enterprise databases, incorporating firewalls, access controls, row-level security, and full auditability. Current approaches\u2014often unmanaged vector stores or in-memory caches\u2014create significant attack surfaces through memory poisoning, tool misuse, and privilege creep. Integrating agent memory into governed, auditable data infrastructure ensures data lineage, lifecycle management, an...", "source": "tldr", "AI": {"tldr": "AI\u4ee3\u7406\u5185\u5b58\u5e94\u50cf\u4f01\u4e1a\u6570\u636e\u5e93\u4e00\u6837\u4e25\u683c\u7ba1\u7406\uff0c\u91c7\u7528\u9632\u706b\u5899\u3001\u8bbf\u95ee\u63a7\u5236\u3001\u884c\u7ea7\u5b89\u5168\u548c\u5b8c\u6574\u5ba1\u8ba1\uff0c\u800c\u975e\u5f53\u524d\u65e0\u7ba1\u7406\u7684\u5411\u91cf\u5b58\u50a8\u6216\u5185\u5b58\u7f13\u5b58", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\uff08\u5982\u65e0\u7ba1\u7406\u7684\u5411\u91cf\u5b58\u50a8\u6216\u5185\u5b58\u7f13\u5b58\uff09\u5b58\u5728\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff0c\u5305\u62ec\u5185\u5b58\u4e2d\u6bd2\u3001\u5de5\u5177\u6ee5\u7528\u548c\u6743\u9650\u8513\u5ef6\uff0c\u9700\u8981\u66f4\u4e25\u683c\u7684\u6570\u636e\u6cbb\u7406", "method": "\u5c06AI\u4ee3\u7406\u5185\u5b58\u96c6\u6210\u5230\u53d7\u6cbb\u7406\u3001\u53ef\u5ba1\u8ba1\u7684\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u4e2d\uff0c\u786e\u4fdd\u6570\u636e\u6cbf\u88ad\u3001\u751f\u547d\u5468\u671f\u7ba1\u7406\uff0c\u5e76\u91c7\u7528\u4f01\u4e1a\u6570\u636e\u5e93\u7ea7\u522b\u7684\u5b89\u5168\u63a7\u5236\u63aa\u65bd", "result": "\u901a\u8fc7\u5c06AI\u5185\u5b58\u89c6\u4e3a\u6570\u636e\u5e93\u95ee\u9898\u5904\u7406\uff0c\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u653b\u51fb\u9762\uff0c\u63d0\u9ad8\u5b89\u5168\u6027\uff0c\u5e76\u786e\u4fdd\u6570\u636e\u7684\u5b8c\u6574\u6027\u548c\u53ef\u8ffd\u6eaf\u6027", "conclusion": "AI\u4ee3\u7406\u5185\u5b58\u7ba1\u7406\u9700\u8981\u91c7\u7528\u4f01\u4e1a\u6570\u636e\u5e93\u7ea7\u522b\u7684\u4e25\u683c\u5b89\u5168\u548c\u63a7\u5236\u63aa\u65bd\uff0c\u800c\u4e0d\u662f\u4f9d\u8d56\u5f53\u524d\u4e0d\u5b89\u5168\u7684\u4e34\u65f6\u89e3\u51b3\u65b9\u6848", "topic": "agent analysis"}}
{"id": "tldr.2512.99d6bddd", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.infoq.com%2Fnews%2F2025%2F12%2Fagentic-postgres-fast-forking%2F%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/HVIUYo5ITYmYIyrdEjwZvHMqeEDV5TVjF8xr21GOrn8=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.infoq.com%2Fnews%2F2025%2F12%2Fagentic-postgres-fast-forking%2F%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/HVIUYo5ITYmYIyrdEjwZvHMqeEDV5TVjF8xr21GOrn8=435", "authors": ["TLDR Newsletter"], "title": "Agentic Postgres: Postgres for Agentic Apps with Fast Forking and AI-Ready Features", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: 2 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.infoq.com%2Fnews%2F2025%2F12%2Fagentic-postgres-fast-forking%2F%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/HVIUYo5ITYmYIyrdEjwZvHMqeEDV5TVjF8xr21GOrn8=435", "summary": "Agentic Postgres: Postgres for Agentic Apps with Fast Forking and AI-Ready Features (2 minute read) Agentic Postgres is a Postgres extension built for AI agents that adds sub-second copy-on-write forking (via Fluid Storage), native BM25 and high-performance vector search, and an integrated MCP server for natural-language schema management and prompt-driven operations. It enables instant, isolated sandboxes on live production data, dramatically speeding up agentic workflows, safe experimentati...", "source": "tldr", "AI": {"tldr": "Agentic Postgres \u662f\u4e00\u4e2a\u4e3aAI\u4ee3\u7406\u8bbe\u8ba1\u7684PostgreSQL\u6269\u5c55\uff0c\u63d0\u4f9b\u79d2\u7ea7\u5199\u65f6\u590d\u5236\u5206\u53c9\u3001\u539f\u751fBM25\u548c\u9ad8\u6027\u80fd\u5411\u91cf\u641c\u7d22\uff0c\u4ee5\u53ca\u96c6\u6210\u7684MCP\u670d\u52a1\u5668\uff0c\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u6a21\u5f0f\u7ba1\u7406\u548c\u63d0\u793a\u9a71\u52a8\u7684\u64cd\u4f5c\u3002", "motivation": "\u73b0\u6709\u7684PostgreSQL\u6570\u636e\u5e93\u5728\u5904\u7406AI\u4ee3\u7406\u5de5\u4f5c\u6d41\u65f6\u5b58\u5728\u6027\u80fd\u74f6\u9888\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5feb\u901f\u6570\u636e\u5206\u53c9\u3001\u5411\u91cf\u641c\u7d22\u548c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u65b9\u9762\u3002AI\u4ee3\u7406\u5e94\u7528\u9700\u8981\u80fd\u591f\u5feb\u901f\u521b\u5efa\u6570\u636e\u6c99\u7bb1\u3001\u8fdb\u884c\u9ad8\u6548\u7684\u8bed\u4e49\u641c\u7d22\uff0c\u4ee5\u53ca\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u7ba1\u7406\u6570\u636e\u5e93\u3002", "method": "\u5f00\u53d1PostgreSQL\u6269\u5c55\uff0c\u96c6\u6210\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1) Fluid Storage\u5b9e\u73b0\u79d2\u7ea7\u5199\u65f6\u590d\u5236\u5206\u53c9\uff1b2) \u539f\u751fBM25\u548c\u9ad8\u6027\u80fd\u5411\u91cf\u641c\u7d22\uff1b3) \u96c6\u6210MCP\u670d\u52a1\u5668\u652f\u6301\u81ea\u7136\u8bed\u8a00\u6a21\u5f0f\u7ba1\u7406\u548c\u63d0\u793a\u9a71\u52a8\u64cd\u4f5c\u3002", "result": "\u80fd\u591f\u4e3aAI\u4ee3\u7406\u5e94\u7528\u63d0\u4f9b\u5373\u65f6\u9694\u79bb\u7684\u6c99\u7bb1\u73af\u5883\uff0c\u663e\u8457\u52a0\u901f\u4ee3\u7406\u5de5\u4f5c\u6d41\uff0c\u652f\u6301\u5b89\u5168\u5b9e\u9a8c\uff0c\u5e76\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u9a71\u52a8\u7684\u6570\u636e\u5e93\u7ba1\u7406\u3002", "conclusion": "Agentic Postgres\u901a\u8fc7\u6269\u5c55PostgreSQL\u529f\u80fd\uff0c\u4f7f\u5176\u66f4\u9002\u5408AI\u4ee3\u7406\u5e94\u7528\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u5206\u53c9\u3001\u641c\u7d22\u6548\u7387\u548c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u7b49\u5173\u952e\u95ee\u9898\u3002", "topic": "code agent"}}
{"id": "tldr.2512.4f4a7163", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fnews%2Fdonating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/kxb0TuUAaCBfwZOOPM_x7GLphNnGOiYAxZMubDf9nnA=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fnews%2Fdonating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/kxb0TuUAaCBfwZOOPM_x7GLphNnGOiYAxZMubDf9nnA=435", "authors": ["TLDR Newsletter"], "title": "Donating the Model Context Protocol and Establishing the Agentic AI Foundation", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fnews%2Fdonating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation%3Futm_source=tldrdata/1/0100019b0d189ec2-3866eb1e-7402-47a9-94e1-f43aca7361c5-000000/kxb0TuUAaCBfwZOOPM_x7GLphNnGOiYAxZMubDf9nnA=435", "summary": "Donating the Model Context Protocol and Establishing the Agentic AI Foundation (4 minute read) Anthropic donated Model Context Protocol (MCP) to the newly created Agentic AI Foundation (AAIF) under Linux Foundation, putting it alongside contributions such as goose (from Block) and AGENTS.md (from OpenAI). The move ensures MCP becomes a vendor-neutral, community-governed standard for linking AI agents to external tools, data, and services that promote interoperability, open governance, and lon...", "source": "tldr", "AI": {"tldr": "Anthropic\u5c06Model Context Protocol\u6350\u8d60\u7ed9\u65b0\u6210\u7acb\u7684Agentic AI Foundation\uff0c\u4f7f\u5176\u6210\u4e3a\u8fde\u63a5AI\u4ee3\u7406\u4e0e\u5916\u90e8\u5de5\u5177\u3001\u6570\u636e\u548c\u670d\u52a1\u7684\u4f9b\u5e94\u5546\u4e2d\u7acb\u3001\u793e\u533a\u6cbb\u7406\u6807\u51c6", "motivation": "\u4fc3\u8fdbAI\u4ee3\u7406\u4e0e\u5916\u90e8\u5de5\u5177\u3001\u6570\u636e\u548c\u670d\u52a1\u7684\u4e92\u64cd\u4f5c\u6027\uff0c\u5efa\u7acb\u5f00\u653e\u6cbb\u7406\u7684\u884c\u4e1a\u6807\u51c6\uff0c\u907f\u514d\u4f9b\u5e94\u5546\u9501\u5b9a", "method": "\u5c06Model Context Protocol\u6350\u8d60\u7ed9Linux Foundation\u4e0b\u7684Agentic AI Foundation\uff0c\u4f7f\u5176\u6210\u4e3a\u793e\u533a\u6cbb\u7406\u7684\u5f00\u653e\u6807\u51c6", "result": "MCP\u6210\u4e3a\u4f9b\u5e94\u5546\u4e2d\u7acb\u7684\u6807\u51c6\u534f\u8bae\uff0c\u4e0egoose\u3001AGENTS.md\u7b49\u8d21\u732e\u5e76\u5217\uff0c\u63a8\u52a8AI\u4ee3\u7406\u751f\u6001\u7684\u4e92\u64cd\u4f5c\u6027", "conclusion": "\u901a\u8fc7\u5efa\u7acb\u5f00\u653e\u6807\u51c6\u4fc3\u8fdbAI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u4e92\u64cd\u4f5c\u6027\u548c\u534f\u4f5c\u53d1\u5c55", "topic": "agent analysis"}}
{"id": "wechat.2512.11f2d065", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAwMjE0NDA5Mg==&mid=2650030709&idx=4&sn=deee01d1cce736a19eb4fc9ed54c6309&chksm=83df50c3ecc5137e35f24acf2f8253e5393780f4a995005f7e3f20f1ca1c5ec3f2016c296ae1#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAwMjE0NDA5Mg==&mid=2650030709&idx=4&sn=deee01d1cce736a19eb4fc9ed54c6309&chksm=83df50c3ecc5137e35f24acf2f8253e5393780f4a995005f7e3f20f1ca1c5ec3f2016c296ae1#rd", "authors": ["\u56fd\u9632\u79d1\u6280\u5927\u5b66\u5b66\u62a5"], "title": "\u56fd\u9632\u79d1\u6280\u5927\u5b66\u201c\u5929\u6cb3\u201d\u9ad8\u6027\u80fd\u8ba1\u7b97\u673a\u7cfb\u7edf\u7ed3\u6784\u7814\u7a76\u56e2\u961f | \u6df1\u5ea6<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u548c\u8d1f\u8f7d\u4e2d\u5fc3\u6027\u7406\u8bba\u878d\u5408\u7684\u5206\u6bb5\u8def\u7531\u4f18\u5316\u7b97\u6cd5", "comment": "Source: WeChat, Published: 2025-12-12 09:02:36", "summary": "\u5229\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u5173\u952e\u8282\u70b9\u90e8\u7f72\u5206\u5e03\u5f0f\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5171\u4eab\u5956\u52b1\u673a\u5236\u534f\u8c03\u8def\u7531\u51b3\u7b56\uff0c\u5b9e\u73b0\u94fe\u8def\u8d1f\u8f7d\u7684\u4e3b\u52a8\u4f18\u5316\u3002\u540c\u65f6\u7ed3\u5408SR\u7684\u7075\u6d3b\u6027\uff0c\u52a8\u6001\u8c03\u6574\u6bb5\u6807\u8bc6\u5217\u8868\u5feb\u901f\u91cd\u8def\u7531\u90e8\u5206\u6d41\u91cf\uff0c\u964d\u4f4e\u672c\u5730\u94fe\u8def\u5229\u7528\u7387\u5e76\u89c4", "AI": {"tldr": "\u5229\u7528\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u5173\u952e\u8282\u70b9\u90e8\u7f72\u5206\u5e03\u5f0f\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u5171\u4eab\u5956\u52b1\u673a\u5236\u534f\u8c03\u8def\u7531\u51b3\u7b56\uff0c\u5b9e\u73b0\u94fe\u8def\u8d1f\u8f7d\u7684\u4e3b\u52a8\u4f18\u5316\u3002\u540c\u65f6\u7ed3\u5408SR\u7684\u7075\u6d3b\u6027\uff0c\u52a8\u6001\u8c03\u6574\u6bb5\u6807\u8bc6\u5217\u8868\u5feb\u901f\u91cd\u8def\u7531\u90e8\u5206\u6d41\u91cf\uff0c\u964d\u4f4e\u672c\u5730\u94fe\u8def\u5229\u7528\u7387\u5e76\u89c4", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.53075470", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzE5ODk0NTY4Ng==&mid=2247483696&idx=1&sn=9fe930ce495b7c8f21d0016554dbc833&chksm=970f7e095e5cf5746ad5ddb225c701c20fb81e5c910876748707191d79c50e5051ab04d5814c#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzE5ODk0NTY4Ng==&mid=2247483696&idx=1&sn=9fe930ce495b7c8f21d0016554dbc833&chksm=970f7e095e5cf5746ad5ddb225c701c20fb81e5c910876748707191d79c50e5051ab04d5814c#rd", "authors": ["\u95f2\u95f2\u7231\u8bd7\u4e66"], "title": "\u4e00\u6587\u8bb2\u6e05\u695a:\u673a\u5668\u5b66\u4e60\u3001\u6df1\u5ea6\u5b66\u4e60\u3001<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>", "comment": "Source: WeChat, Published: 2025-12-12 07:40:26", "summary": "\u5f3a\u5316\u5b66\u4e60\uff1a\u4e0d\u662f\u4ece\u6570\u636e\u91cc\u5b66\uff0c\u800c\u662f\u9760\u201c\u8bd5\u9519 + \u5956\u52b1\u201d\u5b66\u4f1a\u7b56\u7565 \u4e00\u53e5\u8bdd\u603b\u7ed3\u5173\u7cfb\uff1a\u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u5f3a\u5316\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u8303\u5f0f\uff0c\u5b83\u53ef\u4ee5\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e00\u8d77\u7528\u3002", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\uff1a\u4e0d\u662f\u4ece\u6570\u636e\u91cc\u5b66\uff0c\u800c\u662f\u9760\u201c\u8bd5\u9519 + \u5956\u52b1\u201d\u5b66\u4f1a\u7b56\u7565 \u4e00\u53e5\u8bdd\u603b\u7ed3\u5173\u7cfb\uff1a\u6df1\u5ea6\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u65b9\u6cd5\uff0c\u5f3a\u5316\u5b66\u4e60\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u79cd\u8303\u5f0f\uff0c\u5b83\u53ef\u4ee5\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4e00\u8d77\u7528\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.d6fa6775", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0NjM1MTgxNg==&mid=2247490473&idx=1&sn=4c8d08887c46309bbdaa500a9f17dbe2&chksm=c2c9d6e49079a1b3d70685d1439164f343c9db0a55a3b2277ebbf0a55953ebb27cff3178476e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0NjM1MTgxNg==&mid=2247490473&idx=1&sn=4c8d08887c46309bbdaa500a9f17dbe2&chksm=c2c9d6e49079a1b3d70685d1439164f343c9db0a55a3b2277ebbf0a55953ebb27cff3178476e#rd", "authors": ["\u4e9a\u4fe1\u79d1\u6280\u65b0\u6280\u672f\u63a2\u7d22"], "title": "\u591a\u6a21\u6001\u5927\u6a21\u578b\u7ed3\u5408<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7684\u6a21\u5f0f\u63a2\u8ba8", "comment": "Source: WeChat, Published: 2025-12-12 03:58:00", "summary": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u4ef7\u503c\u51fd\u6570\u6216\u7b56\u7565\u51fd\u6570\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\u3002\u4e8c \u6838\u5fc3\u65b9\u6cd5\u4e0e\u6280\u672f\u8def\u5f84", "AI": {"tldr": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u4ef7\u503c\u51fd\u6570\u6216\u7b56\u7565\u51fd\u6570\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u5728\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u7ef4\u5ea6\u707e\u96be\u95ee\u9898\u3002\u4e8c \u6838\u5fc3\u65b9\u6cd5\u4e0e\u6280\u672f\u8def\u5f84", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.46eada90", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkwMTEzMjE5OQ==&mid=2247669742&idx=5&sn=655f7740e4307c6c58730f1ed89fab61&chksm=c1dbbcbc1cf7db9a9fb83887b0f013365673bf79a2e2bd4c65a3c3f19916296158480f61091c#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkwMTEzMjE5OQ==&mid=2247669742&idx=5&sn=655f7740e4307c6c58730f1ed89fab61&chksm=c1dbbcbc1cf7db9a9fb83887b0f013365673bf79a2e2bd4c65a3c3f19916296158480f61091c#rd", "authors": ["\u4eca\u65e5\u65b0\u6750\u6599"], "title": "\u7814\u7a76\u8fdb\u5c55\uff1a\u5fc6\u963b\u5668-\u7c7b\u8111<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em> | Nature Machine Intelligence", "comment": "Source: WeChat, Published: 2025-12-12 03:32:13", "summary": "\u56fe1-\u7c7b\u8111\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\u4e0e\u4efb\u52a1\u793a\u610f\u56fe\u56fe2-\u6a21\u62df\u5fc6\u963b\u5668\u7684\u5236\u5907\u4e0e\u7535\u5b66\u7279\u6027\u56fe3-\u5185\u5b58\u5b66\u4e60\u5faa\u73af\u4e0e\u8bef\u5dee\u6821\u6b63\u673a\u5236\u56fe4-T\u8ff7\u5bab\u5bfc\u822a\u4efb\u52a1\u7684\u786c\u4ef6\u5b9e\u73b0\u7ed3\u679c\u56fe5-\u83ab\u91cc\u65af\u6c34\u8ff7\u5bab\u4efb\u52a1\u7684\u4eff\u771f\u6269\u5c55", "AI": {"tldr": "\u56fe1-\u7c7b\u8111\u5f3a\u5316\u5b66\u4e60\u67b6\u6784\u4e0e\u4efb\u52a1\u793a\u610f\u56fe\u56fe2-\u6a21\u62df\u5fc6\u963b\u5668\u7684\u5236\u5907\u4e0e\u7535\u5b66\u7279\u6027\u56fe3-\u5185\u5b58\u5b66\u4e60\u5faa\u73af\u4e0e\u8bef\u5dee\u6821\u6b63\u673a\u5236\u56fe4-T\u8ff7\u5bab\u5bfc\u822a\u4efb\u52a1\u7684\u786c\u4ef6\u5b9e\u73b0\u7ed3\u679c\u56fe5-\u83ab\u91cc\u65af\u6c34\u8ff7\u5bab\u4efb\u52a1\u7684\u4eff\u771f\u6269\u5c55", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.f60983ae", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2651006802&idx=1&sn=e3c63a11065446d8df4ba386229f7a6d&chksm=851e48891550b96e2fd6e0cad212a7fc8125024ff965c8109ddde2d85e2acd281c89812e4cf7#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2651006802&idx=1&sn=e3c63a11065446d8df4ba386229f7a6d&chksm=851e48891550b96e2fd6e0cad212a7fc8125024ff965c8109ddde2d85e2acd281c89812e4cf7#rd", "authors": ["\u673a\u5668\u4e4b\u5fc3"], "title": "\u5168\u7403<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>+VLA\u8303\u5f0f\uff0cPI*0.6\u80cc\u540e\u90fd\u6709\u8fd9\u5bb6\u4e2d\u56fd\u516c\u53f8\u6280\u672f\u4f0f\u7b14", "comment": "Source: WeChat, Published: 2025-12-12 03:21:40", "summary": "\u7b2c\u4e00\u9636\u6bb5\uff1a\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08\u63a2\u7d22\u4e0e\u53d1\u73b0\uff09\u56fe\u6ce8\uff1a\u7a33\u5b9a\u63a2\u7d22\u5728\u8fd9\u4e2a\u9636\u6bb5\uff0c\u673a\u5668\u4eba\u7684\u76ee\u6807\u662f\u53bb\u8bd5\u9519\uff0c\u63a2\u7d22\u5982\u4f55\u5b8c\u6210\u65b0\u4efb\u52a1\u3002\u51bb\u7ed3\u5927\u8111\uff08Freeze VLM\uff09\uff1a\u4e3a\u4e86\u9632\u6b62\u6a21\u578b\u5d29\u6e83\u548c\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u4f5c\u8005\u51bb\u7ed3\u4e86\u5de8\u5927\u7684 VLM \u4e3b\u5e72\u53c2\u6570\u3002", "AI": {"tldr": "\u7b2c\u4e00\u9636\u6bb5\uff1a\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08\u63a2\u7d22\u4e0e\u53d1\u73b0\uff09\u56fe\u6ce8\uff1a\u7a33\u5b9a\u63a2\u7d22\u5728\u8fd9\u4e2a\u9636\u6bb5\uff0c\u673a\u5668\u4eba\u7684\u76ee\u6807\u662f\u53bb\u8bd5\u9519\uff0c\u63a2\u7d22\u5982\u4f55\u5b8c\u6210\u65b0\u4efb\u52a1\u3002\u51bb\u7ed3\u5927\u8111\uff08Freeze VLM\uff09\uff1a\u4e3a\u4e86\u9632\u6b62\u6a21\u578b\u5d29\u6e83\u548c\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u4f5c\u8005\u51bb\u7ed3\u4e86\u5de8\u5927\u7684 VLM \u4e3b\u5e72\u53c2\u6570\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.0f6d831b", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0NzY3ODMxMA==&mid=2247488841&idx=1&sn=1529aeae908be13175f03b5750ef7979&chksm=c2f86a9aa2539826be9c79d1b347aedfc132c0a7ea4e1821dfe50757342a4a23aef87fbb98be#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0NzY3ODMxMA==&mid=2247488841&idx=1&sn=1529aeae908be13175f03b5750ef7979&chksm=c2f86a9aa2539826be9c79d1b347aedfc132c0a7ea4e1821dfe50757342a4a23aef87fbb98be#rd", "authors": ["AI\u65b0\u6587"], "title": "\u3010\u4e13\u9898\u3011AI\u9886\u57df\u4e2d\u7684\u201c<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u201d\u76f8\u5173\u7814\u7a76-2025\u5e7411-12\u6708", "comment": "Source: WeChat, Published: 2025-12-11 23:06:45", "summary": "\u52a8\u6001\u73af\u5883\u4e0b\u7684\u57fa\u4e8e\u4fe1\u53f7\u6fc0\u52b1\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60 \u539f\u6807\u9898\uff1aSignaling-Driven Incentive Communication for Enhanced Multiagent Reinforcement Learning in Dynamic Environments\u4f5c\u8005\uff1aKexing Peng\uff1b", "AI": {"tldr": "\u52a8\u6001\u73af\u5883\u4e0b\u7684\u57fa\u4e8e\u4fe1\u53f7\u6fc0\u52b1\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60 \u539f\u6807\u9898\uff1aSignaling-Driven Incentive Communication for Enhanced Multiagent Reinforcement Learning in Dynamic Environments\u4f5c\u8005\uff1aKexing Peng\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.32785bcb", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxODMwOTc4OQ==&mid=2650748298&idx=1&sn=0e614637a06af9bf35cae595369d48e2&chksm=828171253ea1e4e9b6494b46c47e1fa395fba263877e5d9ed2aeca5e2c7fd6c5cae25e78312c#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxODMwOTc4OQ==&mid=2650748298&idx=1&sn=0e614637a06af9bf35cae595369d48e2&chksm=828171253ea1e4e9b6494b46c47e1fa395fba263877e5d9ed2aeca5e2c7fd6c5cae25e78312c#rd", "authors": ["\u81f3\u9876\u5934\u6761"], "title": "2025 re:Invent \uff1a\u4e9a\u9a6c\u900a\u4e91\u79d1\u6280\u628a<em class=\"highlight\">Agentic</em> AI\u751f\u6001\u68b3\u7406\u660e\u767d\u4e86", "comment": "Source: WeChat, Published: 2025-12-12 12:10:10", "summary": "\u4e9a\u9a6c\u900a\u4e91\u79d1\u6280\u770b\u5230Agent\u7684\u51fa\u73b0\u8ba9\u4f01\u4e1a\u7684\u6295\u8d44\u5f00\u59cb\u770b\u5230\u6210\u679c\uff0c\u672a\u6765\u6bcf\u4e2a\u4f01\u4e1a\u90fd\u5c06\u4f1a\u6709\u5f88\u591aAgent\uff0c\u5904\u7406\u66f4\u591a\u7684\u4e8b\u60c5\uff0c\u6bcf\u4e2a\u4f01\u4e1a\u90fd\u53ef\u4ee5\u4eceAI\u4e2d\u5f97\u5230\u66f4\u591a\u4ef7\u503c\uff0c\u6240\u4ee5\u4e9a\u9a6c\u900a\u4e91\u79d1\u6280\u5bf9\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u3001\u63a8\u7406\u5e73\u53f0\u3001\u4f01\u4e1a\u6570\u636e\u3001\u6784\u5efaAgent\u7684\u5de5\u5177", "AI": {"tldr": "\u4e9a\u9a6c\u900a\u4e91\u79d1\u6280\u770b\u5230Agent\u7684\u51fa\u73b0\u8ba9\u4f01\u4e1a\u7684\u6295\u8d44\u5f00\u59cb\u770b\u5230\u6210\u679c\uff0c\u672a\u6765\u6bcf\u4e2a\u4f01\u4e1a\u90fd\u5c06\u4f1a\u6709\u5f88\u591aAgent\uff0c\u5904\u7406\u66f4\u591a\u7684\u4e8b\u60c5\uff0c\u6bcf\u4e2a\u4f01\u4e1a\u90fd\u53ef\u4ee5\u4eceAI\u4e2d\u5f97\u5230\u66f4\u591a\u4ef7\u503c\uff0c\u6240\u4ee5\u4e9a\u9a6c\u900a\u4e91\u79d1\u6280\u5bf9\u4eba\u5de5\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u3001\u63a8\u7406\u5e73\u53f0\u3001\u4f01\u4e1a\u6570\u636e\u3001\u6784\u5efaAgent\u7684\u5de5\u5177", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.477e1852", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzUzMjkzNTI5OQ==&mid=2247540984&idx=1&sn=dd6dabfcdfd3335b07b0378ac80113cf&chksm=fbc660b1110c137eaac773c14814fc823f5923b26aa8efa6069a204128420697afee4b06580f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzUzMjkzNTI5OQ==&mid=2247540984&idx=1&sn=dd6dabfcdfd3335b07b0378ac80113cf&chksm=fbc660b1110c137eaac773c14814fc823f5923b26aa8efa6069a204128420697afee4b06580f#rd", "authors": ["\u827e\u90a6\u65b0\u6d88\u8d39\u7535\u5b50\u8d44\u8baf"], "title": "\u7f8e\u56fdFDA\u63a8\u51fa\u65b0\u4e00\u4ee3<em class=\"highlight\">Agentic</em> AI\u5de5\u5177\uff0c\u805a\u7126\u590d\u6742\u5de5\u4f5c\u6d41\u7a0b\u4f18\u5316\uff01", "comment": "Source: WeChat, Published: 2025-12-12 10:05:32", "summary": "Agentic AI \u6307\u4e00\u79cd\u80fd\u591f\u901a\u8fc7\u89c4\u5212\u3001\u63a8\u7406\u548c\u6267\u884c\u591a\u6b65\u9aa4\u884c\u52a8\u6765\u5b9e\u73b0\u7279\u5b9a\u76ee\u6807\u7684\u5148\u8fdb\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002\u8fd9\u7c7b\u7cfb\u7edf\u5185\u7f6e\u6307\u5bfc\u673a\u5236\u2014\u2014\u5305\u62ec\u4eba\u5de5\u76d1\u7763\u2014\u2014\u4ee5\u786e\u4fdd\u7ed3\u679c\u53ef\u9760\u3002", "AI": {"tldr": "Agentic AI \u6307\u4e00\u79cd\u80fd\u591f\u901a\u8fc7\u89c4\u5212\u3001\u63a8\u7406\u548c\u6267\u884c\u591a\u6b65\u9aa4\u884c\u52a8\u6765\u5b9e\u73b0\u7279\u5b9a\u76ee\u6807\u7684\u5148\u8fdb\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002\u8fd9\u7c7b\u7cfb\u7edf\u5185\u7f6e\u6307\u5bfc\u673a\u5236\u2014\u2014\u5305\u62ec\u4eba\u5de5\u76d1\u7763\u2014\u2014\u4ee5\u786e\u4fdd\u7ed3\u679c\u53ef\u9760\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.57c355e6", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyODYzOTM5OQ==&mid=2247500058&idx=1&sn=c5f75a473ca017b2dad6be8b2baf1ed2&chksm=c3120d51b8196e5ee3b02e59b17a5570b300bc83d24797f6e605470e27d341434763aab7b66c#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyODYzOTM5OQ==&mid=2247500058&idx=1&sn=c5f75a473ca017b2dad6be8b2baf1ed2&chksm=c3120d51b8196e5ee3b02e59b17a5570b300bc83d24797f6e605470e27d341434763aab7b66c#rd", "authors": ["ICAEW\u7279\u8bb8\u4f1a\u8ba1\u5e08 ACA"], "title": "ICAEW\u6d1e\u5bdf | <em class=\"highlight\">Agentic</em> AI\u5d1b\u8d77\uff1a\u804c\u573a\u6548\u7387\u9769\u547d\u80cc\u540e\u7684\u7f51\u7edc\u5b89\u5168\u201c\u6697\u6218\u201d", "comment": "Source: WeChat, Published: 2025-12-12 10:00:00", "summary": "Agentic AI\u5219\u6307\u8fd9\u4e9b\u5de5\u5177\u7684\u8fd0\u884c\u6846\u67b6\uff0c\u6216\u662f\u7edf\u7b79\u591a\u4e2a\u667a\u80fd\u4f53\u534f\u540c\u5de5\u4f5c\u3001\u89e3\u51b3\u590d\u6742\u7cbe\u5bc6\u4efb\u52a1\u7684\u6280\u672f\u4f53\u7cfb\u3002\u5b89\u6c38\uff08EY\uff09\u82f1\u56fd\u6280\u672f\u98ce\u9669\u603b\u76d1Alistair Grange\u6307\u51fa\uff1a\u201c\u5c3d\u7ba1AI\u6280\u672f\u5728\u804c\u573a\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5b83\u4e5f\u964d\u4f4e\u4e86\u7f51\u7edc\u72af\u7f6a\u7684\u51c6\u5165\u95e8\u69db\u3002", "AI": {"tldr": "Agentic AI\u5219\u6307\u8fd9\u4e9b\u5de5\u5177\u7684\u8fd0\u884c\u6846\u67b6\uff0c\u6216\u662f\u7edf\u7b79\u591a\u4e2a\u667a\u80fd\u4f53\u534f\u540c\u5de5\u4f5c\u3001\u89e3\u51b3\u590d\u6742\u7cbe\u5bc6\u4efb\u52a1\u7684\u6280\u672f\u4f53\u7cfb\u3002\u5b89\u6c38\uff08EY\uff09\u82f1\u56fd\u6280\u672f\u98ce\u9669\u603b\u76d1Alistair Grange\u6307\u51fa\uff1a\u201c\u5c3d\u7ba1AI\u6280\u672f\u5728\u804c\u573a\u4e2d\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5b83\u4e5f\u964d\u4f4e\u4e86\u7f51\u7edc\u72af\u7f6a\u7684\u51c6\u5165\u95e8\u69db\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.d863d2e4", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk4ODI0NTI1Mw==&mid=2247484151&idx=1&sn=c834e03e3f4db1a1fcb232df9e29d720&chksm=c4da712bb95509823539788d33430ec31c6aea3ec6aa418a77836af37457c8e6a5b95a7a983a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk4ODI0NTI1Mw==&mid=2247484151&idx=1&sn=c834e03e3f4db1a1fcb232df9e29d720&chksm=c4da712bb95509823539788d33430ec31c6aea3ec6aa418a77836af37457c8e6a5b95a7a983a#rd", "authors": ["\u6d77\u8054\u4e91\u79d1\u6280"], "title": "\u544a\u522b\u5de5\u5177\u5c5e\u6027\uff0c\u62e5\u62b1\u4ef7\u503c\u521b\u9020\uff1a<em class=\"highlight\">Agentic</em> AI\u7684\u5546\u4e1a\u9769\u547d\u4e0e\u843d\u5730\u5b9e\u8df5", "comment": "Source: WeChat, Published: 2025-12-12 09:59:23", "summary": "Agentic AI \u8ba9\u670d\u52a1\u4ece \u201c\u88ab\u52a8\u54cd\u5e94\u201d \u8f6c\u5411 \u201c\u4e3b\u52a8\u9884\u5224\u201d\u3002Druva \u901a\u8fc7 Amazon Bedrock AgentCore \u6784\u5efa\u7684\u667a\u80fd\u4f53\uff0c\u81ea\u4e3b\u89e3\u51b363% \u7684\u5ba2\u6237\u652f\u6301\u95ee\u9898\uff0c\u54cd\u5e94\u901f\u5ea6\u63d0\u534758%\uff0c\u8fd9\u79cd\u4ef7\u503c\u4e0d\u4ec5\u4f53\u73b0\u5728\u4eba\u529b\u6210\u672c\u964d\u4f4e\uff0c\u66f4\u5728\u4e8e\u6838\u5fc3\u670d\u52a1\u8d28\u91cf\u7684\u7a81\u7834\u6027\u63d0\u5347\u3002", "AI": {"tldr": "Agentic AI \u8ba9\u670d\u52a1\u4ece \u201c\u88ab\u52a8\u54cd\u5e94\u201d \u8f6c\u5411 \u201c\u4e3b\u52a8\u9884\u5224\u201d\u3002Druva \u901a\u8fc7 Amazon Bedrock AgentCore \u6784\u5efa\u7684\u667a\u80fd\u4f53\uff0c\u81ea\u4e3b\u89e3\u51b363% \u7684\u5ba2\u6237\u652f\u6301\u95ee\u9898\uff0c\u54cd\u5e94\u901f\u5ea6\u63d0\u534758%\uff0c\u8fd9\u79cd\u4ef7\u503c\u4e0d\u4ec5\u4f53\u73b0\u5728\u4eba\u529b\u6210\u672c\u964d\u4f4e\uff0c\u66f4\u5728\u4e8e\u6838\u5fc3\u670d\u52a1\u8d28\u91cf\u7684\u7a81\u7834\u6027\u63d0\u5347\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.53392411", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg2MjE4NDMxNA==&mid=2247483819&idx=1&sn=3cefd915b844cb0c6f520f20de7f5347&chksm=cfa44af29ac7e3e60371401106cfd0d696b7a8da376bfb2264a38dc9e46fd910323ad12884a9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg2MjE4NDMxNA==&mid=2247483819&idx=1&sn=3cefd915b844cb0c6f520f20de7f5347&chksm=cfa44af29ac7e3e60371401106cfd0d696b7a8da376bfb2264a38dc9e46fd910323ad12884a9#rd", "authors": ["\u5bf9\u5f08\u5927\u6a21\u578b"], "title": "\u5982\u4f55\u7406\u89e3 <em class=\"highlight\">Agentic</em> AI\u3001LLM\u683c\u5c40", "comment": "Source: WeChat, Published: 2025-12-12 03:43:29", "summary": "2\u3001Agentic AI\u662fLLM\u7684\u4e00\u4e2a\u65b9\u5411\uff0c\u5176\u9996\u8981\u76ee\u6807\u4e0d\u662f\u8ffd\u6c42\u667a\u5546\uff0c\u800c\u662f\u6267\u884c\u5de5\u4f5c\u4efb\u52a1\uff0c\u8ffd\u6c42\u6267\u884c\u4efb\u52a1\u7684\u5177\u4f53\u80fd\u529b\u6c34\u5e73\uff0c\u5982\u7f16\u7a0b\u4f5c\u56fe\u505a\u89c6\u9891\u7b49\u7b49\u3002\u5178\u578b\u7684\u5982Gemini3\u3002", "AI": {"tldr": "2\u3001Agentic AI\u662fLLM\u7684\u4e00\u4e2a\u65b9\u5411\uff0c\u5176\u9996\u8981\u76ee\u6807\u4e0d\u662f\u8ffd\u6c42\u667a\u5546\uff0c\u800c\u662f\u6267\u884c\u5de5\u4f5c\u4efb\u52a1\uff0c\u8ffd\u6c42\u6267\u884c\u4efb\u52a1\u7684\u5177\u4f53\u80fd\u529b\u6c34\u5e73\uff0c\u5982\u7f16\u7a0b\u4f5c\u56fe\u505a\u89c6\u9891\u7b49\u7b49\u3002\u5178\u578b\u7684\u5982Gemini3\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.19d55516", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYzNzA2OTc3OA==&mid=2247483718&idx=1&sn=25d83cd128cff4b26bdb787694f05e99&chksm=f1c18b8c98e6c56d046fd7be5bc4f1e36c6920f92ed7ef45b8c6dc4089d729991711bda33274#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYzNzA2OTc3OA==&mid=2247483718&idx=1&sn=25d83cd128cff4b26bdb787694f05e99&chksm=f1c18b8c98e6c56d046fd7be5bc4f1e36c6920f92ed7ef45b8c6dc4089d729991711bda33274#rd", "authors": ["\u6c7d\u8f66AI\u804a\u4e0d\u505c"], "title": "\u6c7d\u8f66\u91d1\u878d\u9996\u4e2a\u5f00\u6e90<em class=\"highlight\">Agentic</em>\u5927\u6a21\u578b\u53d1\u5e03\uff0c\u884c\u4e1a\u667a\u80fd\u5316\u8fdb\u5165\u201c\u5feb\u8f66\u9053\u201d", "comment": "Source: WeChat, Published: 2025-12-12 02:10:36", "summary": "\u4ece\u95ed\u6e90\u5230\u5f00\u6e90\uff0c\u4ece\u72ec\u4eab\u5230\u5171\u4eab\uff0c\u5f00\u6e90Agentic\u5927\u6a21\u578b\u4e4b\u4e3e\uff0c\u4e0d\u4ec5\u4ec5\u662f\u4e00\u6b21\u6280\u672f\u53d1\u5e03\uff0c\u66f4\u662f\u4e00\u6b21\u53d1\u5c55\u7406\u5ff5\u7684\u5347\u7ea7\u3002\u5f53\u6280\u672f\u58c1\u5792\u88ab\u6253\u7834\uff0c\u7ade\u4e89\u7684\u6838\u5fc3\u5c06\u66f4\u805a\u7126\u4e8e\u4e1a\u52a1\u573a\u666f\u7684\u6df1\u5ea6\u7406\u89e3\u548c\u6a21\u5f0f\u7684\u521b\u65b0\u3002", "AI": {"tldr": "\u4ece\u95ed\u6e90\u5230\u5f00\u6e90\uff0c\u4ece\u72ec\u4eab\u5230\u5171\u4eab\uff0c\u5f00\u6e90Agentic\u5927\u6a21\u578b\u4e4b\u4e3e\uff0c\u4e0d\u4ec5\u4ec5\u662f\u4e00\u6b21\u6280\u672f\u53d1\u5e03\uff0c\u66f4\u662f\u4e00\u6b21\u53d1\u5c55\u7406\u5ff5\u7684\u5347\u7ea7\u3002\u5f53\u6280\u672f\u58c1\u5792\u88ab\u6253\u7834\uff0c\u7ade\u4e89\u7684\u6838\u5fc3\u5c06\u66f4\u805a\u7126\u4e8e\u4e1a\u52a1\u573a\u666f\u7684\u6df1\u5ea6\u7406\u89e3\u548c\u6a21\u5f0f\u7684\u521b\u65b0\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.56be44a0", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxNzU2MTg5OQ==&mid=2648604824&idx=1&sn=b436c52c8b678152b4fe8db23c4f79eb&chksm=82fe7235bb4f0cb14ce698d9e5e5751973b9378b638b5253baa71e4a404faec19e6b435efe2a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxNzU2MTg5OQ==&mid=2648604824&idx=1&sn=b436c52c8b678152b4fe8db23c4f79eb&chksm=82fe7235bb4f0cb14ce698d9e5e5751973b9378b638b5253baa71e4a404faec19e6b435efe2a#rd", "authors": ["\u64ce\u7fcc\u667a\u80fd"], "title": "AWS re:Invent 2025\uff1a<em class=\"highlight\">Agentic</em> AI \u5f7b\u5e95\u7206\u53d1\uff0c\u5927\u6a21\u578b\u201c\u72ec\u7acb\u201d\u65f6\u4ee3\u5df2\u6765", "comment": "Source: WeChat, Published: 2025-12-12 02:00:22", "summary": "01Agentic AI\u4ece\u201c\u8bf4\u201d\u5230\u201c\u505a\u201d\u7684\u8de8\u8d8a\u5728 re\uff1aInvent 2025 \u7684\u821e\u53f0\u4e0a\uff0c\u6700\u6838\u5fc3\u7684\u5173\u952e\u8bcd\u83ab\u8fc7\u4e8e \"Agentic Workflows\"\uff08\u4ee3\u7406\u5de5\u4f5c\u6d41\uff09\u3002\u8fc7\u53bb\u6211\u4eec\u4f7f\u7528\u5927\u6a21\u578b\uff0c\u662f\u201c\u8f93\u5165 Prompt -> \u5f97\u5230\u6587\u672c\u201d\u3002", "AI": {"tldr": "01Agentic AI\u4ece\u201c\u8bf4\u201d\u5230\u201c\u505a\u201d\u7684\u8de8\u8d8a\u5728 re\uff1aInvent 2025 \u7684\u821e\u53f0\u4e0a\uff0c\u6700\u6838\u5fc3\u7684\u5173\u952e\u8bcd\u83ab\u8fc7\u4e8e \"Agentic Workflows\"\uff08\u4ee3\u7406\u5de5\u4f5c\u6d41\uff09\u3002\u8fc7\u53bb\u6211\u4eec\u4f7f\u7528\u5927\u6a21\u578b\uff0c\u662f\u201c\u8f93\u5165 Prompt -> \u5f97\u5230\u6587\u672c\u201d\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.ada698fe", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzE5MTIyNzU5Mg==&mid=2247484775&idx=1&sn=084f3378eb28f1c07a8b44ae39b98d41&chksm=97c434598e71ad7ea4f67068212052cf50a18aa3a9b1c6d4af3f58fe159956bcb1fa323eebe8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzE5MTIyNzU5Mg==&mid=2247484775&idx=1&sn=084f3378eb28f1c07a8b44ae39b98d41&chksm=97c434598e71ad7ea4f67068212052cf50a18aa3a9b1c6d4af3f58fe159956bcb1fa323eebe8#rd", "authors": ["\u6f6e\u6c55\u709c\u4f73\u5bfc\u5bfc"], "title": "<em class=\"highlight\">Agentic</em> AI\u5b66\u4f1a\u81ea\u4e3b\u884c\u52a8\uff1a\u63a2\u79d8NVIDIA\u5982\u4f55\u7528\u5fae\u670d\u52a1\u67b6\u6784\u91cd\u5851\u751f\u6210\u5f0fAI\u751f\u6001", "comment": "Source: WeChat, Published: 2025-12-11 23:00:48", "summary": "\u7b80\u5355\u6765\u8bf4\uff0cAgentic AI\u6307\u7684\u662f\u5177\u5907\u81ea\u4e3b\u6027\u3001\u80fd\u591f\u7406\u89e3\u590d\u6742\u6307\u4ee4\u3001\u5236\u5b9a\u5206\u6b65\u8ba1\u5212\u5e76\u6267\u884c\u4efb\u52a1\u7684AI\u7cfb\u7edf\u3002\u4e0d\u540c\u4e8e\u4f20\u7edf chatbot \u7684\u4e00\u95ee\u4e00\u7b54\u6a21\u5f0f\uff0c\u8fd9\u4e9bAI\u667a\u80fd\u4f53\u66f4\u50cf\u662f\u4e00\u4f4d\u5f97\u529b\u7684\u6570\u5b57\u52a9\u624b\u2014\u2014\u4f60\u53ea\u9700\u7ed9\u51fa\u4e00\u4e2a\u76ee\u6807\uff0c\u5b83\u5c31\u80fd\u81ea\u5df1\u601d\u8003\u5982\u4f55\u5b9e\u73b0\u3002", "AI": {"tldr": "\u7b80\u5355\u6765\u8bf4\uff0cAgentic AI\u6307\u7684\u662f\u5177\u5907\u81ea\u4e3b\u6027\u3001\u80fd\u591f\u7406\u89e3\u590d\u6742\u6307\u4ee4\u3001\u5236\u5b9a\u5206\u6b65\u8ba1\u5212\u5e76\u6267\u884c\u4efb\u52a1\u7684AI\u7cfb\u7edf\u3002\u4e0d\u540c\u4e8e\u4f20\u7edf chatbot \u7684\u4e00\u95ee\u4e00\u7b54\u6a21\u5f0f\uff0c\u8fd9\u4e9bAI\u667a\u80fd\u4f53\u66f4\u50cf\u662f\u4e00\u4f4d\u5f97\u529b\u7684\u6570\u5b57\u52a9\u624b\u2014\u2014\u4f60\u53ea\u9700\u7ed9\u51fa\u4e00\u4e2a\u76ee\u6807\uff0c\u5b83\u5c31\u80fd\u81ea\u5df1\u601d\u8003\u5982\u4f55\u5b9e\u73b0\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.cb89c5ee", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAwMTc2NTI2MA==&mid=2247483684&idx=1&sn=254a6968bf38c78dc79211a974eebce2&chksm=9b55224aed1596b64d4d5e0f4227b4aa6397174c03855cebf296865e197b411b3a5632424303#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAwMTc2NTI2MA==&mid=2247483684&idx=1&sn=254a6968bf38c78dc79211a974eebce2&chksm=9b55224aed1596b64d4d5e0f4227b4aa6397174c03855cebf296865e197b411b3a5632424303#rd", "authors": ["\u654f\u6cd5\u5de5\u623f"], "title": "<em class=\"highlight\">Agentic</em> OS \u4e2d\u7684\u4e3b\u6d41\u5e94\u7528\u5f62\u6001", "comment": "Source: WeChat, Published: 2025-12-11 15:11:00", "summary": "\u4e0a\u6b21\u5199\u4e86Agentic AI\u6ce8\u5b9a\u8ba9\u8d85\u7ea7\u5e94\u7528unbundling\uff0c\u6700\u8fd1\u968f\u7740OpenAI\u3001Anthropic\u3001Shopify\u5728MCP-UI\u3001MCP App\u4e0a\u7684\u5f00\u653e\u5408\u4f5c\uff0c\u4ee5\u53ca\u7531\u6b64\u53d1\u5c55\u51fa\u7684\u4ee5MCP\u4e3a\u57fa\u7840\u7684\u300cAgentic AI\u57fa\u91d1\u4f1a\u300d\uff08AAIF\uff09\u7eb3\u5165\u4e86\u4e3b\u8981AI Lab\u548cInfra\u5382\u5546\uff08\u8ba9\u6211\u60f3\u8d77\u4e4b\u524dUSD/Khronos\u548cGLTF/W3C\u5f3a\u5f3a\u8054", "AI": {"tldr": "\u4e0a\u6b21\u5199\u4e86Agentic AI\u6ce8\u5b9a\u8ba9\u8d85\u7ea7\u5e94\u7528unbundling\uff0c\u6700\u8fd1\u968f\u7740OpenAI\u3001Anthropic\u3001Shopify\u5728MCP-UI\u3001MCP App\u4e0a\u7684\u5f00\u653e\u5408\u4f5c\uff0c\u4ee5\u53ca\u7531\u6b64\u53d1\u5c55\u51fa\u7684\u4ee5MCP\u4e3a\u57fa\u7840\u7684\u300cAgentic AI\u57fa\u91d1\u4f1a\u300d\uff08AAIF\uff09\u7eb3\u5165\u4e86\u4e3b\u8981AI Lab\u548cInfra\u5382\u5546\uff08\u8ba9\u6211\u60f3\u8d77\u4e4b\u524dUSD/Khronos\u548cGLTF/W3C\u5f3a\u5f3a\u8054", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.c99e4046", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyMDYxNDA5Nw==&mid=2247484833&idx=1&sn=39337364bb4838515e81f5ff2d3df5c1&chksm=c0f2aa8de88116bf3d9b847512f8c96cf0b271f15ff62afb4af4ce082ed32a160ed0521ed319#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyMDYxNDA5Nw==&mid=2247484833&idx=1&sn=39337364bb4838515e81f5ff2d3df5c1&chksm=c0f2aa8de88116bf3d9b847512f8c96cf0b271f15ff62afb4af4ce082ed32a160ed0521ed319#rd", "authors": ["\u53f6\u884c\u5bbd"], "title": "<em class=\"highlight\">Agentic</em>\u8bbe\u8ba1\u6a21\u5f0f\uff084\uff09\uff1a\u53cd\u601d\uff08Reflection\uff09", "comment": "Source: WeChat, Published: 2025-12-11 14:37:58", "summary": "\u4e09\u4eba\u884c\u5fc5\u6709\u6211\u5e08\u8fd9\u79cd\uff0c\u5584\u5047\u4e8e\u7269\u7684\u53cd\u601d\uff0c\u7c7b\u6bd4\u5230\u667a\u80fd\u4f53\u53cd\u601d\uff0c\u5176\u5178\u578b\u5b9e\u73b0\u5982\u4e0b\uff1a\u5c06\u6d41\u7a0b\u62c6\u5206\u4e3a\u4e24\u4e2a\u72ec\u7acb\u7684\u903b\u8f91\u89d2\u8272\uff1a\u751f\u4ea7\u8005\uff08Producer\uff09\u548c\u8bc4\u8bba\u8005\uff08Critic\uff09\u3002", "AI": {"tldr": "\u4e09\u4eba\u884c\u5fc5\u6709\u6211\u5e08\u8fd9\u79cd\uff0c\u5584\u5047\u4e8e\u7269\u7684\u53cd\u601d\uff0c\u7c7b\u6bd4\u5230\u667a\u80fd\u4f53\u53cd\u601d\uff0c\u5176\u5178\u578b\u5b9e\u73b0\u5982\u4e0b\uff1a\u5c06\u6d41\u7a0b\u62c6\u5206\u4e3a\u4e24\u4e2a\u72ec\u7acb\u7684\u903b\u8f91\u89d2\u8272\uff1a\u751f\u4ea7\u8005\uff08Producer\uff09\u548c\u8bc4\u8bba\u8005\uff08Critic\uff09\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.939d8a94", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxODQxOTEyNg==&mid=2247792253&idx=2&sn=3abe193e7dd871b2d4f9629a262ee089&chksm=c0eef7a29906ca6d990740ed31039dc4e453d215268fa608857ad471b635cc4352e6b5c36ba8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxODQxOTEyNg==&mid=2247792253&idx=2&sn=3abe193e7dd871b2d4f9629a262ee089&chksm=c0eef7a29906ca6d990740ed31039dc4e453d215268fa608857ad471b635cc4352e6b5c36ba8#rd", "authors": ["\u4e2d\u56fd\u5409\u6797\u7f51"], "title": "\u559c\u62a5\uff01\u5409\u6797\u4ea4\u901a<em class=\"highlight\">\u5927\u6a21\u578b</em>\u667a\u80fd\u4f53\u83b7\u5168\u56fd\u5927\u8d5b\u4e00\u7b49\u5956", "comment": "Source: WeChat, Published: 2025-12-12 13:17:43", "summary": "\u4ea4\u901a\u8fd0\u8f93\u90e8\u804c\u4e1a\u8d44\u683c\u4e2d\u5fc3\u4e3b\u529e\u7684\u7b2c\u4e00\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u5168\u56fd\u603b\u51b3\u8d5b\u5728\u53a6\u95e8\u843d\u5e55\u3002\u5927\u8d5b\u4ee5\u201c\u667a\u9886\u4ea4\u901a\uff0c\u6167\u89c1\u672a\u6765\u201d\u4e3a\u4e3b\u9898\uff0c\u6db5\u76d6\u653f\u52a1\u4e0e\u7ba1\u7406\u3001\u5b89\u5168\u4e0e\u76d1\u7ba1\u3001\u8fd0\u8425\u4e0e\u670d\u52a1\u3001\u6280\u672f\u4e0e\u521b\u65b0\u7b49\u65b9\u5411\uff0c\u6765\u81ea\u653f\u52a1\u3001\u94c1\u8def", "AI": {"tldr": "\u4ea4\u901a\u8fd0\u8f93\u90e8\u804c\u4e1a\u8d44\u683c\u4e2d\u5fc3\u4e3b\u529e\u7684\u7b2c\u4e00\u5c4a\u7efc\u5408\u4ea4\u901a\u8fd0\u8f93\u5927\u6a21\u578b\u667a\u80fd\u4f53\u521b\u65b0\u5e94\u7528\u5927\u8d5b\u5168\u56fd\u603b\u51b3\u8d5b\u5728\u53a6\u95e8\u843d\u5e55\u3002\u5927\u8d5b\u4ee5\u201c\u667a\u9886\u4ea4\u901a\uff0c\u6167\u89c1\u672a\u6765\u201d\u4e3a\u4e3b\u9898\uff0c\u6db5\u76d6\u653f\u52a1\u4e0e\u7ba1\u7406\u3001\u5b89\u5168\u4e0e\u76d1\u7ba1\u3001\u8fd0\u8425\u4e0e\u670d\u52a1\u3001\u6280\u672f\u4e0e\u521b\u65b0\u7b49\u65b9\u5411\uff0c\u6765\u81ea\u653f\u52a1\u3001\u94c1\u8def", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.261b0d57", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzNzIwNTA1Nw==&mid=2247540365&idx=3&sn=6e4a1adf91443fa1fb55e752515ae9a8&chksm=c3fb43a8235dd7db6e95b609a6c7fcbde1529d91ab1e0d7a18428128fa606edc944ad96a26cd#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzNzIwNTA1Nw==&mid=2247540365&idx=3&sn=6e4a1adf91443fa1fb55e752515ae9a8&chksm=c3fb43a8235dd7db6e95b609a6c7fcbde1529d91ab1e0d7a18428128fa606edc944ad96a26cd#rd", "authors": ["\u6295\u8d44\u4e1c\u839e"], "title": "\u884c\u4e1a\u70ed\u70b9\u8d44\u8baf\uff5cOpenAI\uff1a\u6b63\u5f0f\u63a8\u51fa\u4e13\u4e1a\u77e5\u8bc6\u5de5\u4f5c<em class=\"highlight\">\u5927\u6a21\u578b</em>GPT-5.2", "comment": "Source: WeChat, Published: 2025-12-12 12:56:07", "summary": "\u5de5\u4f5c\u5927\u6a21\u578bGPT-5.2\u5f53\u5730\u65f6\u95f412\u670811\u65e5\uff0cOpenAI\u6b63\u5f0f\u53d1\u5e03\u5176\u6700\u65b0\u6a21\u578bGPT-5.2\uff0c\u8fd9\u662f\u5728\u8c37\u6b4cGemini3\u5f3a\u52bf\u6311\u6218\u4e0b\u7684\u4e00\u6b21\u5168\u9762\u56de\u51fb\u3002\u65b0\u6a21\u578bGPT-5.2\u805a\u7126\u4e13\u4e1a\u5de5\u4f5c\u573a\u666f\u4f18\u5316\uff0c\u5728\u7f16\u7a0b\u3001\u79d1\u5b66\u4efb\u52a1\u3001\u957f\u6587\u6863\u5904\u7406\u7b49\u6838\u5fc3\u80fd\u529b\u4e0a\u5b9e\u73b0\u663e\u8457\u63d0\u5347\u3002", "AI": {"tldr": "\u5de5\u4f5c\u5927\u6a21\u578bGPT-5.2\u5f53\u5730\u65f6\u95f412\u670811\u65e5\uff0cOpenAI\u6b63\u5f0f\u53d1\u5e03\u5176\u6700\u65b0\u6a21\u578bGPT-5.2\uff0c\u8fd9\u662f\u5728\u8c37\u6b4cGemini3\u5f3a\u52bf\u6311\u6218\u4e0b\u7684\u4e00\u6b21\u5168\u9762\u56de\u51fb\u3002\u65b0\u6a21\u578bGPT-5.2\u805a\u7126\u4e13\u4e1a\u5de5\u4f5c\u573a\u666f\u4f18\u5316\uff0c\u5728\u7f16\u7a0b\u3001\u79d1\u5b66\u4efb\u52a1\u3001\u957f\u6587\u6863\u5904\u7406\u7b49\u6838\u5fc3\u80fd\u529b\u4e0a\u5b9e\u73b0\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.be9668c8", "categories": ["wechat.article", "wechat.ai", "wechat.rl", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxODk3NjQ5OQ==&mid=2247484075&idx=1&sn=eabc1d31bedad5ffb9e05904f017101f&chksm=9aa0d6689ee67c571fbcf15d6c87e7871508d0e9e786a11ebbc5f9eff74fdae4a766b9cffcb8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxODk3NjQ5OQ==&mid=2247484075&idx=1&sn=eabc1d31bedad5ffb9e05904f017101f&chksm=9aa0d6689ee67c571fbcf15d6c87e7871508d0e9e786a11ebbc5f9eff74fdae4a766b9cffcb8#rd", "authors": ["\u77ff\u5c71\u767e\u901a-\u77ff\u5c71\u9886\u57df\u7684AI\u4e13\u5bb6"], "title": "\u5927\u8bed\u8a00<em class=\"highlight\">\u6a21\u578b</em>\uff1a\u7406\u89e3\u4e0e\u751f\u6210\u8bed\u8a00\u7684\u4eba\u5de5\u667a\u80fd", "comment": "Source: WeChat, Published: 2025-12-12 10:36:25", "summary": "\u968f\u7740\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u672a\u6765\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u4f1a\u53d8\u5f97\u66f4\u52a0\u667a\u80fd\uff0c\u80fd\u591f\u5904\u7406\u66f4\u590d\u6742\u7684\u4efb\u52a1\uff0c\u7406\u89e3\u66f4\u6df1\u5c42\u6b21\u7684\u542b\u4e49\u3002\u7ed3\u5408\u591a\u6a21\u6001\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5b83\u4eec\u6709\u671b\u5728\u66f4\u591a\u5e94\u7528\u573a\u666f\u4e2d\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\uff0c\u751a\u81f3\u5728\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u548c\u51b3\u7b56\u65b9\u9762\u53d1\u6325\u66f4\u5927\u4f5c\u7528\u3002", "AI": {"tldr": "\u968f\u7740\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u672a\u6765\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u4f1a\u53d8\u5f97\u66f4\u52a0\u667a\u80fd\uff0c\u80fd\u591f\u5904\u7406\u66f4\u590d\u6742\u7684\u4efb\u52a1\uff0c\u7406\u89e3\u66f4\u6df1\u5c42\u6b21\u7684\u542b\u4e49\u3002\u7ed3\u5408\u591a\u6a21\u6001\u5b66\u4e60\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5b83\u4eec\u6709\u671b\u5728\u66f4\u591a\u5e94\u7528\u573a\u666f\u4e2d\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\uff0c\u751a\u81f3\u5728\u6a21\u62df\u4eba\u7c7b\u8ba4\u77e5\u548c\u51b3\u7b56\u65b9\u9762\u53d1\u6325\u66f4\u5927\u4f5c\u7528\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.65e274fc", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI3NjQ3NjUxMA==&mid=2247518760&idx=1&sn=0975d1847a98a26de9f0c686541830cc&chksm=eaa3b71feb09abd9c2b00c21f18afdd153fc70ac48b5038e225fb19d98e55953325d3a436f6b#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI3NjQ3NjUxMA==&mid=2247518760&idx=1&sn=0975d1847a98a26de9f0c686541830cc&chksm=eaa3b71feb09abd9c2b00c21f18afdd153fc70ac48b5038e225fb19d98e55953325d3a436f6b#rd", "authors": ["\u5177\u8eab\u667a\u80fd\u4ea7\u4e1a\u6d1e\u5bdf"], "title": "\u8350\u8bfb | \u57fa\u4e8e\u591a\u6a21\u6001<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7814\u7a76\u8fdb\u5c55\u4e0e\u5c55\u671b\uff0c\u9644\u4e0b\u8f7d", "comment": "Source: WeChat, Published: 2025-12-12 09:45:45", "summary": "\u5373\u53ef\u4e0b\u8f7d\u300a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7814\u7a76\u8fdb\u5c55\u4e0e\u5c55\u671b\u300b\u5b8c\u6574\u7248PDF\u3002\u4ee5\u4e0b\u662f\u90e8\u5206\u5185\u5bb9\uff0c\u656c\u8bf7\u9605\u8bfb\u00b7 \u672a\u5b8c \u00b7", "AI": {"tldr": "\u5373\u53ef\u4e0b\u8f7d\u300a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u6a21\u578b\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7814\u7a76\u8fdb\u5c55\u4e0e\u5c55\u671b\u300b\u5b8c\u6574\u7248PDF\u3002\u4ee5\u4e0b\u662f\u90e8\u5206\u5185\u5bb9\uff0c\u656c\u8bf7\u9605\u8bfb\u00b7 \u672a\u5b8c \u00b7", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.a84f4404", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5MTY5ODE4OQ==&mid=2651618725&idx=4&sn=a8debb1b7194cf04ec03d17c9455cc5b&chksm=bcbd5c54628b369866a6dd3a88be5a664737c91b7e3e277f8a60ead056964a922b1299fadde6#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5MTY5ODE4OQ==&mid=2651618725&idx=4&sn=a8debb1b7194cf04ec03d17c9455cc5b&chksm=bcbd5c54628b369866a6dd3a88be5a664737c91b7e3e277f8a60ead056964a922b1299fadde6#rd", "authors": ["\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a"], "title": "\u201c\u667a\u201d\u53d8\u4e2d\u7684\u201c\u4fe1\u201d\u5b88\uff1a\u63a2\u5bfb\u8f6f\u4ef6\u5de5\u7a0b<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7684\u53ef\u4fe1\u53d8\u9769\u4e4b\u8def | ChinaData", "comment": "Source: WeChat, Published: 2025-12-12 09:05:57", "summary": "\u5927\u6a21\u578b\u6b63\u5728\u91cd\u5851\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5168\u751f\u547d\u5468\u671f\uff0c\u4ece\u9700\u6c42\u5206\u6790\u3001\u4ee3\u7801\u751f\u6210\u5230\u81ea\u52a8\u5316\u6d4b\u8bd5\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u4e86\u663e\u8457\u7684\u6548\u7387\u7ea2\u5229\uff0c\u5df2\u6210\u4e3a\u63a8\u52a8\u8f6f\u4ef6\u751f\u6001\u5efa\u8bbe\u4e0e\u6280\u672f\u7a81\u7834\u7684\u5173\u952e\u529b\u91cf\u3002", "AI": {"tldr": "\u5927\u6a21\u578b\u6b63\u5728\u91cd\u5851\u8f6f\u4ef6\u5de5\u7a0b\u7684\u5168\u751f\u547d\u5468\u671f\uff0c\u4ece\u9700\u6c42\u5206\u6790\u3001\u4ee3\u7801\u751f\u6210\u5230\u81ea\u52a8\u5316\u6d4b\u8bd5\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u5c55\u73b0\u4e86\u663e\u8457\u7684\u6548\u7387\u7ea2\u5229\uff0c\u5df2\u6210\u4e3a\u63a8\u52a8\u8f6f\u4ef6\u751f\u6001\u5efa\u8bbe\u4e0e\u6280\u672f\u7a81\u7834\u7684\u5173\u952e\u529b\u91cf\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.e5f5cba9", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU0OTg2ODc4Nw==&mid=2247594660&idx=1&sn=8a9586a1157e09386d9e0e6ca5075c5b&chksm=fa85a5dfc5671e363988f7c9f12e23af787a4ae3599e9e114d82d097b8b2cfd91f16cd6228ab#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU0OTg2ODc4Nw==&mid=2247594660&idx=1&sn=8a9586a1157e09386d9e0e6ca5075c5b&chksm=fa85a5dfc5671e363988f7c9f12e23af787a4ae3599e9e114d82d097b8b2cfd91f16cd6228ab#rd", "authors": ["\u56fd\u4fe1\u5b89\u6559\u80b2"], "title": "\u4ece\u96f6\u57fa\u7840\u5230\u4f01\u4e1a\u7ea7\u5e94\u7528\uff1a22 \u5929\u5403\u900f AI <em class=\"highlight\">\u5927\u6a21\u578b</em>\u5e94\u7528\uff0c\u8f6c\u5c97 IT \u4e0d\u8e29\u5751", "comment": "Source: WeChat, Published: 2025-12-12 08:08:41", "summary": "\u5168\u65b0AI\u5927\u6a21\u578b\u8bfe\u7a0b\uff0c\u4e3a\u4f60\u91cf\u8eab\u6253\u902002\u7acb\u8db3\u8f6c\u5c97\u4eba\u7fa4\u7684\u5b66\u4e60\u7279\u6027\uff0c\u8bfe\u7a0b\u91c7\u7528\u4e09\u9636\u9012\u8fdb\u5f0f\u8bbe\u8ba1\uff0c\u8ba9\u96f6\u57fa\u7840\u4e5f\u80fd\u7a33\u6b65\u6210\u957f\uff1a\u5b66\u5b8c\u53ef\u80dc\u4efb AI \u5e94\u7528\u5f00\u53d1\u3001RAG \u7cfb\u7edf\u5de5\u7a0b\u5e08\u3001AI \u4ea7\u54c1\u7ecf\u7406\u7b49\u591a\u4e2a\u70ed\u95e8\u5c97\u4f4d\uff0c\u8986\u76d6\u5168\u4ea7\u4e1a\u94fe\u5c31\u4e1a\u9700\u6c42\u3002", "AI": {"tldr": "\u5168\u65b0AI\u5927\u6a21\u578b\u8bfe\u7a0b\uff0c\u4e3a\u4f60\u91cf\u8eab\u6253\u902002\u7acb\u8db3\u8f6c\u5c97\u4eba\u7fa4\u7684\u5b66\u4e60\u7279\u6027\uff0c\u8bfe\u7a0b\u91c7\u7528\u4e09\u9636\u9012\u8fdb\u5f0f\u8bbe\u8ba1\uff0c\u8ba9\u96f6\u57fa\u7840\u4e5f\u80fd\u7a33\u6b65\u6210\u957f\uff1a\u5b66\u5b8c\u53ef\u80dc\u4efb AI \u5e94\u7528\u5f00\u53d1\u3001RAG \u7cfb\u7edf\u5de5\u7a0b\u5e08\u3001AI \u4ea7\u54c1\u7ecf\u7406\u7b49\u591a\u4e2a\u70ed\u95e8\u5c97\u4f4d\uff0c\u8986\u76d6\u5168\u4ea7\u4e1a\u94fe\u5c31\u4e1a\u9700\u6c42\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.c8a4efe1", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0NjcxMDM1Nw==&mid=2247495062&idx=3&sn=237c6df6ca31748d4cec747aac06d093&chksm=c2046c61d772fc512565e81bd4f87e8edc8abec0073fe474605256a6be8746e6263d3c5f79c0#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0NjcxMDM1Nw==&mid=2247495062&idx=3&sn=237c6df6ca31748d4cec747aac06d093&chksm=c2046c61d772fc512565e81bd4f87e8edc8abec0073fe474605256a6be8746e6263d3c5f79c0#rd", "authors": ["\u667a\u80fd\u611f\u77e5\u5de5\u7a0b"], "title": "\u4e2d\u56fd\u5de5\u7a0b\u9662\u9662\u58eb\u8c2d\u5efa\u8363\uff1a\u5343\u4e07\u4e0d\u8981\u5ffd\u89c6\u5c0f\u6a21\u578b\uff01<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7684\u6839\u57fa\u5728\u5c0f\u6a21\u578b\u548c\u5efa\u6a21\u80fd\u529b\uff01\u667a\u80fd\u4f53\u6a21\u578b\u4e0d\u80fd\u53ea\u505c\u7559\u5728\u7aef\u4fa7\uff01", "comment": "Source: WeChat, Published: 2025-12-12 07:35:21", "summary": "\u8c2d\u9662\u58eb\u4e09\u5341\u5e74\u524d\u5c31\u5f00\u59cb\u505a\u6570\u636e\u5efa\u6a21\uff0c\u800c\u5927\u6a21\u578b\u4e4b\u6240\u4ee5\u5d1b\u8d77\uff0c\u662f\u56e0\u4e3a\u957f\u671f\u7684\u6570\u636e\u79ef\u7d2f\u4e0e\u5efa\u6a21\u5de5\u5177\u94fe\u7684\u6210\u719f\u3002\u201c\u6ca1\u6709\u5c0f\u6a21\u578b\uff0c\u54ea\u91cc\u6765\u5927\u6a21\u578b\uff1f\u201d \u540c\u65f6\uff0c\u8c2d\u9662\u58eb\uff0c\u8fd8\u7ed9\u51fa\u4e86\u5927\u6a21\u578b\u7684\u53d1\u5c55\u65b9\u5411\uff1a\u4ece\u201c\u8d8a\u5927\u8d8a\u597d\u201d\u8d70\u5411\u201c\u7cbe\u51c6\u5c0f\u6a21\u578b\uff0b\u884c\u4e1a", "AI": {"tldr": "\u8c2d\u9662\u58eb\u4e09\u5341\u5e74\u524d\u5c31\u5f00\u59cb\u505a\u6570\u636e\u5efa\u6a21\uff0c\u800c\u5927\u6a21\u578b\u4e4b\u6240\u4ee5\u5d1b\u8d77\uff0c\u662f\u56e0\u4e3a\u957f\u671f\u7684\u6570\u636e\u79ef\u7d2f\u4e0e\u5efa\u6a21\u5de5\u5177\u94fe\u7684\u6210\u719f\u3002\u201c\u6ca1\u6709\u5c0f\u6a21\u578b\uff0c\u54ea\u91cc\u6765\u5927\u6a21\u578b\uff1f\u201d \u540c\u65f6\uff0c\u8c2d\u9662\u58eb\uff0c\u8fd8\u7ed9\u51fa\u4e86\u5927\u6a21\u578b\u7684\u53d1\u5c55\u65b9\u5411\uff1a\u4ece\u201c\u8d8a\u5927\u8d8a\u597d\u201d\u8d70\u5411\u201c\u7cbe\u51c6\u5c0f\u6a21\u578b\uff0b\u884c\u4e1a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.8f769444", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI1NjUzMjM1Mw==&mid=2247493656&idx=1&sn=685063aa8b4d554fff747e61a1599cef&chksm=eba6ce08205a6ffa710e72dcccd652f0de8b08ad4b3f325124e290e7133a2bfb222978ca82dd#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI1NjUzMjM1Mw==&mid=2247493656&idx=1&sn=685063aa8b4d554fff747e61a1599cef&chksm=eba6ce08205a6ffa710e72dcccd652f0de8b08ad4b3f325124e290e7133a2bfb222978ca82dd#rd", "authors": ["\u7d2b\u91d1\u8d22\u7ecf"], "title": "AI\u6d6a\u6f6e\u4e4b\u4e0b\uff0c\u56fd\u4ea7<em class=\"highlight\">\u5927\u6a21\u578b</em>\u8d76\u8d85\u4e86\u5417\uff1f", "comment": "Source: WeChat, Published: 2025-12-12 02:45:50", "summary": "\u4e2d\u56fd\u7814\u53d1\u7684\u5f00\u6e90\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u5168\u7403\u4e0b\u8f7d\u91cf\u5360\u6bd4\u8fbe\u5230 17.1%\uff0c\u8d85\u8d8a\u7f8e\u56fd\u7684 15.8%\uff0c\u4f4d\u5c45\u5168\u7403\u7b2c\u4e00\uff0c\u6807\u5fd7\u7740\u56fd\u4ea7\u5927\u6a21\u578b\u5f00\u6e90\u751f\u6001\u6b63\u5f0f\u8dfb\u8eab\u5168\u7403\u9886\u5148\u884c\u5217\u3002\u963f\u91cc\u7684Qwen\u7cfb\u5217\u3001DeepSeek\u7b49\u5f00\u6e90\u6a21\u578b\u5728\u5168\u7403\u5f00\u53d1\u8005\u793e\u533a\u4e2d\u83b7\u5f97\u4e86\u5e7f\u6cdb\u5e94\u7528\u4e0e\u884d\u751f\uff0c\u6784\u5efa", "AI": {"tldr": "\u4e2d\u56fd\u7814\u53d1\u7684\u5f00\u6e90\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u5168\u7403\u4e0b\u8f7d\u91cf\u5360\u6bd4\u8fbe\u5230 17.1%\uff0c\u8d85\u8d8a\u7f8e\u56fd\u7684 15.8%\uff0c\u4f4d\u5c45\u5168\u7403\u7b2c\u4e00\uff0c\u6807\u5fd7\u7740\u56fd\u4ea7\u5927\u6a21\u578b\u5f00\u6e90\u751f\u6001\u6b63\u5f0f\u8dfb\u8eab\u5168\u7403\u9886\u5148\u884c\u5217\u3002\u963f\u91cc\u7684Qwen\u7cfb\u5217\u3001DeepSeek\u7b49\u5f00\u6e90\u6a21\u578b\u5728\u5168\u7403\u5f00\u53d1\u8005\u793e\u533a\u4e2d\u83b7\u5f97\u4e86\u5e7f\u6cdb\u5e94\u7528\u4e0e\u884d\u751f\uff0c\u6784\u5efa", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.91fba14a", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5MTI3MTY3Mg==&mid=2651545854&idx=3&sn=261a28e3c082fc08624040e37ad6e8e9&chksm=bc78af2483cfe910b59d4f61fa8ea7ad90b783897394bf5c72221205a29087a0dc868625bf05#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5MTI3MTY3Mg==&mid=2651545854&idx=3&sn=261a28e3c082fc08624040e37ad6e8e9&chksm=bc78af2483cfe910b59d4f61fa8ea7ad90b783897394bf5c72221205a29087a0dc868625bf05#rd", "authors": ["\u8346\u695a\u7f51"], "title": "OpenAI\u6b63\u5f0f\u53d1\u5e03GPT5.2\uff1a\u505a\u8868\u683c\u3001\u5199PPT\u3001\u6572\u4ee3\u7801\u7b49\u751f\u4ea7\u529b\u5927\u589e", "comment": "Source: WeChat, Published: 2025-12-11 23:37:13", "summary": "\u4eca\u5929\u51cc\u6668\uff0cOpenAI\u6b63\u5f0f\u63a8\u51fa\u65b0\u4e00\u4ee3\u5927\u6a21\u578bGPT-5.2\uff0c\u4ed8\u8d39\u7528\u6237\u7aef\u53caAPI\u540c\u6b65\u5f00\u653e\u3002\u6b64\u4e3e\u8ddd\u4e0a\u4e00\u4ee3GPT-5.1\u53d1\u5e03\u4e0d\u8db3\u4e00\u6708\uff0c\u80cc\u540e\u662f\u8c37\u6b4cGemini 3\u5f15\u53d1\u7684\u201c\u7ea2\u8272\u8b66\u62a5\u201d\u7ade\u4e89\u538b\u529b\u2014\u2014OpenAI\u6b64\u524d\u7d27\u6025\u53eb\u505c\u5e7f\u544a\u3001\u8d44\u8baf\u7b49\u4fa7\u9879\u76ee\uff0c\u5c06\u6240\u6709\u8d44\u6e90\u96c6\u4e2d\u4e8e\u4e3b\u6a21\u578b", "AI": {"tldr": "\u4eca\u5929\u51cc\u6668\uff0cOpenAI\u6b63\u5f0f\u63a8\u51fa\u65b0\u4e00\u4ee3\u5927\u6a21\u578bGPT-5.2\uff0c\u4ed8\u8d39\u7528\u6237\u7aef\u53caAPI\u540c\u6b65\u5f00\u653e\u3002\u6b64\u4e3e\u8ddd\u4e0a\u4e00\u4ee3GPT-5.1\u53d1\u5e03\u4e0d\u8db3\u4e00\u6708\uff0c\u80cc\u540e\u662f\u8c37\u6b4cGemini 3\u5f15\u53d1\u7684\u201c\u7ea2\u8272\u8b66\u62a5\u201d\u7ade\u4e89\u538b\u529b\u2014\u2014OpenAI\u6b64\u524d\u7d27\u6025\u53eb\u505c\u5e7f\u544a\u3001\u8d44\u8baf\u7b49\u4fa7\u9879\u76ee\uff0c\u5c06\u6240\u6709\u8d44\u6e90\u96c6\u4e2d\u4e8e\u4e3b\u6a21\u578b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
