<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 6]
- [tldr.article](#tldr.article) [Total: 13]
- [wechat.article](#wechat.article) [Total: 21]
- [cs.LG](#cs.LG) [Total: 6]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.SE](#cs.SE) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Affects the Effective Depth of Large Language Models?](https://arxiv.org/abs/2512.14064)
*Yi Hu,Cai Zhou,Muhan Zhang*

Main category: cs.CL

TL;DR: 研究发现当前大语言模型在不同规模、训练范式和任务难度下都存在层利用率不足的问题，有效深度比例保持稳定而非随难度增加，推理能力提升主要来自上下文长度而非更深层计算。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向更深层发展，性能增益却逐渐减少。先前研究提出"有效深度"概念，认为深层模型未能充分利用所有层进行有意义的计算。本研究旨在系统探索有效深度如何随模型规模、训练类型和任务难度变化。

Method: 系统分析Qwen-2.5系列模型（1.5B-32B），研究有效层数随模型规模的变化；比较基础模型与对应长思维链模型的有效深度；评估不同难度任务下模型是否动态使用更多层。

Result: 有效层数随模型规模增长，但有效深度比例保持稳定；长思维链模型相比基础模型并未增加有效深度，推理能力提升主要来自更长上下文而非更深层计算；模型不会为更难问题动态使用更多层。

Conclusion: 当前LLMs在不同规模、训练范式和任务难度下都存在层利用率不足的问题，这为提升LLM层利用率、模型剪枝和早期退出等研究方向提供了机会。

Abstract: The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of "effective depth", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model scale, training type, and task difficulty. First, we analyze the model behavior of Qwen-2.5 family (1.5B-32B) and find that while the number of effective layers grows with model size, the effective depth ratio remains stable. Besides, comparisons between base and corresponding long-CoT models show no increase in effective depth, suggesting that improved reasoning stems from longer context rather than deeper per-token computation. Furthermore, evaluations across tasks of varying difficulty indicate that models do not dynamically use more layers for harder problems. Our results suggest that current LLMs underuse available depth across scales, training paradigms and tasks of varying difficulties, pointing out research opportunities on increasing the layer utilization rate of LLMs, model pruning, and early exiting. Our code is released at https://github.com/AheadOFpotato/what_affects_effective_depth.

</details>


### [2] [CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models](https://arxiv.org/abs/2512.14118)
*Yiran Zhang,Jincheng Hu,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: CogMem是一个受认知启发的记忆增强LLM架构，通过结构化持久记忆支持持续迭代推理，解决LLM在多轮交互中的准确性和连贯性下降问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在单轮推理中表现出色，但在多轮交互中容易失去准确性和连贯性。现有方法通常附加完整对话历史，导致上下文无限增长、计算成本增加和推理效率降低。

Method: CogMem采用三层架构：长期记忆层（LTM）整合跨会话推理策略；直接访问记忆层（DA）维护会话级笔记并检索相关长期记忆；注意力焦点机制（FoA）动态重建简洁的任务相关上下文。

Result: 在TurnBench上的实验表明，这种分层设计能够缓解推理失败、控制上下文增长，并提高扩展推理链的一致性。

Conclusion: CogMem通过结构化记忆架构使LLM能够进行更可靠、更类人的推理，朝着可持续迭代推理的方向发展。

Abstract: Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.

</details>


### [3] [Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents](https://arxiv.org/abs/2512.14142)
*Hongqiu Ni,Jiabao Zhang,Guopeng Li,Zilong Wang,Ruiqi Wu,Chi Zhang,Haisheng Tan*

Main category: cs.CL

TL;DR: Astraea是一个为LLM智能代理设计的服务引擎，通过全局请求生命周期优化和分层调度算法，相比现有系统将平均作业完成时间降低达25.5%。


<details>
  <summary>Details</summary>
Motivation: LLM智能代理的多阶段工作流（本地计算与外部API调用交替）与现有推理系统（如vLLM）的调度粒度不匹配，现有系统专注于局部段优化，无法最小化整个代理工作流的端到端延迟。

Method: 提出Astraea服务引擎，采用状态感知的分层调度算法，结合请求历史状态和未来预测，动态分类I/O密集型和计算密集型请求，使用增强的HRRN策略平衡效率与公平性，并实现自适应KV缓存管理器智能处理I/O等待期间的代理状态。

Result: Astraea相比基线方法将平均作业完成时间降低达25.5%，在高负载下表现出强大的鲁棒性和稳定性，适用于各种模型规模。

Conclusion: Astraea通过将优化从局部段转移到全局请求生命周期，有效解决了LLM智能代理工作流中的调度不匹配问题，显著提升了系统性能。

Abstract: Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.

</details>


### [4] [Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2512.14427)
*Gabriele Prato,Shagun Sodhani,Alessandro Sordoni,Sarath Chandar*

Main category: cs.CL

TL;DR: 研究不同文档打包策略对LLM多跳推理能力的影响，发现打包能提升性能但增加计算成本，并通过消融实验揭示其优势机制。


<details>
  <summary>Details</summary>
Motivation: 当前LLM训练中普遍采用文档打包策略以提高计算效率，但这种做法对模型能力的影响尚未得到充分研究，特别是对多跳推理能力的影响。

Method: 研究不同文档打包策略，比较打包训练与单文档训练的效果，通过消融实验分析影响打包优势的关键因素。

Result: 文档打包能提升LLM的多跳推理性能，但需要更多计算资源；消融实验揭示了打包优势的具体机制和关键因素。

Conclusion: 研究深化了对LLM训练动态的理解，为优化模型开发提供了实用见解，表明文档打包策略需要在性能提升和计算成本之间权衡。

Abstract: The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.

</details>


### [5] [C-ing Clearly: Enhanced Binary Code Explanations using C code](https://arxiv.org/abs/2512.14500)
*Teodor Poncu,Ioana Pintilie,Marius Dragoi,Dragos Tantaru,Florin Brad*

Main category: cs.CL

TL;DR: 提出C-ing Clearly方法，利用C代码生成合成数据来增强LLM对汇编语言的理解，在二进制代码摘要和漏洞检测任务上取得性能提升。


<details>
  <summary>Details</summary>
Motivation: LLM通常在高级编程语言任务上表现优异，但在低级语言如汇编语言上表现不佳。需要提升LLM对汇编代码的理解能力。

Method: 提出C-ing Clearly合成数据生成方法，利用对应的C代码来增强LLM对汇编的理解。通过该方法生成的数据进行微调。

Result: 在二进制代码摘要和漏洞检测任务上展示了改进的LLM性能。在不同LLM家族和模型规模上都获得了一致的性能提升。

Conclusion: 通过利用C代码生成合成数据的方法可以有效提升LLM对汇编语言的理解能力，在相关任务上取得显著改进。

Abstract: Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.

</details>


### [6] [VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models](https://arxiv.org/abs/2512.14554)
*Nguyen Tien Dong,Minh-Anh Nguyen,Thanh Dat Hoang,Nguyen Tuan Ngoc,Dao Xuan Quang Minh,Phan Phi Hai,Nguyen Thi Ngoc Anh,Dang Van Tu,Binh Vu*

Main category: cs.CL

TL;DR: VLegal-Bench是首个针对越南法律的全面基准测试，包含10,450个样本，基于Bloom认知分类法设计，用于系统评估LLM在越南法律任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 越南法律的复杂性、层级结构和频繁修订给评估LLM理解和应用法律知识带来了挑战，需要专门的基准测试来系统评估LLM在越南法律领域的表现。

Method: 基于Bloom认知分类法设计多层次法律理解任务，通过严格的标注流程生成10,450个样本，由法律专家标注和交叉验证，确保每个样本都基于权威法律文件并反映真实法律助理工作流程。

Result: 创建了首个全面的越南法律基准测试VLegal-Bench，涵盖一般法律问答、检索增强生成、多步推理和基于越南法律的场景问题解决等任务。

Conclusion: VLegal-Bench为评估LLM在越南法律环境中的表现提供了标准化、透明且认知知情的评估框架，支持开发更可靠、可解释且符合伦理的AI辅助法律系统。

Abstract: The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.

</details>


<div id='tldr.article'></div>

# tldr.article [[Back]](#toc)

### [7] [Ask HN: How can I get better at using AI for programming?](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnews.ycombinator.com%2Fitem%3Fid=46255285%26utm_source=tldrdev/1/0100019b21eb958d-2b38da21-1af5-4b6d-b2b7-cec487b65017-000000/aWnKk_pgpfpCSDUvCzuQeq7p8U5B6nIUpFp4tgxujFs=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Hacker News讨论如何更有效使用AI编程工具（特别是Claude Code），分享将jQuery/Django项目重写为SvelteKit的经验技巧


<details>
  <summary>Details</summary>
Motivation: 开发者在使用AI工具（特别是Claude Code）进行编程时遇到困难，需要提高AI辅助编程的效率和质量，特别是在重构旧项目时

Method: 社区经验分享：正确使用CLAUDE.md文件提供持久指令，使用"plan mode"进行任务分解，通过测试建立反馈循环验证AI输出，推荐使用Opus 4.5模型

Result: 社区成员分享了实用的AI编程技巧，包括文件组织、任务规划、测试验证等最佳实践，帮助开发者更有效地利用AI工具完成复杂重构任务

Conclusion: 有效使用AI编程需要系统性的方法：提供清晰上下文、分步规划、建立验证机制，并选择合适的模型，这些技巧能显著提高AI辅助编程的效果

Abstract: Ask HN: How can I get better at using AI for programming? (Hacker News Thread) A dev is struggling to effectively use AI, specifically Claude Code, to rewrite an old jQuery and Django project into SvelteKit. Experienced users recommend using a CLAUDE.md file correctly for persistent instructions, using Claude's "plan mode" for task breakdown before implementation, and adding feedback loops through tests to verify the AI's work. Also, Opus 4.5 should be used over any other model for coding whe...

</details>


### [8] [Coding Agents & Complexity Budgets](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fleerob.com%2Fagents%3Futm_source=tldrdev/1/0100019b21eb958d-2b38da21-1af5-4b6d-b2b7-cec487b65017-000000/lXNytNyz4ljfqwsNm8JEe9V1XGLhDsQXCdpK-LyB_3Y=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Cursor公司使用AI编码代理在3天内以260美元的成本将内容管理系统迁移到原始代码和Markdown，显著提升了效率。


<details>
  <summary>Details</summary>
Motivation: 现有的CMS系统创建了不必要的抽象层，导致内容更新速度变慢，需要更高效、直接的解决方案。

Method: 使用Cursor的AI编码代理自动化内容导出、转换和代码库重构，实现从CMS到原始代码和Markdown的迁移。

Result: 在3天内完成迁移，仅花费260美元token费用，显著提升了内容更新效率和开发速度。

Conclusion: AI编码代理能够有效处理复杂的代码迁移任务，以较低成本实现快速系统重构，证明了其在软件开发中的实用价值。

Abstract: Coding Agents & Complexity Budgets (7 minute read) Cursor migrated from a headless CMS to raw code and Markdown after realizing the CMS created unnecessary abstraction and slowed down content updates. They used Cursor's AI coding agents and completed the migration in just three days, spending only $260 in tokens to automate content export, conversion, and codebase refactoring.

</details>


### [9] [Capabilities Are the Only Way to Secure Agent Delegation](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fniyikiza.com%2Fposts%2Fcapability-delegation%2F%3Futm_source=tldrinfosec/1/0100019b225807a2-0e116e17-b5db-4319-a291-3cdc8b6ea899-000000/EqbJP7FgvATTK-uUjKkyGPKRelKl63OoqP40fmU__MQ=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 论文提出传统IAM系统不适合AI代理授权，因为其验证身份而非跟踪动态任务链中的权限传递，导致"困惑副手"问题。能力授权系统通过加密签名令牌解决此问题，将权限作为可追踪、可撤销的令牌处理。


<details>
  <summary>Details</summary>
Motivation: 传统身份和访问管理(IAM)系统在AI代理授权场景中存在根本缺陷，因为它们基于身份验证而非权限跟踪，导致代理拥有环境权限却不理解其来源和范围，产生"困惑副手"问题，无法安全地管理动态任务链中的权限委托。

Method: 采用基于能力(capability-based)的授权系统，将权限表示为加密签名的令牌，这些令牌可以明确追踪权限的来源、范围和传递路径，确保代理只能执行明确授予的任务，并能随时撤销权限。

Result: 能力授权系统能够有效解决AI代理授权中的安全问题，通过加密签名令牌实现细粒度、可追踪、可撤销的权限管理，防止权限滥用和"困惑副手"问题，为AI代理的安全委托提供可靠框架。

Conclusion: 能力授权是确保AI代理安全委托的唯一有效方法，它通过加密签名令牌系统解决了传统IAM在动态任务链中的根本缺陷，为AI代理的安全操作提供了必要的权限控制机制。

Abstract: Capabilities Are the Only Way to Secure Agent Delegation (9 minute read) Traditional IAM systems are inadequate for securing AI agent delegation because they verify identity rather than track authority derivation across dynamic task chains, creating the Confused Deputy problem where agents possess ambient permissions without understanding their origin or intended scope. Capability-based authorization systems address this by treating authority as cryptographically-signed tokens that are explic...

</details>


### [10] [Text Diffusion Models are Faster at Writing Code](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fnathan.rs%2Fposts%2Fdllm-faster-code-generation%2F%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/ZIbbpDj2KvG3gXNtqBDwifLsgA6ycWsEhyyPZiuDvD0=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 文本扩散模型在代码生成方面比大型语言模型更快，这是因为代码的结构性降低了熵，从而提高了并行解码效率


<details>
  <summary>Details</summary>
Motivation: 研究文本扩散模型在代码生成任务上的效率优势，探索结构性输出如何影响生成速度

Method: 通过分析代码的结构特性与熵的关系，研究扩散语言模型在并行解码方面的优势，并进行实验验证

Result: 扩散语言模型生成代码的速度比大型语言模型更快，这主要归因于代码的结构性降低了熵，从而提高了预测置信度和并行解码效率

Conclusion: 代码的结构性而非记忆效应是扩散模型在代码生成中速度优势的关键因素，这为高效代码生成模型的设计提供了新思路

Abstract: Text Diffusion Models are Faster at Writing Code (7 minute read) Diffusion language models generate code at a faster rate than large language models. Increased structure tends to correlate with reduced entropy, which leads to higher confidence token predictions, which directly means more tokens decoded in parallel per step. Tests suggest that it really is the structuredness of the output, not memorization, that matters.

</details>


### [11] [Inside our effort to improve the Mintlify assistant](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.mintlify.com%2Fblog%2Fassistant-improvements%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/hKwp13rZbgEapavVha37LuInkdcPbVePb4ReeL3KCq4=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Mintlify团队分析并改进了其AI助手，通过重建反馈管道、迁移对话数据到ClickHouse、大规模分类负面交互，发现搜索质量是主要问题


<details>
  <summary>Details</summary>
Motivation: Mintlify的AI助手未能达到预期性能，团队需要分析问题并改进助手以更好地帮助用户从文档中获取答案

Method: 重建反馈管道，将对话数据迁移到ClickHouse数据库，大规模分类负面交互，分析用户交互数据

Result: 分析发现搜索质量是主要问题，通过改进措施提升了助手性能

Conclusion: 系统化的数据分析和反馈管道改进是提升AI助手性能的关键

Abstract: Inside our effort to improve the Mintlify assistant (3 minute read) Mintlify's AI-powered assistant helps end users get answers from docs with clear citations and useful code examples. This article walks through how the team analyzed and improved the assistant after they decided that it wasn't performing the way they wanted. The team rebuilt its feedback pipeline, moved conversation data into ClickHouse, and categorized negative interactions at scale. Its analysis surfaced that search quality...

</details>


### [12] [Agentic coding tools should give more control over message queueing](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsolmaz.io%2Fagentic-coding-tools-message-queueing%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/kXIklas8YG4zJj1JCXpXuWL-2Rxn9GyBQ7JKMyyJOR8=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 论文讨论了智能编码工具的消息队列机制，比较了Claude Code的边界感知队列和OpenAI Codex的后轮次队列，建议智能工具应同时实现两种队列机制并让用户选择。


<details>
  <summary>Details</summary>
Motivation: 当前智能编码工具的消息队列处理方式不同，影响了用户与AI交互的流畅性和控制性。Claude Code和OpenAI Codex采用不同的队列策略，各有优缺点，需要为开发者提供更灵活的控制选项。

Method: 分析比较了两种队列机制：1）边界感知队列（Claude Code）：在自然断点处插入新消息，平滑改变模型行为而不中断当前生成；2）后轮次队列（OpenAI Codex）：用户消息等待当前操作完全完成后才被处理。建议智能工具应同时实现这两种机制。

Result: 通过对比分析，发现不同队列策略对用户体验和开发效率有显著影响。边界感知队列提供更流畅的交互体验，而后轮次队列确保操作的完整性。两者各有适用场景。

Conclusion: 智能编码工具应该同时实现边界感知队列和后轮次队列两种消息处理机制，并让用户根据具体需求选择使用哪种方式，以提供更好的控制性和灵活性。

Abstract: Agentic coding tools should give more control over message queueing (7 minute read) Claude Code uses boundary-aware queuing, where new messages are inserted at natural break points, which changes the model's course of action smoothly without stopping ongoing generation. OpenAI Codex uses post-turn queuing, where user messages wait until the current action finishes completely before they are handled. Agentic tools should implement both types of queuing and let users choose which to use. Having...

</details>


### [13] [Skills vs Dynamic MCP Loadouts](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flucumr.pocoo.org%2F2025%2F12%2F13%2Fskills-vs-mcp%2F%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/pimyX2Q-_LfFEJmwUmD_0tAvAyulY3wWl4o4mzz5zaU=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 论文探讨了两种工具使用方式：让AI代理编写技能（用户控制）vs 动态MCP工具加载（需要协议改进），认为技能方式更简单直接


<details>
  <summary>Details</summary>
Motivation: 探索如何让AI代理更有效地使用工具，比较用户控制技能编写与动态工具加载两种方法的优劣，寻找更实用的工具集成方案

Method: 对比分析两种方法：1) 让代理编写技能作为工具，用户保持控制权；2) 动态MCP工具加载，需要协议改进来支持技能式摘要和内置手册

Result: 技能编写方法更简单实用，用户控制工具且易于调整；动态MCP加载需要更多协议改进才能达到类似效果

Conclusion: 目前让代理编写技能是更可行的工具使用方法，动态MCP加载虽然前景好但需要更多技术发展

Abstract: Skills vs Dynamic MCP Loadouts (7 minute read) The easiest way to work with tools is to ask agents to write their own tools as a skill. This leaves control of the tool largely to the user. Whenever it breaks or needs modification, the user can just ask the agent to adjust it. Dynamic tool loading with MCP will likely become a thing, but it will probably take quite a few protocol changes to bring in skill-like summaries and built-in manuals for the tools.

</details>


### [14] [MCP Writing Code to Call MCP: MCPs All the Way Down](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Frouxbot.com%2Fp%2Fmcp-code-mode%3Futm_source=tldrai/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/n0RB2NOPkRK4kFzfkV6wV9mYPlcQatK3e4Gh3Y0B8EA=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 构建通用引擎实现任意基于模式的集成，无需手动连接代码


<details>
  <summary>Details</summary>
Motivation: 当前基于模式的集成需要大量手动连接代码，开发效率低下且容易出错，需要一种自动化解决方案

Method: 通过MCP（模式调用协议）递归调用自身，构建通用引擎来自动处理任意模式集成

Result: 实现了无需手动代码的通用集成引擎，能够自动处理各种模式化集成需求

Conclusion: 通过MCP递归调用方法，成功构建了通用集成引擎，显著提高了开发效率和系统可靠性

Abstract: MCP Writing Code to Call MCP: MCPs All the Way Down (13 minute read) This post explores how to build a universal engine for any schema-based integration, without manual plumbing.

</details>


### [15] [advertise with us](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrai%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/yrhSdBSSeVn-CTOSY_ayENxH2u8CIk729QBa7q-PUIU=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 构建一个用于任何基于模式集成的通用引擎，无需手动连接代码


<details>
  <summary>Details</summary>
Motivation: 当前基于模式的集成需要大量手动编码和连接工作，缺乏通用解决方案

Method: 开发一个能够自动处理任何模式集成的通用引擎，通过代码生成和自动化连接实现

Result: 创建了一个能够处理各种模式集成的通用引擎，减少了手动编码工作

Conclusion: 通过构建通用集成引擎，可以显著简化基于模式集成的开发流程

Abstract: MCP Writing Code to Call MCP: MCPs All the Way Down (13 minute read) This post explores how to build a universal engine for any schema-based integration, without manual plumbing.

</details>


### [16] [create your own role](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/YLF0Fg3uB8sqpfd5FoVk0ahKMGUOed5gCVsmsHhH1To=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 构建一个无需手动配置的通用引擎，用于处理任何基于模式的集成


<details>
  <summary>Details</summary>
Motivation: 现有的模式集成需要大量手动配置和管道工作，作者希望创建一个通用解决方案来简化这一过程

Method: 开发一个能够自动处理任何模式集成的通用引擎，通过代码生成和自动化来消除手动配置

Result: 成功构建了一个通用集成引擎，能够处理各种模式集成而无需手动管道工作

Conclusion: 通过构建通用集成引擎，可以显著简化模式集成过程，提高开发效率

Abstract: MCP Writing Code to Call MCP: MCPs All the Way Down (13 minute read) This post explores how to build a universal engine for any schema-based integration, without manual plumbing.

</details>


### [17] [Inc.'s Best Bootstrapped businesses](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b227c0926-969e6904-8a3d-45ae-bc1b-2f238681ef63-000000/kAluSy5IwYk1lSjUtQzYHV45PpnIIMf8zUvlGHgBneM=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 构建一个无需手动配置的通用引擎，用于处理任何基于模式的集成


<details>
  <summary>Details</summary>
Motivation: 现有的模式集成需要大量手动配置和管道工作，作者希望创建一个通用解决方案来自动化这一过程

Method: 开发一个能够自动处理任何模式集成的通用引擎，通过代码生成和自动化来消除手动配置

Result: 创建了一个能够处理各种模式集成的通用引擎，减少了手动配置工作

Conclusion: 通过构建通用集成引擎，可以显著减少模式集成中的手动工作，提高开发效率

Abstract: MCP Writing Code to Call MCP: MCPs All the Way Down (13 minute read) This post explores how to build a universal engine for any schema-based integration, without manual plumbing.

</details>


### [18] [Shopify doubles down on AI in the latest large update to its Developer platform](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.shopify.com%2Fnews%2Fwinter-26-edition-dev%3Futm_source=comms_paid%26utm_medium=newsletter%26utm_campaign=winter26edition-launch_Q425BACADO%26utm_content=tldrdev-v1/1/0100019b270fa692-84b582a6-0262-4a76-8259-9c1c99efda2f-000000/5aq655fxvhhpd0xTQrlKwx5rUqKOoOIpO5Hs9vthdLA=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Shopify在最新的开发者平台更新中大幅增强AI能力，使AI代理能够创建开发商店、搭建应用、执行GraphQL操作，并在多个技术栈中生成经过验证的代码。


<details>
  <summary>Details</summary>
Motivation: Shopify希望通过增强AI能力来提升开发者体验，让开发者能够使用自然语言提问并获得可直接使用的验证代码，从而提高开发效率和降低技术门槛。

Method: Shopify在'26冬季版中集成了更先进的AI功能，使AI代理能够执行多种开发任务，包括创建开发商店、搭建应用框架、运行GraphQL操作，并在Admin、UI扩展、Liquid和Hydrogen等不同技术栈中生成经过验证的代码。

Result: 开发者现在可以使用自然语言提问并获得可直接工作的验证代码，同时获得shopify.dev的直接链接，这显著提升了开发效率和代码质量。

Conclusion: Shopify通过大规模AI集成成功提升了开发者平台的智能化水平，使开发工作更加高效和便捷，为开发者提供了更强大的工具支持。

Abstract: Shopify doubles down on AI in the latest large update to its Developer platform (Sponsor) The '26 Winter Edition adds more advanced AI capabilities to Shopify: agents can create dev stores, scaffold apps, run GraphQL operations, and generate validated code across Admin, UI extensions, Liquid, and Hydrogen. Developers can ask questions in natural language and receive working, validated code with direct shopify.dev links. See what's new

</details>


### [19] [Claude Mem](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Fthedotmack%2Fclaude-mem%3Futm_source=tldrdev/1/0100019b270fa692-84b582a6-0262-4a76-8259-9c1c99efda2f-000000/obZxM2wUUVnl4iwTTB9-r5B5jrj210uBctgDeRLZ_tw=435)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: Claude Mem是一个Claude Code插件，通过自动捕获工具使用观察并生成语义摘要，提供持久化记忆系统，将相关上下文注入未来会话，实现跨项目知识连续性。


<details>
  <summary>Details</summary>
Motivation: 解决代码助手在跨会话和跨项目中缺乏持久记忆的问题，使Claude Code能够记住之前的工具使用和项目上下文，提高开发效率和连续性。

Method: 开发Claude Code插件，自动捕获工具使用观察，生成语义摘要，建立持久记忆系统，并将相关上下文注入到未来的会话中。

Result: 创建了Claude Mem插件，实现了跨会话和跨项目的知识连续性，使Claude Code能够维护和利用历史工具使用信息。

Conclusion: Claude Mem通过持久记忆系统显著提升了Claude Code的连续性和实用性，为代码助手提供了更好的上下文感知能力。

Abstract: Claude Mem (GitHub Repo) Claude-Mem is a Claude Code plugin that provides a persistent memory system by automatically capturing tool usage observations and generating semantic summaries. It injects this relevant context back into future sessions, allowing Claude Code to maintain knowledge continuity across projects.

</details>


<div id='wechat.article'></div>

# wechat.article [[Back]](#toc)

### [20] [情绪是函数：AI 视角下的人脑降维机制与<em class="highlight">强化学习</em>（RL）（上）](http://mp.weixin.qq.com/s?__biz=Mzg4MDU5MzYyNA==&mid=2247486539&idx=1&sn=c130a2f0aed6970790071bb69e07b4e7&chksm=cebf3f949183306ef594655f095bfc46a2ca0b1f006bfe4e2b8db227965ae46967a6feb2b2df#rd)
*从中学竞赛到大学预科*

Main category: wechat.article

TL;DR: 强化学习（RL）这个词，很多人听过，但大多觉得它是机房里研究员才用的玩意儿。但当你把它放在“情绪函数”上，它反而变得特别直观。RL 本质上是一个不断更新的数学系统，它的结构和我们的情绪反应几乎一模一样，靠三


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 强化学习（RL）这个词，很多人听过，但大多觉得它是机房里研究员才用的玩意儿。但当你把它放在“情绪函数”上，它反而变得特别直观。RL 本质上是一个不断更新的数学系统，它的结构和我们的情绪反应几乎一模一样，靠三

</details>


### [21] [【基于模型的<em class="highlight">强化学习</em>】#1 引论：Dyna架构](http://mp.weixin.qq.com/s?__biz=Mzk0MjY5NzY5OQ==&mid=2247487129&idx=1&sn=ad458e518351ac7a7fb3473d29c1ad19&chksm=c219e203fa2f6b468ae230695993458d8b20291cd6fae2d76459c134c448a3a6f000393ad9ed#rd)
*一杯为品*

Main category: wechat.article

TL;DR: 基于模型的强化学习环境的模型（Model）是一个智能体可以用来预测环境对其动作的反应的任何事物。给定一个状态和一个动作，模型能产生后继状态和下一个收益的预测作为环境的反应结果。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 基于模型的强化学习环境的模型（Model）是一个智能体可以用来预测环境对其动作的反应的任何事物。给定一个状态和一个动作，模型能产生后继状态和下一个收益的预测作为环境的反应结果。

</details>


### [22] [OpenAI：进化策略作为<em class="highlight">强化学习</em>的可扩展替代方案](http://mp.weixin.qq.com/s?__biz=Mzk0Njc5ODg0OQ==&mid=2247484550&idx=1&sn=3fbe3641de4b42c5348ed873111dd99e&chksm=c23835348c350764c969662832c53db363253cdbb1a65ca790d66167ce9b23a1ebbc6cfa85d3#rd)
*EvoDiary*

Main category: wechat.article

TL;DR: 在深入原理之前，我们需要先看看当时主流深度强化学习（Deep RL）面临的痛点：梯度计算难：无论是 Q-learning 还是 Policy Gradients，本质上都依赖于梯度的反向传播。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 在深入原理之前，我们需要先看看当时主流深度强化学习（Deep RL）面临的痛点：梯度计算难：无论是 Q-learning 还是 Policy Gradients，本质上都依赖于梯度的反向传播。

</details>


### [23] [猫又的学习笔记——<em class="highlight">强化学习</em>Part3.3](http://mp.weixin.qq.com/s?__biz=Mzk0NjQ0MDU5NA==&mid=2247484452&idx=1&sn=1901fb008acbda019e73d164fc7aeec9&chksm=c2e408f7e63899f92517cc5a80e76f42c8c670929e7b4b051e93343d71b25d6b7cc21198d1c9#rd)
*猫又和猹狐的杂乱日记*

Main category: wechat.article

TL;DR: 这会将强化学习的问题转变为：其中 是权衡系数（trade-off coefficient）。（注意：公式中我们假设的是infinite-horizon discounted设定，接下来的讲述也都在这个设定下展开）接着我们可以在这个设定下定义稍有不同的value function。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 这会将强化学习的问题转变为：其中 是权衡系数（trade-off coefficient）。（注意：公式中我们假设的是infinite-horizon discounted设定，接下来的讲述也都在这个设定下展开）接着我们可以在这个设定下定义稍有不同的value function。

</details>


### [24] [2025年 7种大模型最流行的<em class="highlight">强化学习</em>算法总结](http://mp.weixin.qq.com/s?__biz=MzE5MTYxNjkwMQ==&mid=2247486171&idx=1&sn=70c6c428c5738013c1630e335306431c&chksm=97943d23b9bcce428b59631d14eb75bc7944af9cd711a9ff52f98d1790c17ee71fe2fe74280a#rd)
*LLM炼丹炉*

Main category: wechat.article

TL;DR: 算法简介： DPO做了一次“减法”：它完全绕过了传统RLHF中先训练奖励模型、再用强化学习优化的复杂流程，直接将偏好学习变成了一个简单的监督学习问题。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 算法简介： DPO做了一次“减法”：它完全绕过了传统RLHF中先训练奖励模型、再用强化学习优化的复杂流程，直接将偏好学习变成了一个简单的监督学习问题。

</details>


### [25] [[论文分享]Nature 2025 发现最先进的<em class="highlight">强化学习</em>算法](http://mp.weixin.qq.com/s?__biz=MzkxODQ0MTQzMg==&mid=2247492051&idx=1&sn=6abce216f5ee0ddf2d570dddf7fabfbd&chksm=c0180df44213bd3bd726c282c46abcffd301d1a6783185e5491737f53484ad711663ec85965d#rd)
*EvoIGroup*

Main category: wechat.article

TL;DR: 在这个概念上，可以把强化学习的组件分为三个元学习的对象：①学习算法：学习如何更新策略，比如梯度更新规则、损失函数等等-元学习优化器；


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 在这个概念上，可以把强化学习的组件分为三个元学习的对象：①学习算法：学习如何更新策略，比如梯度更新规则、损失函数等等-元学习优化器；

</details>


### [26] [【Nature 2025】谷歌重磅发布DiscoRL ：让 AI 自主“发明”<em class="highlight">强化学习</em>算法，性能横扫人类设计](http://mp.weixin.qq.com/s?__biz=Mzk0Nzg0MjM1MA==&mid=2247484208&idx=1&sn=3fcd54aa21662f0d08220824ee972417&chksm=c2f12e6c4049e2ff6d725eae552017e8335f08220e451a3515f1b133d5cfec59abd6d03e7659#rd)
*智能迷路*

Main category: wechat.article

TL;DR: 在人工智能的长河中，强化学习（RL）算法如同一把开启智能之门的钥匙 。从战胜围棋冠军的 AlphaGo 到掌控复杂物理系统的机器人，这些辉煌成就的背后，通常是人类科学家花费数十年心血、基于直觉和经验手工设计的学习规则


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 在人工智能的长河中，强化学习（RL）算法如同一把开启智能之门的钥匙 。从战胜围棋冠军的 AlphaGo 到掌控复杂物理系统的机器人，这些辉煌成就的背后，通常是人类科学家花费数十年心血、基于直觉和经验手工设计的学习规则

</details>


### [27] [18个常用的<em class="highlight">强化学习</em>算法整理：从基础方法到高级模型的理论技术与代码实现](http://mp.weixin.qq.com/s?__biz=MzAxNTc4MTc1Ng==&mid=2649479929&idx=1&sn=054a49dae1473d491476366270b935c6&chksm=8298852dd73f348042b9d0a60e27f90cbcdd96c3709c2461e928b1d082d07d4c4c731910bca9#rd)
*新机器视觉*

Main category: wechat.article

TL;DR: 本文系统讲解从基本强化学习方法到高级技术（如PPO、A3C、PlaNet等）的实现原理与编码过程，旨在通过理论结合代码的方式，构建对强化学习算法的全面理解。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 本文系统讲解从基本强化学习方法到高级技术（如PPO、A3C、PlaNet等）的实现原理与编码过程，旨在通过理论结合代码的方式，构建对强化学习算法的全面理解。

</details>


### [28] [什么是 <em class="highlight">Agentic</em> Commerce？](http://mp.weixin.qq.com/s?__biz=MzYzNDQzMDMyMQ==&mid=2247483663&idx=1&sn=b7f4d1c2b9c91303e3f7d0a7f409da0c&chksm=f10abe339206b9e41e2436bba988945f899a0ba52ecdef72593ef1f563059c657c53a8e0a35c#rd)
*高科销研*

Main category: wechat.article

TL;DR: “Agentic Commerce” 可以理解为“代理式商务”或“智能体主导的商业”。它指的是由自主或半自主的人工智能代理来主导、执行和优化商业流程与消费者互动的一种新型商业模式。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: “Agentic Commerce” 可以理解为“代理式商务”或“智能体主导的商业”。它指的是由自主或半自主的人工智能代理来主导、执行和优化商业流程与消费者互动的一种新型商业模式。

</details>


### [29] [韩家炜教授新作：下一代<em class="highlight">Agentic</em> AI应如何“适配”？](http://mp.weixin.qq.com/s?__biz=Mzg4MDE3OTA5NA==&mid=2247601405&idx=1&sn=23f76a7fa343c18bd6f1b391397b84cd&chksm=cefa802a9e54ede1c4b580c2890443731926c4e2d7a7901b36cef647d6edfe084710cd98a41a#rd)
*学术头条*

Main category: wechat.article

TL;DR: 随着基础模型，尤其是大语言模型（LLM）的快速发展，Agentic AI 迅速兴起，并广泛应用于在科研、软件开发、药物研发、临床研究等广泛领域。然而，工具使用不稳定、长程任务规划能力有限、特定领域的推理能力不足、真实环


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 随着基础模型，尤其是大语言模型（LLM）的快速发展，Agentic AI 迅速兴起，并广泛应用于在科研、软件开发、药物研发、临床研究等广泛领域。然而，工具使用不稳定、长程任务规划能力有限、特定领域的推理能力不足、真实环

</details>


### [30] [亚马逊 | <em class="highlight">Agentic</em>+AI应用构建实践指南（附下载）](http://mp.weixin.qq.com/s?__biz=MzIyNjAyNjA1Ng==&mid=2657873058&idx=2&sn=0aa2a133f886aa562efb3860cdb64c75&chksm=f212dd3531cd326b584dddd630e6388a8942a15fe7f2d0a9c899f2b8409ae7b1f08b994de635#rd)
*工业4俱乐部*

Main category: wechat.article

TL;DR: Agentic AI 源于 AI Agent 技术，经 LLM 赋能实现从面向过程到面向目标的架构转型，是能自主推理、规划并完成任务的软件系统，核心能力包括自然语言理解、推理、自主规划及工具使用，其记忆机制（短期维护会话上下文、长期依


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: Agentic AI 源于 AI Agent 技术，经 LLM 赋能实现从面向过程到面向目标的架构转型，是能自主推理、规划并完成任务的软件系统，核心能力包括自然语言理解、推理、自主规划及工具使用，其记忆机制（短期维护会话上下文、长期依

</details>


### [31] [小米发布最新MiMo<em class="highlight">大模型</em> 布局短剧 SU7将换代](http://mp.weixin.qq.com/s?__biz=MjM5MDQ4MzU5NQ==&mid=2659209039&idx=1&sn=0f729652f3dd56e2f5d3a1a69ab61725&chksm=bcf215391e721a3b9a6fc8a239788d06331d86aadcf4b9dc4ae71501ff0b69174b29135a1b3d#rd)
*科技美学*

Main category: wechat.article

TL;DR: 去年年底有消息称，雷军曾希望用千万年薪挖角DeepSeek 开源大模型 DeepSeek-V2 的关键开发者之一罗福莉，邀请她到小米带领团队从事AI大模型研究。上个月，有消息显示，罗福莉在朋友圈官宣加入小米 Xiaomi MiMo 大模型团队。据了


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 去年年底有消息称，雷军曾希望用千万年薪挖角DeepSeek 开源大模型 DeepSeek-V2 的关键开发者之一罗福莉，邀请她到小米带领团队从事AI大模型研究。上个月，有消息显示，罗福莉在朋友圈官宣加入小米 Xiaomi MiMo 大模型团队。据了

</details>


### [32] [<em class="highlight">大模型</em>驱动的护理智能体实践：智能护理新时代的全面概述](http://mp.weixin.qq.com/s?__biz=MzI3ODE5Mzc1Ng==&mid=2247511544&idx=1&sn=bca7db25525f75be23d8c44eec238ea1&chksm=ea78c0527ad088c104373826a6d7f12aa8b2714343d75e43d57b1891a3304f03713407d21f1f#rd)
*知识图谱科技*

Main category: wechat.article

TL;DR: 为此，大语言模型驱动代理（LLMDAs）应运而生。这些代理本质上是多代理系统，以 LLM 作为核心引擎，负责语义理解、逻辑推理和任务分解，从而弥补传统代理的不足。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 为此，大语言模型驱动代理（LLMDAs）应运而生。这些代理本质上是多代理系统，以 LLM 作为核心引擎，负责语义理解、逻辑推理和任务分解，从而弥补传统代理的不足。

</details>


### [33] [天才少女首秀，小米开源“闪电”<em class="highlight">大模型</em>，推理速度提升2.6倍！](http://mp.weixin.qq.com/s?__biz=MzI3MDE2NzAxNA==&mid=2247491935&idx=1&sn=510ae221187f3e0cc55776ef9fe42edf&chksm=eb89f6a5ee89811adee8175f0489de197b17269f51a23f3f122a563e2e025dd8ee9ce6062bce#rd)
*科技闲聊馆*

Main category: wechat.article

TL;DR: 这种“模拟世界”的能力，标志着大模型正从文本理解向物理世界认知迈进。发布会结束后，体验Web Demo迅速上线，模型权重和推理代码全面开源。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 这种“模拟世界”的能力，标志着大模型正从文本理解向物理世界认知迈进。发布会结束后，体验Web Demo迅速上线，模型权重和推理代码全面开源。

</details>


### [34] [小米发布最新MiMo<em class="highlight">大模型</em>，负责人AI“天才少女”罗福莉首秀](http://mp.weixin.qq.com/s?__biz=MjExMTExNDA2MQ==&mid=2663157388&idx=7&sn=7090a0dab1582ba1040a124a0429c044&chksm=4f550a0f949389a403811a279a2fb738f5e8ed76d7ce77d08cb0ec66eb013b9e041286465d5d#rd)
*19楼*

Main category: wechat.article

TL;DR: 当日上午，小米集团合伙人、集团总裁卢伟冰宣布小米自研AI大模型Xiaomi MiMo-V2-Flash正式开源上线。据小米方面介绍，Xiaomi MiMo-V2-Flash是小米自研的总参数309B（激活15B）的MoE模型，代码能力比肩标杆闭源模型Claude Sonnet 4.5，但推理


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 当日上午，小米集团合伙人、集团总裁卢伟冰宣布小米自研AI大模型Xiaomi MiMo-V2-Flash正式开源上线。据小米方面介绍，Xiaomi MiMo-V2-Flash是小米自研的总参数309B（激活15B）的MoE模型，代码能力比肩标杆闭源模型Claude Sonnet 4.5，但推理

</details>


### [35] [【前沿】小米发布最新MiMo<em class="highlight">大模型</em>](http://mp.weixin.qq.com/s?__biz=MzAwOTUzNTYxOQ==&mid=2680393982&idx=4&sn=5719d90c9f0090b8aed57ef84d3f9cc8&chksm=8014c504d1089db8a243b7d2c978284fa047d33a216f47a46df4f291a0e82fb34709b4ec40c8#rd)
*小白测评*

Main category: wechat.article

TL;DR: 据介绍，Xiaomi MiMo-V2-Flash全新开源MoE模型，总参数量309B，活跃参数量15B，专为智能体AI设计，专注于快，官方称在通用基准测试中和DeepSeek V3.2性能相当但延迟更低。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 据介绍，Xiaomi MiMo-V2-Flash全新开源MoE模型，总参数量309B，活跃参数量15B，专为智能体AI设计，专注于快，官方称在通用基准测试中和DeepSeek V3.2性能相当但延迟更低。

</details>


### [36] [小米<em class="highlight">大模型</em>MiMo-V2-Flash背后，小米真正的AI野心](http://mp.weixin.qq.com/s?__biz=MzU0MjE3MzA4Nw==&mid=2247486545&idx=1&sn=ac309eebf95dc721bf894d4709563404&chksm=fae9e8980e2451f79d4058ede7824a60b0ac27c23f381f02d19a5a56f357c35c9ccc42cfb7dc#rd)
*科技圈观察*

Main category: wechat.article

TL;DR: AI大模型，小米晚到但没有缺席，小米的大模型终于来了。日前小米的大模型MiMo-V2-Flash正式发布了，总参数量3090亿，活跃参数150亿，使用的是MoE（混合专家模型）架构，在多个综合AI基准测试中，MiMo-V2-Flash与DeepSeek V3.2的表现非


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: AI大模型，小米晚到但没有缺席，小米的大模型终于来了。日前小米的大模型MiMo-V2-Flash正式发布了，总参数量3090亿，活跃参数150亿，使用的是MoE（混合专家模型）架构，在多个综合AI基准测试中，MiMo-V2-Flash与DeepSeek V3.2的表现非

</details>


### [37] [<em class="highlight">大模型</em>评测基准技术解析丨AI Insight Talk 直播预告](http://mp.weixin.qq.com/s?__biz=Mzk0MDg1MjIwNg==&mid=2247530443&idx=1&sn=eb009243f94d33ab3ab4b690d57e9d77&chksm=c346f274432a6ced74f8bd2456226d38cd243a6f7f8e9774bdd0e843f2ccfb79d6b8bfde69fc#rd)
*OpenMMLab*

Main category: wechat.article

TL;DR: 多模态大模型正在从图像、视频和语音的单模态理解模型和生成模型，逐渐演进为全模态的理解和生成统一模型。然而，能够达到理想态中，不同模态间的协同促进、生成和理解互相增强的技术路线多样，尚未收敛。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 多模态大模型正在从图像、视频和语音的单模态理解模型和生成模型，逐渐演进为全模态的理解和生成统一模型。然而，能够达到理想态中，不同模态间的协同促进、生成和理解互相增强的技术路线多样，尚未收敛。

</details>


### [38] [小米发布最新<em class="highlight">大模型</em>！](http://mp.weixin.qq.com/s?__biz=MTE3MzE4MTAyMQ==&mid=2651411702&idx=1&sn=6cb9f86b107d70473c883a2728fef285&chksm=772bbfd2f77216d2fa4f4dfac90ed02f1ff7966f639d34e9c16ee791606059f2cec2a2c1c75f#rd)
*TechWeb*

Main category: wechat.article

TL;DR: 大会前夕，专为极致推理效率自研的混合专家（MoE）大语言模型Xiaomi MiMo-V2-Flash宣布正式开源，凭借其强大的代码与Agent能力、极快的生成速度和低廉的推理成本，在多个Agent测评基准上跻身“全球开源模型TOP2”。


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 大会前夕，专为极致推理效率自研的混合专家（MoE）大语言模型Xiaomi MiMo-V2-Flash宣布正式开源，凭借其强大的代码与Agent能力、极快的生成速度和低廉的推理成本，在多个Agent测评基准上跻身“全球开源模型TOP2”。

</details>


### [39] [官宣！前 OpenAI 华人科学家姚顺雨加入腾讯，<em class="highlight">大模型</em>“系统战”开启！](http://mp.weixin.qq.com/s?__biz=Mzg4NDQwNTI0OQ==&mid=2247588532&idx=1&sn=72c249b4fa628deacd7d84587eb6e477&chksm=ce80ab03b7ed5c9b660cab4617d51e68dd6965679d6f13cd3e1dfbfe69f09f4d173e5f3751e2#rd)
*AI科技大本营*

Main category: wechat.article

TL;DR: AI Data 部：由刘煜宏负责，专注于大模型数据及评测体系建设。数据计算平台部：由陈鹏负责，致力于大数据和机器学习的数据智能融合平台建设。注：刘煜宏与陈鹏均向公司副总裁蒋杰汇报；


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: AI Data 部：由刘煜宏负责，专注于大模型数据及评测体系建设。数据计算平台部：由陈鹏负责，致力于大数据和机器学习的数据智能融合平台建设。注：刘煜宏与陈鹏均向公司副总裁蒋杰汇报；

</details>


### [40] [小米全新<em class="highlight">大模型</em>发布，速度比DeepSeek、豆包更快](http://mp.weixin.qq.com/s?__biz=MzIyODgwMDY3MQ==&mid=2247610447&idx=7&sn=4638a3605550ea865128f72d46304e3a&chksm=e90f3f64a8450710e34a3a21108472557bbd41a43d42388486d95660923f851c90da645ea06d#rd)
*泡泡网PCPOP*

Main category: wechat.article

TL;DR: 已成功跻身当前开源大模型第 一梯队。值得一提的是，该模型的权重与推理代码均采用MIT协议全面开源，为开发者社区提供了充足的探索空间。成本方面，MiMo-V2-Flash也展现出极高的性价比，其API定价为每百万输入Token 0.1美元、


<details>
  <summary>Details</summary>
Motivation: 微信公众号文章，分享AI相关技术内容

Method: 基于实际应用经验的技术分享

Result: 提供实用的AI技术见解和案例分析

Conclusion: 适合了解AI技术在实际场景中的应用

Abstract: 已成功跻身当前开源大模型第 一梯队。值得一提的是，该模型的权重与推理代码均采用MIT协议全面开源，为开发者社区提供了充足的探索空间。成本方面，MiMo-V2-Flash也展现出极高的性价比，其API定价为每百万输入Token 0.1美元、

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [41] [RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing](https://arxiv.org/abs/2512.13727)
*Yuhan Tang,Kangxin Cui,Jung Ho Park,Yibo Zhao,Xuan Jiang,Haoze He,Dingyi Zhuang,Shenhao Wang,Jiangbo Yu,Haris Koutsopoulos,Jinhua Zhao*

Main category: cs.LG

TL;DR: 提出RAST-MoE框架，使用专家混合自注意力编码器解决网约车平台的自适应延迟匹配问题，在真实Uber数据上提升总奖励13%，减少匹配和接驾延迟10%和15%。


<details>
  <summary>Details</summary>
Motivation: 网约车平台需要在高度不确定的供需条件下平衡乘客等待时间和系统效率。现有方法常过度简化交通动态或使用浅层编码器，无法捕捉复杂的时空模式。

Method: 提出Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE)，将自适应延迟匹配形式化为机制感知MDP，配备自注意力MoE编码器。专家自动专业化，提高表示能力同时保持计算效率。使用物理信息拥堵代理实现高效模拟，自适应奖励方案防止病态策略。

Result: 仅用1200万参数，在真实Uber轨迹数据（旧金山）上总奖励提升超过13%，平均匹配延迟减少10%，接驾延迟减少15%。在未见需求机制下表现鲁棒，训练稳定。

Conclusion: MoE增强的RL在处理复杂时空动态的大规模决策中具有潜力，RAST-MoE框架有效解决了网约车平台的延迟匹配问题。

Abstract: Ride-hailing platforms face the challenge of balancing passenger waiting times with overall system efficiency under highly uncertain supply-demand conditions. Adaptive delayed matching creates a trade-off between matching and pickup delays by deciding whether to assign drivers immediately or batch requests. Since outcomes accumulate over long horizons with stochastic dynamics, reinforcement learning (RL) is a suitable framework. However, existing approaches often oversimplify traffic dynamics or use shallow encoders that miss complex spatiotemporal patterns.
  We introduce the Regime-Aware Spatio-Temporal Mixture-of-Experts (RAST-MoE), which formalizes adaptive delayed matching as a regime-aware MDP equipped with a self-attention MoE encoder. Unlike monolithic networks, our experts specialize automatically, improving representation capacity while maintaining computational efficiency. A physics-informed congestion surrogate preserves realistic density-speed feedback, enabling millions of efficient rollouts, while an adaptive reward scheme guards against pathological strategies.
  With only 12M parameters, our framework outperforms strong baselines. On real-world Uber trajectory data (San Francisco), it improves total reward by over 13%, reducing average matching and pickup delays by 10% and 15% respectively. It demonstrates robustness across unseen demand regimes and stable training. These findings highlight the potential of MoE-enhanced RL for large-scale decision-making with complex spatiotemporal dynamics.

</details>


### [42] [The Laminar Flow Hypothesis: Detecting Jailbreaks via Semantic Turbulence in Large Language Models](https://arxiv.org/abs/2512.13741)
*Md. Hasib Ur Rahman*

Main category: cs.LG

TL;DR: 提出"层流假设"，认为良性输入在LLM潜在空间中产生平滑过渡，而对抗性提示引发"语义湍流"，可通过层间余弦速度方差检测。实验验证该指标能有效识别越狱攻击并分类模型安全架构。


<details>
  <summary>Details</summary>
Motivation: 当前LLM防御策略依赖计算昂贵的外部分类器或脆弱的词汇过滤器，忽视了模型推理过程的内在动态。需要更轻量、实时的越狱检测方法，并理解不同模型的安全架构差异。

Method: 提出层流假设和语义湍流概念，形式化为零指标：层间余弦速度方差。通过实验评估多个小型语言模型在对抗性提示下的响应模式，分析不同安全架构的表现差异。

Result: RLHF对齐的Qwen2-1.5B在攻击下湍流增加75.4%，验证了内部冲突假设；Gemma-2B则显示22.0%的湍流减少，表现出不同的"基于反射"的拒绝机制。该指标能有效检测越狱并分类安全架构。

Conclusion: 语义湍流不仅可作为轻量级实时越狱检测器，还能作为非侵入式诊断工具，用于分类黑盒模型的安全架构类型，为LLM安全防御提供新视角。

Abstract: As Large Language Models (LLMs) become ubiquitous, the challenge of securing them against adversarial "jailbreaking" attacks has intensified. Current defense strategies often rely on computationally expensive external classifiers or brittle lexical filters, overlooking the intrinsic dynamics of the model's reasoning process. In this work, the Laminar Flow Hypothesis is introduced, which posits that benign inputs induce smooth, gradual transitions in an LLM's high-dimensional latent space, whereas adversarial prompts trigger chaotic, high-variance trajectories - termed Semantic Turbulence - resulting from the internal conflict between safety alignment and instruction-following objectives. This phenomenon is formalized through a novel, zero-shot metric: the variance of layer-wise cosine velocity. Experimental evaluation across diverse small language models reveals a striking diagnostic capability. The RLHF-aligned Qwen2-1.5B exhibits a statistically significant 75.4% increase in turbulence under attack (p less than 0.001), validating the hypothesis of internal conflict. Conversely, Gemma-2B displays a 22.0% decrease in turbulence, characterizing a distinct, low-entropy "reflex-based" refusal mechanism. These findings demonstrate that Semantic Turbulence serves not only as a lightweight, real-time jailbreak detector but also as a non-invasive diagnostic tool for categorizing the underlying safety architecture of black-box models.

</details>


### [43] [The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces](https://arxiv.org/abs/2512.13821)
*Subramanyam Sahoo,Jared Junkin*

Main category: cs.LG

TL;DR: 提出CTVP框架，通过语义轨道分析验证不可信代码生成模型，检测后门注入，引入ARQ指标量化验证成本，证明不可博弈性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地生成代码而人工监督减少，后门注入和恶意行为成为关键问题，需要可靠的AI控制框架来验证代码生成模型的安全性。

Method: 提出跨轨迹验证协议(CTVP)，不直接执行可能恶意的代码，而是通过分析模型在语义等价程序变换上的执行轨迹预测一致性，检测行为异常。

Result: 引入对抗鲁棒商(ARQ)量化验证成本，显示随轨道大小指数增长；理论分析建立信息论边界，证明不可博弈性，即对手无法通过训练改进。

Conclusion: 语义轨道分析为代码生成任务提供了可扩展、理论基础的AI控制方法，能够有效检测后门行为。

Abstract: Large language models (LLMs) increasingly generate code with minimal human oversight, raising critical concerns about backdoor injection and malicious behavior. We present Cross-Trace Verification Protocol (CTVP), a novel AI control framework that verifies untrusted code-generating models through semantic orbit analysis. Rather than directly executing potentially malicious code, CTVP leverages the model's own predictions of execution traces across semantically equivalent program transformations. By analyzing consistency patterns in these predicted traces, we detect behavioral anomalies indicative of backdoors. Our approach introduces the Adversarial Robustness Quotient (ARQ), which quantifies the computational cost of verification relative to baseline generation, demonstrating exponential growth with orbit size. Theoretical analysis establishes information-theoretic bounds showing non-gamifiability -- adversaries cannot improve through training due to fundamental space complexity constraints. This work demonstrates that semantic orbit analysis provides a scalable, theoretically grounded approach to AI control for code generation tasks.

</details>


### [44] [A First-Order Logic-Based Alternative to Reward Models in RLHF](https://arxiv.org/abs/2512.14100)
*Chunjin Jian,Xinhua Zhu*

Main category: cs.LG

TL;DR: 提出S-GRPO方法，用逻辑相似性奖励机制替代传统奖励建模，通过形式逻辑一致性引导模型对齐人类偏好，避免模型崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法依赖奖励模型的质量和稳定性，但传统奖励建模存在启发式估计的局限性。需要更稳定、逻辑一致的方法来对齐大语言模型与人类偏好。

Method: 提出逻辑相似性奖励机制，基于形式逻辑一致性而非启发式奖励估计。引入S-GRPO（GRPO的监督变体），结合监督组件，联合优化生成项、KL散度正则化和基于标签的目标。

Result: S-GRPO在性能和鲁棒性上均优于标准监督微调（SFT），并能扩展GRPO和DPO等现有偏好学习框架，提供更灵活、任务自适应的对齐训练方法。

Conclusion: 逻辑相似性奖励机制和S-GRPO框架为RLHF提供了更稳定、逻辑一致的对齐方法，能有效避免模型崩溃，提升对齐性能。

Abstract: Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.
  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.
  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.

</details>


### [45] [Understanding and Improving Hyperbolic Deep Reinforcement Learning](https://arxiv.org/abs/2512.14202)
*Timo Klein,Thomas Lang,Andrii Shkabrii,Alexander Sturm,Kevin Sidak,Lukas Miklautz,Claudia Plant,Yllka Velaj,Sebastian Tschiatschek*

Main category: cs.LG

TL;DR: 提出Hyper++，一种改进的双曲强化学习代理，通过稳定梯度训练、特征正则化和优化友好的网络层设计，解决双曲特征空间在RL中的优化挑战。


<details>
  <summary>Details</summary>
Motivation: 双曲特征空间能自然捕捉复杂RL环境中的层次和关系结构，但RL的非平稳性导致优化困难，现有方法存在梯度不稳定和训练失败问题。

Method: 分析Poincaré Ball和Hyperboloid模型中的梯度问题，提出Hyper++：1) 使用分类值损失稳定critic训练；2) 特征正则化保证有界范数；3) 优化友好的双曲网络层设计。

Result: 在ProcGen上保证稳定学习，优于先前双曲代理，减少约30%训练时间；在Atari-5上显著超越欧几里得和双曲基线方法。

Conclusion: 通过系统分析双曲RL的梯度问题并提出相应解决方案，Hyper++实现了稳定高效的双曲强化学习，为复杂环境中的层次结构表示提供了实用工具。

Abstract: The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincaré Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .

</details>


### [46] [Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes](https://arxiv.org/abs/2512.14617)
*Alessandro Trapasso,Luca Iocchi,Fabio Patrizi*

Main category: cs.LG

TL;DR: QR-MAX是首个针对非马尔可夫奖励决策过程(NMRDPs)的基于模型的强化学习算法，通过奖励机分解马尔可夫转移学习与非马尔可夫奖励处理，实现了多项式样本复杂度的PAC收敛保证，并在连续状态空间中扩展为Bucket-QR-MAX。


<details>
  <summary>Details</summary>
Motivation: 许多实际决策问题涉及依赖于整个系统历史的任务，而不仅仅是达到具有期望属性的状态。马尔可夫强化学习方法不适合此类任务，而非马尔可夫奖励决策过程(NMRDPs)虽然能处理时间依赖任务，但长期以来缺乏形式化保证（近最优性和样本效率）。

Method: 提出QR-MAX算法，通过奖励机将马尔可夫转移学习与非马尔可夫奖励处理进行分解，这是首个利用这种分解实现多项式样本复杂度PAC收敛的基于模型RL算法。然后扩展为Bucket-QR-MAX，使用SimHash-based离散化器处理连续状态空间，保持相同的分解结构。

Result: QR-MAX实现了ε-最优策略的PAC收敛，具有多项式样本复杂度。在复杂度递增的环境上与最先进的基于模型RL方法进行实验比较，显示出显著的样本效率提升和寻找最优策略的鲁棒性增强。

Conclusion: QR-MAX解决了NMRDPs中长期缺乏形式化保证的问题，通过分解方法实现了高效学习，并在连续状态空间中保持相同优势，为非马尔可夫任务的强化学习提供了理论保证和实践有效的解决方案。

Abstract: Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [47] [LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms](https://arxiv.org/abs/2512.13713)
*Ali Parsaee,Yashar Talebirad,Csongor Szepesvári,Vishwajeet Ohal,Eden Redman*

Main category: cs.AI

TL;DR: LoopBench是一个评估LLM在分布式对称性打破和元认知推理能力的基准，专注于奇数环图着色问题，展示了高级推理模型能够设计策略避免死锁。


<details>
  <summary>Details</summary>
Motivation: LLM越来越多地被用作自主代理，但它们在分布式系统中的协调能力仍未被充分理解。需要评估LLM在分布式对称性打破和元认知推理方面的能力。

Method: 引入LoopBench基准，专注于奇数环图（C3、C5、C11）的着色问题，使用有限颜色。实现策略传递机制作为一致内存形式，评估LLM在非通信代理环境下的表现。

Result: 标准LLM和经典启发式方法难以解决该问题，而高级推理模型（如O3）能够设计策略来避免死锁和无限循环。

Conclusion: LoopBench为研究基于语言推理的分布式算法提供了测试平台，有助于探索集体智能的涌现行为。

Abstract: Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infinite loops. A strategy passing mechanism is implemented as a form of consistent memory. We show that while standard LLMs and classical heuristics struggle, advanced reasoning models (e.g., O3) devise strategies to escape deadlocks. LoopBench allows the study of emergent distributed algorithms based on language-based reasoning, offering a testbed for collective intelligence.

</details>


### [48] [AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach](https://arxiv.org/abs/2512.13714)
*Gangesh Pathak,Prasanna Kumar*

Main category: cs.AI

TL;DR: 提出AI辅助标注流水线，通过人机协同方法识别、标注和修复LLM输出的不稳定性模式，以提升LLM在高度监管行业中的可靠性。


<details>
  <summary>Details</summary>
Motivation: LLM在高度监管行业应用受限，存在不稳定性、不一致推理、幻觉和性能波动等问题，现有稳定化方法（如RLHF和监督微调）成本高、依赖人工标注，难以规模化。

Method: 开发AI辅助标注流水线，结合自动弱监督和基于置信度的标注，辅以人工验证，引入语义一致性、事实正确性和逻辑连贯性等稳定性特定标注类别，通过反馈循环持续校准模型。

Result: 论文提出的人机协同方法能够系统识别和修复LLM不稳定性模式，确保反馈信息的可靠性和道德完整性，增强模型鲁棒性。

Conclusion: AI辅助标注流水线为LLM稳定性问题提供了可扩展的解决方案，通过人机协同实现持续模型校准，有望推动LLM在高度监管行业的可靠应用。

Abstract: LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior (Aiyappa et al., 2023). The current methods of stabilization, such as, reinforcement learning with human feedback (RLHF) and supervised fine-tuning, offer quantifiable improvements but are expensive and based on the intensive annotation of humans, thus being not easily scaled in a sustainable way (Dong et al., 2023; Retzlaff et al., 2024). This paper presents an AI-based annotation pipeline that systematically identifies, labels, and fixes for instability patterns on LLM output. Our human-AI synergy method combines the models of automated weak supervision and confidence-based annotation with the target human validation to guarantee the reliability and moral uprightness of feedback information (Cabitza et al., 2023; Jiang et al., 2023). The semantic consistency, factual correctness, and logical coherence categories of stability-specific annotation are introduced into our framework, allowing the continuous calibration of models and the enhancement of their robustness based on the feedback loops (Honovich et al., 2021; Nan et al., 2021).

</details>


### [49] [ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making](https://arxiv.org/abs/2512.13716)
*Yitong Luo,Ziang Chen,Hou Hei Lam,Jiayu zhan,Junqi Wang,Zhenliang Zhang,Xue Feng*

Main category: cs.AI

TL;DR: ValuePilot：一个两阶段框架，通过价值驱动的决策方法实现个性化AI代理，包含数据集生成工具包和决策模块，在未见场景中优于主流LLM基线。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统扩展到现实世界应用，适应超越任务完成或集体对齐的个性化价值偏好成为关键挑战。个性化决策对于人机交互至关重要，使AI代理能够与个体用户的价值偏好保持一致。

Method: 提出ValuePilot两阶段框架：1) 数据集生成工具包(DGT)：通过人-LLM协作流程构建多样化的价值标注场景；2) 决策模块(DMM)：学习基于个人价值偏好评估行动，实现上下文敏感的个性化决策。

Result: 在未见场景评估中，DMM在符合人类行动选择方面优于GPT-5、Claude-Sonnet-4、Gemini-2-flash和Llama-3.1-70b等强LLM基线。

Conclusion: 价值驱动的决策是构建可解释、个性化AI代理的有效且可扩展的工程路径，人类价值作为稳定、可转移的信号支持跨上下文的一致和可泛化行为。

Abstract: Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical challenge. We address this by proposing a value-driven approach to personalized decision-making. Human values serve as stable, transferable signals that support consistent and generalizable behavior across contexts. Compared to task-oriented paradigms driven by external rewards and incentives, value-driven decision-making enhances interpretability and enables agents to act appropriately even in novel scenarios. We introduce ValuePilot, a two-phase framework consisting of a dataset generation toolkit (DGT) and a decision-making module (DMM). DGT constructs diverse, value-annotated scenarios from a human-LLM collaborative pipeline. DMM learns to evaluate actions based on personal value preferences, enabling context-sensitive, individualized decisions. When evaluated on previously unseen scenarios, DMM outperforms strong LLM baselines, including GPT-5, Claude-Sonnet-4, Gemini-2-flash, and Llama-3.1-70b, in aligning with human action choices. Our results demonstrate that value-driven decision-making is an effective and extensible engineering pathway toward building interpretable, personalized AI agents.

</details>


### [50] [Seismology modeling agent: A smart assistant for geophysical researchers](https://arxiv.org/abs/2512.14429)
*Yukun Ren,Siwei Yu,Kai Chen,Jianwei Ma*

Main category: cs.AI

TL;DR: 提出基于大语言模型的智能交互工作流，用于简化SPECFEM地震波模拟软件的使用，通过MCP服务器将复杂操作分解为可执行的工具，实现从文件驱动到意图驱动的转变。


<details>
  <summary>Details</summary>
Motivation: 传统SPECFEM软件学习曲线陡峭，依赖复杂的手动文件编辑和命令行操作，需要简化工作流程并降低使用门槛。

Method: 开发首个SPECFEM的MCP服务器套件，将模拟过程分解为离散的、可由智能体执行的工具（参数生成、网格划分、求解器执行、可视化等），支持全自动执行和人机协作两种模式。

Result: 通过多个案例验证，工作流在自主和交互模式下都能无缝运行，产生与标准基准一致的高保真结果，显著降低了入门门槛并增强了可重复性。

Conclusion: 这是MCP技术在计算地震学中的首次应用，为计算地球物理学向AI辅助和自动化科学研究提供了有前景的途径。

Abstract: To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.

</details>


### [51] [Mathematics and Coding are Universal AI Benchmarks](https://arxiv.org/abs/2512.13764)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 该论文研究数学和编程在AI智能体心理测量测试空间中的特殊作用，证明数学定理证明和编程任务生成的测试子空间在评估度量下是稠密的，编码具有普遍性，而纯数学具有谱稳定性优势，为AI智能体递归自我改进提供了自然起点。


<details>
  <summary>Details</summary>
Motivation: 研究数学和编程在AI智能体评估中的特殊地位，探索它们如何作为"通用坐标"来评估AI能力，并理解正式数学为何能成为高级AI智能体递归自我改进的自然起点。

Method: 基于AAI框架和GVU动力学，定义数学纤维概念，结合形式证明核（如Lean、Coq），分析GVU流在数学纤维上的谱稳定性。主要技术结果是密度定理：在智能体输出均匀紧性和Lipschitz AAI泛函条件下，证明数学定理证明和编程任务生成的测试子空间在评估度量下是稠密的。

Result: 编码在表达性上具有普遍性，而纯数学虽然不具备普遍表达性，但在谱稳定性方面具有特权。数学纤维与形式证明核结合时，GVU流允许谱稳定的自我改进机制。数学和编程为AI智能体评估提供了"通用坐标"。

Conclusion: 数学和编程是评估AI智能体的关键维度，编码具有普遍表达性，而正式数学由于其谱稳定性特性，成为高级AI智能体递归自我改进的自然点火域。

Abstract: We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.

</details>


### [52] [EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery](https://arxiv.org/abs/2512.13857)
*Kamer Ali Yuksel*

Main category: cs.AI

TL;DR: EvoLattice 提出了一种基于有向无环图的进化框架，将候选程序或智能体行为表示为图中的节点，每个节点存储多个持久化备选方案，通过不同路径组合形成可执行候选，实现更稳定、表达能力更强的进化。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的程序和智能体进化方法大多采用覆盖式突变，只维护单个候选，会丢弃有用变体、遭受破坏性编辑，且搜索空间脆弱易出现结构故障。需要一种能保留成功组件、提供更稳定进化过程的方法。

Method: EvoLattice 使用有向无环图表示整个候选种群，每个节点存储多个持久化备选方案，每个有效路径定义一个可执行候选。通过跨路径评估每个备选方案，获得数据驱动的反馈信号，用于LLM引导的突变、重组和剪枝。包含确定性自修复机制保证结构正确性。

Result: 在程序合成（代理和优化器元学习）任务中，EvoLattice 相比现有LLM引导方法展现出更稳定的进化、更强的表达能力和更好的改进轨迹。其动态特性类似于质量-多样性优化，但这是从内部多备选表示中隐式涌现的。

Conclusion: EvoLattice 通过图结构的多备选表示，解决了传统LLM进化方法的局限性，实现了更鲁棒、表达能力更强的进化过程，并能自然扩展到智能体进化领域。

Abstract: Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle search space prone to structural failure. We introduce EvoLattice, a framework that represents an entire population of candidate programs or agent behaviors within a single directed acyclic graph. Each node stores multiple persistent alternatives, and every valid path through the graph defines a distinct executable candidate, yielding a large combinatorial search space without duplicating structure. EvoLattice enables fine-grained alternative-level evaluation by scoring each alternative across all paths in which it appears, producing statistics that reveal how local design choices affect global performance. These statistics provide a dense, data-driven feedback signal for LLM-guided mutation, recombination, and pruning, while preserving successful components. Structural correctness is guaranteed by a deterministic self-repair mechanism that enforces acyclicity and dependency consistency independently of the LLM. EvoLattice naturally extends to agent evolution by interpreting alternatives as prompt fragments or sub-agent behaviors. Across program synthesis (proxy and optimizer meta-learning), EvoLattice yields more stable evolution, greater expressivity, and stronger improvement trajectories than prior LLM-guided methods. The resulting dynamics resemble quality-diversity optimization, emerging implicitly from EvoLattice's internal multi-alternative representation rather than an explicit external archive.

</details>


### [53] [Evaluating Frontier LLMs on PhD-Level Mathematical Reasoning: A Benchmark on a Textbook in Theoretical Computer Science about Randomized Algorithms](https://arxiv.org/abs/2512.13978)
*Yang Cao,Yubin Chen,Xuyang Guo,Zhao Song,Song Yue,Jiahao Zhang,Jiale Zhao*

Main category: cs.AI

TL;DR: 论文提出了一个针对前沿LLM在研究生级随机算法课程上的基准测试，评估了GPT-5、Gemini-3-Pro、Claude-Sonnet-4.5和Grok-4四个模型在生成形式化LaTeX证明方面的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在数学推理和科学发现方面取得了显著进展，但缺乏对这些模型在经典研究生级数学理论上基准推理能力的严格评估。需要了解它们在严谨数学推导方面的可靠性和一致性。

Method: 使用Motwani和Raghavan的《随机算法》教材作为基准，要求四个前沿LLM（GPT-5-Thinking、Gemini-3-Pro、Claude-Sonnet-4.5-Thinking、Grok-4）为教材中的引理和练习生成形式化LaTeX证明，并进行定量和定性分析。

Result: 顶级模型（Gemini和Claude）达到约66%的准确率，表现出对概率方法和形式逻辑的良好掌握；其他模型的一致性显著较低（约40%）。分析揭示了在简洁性、幻觉率和逻辑结构方面的差异。

Conclusion: 前沿模型已达到适合研究生级教学辅助和形式化的熟练度阈值，但在严谨数学推导的可靠性方面存在显著差异。代码和LLM生成响应已开源。

Abstract: The rapid advancement of large language models (LLMs) has led to significant breakthroughs in automated mathematical reasoning and scientific discovery. Georgiev, G${ó}$mez-Serrano, Tao, and Wagner [GGSTW+25] demonstrate that AI systems can explore new constructions and improve existing bounds, illustrating the growing potential of LLMs to accelerate mathematical discovery. Similarly, Bubeck et al. [BCE+25] show that GPT-5 can meaningfully contribute to scientific workflows, from proposing hypotheses to generating proofs and analyses. Despite these advances, a rigorous evaluation of these models on canonical, graduate-level mathematical theory remains necessary to understand their baseline reasoning capabilities. In this paper, we present a comprehensive benchmark of four frontier models: GPT-5-Thinking, Gemini-3-Pro, Claude-Sonnet-4.5-Thinking, and Grok-4 against the classic curriculum of Randomized Algorithms by Motwani and Raghavan [MR95].
  We tasked each model with generating formal LaTeX proofs for a series of lemmas and exercises spanning the textbook. We find that while the top-tier models (Gemini, and Claude) achieve a high accuracy rate (approx. 66%), demonstrating a robust grasp of probabilistic method and formal logic, other models lag significantly in consistency (approx. 40%). We provide a qualitative analysis of the generated proofs, highlighting differences in conciseness, hallucination rates, and logical structure. Our results suggest that while frontier models have reached a threshold of proficiency suitable for graduate-level pedagogical assistance and formalization, significant variance exists in their reliability for rigorous mathematical derivation. The code and the full set of LLM-generated responses are open-sourced and publicly available at https://github.com/magiclinux/math_benchmark_probability.

</details>


### [54] [MobileWorldBench: Towards Semantic World Modeling For Mobile Agents](https://arxiv.org/abs/2512.14014)
*Shufan Li,Konstantinos Kallidromitis,Akash Gokul,Yusuke Kato,Kazuki Kozuka,Aditya Grover*

Main category: cs.AI

TL;DR: 提出MobileWorldBench基准测试和MobileWorld数据集，探索用于GUI代理的自然语言世界模型，通过语义而非像素预测来改进移动代理的任务成功率


<details>
  <summary>Details</summary>
Motivation: 现有像素空间世界模型在GUI环境中面临实际限制，预测复杂视觉元素困难，需要探索替代方案

Method: 1) 引入MobileWorldBench基准测试评估VLMs作为GUI代理世界模型的能力；2) 发布包含140万样本的MobileWorld数据集；3) 提出将VLM世界模型集成到移动代理规划框架的新框架

Result: 语义世界模型能直接提升移动代理的任务成功率，MobileWorld数据集显著改善了VLMs的世界建模能力

Conclusion: 自然语言世界模型是GUI代理的有效替代方案，能克服像素空间模型的限制，提升代理性能

Abstract: World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld

</details>


### [55] [Evaluating Small Language Models for Agentic On-Farm Decision Support Systems](https://arxiv.org/abs/2512.14043)
*Enhong Liu,Haiyu Yang,Miel Hostens*

Main category: cs.AI

TL;DR: 该研究评估了20个开源小语言模型在奶牛养殖决策支持中的可行性，开发了一个包含5个任务特定代理的AI系统，Qwen-4B在多数任务中表现最佳，但PySpark中的NoSQL交互仍不稳定。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型有潜力支持奶牛养殖决策，但其高计算需求限制了在农场环境中的实际应用。需要能够在农场硬件上本地运行的轻量级替代方案。

Method: 在农场现实的算力约束下，对HuggingFace上的20个开源小语言模型进行基准测试。开发了一个包含文献搜索、网络搜索、SQL数据库交互、NoSQL数据库交互和图生成五个任务特定代理的AI系统。评估分两阶段：第一阶段用5个测试问题进行初步筛选，第二阶段用30个问题（每个任务类别5个，加上诚信类别）进行详细评估。

Result: Qwen-4B在大多数任务类别中取得了最佳性能，但在通过PySpark进行NoSQL数据库交互时表现出不稳定的效果。这是首个明确评估小语言模型作为奶牛养殖决策引擎可行性的研究。

Conclusion: 小语言模型辅助工具在奶牛养殖实际部署中具有前景，但仍面临挑战，需要通过微调来提升在奶牛养殖特定问题上的性能。

Abstract: Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.

</details>


### [56] [Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation](https://arxiv.org/abs/2512.14048)
*Shen Li,Li Huang,Shaoxiong Zhan,Weifeng Sun,Tao Yin,Zhongxin Liu,Meng Yan*

Main category: cs.AI

TL;DR: RoutingGen：一个难度感知的路由框架，根据任务复杂度动态选择提示策略，简单任务用few-shot提示，复杂任务用Intention Chain-of-Thought（ICoT）进行结构化推理，在代码生成任务中实现SOTA性能并减少46.37%的token使用。


<details>
  <summary>Details</summary>
Motivation: 现有CoT提示方法存在两个主要局限：1）统一应用导致简单任务上过度思考；2）缺乏代码生成中的意图抽象（如核心算法设计和效率建模），使模型关注表面结构而忽视全局目标。受认知经济原则启发，需要仅在必要时进行结构化推理以节省认知资源。

Method: 提出RoutingGen框架：1）难度感知路由机制，动态评估任务复杂度；2）简单任务采用few-shot提示；3）复杂任务采用Intention Chain-of-Thought（ICoT），引导模型捕获任务意图（核心算法逻辑和时间复杂度等）。

Result: 在3个模型和6个标准代码生成基准测试中，RoutingGen在大多数设置下达到最先进性能，同时平均减少46.37%的token使用。ICoT在挑战性基准上优于6个现有提示基线。

Conclusion: RoutingGen通过难度感知路由和意图链式思维，有效解决了现有CoT方法的局限性，在保持高性能的同时显著提高了效率，为代码生成任务提供了更智能的提示策略。

Abstract: Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.

</details>


### [57] [Grammar Search for Multi-Agent Systems](https://arxiv.org/abs/2512.14079)
*Mayank Singh,Vikas Yadav,Shiva Krishna Reddy Malay,Shravan Nayak,Sai Rajeswar,Sathwik Tejaswi Madhusudhan,Eduardo Blanco*

Main category: cs.AI

TL;DR: 提出了一种基于固定可组合组件的结构化多智能体系统搜索框架，相比基于LLM的自由形式搜索，在数学和问答领域的五个基准测试中，有四个表现更优，且更经济、可解释。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统自动搜索主要依赖LLM进行代码空间的自由形式搜索，这种方法缺乏结构性和效率。作者希望开发一个更结构化、经济高效且可解释的搜索框架。

Method: 提出结构化框架，使用一组固定的简单可组合组件来探索多智能体系统空间，而不是依赖LLM的生成灵活性。通过组合这些组件来构建候选系统。

Result: 在数学和问答两个领域的五个基准测试中，该方法在四个测试上超越了先前基于LLM的方法。同时具有搜索成本更低、生成的多智能体系统更模块化、可解释、逻辑更简单的优势。

Conclusion: 结构化组件方法在多智能体系统搜索中比自由形式LLM搜索更有效，提供了性能、成本和可解释性方面的综合优势。

Abstract: Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple, composable components. We show that, despite lacking the generative flexibility of LLMs during the candidate generation stage, our method outperforms prior approaches on four out of five benchmarks across two domains: mathematics and question answering. Furthermore, our method offers additional advantages, including a more cost-efficient search process and the generation of modular, interpretable multi-agent systems with simpler logic.

</details>


### [58] [Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis](https://arxiv.org/abs/2512.14157)
*Yankai Jiang,Yujie Zhang,Peng Zhang,Yichen Li,Jintai Chen,Xiaoming Shi,Shihui Zhen*

Main category: cs.AI

TL;DR: Ophiuchus是一个工具增强的医学MLLM框架，通过动态聚焦细粒度视觉区域实现精确的医学图像诊断和推理。


<details>
  <summary>Details</summary>
Motivation: 现有的医学MLLM在生成文本推理链方面有进展，但在需要动态迭代聚焦细粒度视觉区域的复杂任务中仍存在困难，无法实现精确的定位和诊断。

Method: 采用三阶段训练策略：1)冷启动训练，使用工具集成的推理数据实现基本工具选择和关键区域检查；2)自反思微调，加强反思推理并鼓励重新审视工具输出；3)代理工具强化学习，直接优化任务特定奖励并模拟专家诊断行为。

Result: 在多种医学基准测试（包括VQA、检测和基于推理的分割）中，Ophiuchus持续优于闭源和开源的最先进方法。

Conclusion: 该方法为医学AI代理通过工具集成推理实现真正"用图像思考"开辟了道路。

Abstract: Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely "think with images" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.

</details>


### [59] [PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals](https://arxiv.org/abs/2512.14417)
*Jia Hu,Junqi Li,Weimeng Lin,Peng Jia,Yuxiong Ji,Jintao Lai*

Main category: cs.AI

TL;DR: PortAgent：基于大语言模型的车辆调度代理，通过虚拟专家团队自动化实现跨自动化集装箱码头的车辆调度系统迁移，无需港口运营专家、数据需求低、部署快速


<details>
  <summary>Details</summary>
Motivation: 自动化集装箱码头（ACT）的车辆调度系统（VDS）商业化应用面临跨码头可迁移性低的挑战，主要受限于对港口运营专家的高度依赖、对码头特定数据的高需求以及耗时的手动部署过程

Method: 提出PortAgent LLM驱动车辆调度代理，采用虚拟专家团队（VET）架构，包括知识检索器、建模器、编码器和调试器四个虚拟专家，通过few-shot示例学习和检索增强生成（RAG）机制获取VDS领域知识，并建立基于LLM Reflexion框架的自校正循环的自动化工作流

Result: PortAgent实现了车辆调度系统迁移工作流的完全自动化，消除了对港口运营专家的依赖，降低了对码头特定数据的需求，并实现了快速部署

Conclusion: PortAgent通过LLM驱动的虚拟专家团队方法，有效解决了自动化集装箱码头车辆调度系统的可迁移性问题，为VDS的商业化应用提供了可行的技术方案

Abstract: Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created

</details>


### [60] [Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling](https://arxiv.org/abs/2512.14474)
*Annu Rana,Gaurav Kumar*

Main category: cs.AI

TL;DR: 提出Model-First Reasoning (MFR)方法，让LLM先构建明确的问题模型（实体、状态变量、动作、约束），再生成解决方案，显著减少约束违反并提高规划质量。


<details>
  <summary>Details</summary>
Motivation: LLM在处理复杂多步规划任务时经常出现约束违反和不一致解决方案，现有方法如Chain-of-Thought和ReAct依赖隐式状态跟踪，缺乏明确的问题表示。

Method: 提出Model-First Reasoning (MFR)两阶段范式：1) LLM首先构建明确的问题模型，定义实体、状态变量、动作和约束；2) 基于该模型生成解决方案计划。

Result: 在医疗调度、路线规划、资源分配、逻辑谜题和程序合成等多个规划领域中，MFR相比Chain-of-Thought和ReAct减少了约束违反并提高了解决方案质量。

Conclusion: 许多LLM规划失败源于表示缺陷而非推理限制，明确建模是构建鲁棒和可解释AI代理的关键组件。

Abstract: Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.

</details>


### [61] [Universal Reasoning Model](https://arxiv.org/abs/2512.14693)
*Zitian Gao,Lynx Chen,Yihao Xiao,He Xing,Ran Tao,Haoming Luo,Joey Zhou,Bryan Dai*

Main category: cs.AI

TL;DR: 论文提出通用推理模型（URM），通过短卷积和截断反向传播增强通用Transformer，在ARC-AGI基准上取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 通用Transformer在复杂推理任务中表现出色，但其性能提升的具体来源尚不明确。本文旨在系统分析UT变体，揭示其性能提升的真正原因，并基于此设计更有效的推理模型。

Method: 首先系统分析通用Transformer变体，发现性能提升主要来自循环归纳偏置和Transformer的强非线性组件。基于此提出通用推理模型（URM），通过短卷积和截断反向传播来增强通用Transformer。

Result: 在ARC-AGI基准上取得显著提升：ARC-AGI 1达到53.8% pass@1，ARC-AGI 2达到16.0% pass@1，均达到最先进水平。

Conclusion: 通用Transformer在复杂推理任务中的性能提升主要源于循环归纳偏置和强非线性组件，而非复杂的架构设计。提出的URM模型通过简单有效的改进实现了SOTA性能。

Abstract: Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.

</details>


### [62] [IPR-1: Interactive Physical Reasoner](https://arxiv.org/abs/2511.15407)
*Mingyu Zhang,Lifeng Zhuo,Tianxi Tan,Guocan Xie,Xian Nie,Yan Li,Renjie Zhao,Zizhu He,Ziyu Wang,Jiting Cai,Yong-Lu Li*

Main category: cs.AI

TL;DR: 提出IPR（交互式物理推理器），通过世界模型推演来评估和强化VLM策略，引入PhysCode物理中心动作编码，在1000+游戏中预训练，实现从直觉到目标驱动的物理推理，性能超越GPT-5。


<details>
  <summary>Details</summary>
Motivation: 人类通过观察、交互和环境互动来学习物理和因果关系。研究智能体是否也能通过类似方式获得类人推理能力，并在更多经验中持续改进。现有方法（VLMs和世界模型）难以捕捉底层物理和因果关系，因为它们过度关注视觉细节而非核心机制。

Method: 提出IPR（交互式物理推理器），使用世界模型推演来评分和强化VLM的策略。引入PhysCode物理中心动作编码，将语义意图与动力学对齐，为预测和推理提供共享动作空间。在1000+异质游戏上进行预训练。

Result: IPR在从原始直觉到目标驱动推理的各种关卡中表现稳健，整体性能甚至超越GPT-5。性能随着训练游戏数量和交互步数的增加而提升，并能零样本迁移到未见过的游戏。

Conclusion: 物理中心的交互是实现持续改进物理推理能力的有效途径。模型通过大量游戏交互学习到了可泛化的物理推理能力。

Abstract: Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. To study this, we introduce a Game-to-Unseen (G2U) benchmark of 1,000+ heterogeneous games that exhibit significant visual domain gaps. Existing approaches, including VLMs and world models, struggle to capture underlying physics and causality since they are not focused on core mechanisms and overfit to visual details. VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on levels from primitive intuition to goal-driven reasoning, and even surpasses GPT-5 overall. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning. Further demos and project details can be found at https://mybearyzhang.github.io/ipr-1.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [63] [Verification-Guided Context Optimization for Tool Calling via Hierarchical LLMs-as-Editors](https://arxiv.org/abs/2512.13860)
*Henger Li,Shuangjie You,Flavio Di Palo,Yiyue Qian,Ayush Jain*

Main category: cs.SE

TL;DR: VGCO框架使用LLM作为编辑器自动优化工具文档和知识库上下文，通过评估和优化两阶段解决工具调用中的文档与LLM理解不匹配问题，显著提升准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前工具调用依赖的文档和知识库上下文通常为人类用户设计，与LLM的信息处理方式不匹配，特别是在工业环境中存在大量功能重叠的工具，导致可扩展性、可变性和模糊性挑战。

Method: 提出验证引导的上下文优化框架VGCO，包含两个阶段：评估阶段收集真实失败案例并识别工具与上下文的不匹配；优化阶段通过离线学习进行分层编辑，采用结构感知的上下文内优化。LLM编辑器具有分层结构、状态感知、动作特定和验证引导的特点。

Result: VGCO在单轮大规模工具调用问题上显著提高了准确性、鲁棒性和泛化能力，相比之前强调多轮推理的工作有显著改进。

Conclusion: VGCO框架通过自动优化工具相关文档和知识库上下文，有效解决了LLM工具调用中的文档不匹配问题，为工业环境中的大规模工具调用提供了实用解决方案。

Abstract: Tool calling enables large language models (LLMs) to interact with external environments through tool invocation, providing a practical way to overcome the limitations of pretraining. However, the effectiveness of tool use depends heavily on the quality of the associated documentation and knowledge base context. These materials are usually written for human users and are often misaligned with how LLMs interpret information. This problem is even more pronounced in industrial settings, where hundreds of tools with overlapping functionality create challenges in scalability, variability, and ambiguity. We propose Verification-Guided Context Optimization (VGCO), a framework that uses LLMs as editors to automatically refine tool-related documentation and knowledge base context. VGCO works in two stages. First, Evaluation collects real-world failure cases and identifies mismatches between tools and their context. Second, Optimization performs hierarchical editing through offline learning with structure-aware, in-context optimization. The novelty of our LLM editors has three main aspects. First, they use a hierarchical structure that naturally integrates into the tool-calling workflow. Second, they are state-aware, action-specific, and verification-guided, which constrains the search space and enables efficient, targeted improvements. Third, they enable cost-efficient sub-task specialization, either by prompt engineering large editor models or by post-training smaller editor models. Unlike prior work that emphasizes multi-turn reasoning, VGCO focuses on the single-turn, large-scale tool-calling problem and achieves significant improvements in accuracy, robustness, and generalization across LLMs.

</details>


### [64] [Context Branching for LLM Conversations: A Version Control Approach to Exploratory Programming](https://arxiv.org/abs/2512.13914)
*Bhargav Chickmagalur Nanjundappa,Spandan Maaheshwari*

Main category: cs.SE

TL;DR: ContextBranch是一个对话管理系统，将版本控制语义应用于LLM交互，通过检查点、分支、切换和注入四个核心原语，解决多轮对话中性能下降和上下文污染问题。


<details>
  <summary>Details</summary>
Motivation: LLM在多轮对话中性能显著下降（平均下降39%），特别是在探索性编程任务中，用户需要在不同方法间切换而不丢失上下文。现有解决方案要么继续被污染的对话，要么重新开始丢失所有积累的上下文。

Method: 提出ContextBranch系统，引入四个核心原语：checkpoint（检查点）捕获对话状态，branch（分支）在隔离环境中探索替代方案，switch（切换）在不同分支间移动，inject（注入）选择性合并见解。

Result: 在30个软件工程场景的实验中，分支对话相比线性对话获得更高质量响应，在涉及概念上遥远探索的复杂场景中改进最大。分支将上下文大小减少58.1%（从31.0条消息减少到13.0条），消除了不相关的探索内容。

Conclusion: 对话分支是AI辅助探索性工作的基本原语，隔离机制在探索替代方案时能有效防止上下文污染。

Abstract: Large Language Models (LLMs) have become integral to software engineering workflows, yet their effectiveness degrades significantly in multi-turn conversations. Recent studies demonstrate an average 39% performance drop when instructions are delivered across multiple turns, with models making premature assumptions and failing to course correct (Laban et al., 2025). This degradation is particularly problematic in exploratory programming tasks where developers need to investigate alternative approaches without committing to a single path. Current solutions force users into a false dichotomy: continue in a context-polluted conversation where the LLM becomes increasingly confused, or start fresh and lose all accumulated context.
  We present ContextBranch, a conversation management system that applies version control semantics to LLM interactions. ContextBranch provides four core primitives--checkpoint, branch, switch, and inject--enabling users to capture conversation state, explore alternatives in isolation, and selectively merge insights. We evaluate ContextBranch through a controlled experiment with 30 software engineering scenarios featuring intentionally polluting explorations. Branched conversations achieved higher response quality compared to linear conversations, with large improvements in focus and context awareness. Benefits were concentrated in complex scenarios involving conceptually distant explorations. Branching reduced context size by 58.1% (31.0 to 13.0 messages), eliminating irrelevant exploratory content. Our work establishes conversation branching as a fundamental primitive for AI-assisted exploratory work, demonstrating that isolation prevents context pollution when exploring alternatives.

</details>


### [65] [Professional Software Developers Don't Vibe, They Control: AI Agent Use for Coding in 2025](https://arxiv.org/abs/2512.14012)
*Ruanqianqian Huang,Avery Reyna,Sorin Lerner,Haijun Xia,Brian Hempel*

Main category: cs.SE

TL;DR: 经验开发者将AI代理视为生产力工具，但保持对软件设计和实现的控制权，通过专业知识指导代理行为，整体对代理持积极态度。


<details>
  <summary>Details</summary>
Motivation: 研究AI代理在专业软件开发中的实际角色，了解经验开发者如何使用代理、他们的动机、策略、任务适用性和情感态度。

Method: 通过实地观察（N=13）和定性调查（N=99）收集数据，分析经验开发者使用AI代理的模式和策略。

Result: 经验开发者重视代理作为生产力提升工具，但坚持对软件设计和实现的控制，以确保软件质量；他们利用专业知识指导代理行为，对代理融入软件开发持积极态度。

Conclusion: 软件开发最佳实践对有效使用代理至关重要，研究指出了代理适用的任务类型，并建议未来改进代理界面和使用指南。

Abstract: The rise of AI agents is transforming how software can be built. The promise of agents is that developers might write code quicker, delegate multiple tasks to different agents, and even write a full piece of software purely out of natural language. In reality, what roles agents play in professional software development remains in question. This paper investigates how experienced developers use agents in building software, including their motivations, strategies, task suitability, and sentiments. Through field observations (N=13) and qualitative surveys (N=99), we find that while experienced developers value agents as a productivity boost, they retain their agency in software design and implementation out of insistence on fundamental software quality attributes, employing strategies for controlling agent behavior leveraging their expertise. In addition, experienced developers feel overall positive about incorporating agents into software development given their confidence in complementing the agents' limitations. Our results shed light on the value of software development best practices in effective use of agents, suggest the kinds of tasks for which agents may be suitable, and point towards future opportunities for better agentic interfaces and agentic use guidelines.

</details>


### [66] [PerfCoder: Large Language Models for Interpretable Code Performance Optimization](https://arxiv.org/abs/2512.14018)
*Jiuding Yang,Shengyao Lu,Hongxuan Liu,Shayan Shirahmad Gale Bagi,Zahra Fazel,Tomasz Czajkowski,Di Niu*

Main category: cs.SE

TL;DR: PerfCoder是一个专门用于生成高性能代码的LLM家族，通过可解释的定制化优化来提升代码性能，超越了现有模型在运行时加速和优化率方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在自动代码生成方面取得了显著进展，但在生成高性能代码方面仍有局限。这不仅是由于数据稀缺，更重要的是缺乏指导可解释和有效性能改进的监督。

Method: PerfCoder通过以下方法构建：1）在带有人类可读注释的真实世界优化轨迹上进行微调；2）使用运行时测量进行强化微调以实现偏好对齐；3）能够提出输入特定的改进策略并直接应用，无需依赖迭代优化。

Result: 在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面超越了所有现有模型。此外，当PerfCoder的可解释反馈作为输入提供给更大LLM时，在规划者-优化器协作工作流中，能够将32B模型和GPT-5的性能提升到新水平。

Conclusion: 性能优化不能仅通过规模扩展实现，而需要优化策略意识。PerfCoder展示了通过专门设计的监督和强化微调，LLM能够生成高性能代码并提供可解释的优化反馈。

Abstract: Large language models (LLMs) have achieved remarkable progress in automatic code generation, yet their ability to produce high-performance code remains limited--a critical requirement in real-world software systems. We argue that current LLMs struggle not only due to data scarcity but, more importantly, because they lack supervision that guides interpretable and effective performance improvements. In this work, we introduce PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code from source code via interpretable, customized optimizations. PerfCoder is fine-tuned on a curated collection of real-world optimization trajectories with human-readable annotations, and preference-aligned by reinforcement fine-tuning using runtime measurements, enabling it to propose input-specific improvement strategies and apply them directly without relying on iterative refinement. On the PIE code performance benchmark, PerfCoder surpasses all existing models in both runtime speedup and effective optimization rate, demonstrating that performance optimization cannot be achieved by scale alone but requires optimization stratetgy awareness. In addition, PerfCoder can generate interpretable feedback about the source code, which, when provided as input to a larger LLM in a planner-and-optimizer cooperative workflow, can further improve outcomes. Specifically, we elevate the performance of 32B models and GPT-5 to new levels on code optimization, substantially surpassing their original performance.

</details>


### [67] [Reconsidering Conversational Norms in LLM Chatbots for Sustainable AI](https://arxiv.org/abs/2512.14673)
*Ronnie de Souza Santos,Cleyton Magalhães,Italo Santos*

Main category: cs.SE

TL;DR: 本文指出LLM聊天机器人的用户交互行为是影响系统环境可持续性的关键但被忽视的因素，提出了四个维度：扩展对话模式增加计算成本、即时响应期望限制节能调度、用户习惯累积需求、上下文积累降低效率。


<details>
  <summary>Details</summary>
Motivation: 现有关于LLM系统可持续性的研究主要关注模型架构、硬件效率和部署基础设施，但忽视了用户交互实践本身如何塑造系统的能源消耗特征。本文认为交互层面的行为是影响LLM系统环境影响的一个未被充分研究的因素。

Method: 这是一篇愿景论文，通过理论分析和概念框架，从四个维度探讨用户交互行为如何影响LLM系统的环境可持续性：1) 扩展对话模式增加token生成和推理计算成本；2) 即时响应期望限制能源感知调度和工作负载整合机会；3) 日常用户习惯累积操作需求；4) 上下文积累影响内存需求和长对话效率。

Result: 论文提出了用户交互行为是LLM系统环境可持续性的重要但被忽视的影响因素，并系统性地识别了四个关键维度。这些发现表明需要重新思考聊天机器人交互的设计和概念化方式。

Conclusion: 解决这些挑战需要重新设计聊天机器人交互，并采用新的视角，认识到可持续性部分取决于用户与LLM系统交互的对话规范。需要将可持续性考虑纳入交互设计层面。

Abstract: LLM based chatbots have become central interfaces in technical, educational, and analytical domains, supporting tasks such as code reasoning, problem solving, and information exploration. As these systems scale, sustainability concerns have intensified, with most assessments focusing on model architecture, hardware efficiency, and deployment infrastructure. However, existing mitigation efforts largely overlook how user interaction practices themselves shape the energy profile of LLM based systems. In this vision paper, we argue that interaction level behavior appears to be an underexamined factor shaping the environmental impact of LLM based systems, and we present this issue across four dimensions. First, extended conversational patterns increase token production and raise the computational cost of inference. Second, expectations of instant responses limit opportunities for energy aware scheduling and workload consolidation. Third, everyday user habits contribute to cumulative operational demand in ways that are rarely quantified. Fourth, the accumulation of context affects memory requirements and reduces the efficiency of long running dialogues. Addressing these challenges requires rethinking how chatbot interactions are designed and conceptualized, and adopting perspectives that recognize sustainability as partly dependent on the conversational norms through which users engage with LLM based systems.

</details>
