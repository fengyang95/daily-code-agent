{"id": "2512.14766", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14766", "abs": "https://arxiv.org/abs/2512.14766", "authors": ["Dongzhuoran Zhou", "Yuqicheng Zhu", "Xiaxia Wang", "Hongkuan Zhou", "Jiaoyan Chen", "Steffen Staab", "Yuan He", "Evgeny Kharlamov"], "title": "GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge", "comment": null, "summary": "Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from existing facts. We bridge this gap by proposing a methodology for constructing benchmarks under KG incompleteness, which removes direct supporting triples while ensuring that alternative reasoning paths required to infer the answer remain. Experiments on benchmarks constructed using our methodology show that existing methods suffer consistent performance degradation under incompleteness, highlighting their limited reasoning ability. To overcome this limitation, we present the Adaptive Graph Reasoning Agent (GR-Agent). It first constructs an interactive environment from the KG, and then formalizes KGQA as agent environment interaction within this environment. GR-Agent operates over an action space comprising graph reasoning tools and maintains a memory of potential supporting reasoning evidence, including relevant relations and reasoning paths. Extensive experiments demonstrate that GR-Agent outperforms non-training baselines and performs comparably to training-based methods under both complete and incomplete settings.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u77e5\u8bc6\u56fe\u8c31\u4e0d\u5b8c\u6574\u60c5\u51b5\u4e0b\u6784\u5efa\u57fa\u51c6\u6d4b\u8bd5\u7684\u65b9\u6cd5\u8bba\uff0c\u5e76\u5f00\u53d1\u4e86\u81ea\u9002\u5e94\u56fe\u63a8\u7406\u667a\u80fd\u4f53\uff08GR-Agent\uff09\u6765\u89e3\u51b3\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u4e0a\u7684\u95ee\u7b54\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u5927\u591a\u5047\u8bbe\u77e5\u8bc6\u56fe\u8c31\u662f\u5b8c\u6574\u7684\uff0c\u8fd9\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u77e5\u8bc6\u56fe\u8c31\u901a\u5e38\u4e0d\u5b8c\u6574\u7684\u4e8b\u5b9e\u3002\u5f53\u76f4\u63a5\u652f\u6301\u4e09\u5143\u7ec4\u7f3a\u5931\u65f6\uff0c\u9700\u8981\u4ece\u73b0\u6709\u4e8b\u5b9e\u4e2d\u63a8\u7406\u7b54\u6848\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u7684\u63a8\u7406\u80fd\u529b\u6709\u9650\u3002", "method": "1) \u63d0\u51fa\u6784\u5efa\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u57fa\u51c6\u6d4b\u8bd5\u7684\u65b9\u6cd5\u8bba\uff0c\u79fb\u9664\u76f4\u63a5\u652f\u6301\u4e09\u5143\u7ec4\u4f46\u4fdd\u7559\u66ff\u4ee3\u63a8\u7406\u8def\u5f84\uff1b2) \u5f00\u53d1\u81ea\u9002\u5e94\u56fe\u63a8\u7406\u667a\u80fd\u4f53\uff08GR-Agent\uff09\uff0c\u5c06\u77e5\u8bc6\u56fe\u8c31\u6784\u5efa\u4e3a\u4ea4\u4e92\u73af\u5883\uff0c\u5c06\u95ee\u7b54\u5f62\u5f0f\u5316\u4e3a\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u4f7f\u7528\u56fe\u63a8\u7406\u5de5\u5177\u4f5c\u4e3a\u52a8\u4f5c\u7a7a\u95f4\uff0c\u5e76\u7ef4\u62a4\u6f5c\u5728\u652f\u6301\u63a8\u7406\u8bc1\u636e\u7684\u8bb0\u5fc6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u4e0b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u800cGR-Agent\u5728\u5b8c\u6574\u548c\u4e0d\u5b8c\u6574\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u975e\u8bad\u7ec3\u57fa\u7ebf\uff0c\u4e0e\u57fa\u4e8e\u8bad\u7ec3\u7684\u65b9\u6cd5\u6027\u80fd\u76f8\u5f53\u3002", "conclusion": "\u8bba\u6587\u5f3a\u8c03\u4e86\u8bc4\u4f30\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u7cfb\u7edf\u5728\u4e0d\u5b8c\u6574\u77e5\u8bc6\u56fe\u8c31\u4e0b\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u7684GR-Agent\u5c55\u793a\u4e86\u901a\u8fc7\u667a\u80fd\u4f53\u6846\u67b6\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u6027\u3002", "topic": "agent analysis"}}
{"id": "2512.14754", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14754", "abs": "https://arxiv.org/abs/2512.14754", "authors": ["Jianshuo Dong", "Yutong Zhang", "Yan Liu", "Zhenyu Zhong", "Tao Wei", "Chao Zhang", "Han Qiu"], "title": "Revisiting the Reliability of Language Models in Instruction-Following", "comment": "Preprint", "summary": "Advanced LLMs have achieved near-ceiling instruction-following accuracy on benchmarks such as IFEval. However, these impressive scores do not necessarily translate to reliable services in real-world use, where users often vary their phrasing, contextual framing, and task formulations. In this paper, we study nuance-oriented reliability: whether models exhibit consistent competence across cousin prompts that convey analogous user intents but with subtle nuances. To quantify this, we introduce a new metric, reliable@k, and develop an automated pipeline that generates high-quality cousin prompts via data augmentation. Building upon this, we construct IFEval++ for systematic evaluation. Across 20 proprietary and 26 open-source LLMs, we find that current models exhibit substantial insufficiency in nuance-oriented reliability -- their performance can drop by up to 61.8% with nuanced prompt modifications. What's more, we characterize it and explore three potential improvement recipes. Our findings highlight nuance-oriented reliability as a crucial yet underexplored next step toward more dependable and trustworthy LLM behavior. Our code and benchmark are accessible: https://github.com/jianshuod/IFEval-pp.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLM\u5728\u7ec6\u5fae\u5dee\u522b\u5bfc\u5411\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u53d1\u73b0\u5373\u4f7f\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u9762\u5bf9\u8868\u8fbe\u76f8\u540c\u610f\u56fe\u4f46\u63aa\u8f9e\u7565\u6709\u4e0d\u540c\u7684\"cousin prompts\"\u65f6\uff0c\u6027\u80fd\u53ef\u80fd\u5927\u5e45\u4e0b\u964d\u8fbe61.8%\u3002", "motivation": "\u5c3d\u7ba1\u5148\u8fdbLLM\u5728IFEval\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u63a5\u8fd1\u5929\u82b1\u677f\u7684\u6307\u4ee4\u8ddf\u968f\u51c6\u786e\u7387\uff0c\u4f46\u8fd9\u4e9b\u9ad8\u5206\u4e0d\u4e00\u5b9a\u80fd\u8f6c\u5316\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u53ef\u9760\u670d\u52a1\uff0c\u56e0\u4e3a\u7528\u6237\u7ecf\u5e38\u53d8\u5316\u63aa\u8f9e\u3001\u4e0a\u4e0b\u6587\u6846\u67b6\u548c\u4efb\u52a1\u8868\u8ff0\u65b9\u5f0f\u3002", "method": "\u5f15\u5165\u65b0\u7684\u53ef\u9760\u5ea6\u6307\u6807reliable@k\uff0c\u5f00\u53d1\u81ea\u52a8\u5316\u6d41\u6c34\u7ebf\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u751f\u6210\u9ad8\u8d28\u91cf\u7684cousin prompts\uff0c\u6784\u5efaIFEval++\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u4e8620\u4e2a\u4e13\u6709\u548c26\u4e2a\u5f00\u6e90LLM\u3002", "result": "\u5f53\u524d\u6a21\u578b\u5728\u7ec6\u5fae\u5dee\u522b\u5bfc\u5411\u7684\u53ef\u9760\u6027\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u4e0d\u8db3\uff0c\u6027\u80fd\u53ef\u80fd\u56e0\u7ec6\u5fae\u7684\u63d0\u793a\u4fee\u6539\u800c\u4e0b\u964d\u9ad8\u8fbe61.8%\u3002\u8bba\u6587\u8fd8\u63cf\u8ff0\u4e86\u8fd9\u4e00\u73b0\u8c61\u5e76\u63a2\u7d22\u4e86\u4e09\u79cd\u6f5c\u5728\u7684\u6539\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u7ec6\u5fae\u5dee\u522b\u5bfc\u5411\u7684\u53ef\u9760\u6027\u662f\u5b9e\u73b0\u66f4\u53ef\u9760\u3001\u66f4\u53ef\u4fe1LLM\u884c\u4e3a\u7684\u5173\u952e\u4f46\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u7684\u4e0b\u4e00\u6b65\uff0c\u8bba\u6587\u7684\u4ee3\u7801\u548c\u57fa\u51c6\u6d4b\u8bd5\u5df2\u5f00\u6e90\u3002", "topic": "agent analysis"}}
{"id": "2512.14792", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.14792", "abs": "https://arxiv.org/abs/2512.14792", "authors": ["Roman Nekrasov", "Stefano Fossati", "Indika Kumara", "Damian Andrew Tamburri", "Willem-Jan van den Heuvel"], "title": "IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection", "comment": "Submitted to ACM", "summary": "Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a \"Correctness-Congruence Gap\" where LLMs can become proficient \"coders\" but remain limited \"architects\" in fulfilling nuanced user intent.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7ed3\u6784\u5316\u914d\u7f6e\u77e5\u8bc6\u6ce8\u5165\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u751f\u6210\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\uff08IaC\uff09\u7684\u6b63\u786e\u7387\uff0c\u4ece\u57fa\u7ebf27.1%\u63d0\u5347\u81f362.6%\uff0c\u4f46\u53d1\u73b0LLM\u5728\u610f\u56fe\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u74f6\u9888\uff0c\u5f62\u6210\u4e86\"\u6b63\u786e\u6027-\u4e00\u81f4\u6027\u5dee\u8ddd\"\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u6b63\u786e\u4e14\u610f\u56fe\u5bf9\u9f50\u7684\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\uff08\u7279\u522b\u662fTerraform\uff09\u65b9\u9762\u6210\u529f\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u63d0\u5347LLM\u7684IaC\u751f\u6210\u80fd\u529b\u3002", "method": "1) \u589e\u5f3aIaC-Eval\u57fa\u51c6\u6d4b\u8bd5\uff0c\u52a0\u5165\u4e91\u4eff\u771f\u548c\u81ea\u52a8\u5316\u9519\u8bef\u5206\u6790\uff1b2) \u5f00\u53d1LLM\u8f85\u52a9IaC\u4ee3\u7801\u751f\u6210\u7684\u9519\u8bef\u5206\u7c7b\u6cd5\uff1b3) \u5b9e\u73b0\u4ece\u6734\u7d20\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5230\u66f4\u590d\u6742\u7684\u56feRAG\u65b9\u6cd5\u7684\u77e5\u8bc6\u6ce8\u5165\u6280\u672f\uff0c\u5305\u62ec\u56fe\u7ec4\u4ef6\u7684\u8bed\u4e49\u4e30\u5bcc\u5316\u548c\u8d44\u6e90\u95f4\u4f9d\u8d56\u5173\u7cfb\u5efa\u6a21\u3002", "result": "\u57fa\u7ebfLLM\u6027\u80fd\u8f83\u5dee\uff08\u603b\u4f53\u6210\u529f\u738727.1%\uff09\uff0c\u6ce8\u5165\u7ed3\u6784\u5316\u914d\u7f6e\u77e5\u8bc6\u540e\uff0c\u6280\u672f\u9a8c\u8bc1\u6210\u529f\u7387\u63d0\u5347\u81f375.3%\uff0c\u603b\u4f53\u6210\u529f\u7387\u63d0\u5347\u81f362.6%\u3002\u4f46\u610f\u56fe\u5bf9\u9f50\u65b9\u9762\u51fa\u73b0\u5e73\u53f0\u671f\uff0c\u63ed\u793a\u4e86\"\u6b63\u786e\u6027-\u4e00\u81f4\u6027\u5dee\u8ddd\"\u3002", "conclusion": "\u7ed3\u6784\u5316\u77e5\u8bc6\u6ce8\u5165\u80fd\u663e\u8457\u63d0\u5347LLM\u751f\u6210IaC\u7684\u6280\u672f\u6b63\u786e\u6027\uff0c\u4f46LLM\u5728\u7406\u89e3\u590d\u6742\u7528\u6237\u610f\u56fe\u65b9\u9762\u4ecd\u6709\u5c40\u9650\uff0c\u53ef\u80fd\u6210\u4e3a\u719f\u7ec3\u7684\"\u7f16\u7801\u8005\"\u4f46\u4ecd\u662f\u6709\u9650\u7684\"\u67b6\u6784\u5e08\"\u3002", "topic": "code agent"}}
{"id": "2512.14910", "categories": ["cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.14910", "abs": "https://arxiv.org/abs/2512.14910", "authors": ["Nadine Angela Cantonjos", "Arpita Biswas"], "title": "AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally", "comment": null, "summary": "Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.", "AI": {"tldr": "AgroAskAI\u662f\u4e00\u4e2a\u7528\u4e8e\u519c\u4e1a\u6c14\u5019\u9002\u5e94\u51b3\u7b56\u652f\u6301\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7cfb\u7edf\uff0c\u91c7\u7528\u6a21\u5757\u5316\u89d2\u8272\u4e13\u4e1a\u5316\u67b6\u6784\uff0c\u901a\u8fc7\u8d23\u4efb\u94fe\u65b9\u6cd5\u534f\u8c03\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u96c6\u6210\u5b9e\u65f6\u5de5\u5177\u548c\u6570\u636e\u96c6\uff0c\u652f\u6301\u591a\u8bed\u8a00\u4ea4\u4e92\uff0c\u4e3a\u8106\u5f31\u519c\u6751\u793e\u533a\u63d0\u4f9b\u53ef\u64cd\u4f5c\u3001\u63a5\u5730\u6c14\u4e14\u5305\u5bb9\u6027\u7684\u6c14\u5019\u9002\u5e94\u7b56\u7565\u3002", "motivation": "\u519c\u6751\u519c\u4e1a\u5730\u533a\u9762\u4e34\u5e72\u65f1\u3001\u5f3a\u964d\u96e8\u548c\u5929\u6c14\u6a21\u5f0f\u53d8\u5316\u7b49\u6c14\u5019\u76f8\u5173\u98ce\u9669\u7684\u635f\u5bb3\u3002\u73b0\u6709\u7814\u7a76\u547c\u5401\u9002\u5e94\u6027\u98ce\u9669\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u548c\u51b3\u7b56\u7b56\u7565\u3002\u867d\u7136\u8fc7\u53bb\u7cfb\u7edf\u4f9d\u8d56\u5355\u667a\u80fd\u4f53\u6a21\u578b\u6216\u4ec5\u5c06\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7528\u4e8e\u9759\u6001\u529f\u80fd\uff0c\u4f46\u9700\u8981\u652f\u6301\u52a8\u6001\u534f\u4f5c\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u8f93\u51fa\u7684\u67b6\u6784\u3002", "method": "\u63d0\u51faAgroAskAI\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7cfb\u7edf\uff0c\u91c7\u7528\u6a21\u5757\u5316\u3001\u89d2\u8272\u4e13\u4e1a\u5316\u7684\u67b6\u6784\uff0c\u4f7f\u7528\u8d23\u4efb\u94fe\u65b9\u6cd5\u534f\u8c03\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u96c6\u6210\u5b9e\u65f6\u5de5\u5177\u548c\u6570\u636e\u96c6\u3002\u7cfb\u7edf\u5185\u7f6e\u6cbb\u7406\u673a\u5236\u51cf\u8f7b\u5e7b\u89c9\uff0c\u652f\u6301\u5185\u90e8\u53cd\u9988\u4ee5\u4ea7\u751f\u8fde\u8d2f\u3001\u672c\u5730\u76f8\u5173\u7684\u7b56\u7565\uff0c\u5e76\u652f\u6301\u591a\u8bed\u8a00\u4ea4\u4e92\u3002", "result": "\u5728\u5e38\u89c1\u519c\u4e1a\u6c14\u5019\u9002\u5e94\u67e5\u8be2\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u989d\u5916\u5de5\u5177\u548c\u63d0\u793a\u4f18\u5316\uff0cAgroAskAI\u80fd\u591f\u63d0\u4f9b\u66f4\u53ef\u64cd\u4f5c\u3001\u63a5\u5730\u6c14\u548c\u5305\u5bb9\u6027\u7684\u8f93\u51fa\u3002\u5b9e\u9a8c\u7ed3\u679c\u7a81\u663e\u4e86\u667a\u80fd\u4f53AI\u5728\u519c\u4e1a\u6c14\u5019\u9002\u5e94\u4e2d\u53ef\u6301\u7eed\u548c\u8d1f\u8d23\u4efb\u51b3\u7b56\u652f\u6301\u7684\u6f5c\u529b\u3002", "conclusion": "AgroAskAI\u5c55\u793a\u4e86\u667a\u80fd\u4f53AI\u5728\u519c\u4e1a\u6c14\u5019\u9002\u5e94\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3a\u8106\u5f31\u519c\u6751\u793e\u533a\u63d0\u4f9b\u52a8\u6001\u534f\u4f5c\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u53ef\u6301\u7eed\u548c\u8d1f\u8d23\u4efb\u7684\u519c\u4e1a\u5b9e\u8df5\u3002", "topic": "agent analysis"}}
{"id": "2512.14762", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14762", "abs": "https://arxiv.org/abs/2512.14762", "authors": ["Henry Gray", "Tom Yotam", "Octavian Udrea"], "title": "Workflows vs Agents for Code Translation", "comment": null, "summary": "Translating algorithms from high-level languages like MATLAB to hardware description languages (HDLs) is a resource-intensive but necessary step for deployment on FPGAs and ASICs. While large language models (LLMs) offer a path to automation, their limited training on HDL code makes end-to-end transpilation brittle and prone to syntax errors. We compare two LLM-driven methods for syntax repair in a MATLAB-to-HDL pipeline: a structured, expert-designed flow that follows a fixed sequence of operations, and a more autonomous agentic approach that uses the Model Context Protocol (MCP) \\cite{anthropic2024mcp} to dynamically select its own tools. We study 42 MATLAB signal-processing functions and isolate the syntax-repair stage. Across three model scales, the agentic approach is more effective at resolving initial syntax errors, unblocking a greater number of candidates to proceed through the pipeline. This upstream improvement yields measurable downstream improvements, most notably on mid-sized models, where it increases the simulation reach rate by over 20 percentage points. We hypothesize the gains come from short prompts, aggressive context management, and conditional tool use. Conditional retrieval helps at 8B and 30B; at 235B final-success gains are small and a naive RAG variant attains the highest final success. Our findings suggest that these agentic frameworks, when properly designed, are most effective at compensating for the capacity limits of small and mid-sized models.", "AI": {"tldr": "\u6bd4\u8f83\u4e24\u79cd\u57fa\u4e8eLLM\u7684MATLAB\u5230HDL\u8bed\u6cd5\u4fee\u590d\u65b9\u6cd5\uff1a\u7ed3\u6784\u5316\u4e13\u5bb6\u6d41\u7a0b\u4e0e\u81ea\u4e3b\u4ee3\u7406\u65b9\u6cd5\uff0c\u53d1\u73b0\u4ee3\u7406\u65b9\u6cd5\u5728\u89e3\u51b3\u8bed\u6cd5\u9519\u8bef\u65b9\u9762\u66f4\u6709\u6548\uff0c\u5c24\u5176\u80fd\u63d0\u5347\u4e2d\u5c0f\u89c4\u6a21\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5c06MATLAB\u7b97\u6cd5\u8f6c\u6362\u4e3a\u786c\u4ef6\u63cf\u8ff0\u8bed\u8a00(HDL)\u662fFPGA/ASIC\u90e8\u7f72\u7684\u5fc5\u8981\u6b65\u9aa4\uff0c\u4f46LLM\u5728HDL\u4ee3\u7801\u8bad\u7ec3\u6709\u9650\uff0c\u5bfc\u81f4\u7aef\u5230\u7aef\u8f6c\u6362\u5bb9\u6613\u4ea7\u751f\u8bed\u6cd5\u9519\u8bef\u3002\u9700\u8981\u7814\u7a76\u6709\u6548\u7684\u8bed\u6cd5\u4fee\u590d\u65b9\u6cd5\u3002", "method": "\u6bd4\u8f83\u4e24\u79cdLLM\u9a71\u52a8\u7684\u8bed\u6cd5\u4fee\u590d\u65b9\u6cd5\uff1a1) \u7ed3\u6784\u5316\u4e13\u5bb6\u8bbe\u8ba1\u6d41\u7a0b\uff08\u56fa\u5b9a\u64cd\u4f5c\u5e8f\u5217\uff09\uff1b2) \u81ea\u4e3b\u4ee3\u7406\u65b9\u6cd5\uff08\u4f7f\u7528MCP\u52a8\u6001\u9009\u62e9\u5de5\u5177\uff09\u3002\u7814\u7a7642\u4e2aMATLAB\u4fe1\u53f7\u5904\u7406\u51fd\u6570\uff0c\u9694\u79bb\u8bed\u6cd5\u4fee\u590d\u9636\u6bb5\uff0c\u6d4b\u8bd5\u4e09\u79cd\u6a21\u578b\u89c4\u6a21\u3002", "result": "\u4ee3\u7406\u65b9\u6cd5\u5728\u89e3\u51b3\u521d\u59cb\u8bed\u6cd5\u9519\u8bef\u65b9\u9762\u66f4\u6709\u6548\uff0c\u80fd\u89e3\u9501\u66f4\u591a\u5019\u9009\u4ee3\u7801\u901a\u8fc7\u6d41\u7a0b\u3002\u4e0a\u6e38\u6539\u8fdb\u5e26\u6765\u4e0b\u6e38\u53ef\u6d4b\u91cf\u7684\u63d0\u5347\uff0c\u7279\u522b\u662f\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\uff0c\u4eff\u771f\u6210\u529f\u7387\u63d0\u9ad8\u8d85\u8fc720\u4e2a\u767e\u5206\u70b9\u3002\u6761\u4ef6\u68c0\u7d22\u57288B\u548c30B\u6a21\u578b\u4e2d\u6709\u6548\uff0c235B\u6a21\u578b\u6700\u7ec8\u6210\u529f\u7387\u63d0\u5347\u8f83\u5c0f\u3002", "conclusion": "\u5f53\u8bbe\u8ba1\u6070\u5f53\u65f6\uff0c\u8fd9\u4e9b\u4ee3\u7406\u6846\u67b6\u80fd\u6709\u6548\u8865\u507f\u4e2d\u5c0f\u89c4\u6a21\u6a21\u578b\u7684\u80fd\u529b\u9650\u5236\u3002\u4ee3\u7406\u65b9\u6cd5\u7684\u4f18\u52bf\u6765\u81ea\u77ed\u63d0\u793a\u3001\u79ef\u6781\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u6761\u4ef6\u5de5\u5177\u4f7f\u7528\u3002", "topic": "agent analysis"}}
{"id": "2512.15089", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15089", "abs": "https://arxiv.org/abs/2512.15089", "authors": ["Jinwu Hu", "Dongjin Yang", "Langyu Bian", "Zhiquan Wen", "Yufeng Wang", "Yaofo Chen", "Bin Xiao", "Yuanqing Li", "Mingkui Tan"], "title": "Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models", "comment": "under review", "summary": "Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.", "AI": {"tldr": "CogER\u662f\u4e00\u4e2a\u53d7\u4eba\u7c7b\u5206\u5c42\u63a8\u7406\u542f\u53d1\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4ee3\u7406\u52a8\u6001\u9009\u62e9\u6700\u9002\u5408\u6bcf\u4e2a\u67e5\u8be2\u7684\u63a8\u7406\u7b56\u7565\uff0c\u5e73\u8861\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709LLM\u63a8\u7406\u7b56\u7565\u4e3b\u8981\u4f9d\u8d56\u6a21\u578b\u81ea\u8eab\u7684\u5feb\u6162\u6a21\u5f0f\uff0c\u96be\u4ee5\u5728\u4e0d\u540c\u96be\u5ea6\u67e5\u8be2\u95f4\u5e73\u8861\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u6839\u636e\u67e5\u8be2\u590d\u6742\u5ea6\u52a8\u6001\u9009\u62e9\u7b56\u7565\u7684\u65b9\u6cd5\u3002", "method": "CogER\u9996\u5148\u8bc4\u4f30\u67e5\u8be2\u590d\u6742\u5ea6\u5e76\u5206\u914d\u5230\u9884\u5b9a\u4e49\u7ea7\u522b\uff0c\u6bcf\u4e2a\u7ea7\u522b\u5bf9\u5e94\u5b9a\u5236\u5904\u7406\u7b56\u7565\u3002\u5c06\u7b56\u7565\u9009\u62e9\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3CogER-Agent\uff0c\u5956\u52b1\u51fd\u6570\u5e73\u8861\u89e3\u8d28\u91cf\u548c\u8ba1\u7b97\u6210\u672c\u3002\u5bf9\u4e8e\u9700\u8981\u5916\u90e8\u5de5\u5177\u7684\u67e5\u8be2\uff0c\u5f15\u5165\u8ba4\u77e5\u5de5\u5177\u8f85\u52a9\u63a8\u7406\uff0c\u8ba9LLM\u5728\u601d\u7ef4\u94fe\u4e2d\u81ea\u4e3b\u8c03\u7528\u5916\u90e8\u5de5\u5177\u3002", "result": "CogER\u5728\u9886\u57df\u5185\u4efb\u52a1\u4e0a\u76f8\u5bf9\u73b0\u6709\u6d4b\u8bd5\u65f6\u7f29\u653e\u65b9\u6cd5\u81f3\u5c11\u63d0\u534713%\u7684\u5e73\u5747\u7cbe\u786e\u5339\u914d\u7387\uff0c\u5728\u9886\u57df\u5916\u4efb\u52a1\u4e0a\u83b7\u5f978%\u7684\u76f8\u5bf9\u589e\u76ca\u3002", "conclusion": "CogER\u901a\u8fc7\u52a8\u6001\u7b56\u7565\u9009\u62e9\u6709\u6548\u5e73\u8861\u4e86\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5206\u5c42\u63a8\u7406\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.15146", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15146", "abs": "https://arxiv.org/abs/2512.15146", "authors": ["Weiqin Wang", "Yile Wang", "Kehao Chen", "Hui Huang"], "title": "Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning", "comment": null, "summary": "Test-time reinforcement learning mitigates the reliance on annotated data by using majority voting results as pseudo-labels, emerging as a complementary direction to reinforcement learning with verifiable rewards (RLVR) for improving reasoning ability of large language models (LLMs). However, this voting strategy often induces confirmation bias and suffers from sparse rewards, limiting the overall performance. In this work, we propose subgroup-specific step-wise confidence-weighted pseudo-label estimation (SCOPE), a framework integrating model confidence and dynamic subgroup partitioning to address these issues. Specifically, SCOPE integrates the proposed step-wise confidence into pseudo label deduction, prioritizing high-quality reasoning paths over simple frequency count. Furthermore, it dynamically partitions the candidate outputs pool into independent subgroups by balancing reasoning quality against exploration diversity. By deriving local consensus via repeat sampling for each sub group, SCOPE provides diverse supervision targets to encourage broader exploration. We conduct experiments across various models and benchmarks, experimental results show that SCOPE consistently outperforms recent baselines. Notably, SCOPE achieving relative improvements of 13.1\\% on challenging AIME 2025 and 8.1\\% on AMC. The code is released at \\href{https://github.com/szu-tera/SCOPE}{https://github.com/szu-tera/SCOPE}.", "AI": {"tldr": "SCOPE\u6846\u67b6\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u52a0\u6743\u4f2a\u6807\u7b7e\u4f30\u8ba1\u548c\u52a8\u6001\u5b50\u7fa4\u5212\u5206\uff0c\u89e3\u51b3\u4e86\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u4e2d\u591a\u6570\u6295\u7968\u7b56\u7565\u7684\u786e\u8ba4\u504f\u5dee\u548c\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u4f7f\u7528\u591a\u6570\u6295\u7968\u7ed3\u679c\u4f5c\u4e3a\u4f2a\u6807\u7b7e\u6765\u51cf\u5c11\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u4f46\u73b0\u6709\u6295\u7968\u7b56\u7565\u5b58\u5728\u786e\u8ba4\u504f\u5dee\u548c\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51faSCOPE\u6846\u67b6\uff1a1\uff09\u5f15\u5165\u9010\u6b65\u7f6e\u4fe1\u5ea6\u52a0\u6743\u4f2a\u6807\u7b7e\u63a8\u5bfc\uff0c\u4f18\u5148\u8003\u8651\u9ad8\u8d28\u91cf\u63a8\u7406\u8def\u5f84\u800c\u975e\u7b80\u5355\u9891\u7387\u8ba1\u6570\uff1b2\uff09\u52a8\u6001\u5212\u5206\u5019\u9009\u8f93\u51fa\u6c60\u4e3a\u72ec\u7acb\u5b50\u7fa4\uff0c\u5e73\u8861\u63a8\u7406\u8d28\u91cf\u4e0e\u63a2\u7d22\u591a\u6837\u6027\uff1b3\uff09\u901a\u8fc7\u91cd\u590d\u91c7\u6837\u4e3a\u6bcf\u4e2a\u5b50\u7fa4\u83b7\u53d6\u5c40\u90e8\u5171\u8bc6\uff0c\u63d0\u4f9b\u591a\u6837\u5316\u76d1\u7763\u76ee\u6807\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSCOPE\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728AIME 2025\u4e0a\u76f8\u5bf9\u63d0\u534713.1%\uff0c\u5728AMC\u4e0a\u76f8\u5bf9\u63d0\u53478.1%\u3002", "conclusion": "SCOPE\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u52a0\u6743\u548c\u52a8\u6001\u5b50\u7fa4\u5212\u5206\u6709\u6548\u89e3\u51b3\u4e86\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u786e\u8ba4\u504f\u5dee\u548c\u7a00\u758f\u5956\u52b1\u95ee\u9898\uff0c\u4e3a\u63d0\u5347LLM\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.14917", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.14917", "abs": "https://arxiv.org/abs/2512.14917", "authors": ["Changshu Liu", "Alireza Ghazanfari", "Yang Chen", "Reyhaneh Jabbarvand"], "title": "Evaluating Code Reasoning Abilities of Large Language Models Under Real-World Settings", "comment": null, "summary": "Code reasoning tasks are becoming prevalent in large language model (LLM) assessments. Existing benchmarks involve simple programs, failing to represent real-world complexities such as inter- or intra-procedural dependencies, core or third-party API calls, highly nested constructs, and non-primitive complex types. Evaluating LLMs under such a simplistic setting poses a significant threat to assumptions about their generalizability in practice. To enable a more realistic evaluation of code reasoning, this paper proposes RE2-Bench, a benchmark of 1,101 reasoning problems, including 195 drawn from mature real-world projects. RE2-Bench leverages static and dynamic program analysis to automatically serialize and deserialize compound, complex, and custom types in real-world code, going far beyond the primitive-only settings used in prior work.\n  A key feature of RE2-Bench is categorizing each reasoning problem as Easy or Hard via a principled majority-vote mechanism over nine interpretable code complexity metrics, resulting in two well-separated and semantically meaningful difficulty categories suitable for precise calibration of LLM reasoning ability. A comprehensive evaluation of six general-purpose and reasoning-oriented LLMs on two widely used code reasoning tasks -- input prediction and output prediction -- using RE2-Bench reveals a significant performance drop from Easy to Hard problems (51.50\\% for input prediction and 42.15\\% for output prediction), confirming that prior evaluations substantially overestimate the reasoning capabilities of LLMs.", "AI": {"tldr": "RE2-Bench\u662f\u4e00\u4e2a\u5305\u542b1101\u4e2a\u4ee3\u7801\u63a8\u7406\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5176\u4e2d195\u4e2a\u6765\u81ea\u771f\u5b9e\u9879\u76ee\uff0c\u901a\u8fc7\u7a0b\u5e8f\u5206\u6790\u5904\u7406\u590d\u6742\u7c7b\u578b\uff0c\u5e76\u4f7f\u75289\u4e2a\u590d\u6742\u5ea6\u6307\u6807\u5c06\u95ee\u9898\u5206\u4e3aEasy\u548cHard\u4e24\u7c7b\uff0c\u63ed\u793a\u4e86LLM\u5728\u771f\u5b9e\u590d\u6742\u4ee3\u7801\u63a8\u7406\u4e2d\u7684\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4f7f\u7528\u7b80\u5355\u7a0b\u5e8f\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u4ee3\u7801\u7684\u590d\u6742\u6027\uff08\u5982\u8fc7\u7a0b\u95f4\u4f9d\u8d56\u3001API\u8c03\u7528\u3001\u5d4c\u5957\u7ed3\u6784\u3001\u590d\u6742\u7c7b\u578b\u7b49\uff09\uff0c\u5bfc\u81f4\u5bf9LLM\u6cdb\u5316\u80fd\u529b\u7684\u8bc4\u4f30\u5b58\u5728\u504f\u5dee\u3002", "method": "\u63d0\u51faRE2-Bench\u57fa\u51c6\uff1a1\uff09\u5305\u542b1101\u4e2a\u63a8\u7406\u95ee\u9898\uff08195\u4e2a\u6765\u81ea\u771f\u5b9e\u9879\u76ee\uff09\uff1b2\uff09\u4f7f\u7528\u9759\u6001\u548c\u52a8\u6001\u7a0b\u5e8f\u5206\u6790\u81ea\u52a8\u5e8f\u5217\u5316/\u53cd\u5e8f\u5217\u5316\u590d\u6742\u7c7b\u578b\uff1b3\uff09\u901a\u8fc79\u4e2a\u53ef\u89e3\u91ca\u4ee3\u7801\u590d\u6742\u5ea6\u6307\u6807\u7684\u591a\u6570\u6295\u7968\u673a\u5236\u5c06\u95ee\u9898\u5206\u7c7b\u4e3aEasy\u6216Hard\u3002", "result": "\u5728\u8f93\u5165\u9884\u6d4b\u548c\u8f93\u51fa\u9884\u6d4b\u4e24\u4e2a\u4efb\u52a1\u4e0a\u8bc4\u4f306\u4e2aLLM\uff0c\u53d1\u73b0\u4eceEasy\u5230Hard\u95ee\u9898\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff08\u8f93\u5165\u9884\u6d4b\u4e0b\u964d51.50%\uff0c\u8f93\u51fa\u9884\u6d4b\u4e0b\u964d42.15%\uff09\uff0c\u8bc1\u5b9e\u5148\u524d\u8bc4\u4f30\u9ad8\u4f30\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "RE2-Bench\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u4ee3\u7801\u63a8\u7406\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86LLM\u5728\u590d\u6742\u4ee3\u7801\u63a8\u7406\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5148\u524d\u57fa\u4e8e\u7b80\u5355\u7a0b\u5e8f\u7684\u8bc4\u4f30\u663e\u8457\u9ad8\u4f30\u4e86LLM\u7684\u5b9e\u9645\u63a8\u7406\u80fd\u529b\u3002", "topic": "swe benchmark"}}
{"id": "2512.14990", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14990", "abs": "https://arxiv.org/abs/2512.14990", "authors": ["Mehil B Shah", "Mohammad Masudur Rahman", "Foutse Khomh"], "title": "Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent", "comment": "Accepted by the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026)", "summary": "Despite their wide adoption in various domains (e.g., healthcare, finance, software engineering), Deep Learning (DL)-based applications suffer from many bugs, failures, and vulnerabilities. Reproducing these bugs is essential for their resolution, but it is extremely challenging due to the inherent nondeterminism of DL models and their tight coupling with hardware and software environments. According to recent studies, only about 3% of DL bugs can be reliably reproduced using manual approaches. To address these challenges, we present RepGen, a novel, automated, and intelligent approach for reproducing deep learning bugs. RepGen constructs a learning-enhanced context from a project, develops a comprehensive plan for bug reproduction, employs an iterative generate-validate-refine mechanism, and thus generates such code using an LLM that reproduces the bug at hand. We evaluate RepGen on 106 real-world deep learning bugs and achieve a reproduction rate of 80.19%, a 19.81% improvement over the state-of-the-art measure. A developer study involving 27 participants shows that RepGen improves the success rate of DL bug reproduction by 23.35%, reduces the time to reproduce by 56.8%, and lowers participants' cognitive load.", "AI": {"tldr": "RepGen\uff1a\u4e00\u79cd\u81ea\u52a8\u5316\u667a\u80fd\u65b9\u6cd5\uff0c\u7528\u4e8e\u590d\u73b0\u6df1\u5ea6\u5b66\u4e60bug\uff0c\u901a\u8fc7\u6784\u5efa\u5b66\u4e60\u589e\u5f3a\u4e0a\u4e0b\u6587\u3001\u5236\u5b9a\u590d\u73b0\u8ba1\u5212\u3001\u91c7\u7528\u8fed\u4ee3\u751f\u6210-\u9a8c\u8bc1-\u7cbe\u70bc\u673a\u5236\uff0c\u4f7f\u7528LLM\u751f\u6210\u590d\u73b0\u4ee3\u7801\uff0c\u5728106\u4e2a\u771f\u5b9ebug\u4e0a\u8fbe\u523080.19%\u7684\u590d\u73b0\u7387\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u5b58\u5728\u5927\u91cfbug\u3001\u6545\u969c\u548c\u6f0f\u6d1e\uff0c\u4f46\u7531\u4e8eDL\u6a21\u578b\u7684\u56fa\u6709\u975e\u786e\u5b9a\u6027\u548c\u4e0e\u8f6f\u786c\u4ef6\u73af\u5883\u7684\u7d27\u5bc6\u8026\u5408\uff0c\u590d\u73b0\u8fd9\u4e9bbug\u6781\u5177\u6311\u6218\u6027\u3002\u7814\u7a76\u8868\u660e\u4ec5\u6709\u7ea63%\u7684DL bug\u53ef\u4ee5\u901a\u8fc7\u624b\u52a8\u65b9\u6cd5\u53ef\u9760\u590d\u73b0\u3002", "method": "1) \u4ece\u9879\u76ee\u4e2d\u6784\u5efa\u5b66\u4e60\u589e\u5f3a\u4e0a\u4e0b\u6587\uff1b2) \u5236\u5b9a\u5168\u9762\u7684bug\u590d\u73b0\u8ba1\u5212\uff1b3) \u91c7\u7528\u8fed\u4ee3\u7684\u751f\u6210-\u9a8c\u8bc1-\u7cbe\u70bc\u673a\u5236\uff1b4) \u4f7f\u7528LLM\u751f\u6210\u80fd\u591f\u590d\u73b0bug\u7684\u4ee3\u7801\u3002", "result": "\u5728106\u4e2a\u771f\u5b9e\u6df1\u5ea6\u5b66\u4e60bug\u4e0a\u8bc4\u4f30\uff0c\u8fbe\u523080.19%\u7684\u590d\u73b0\u7387\uff0c\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u534719.81%\u3002\u5f00\u53d1\u8005\u7814\u7a76\u663e\u793a\uff1a\u590d\u73b0\u6210\u529f\u7387\u63d0\u9ad823.35%\uff0c\u590d\u73b0\u65f6\u95f4\u51cf\u5c1156.8%\uff0c\u8ba4\u77e5\u8d1f\u8377\u964d\u4f4e\u3002", "conclusion": "RepGen\u662f\u9996\u4e2a\u81ea\u52a8\u5316\u667a\u80fdDL bug\u590d\u73b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u590d\u73b0\u7387\u548c\u6548\u7387\uff0c\u964d\u4f4e\u5f00\u53d1\u8005\u8d1f\u62c5\uff0c\u4e3aDL\u7cfb\u7edf\u53ef\u9760\u6027\u63d0\u4f9b\u91cd\u8981\u652f\u6301\u3002", "topic": "swe application"}}
{"id": "2512.15163", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15163", "abs": "https://arxiv.org/abs/2512.15163", "authors": ["Xuanjun Zong", "Zhiqi Shen", "Lei Wang", "Yunshi Lan", "Chao Yang"], "title": "MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers", "comment": "Our benchmark is available at https://github.com/xjzzzzzzzz/MCPSafety", "summary": "Large language models (LLMs) are evolving into agentic systems that reason, plan, and operate external tools. The Model Context Protocol (MCP) is a key enabler of this transition, offering a standardized interface for connecting LLMs with heterogeneous tools and services. Yet MCP's openness and multi-server workflows introduce new safety risks that existing benchmarks fail to capture, as they focus on isolated attacks or lack real-world coverage. We present MCP-SafetyBench, a comprehensive benchmark built on real MCP servers that supports realistic multi-turn evaluation across five domains: browser automation, financial analysis, location navigation, repository management, and web search. It incorporates a unified taxonomy of 20 MCP attack types spanning server, host, and user sides, and includes tasks requiring multi-step reasoning and cross-server coordination under uncertainty. Using MCP-SafetyBench, we systematically evaluate leading open- and closed-source LLMs, revealing large disparities in safety performance and escalating vulnerabilities as task horizons and server interactions grow. Our results highlight the urgent need for stronger defenses and establish MCP-SafetyBench as a foundation for diagnosing and mitigating safety risks in real-world MCP deployments.", "AI": {"tldr": "MCP-SafetyBench\uff1a\u9996\u4e2a\u57fa\u4e8e\u771f\u5b9eMCP\u670d\u52a1\u5668\u7684\u7efc\u5408\u6027\u5b89\u5168\u57fa\u51c6\uff0c\u8bc4\u4f30LLM\u5728\u591a\u670d\u52a1\u5668\u5de5\u4f5c\u6d41\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u6db5\u76d65\u4e2a\u9886\u57df20\u79cd\u653b\u51fb\u7c7b\u578b", "motivation": "MCP\u4f5c\u4e3a\u8fde\u63a5LLM\u4e0e\u5f02\u6784\u5de5\u5177\u7684\u5173\u952e\u534f\u8bae\uff0c\u5176\u5f00\u653e\u6027\u548c\u591a\u670d\u52a1\u5668\u5de5\u4f5c\u6d41\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u6355\u6349\u8fd9\u4e9b\u73b0\u5b9e\u5a01\u80c1", "method": "\u6784\u5efa\u57fa\u4e8e\u771f\u5b9eMCP\u670d\u52a1\u5668\u7684\u57fa\u51c6\uff0c\u652f\u6301\u591a\u8f6e\u8bc4\u4f30\uff0c\u6db5\u76d6\u6d4f\u89c8\u5668\u81ea\u52a8\u5316\u3001\u91d1\u878d\u5206\u6790\u3001\u4f4d\u7f6e\u5bfc\u822a\u3001\u4ed3\u5e93\u7ba1\u7406\u548c\u7f51\u7edc\u641c\u7d225\u4e2a\u9886\u57df\uff0c\u5305\u542b20\u79cd\u653b\u51fb\u7c7b\u578b\u7684\u7edf\u4e00\u5206\u7c7b\u6cd5", "result": "\u7cfb\u7edf\u8bc4\u4f30\u9886\u5148\u7684\u5f00\u6e90\u548c\u95ed\u6e90LLM\uff0c\u53d1\u73b0\u5b89\u5168\u6027\u80fd\u5b58\u5728\u5de8\u5927\u5dee\u5f02\uff0c\u968f\u7740\u4efb\u52a1\u8303\u56f4\u548c\u670d\u52a1\u5668\u4ea4\u4e92\u589e\u52a0\uff0c\u6f0f\u6d1e\u5448\u5347\u7ea7\u8d8b\u52bf", "conclusion": "MCP-SafetyBench\u4e3a\u8bca\u65ad\u548c\u7f13\u89e3\u771f\u5b9eMCP\u90e8\u7f72\u4e2d\u7684\u5b89\u5168\u98ce\u9669\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u7a81\u663e\u4e86\u52a0\u5f3a\u9632\u5fa1\u7684\u7d27\u8feb\u9700\u6c42", "topic": "agent analysis"}}
{"id": "2512.15295", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15295", "abs": "https://arxiv.org/abs/2512.15295", "authors": ["Toshihide Ubukata", "Enhong Mu", "Takuto Yamauchi", "Mingyue Zhang", "Jialong Li", "Kenji Tei"], "title": "Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis", "comment": null, "summary": "Controller synthesis is a formal method approach for automatically generating Labeled Transition System (LTS) controllers that satisfy specified properties. The efficiency of the synthesis process, however, is critically dependent on exploration policies. These policies often rely on fixed rules or strategies learned through reinforcement learning (RL) that consider only a limited set of current features. To address this limitation, this paper introduces GCRL, an approach that enhances RL-based methods by integrating Graph Neural Networks (GNNs). GCRL encodes the history of LTS exploration into a graph structure, allowing it to capture a broader, non-current-based context. In a comparative experiment against state-of-the-art methods, GCRL exhibited superior learning efficiency and generalization across four out of five benchmark domains, except one particular domain characterized by high symmetry and strictly local interactions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGCRL\u65b9\u6cd5\uff0c\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u5728\u63a7\u5236\u5668\u5408\u6210\u4e2d\u7684\u63a2\u7d22\u7b56\u7565\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u591a\u6570\u57fa\u51c6\u9886\u57df\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u5b66\u4e60\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u63a7\u5236\u5668\u5408\u6210\u4e2d\u63a2\u7d22\u7b56\u7565\u7684\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u56fa\u5b9a\u89c4\u5219\u6216\u4ec5\u8003\u8651\u6709\u9650\u5f53\u524d\u7279\u5f81\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u5386\u53f2\u63a2\u7d22\u4fe1\u606f\u3002", "method": "\u63d0\u51faGCRL\u65b9\u6cd5\uff0c\u5c06LTS\u63a2\u7d22\u5386\u53f2\u7f16\u7801\u4e3a\u56fe\u7ed3\u6784\uff0c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u6355\u6349\u66f4\u5e7f\u6cdb\u7684\u975e\u5f53\u524d\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u589e\u5f3a\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u7b56\u7565\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u9886\u57df\u7684\u6bd4\u8f83\u5b9e\u9a8c\u4e2d\uff0cGCRL\u5728\u56db\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u5b66\u4e60\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5728\u5177\u6709\u9ad8\u5bf9\u79f0\u6027\u548c\u4e25\u683c\u5c40\u90e8\u4ea4\u4e92\u7279\u6027\u7684\u7279\u5b9a\u9886\u57df\u8868\u73b0\u4e0d\u4f73\u3002", "conclusion": "GCRL\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u6574\u5408\u5386\u53f2\u63a2\u7d22\u4fe1\u606f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u63a7\u5236\u5668\u5408\u6210\u4e2d\u63a2\u7d22\u7b56\u7565\u7684\u6027\u80fd\uff0c\u4f46\u5728\u7279\u5b9a\u5bf9\u79f0\u6027\u5f3a\u7684\u9886\u57df\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.15076", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.15076", "abs": "https://arxiv.org/abs/2512.15076", "authors": ["Shlok Tomar", "Aryan Deshwal", "Ethan Villalovoz", "Mattia Fazzini", "Haipeng Cai", "Janardhan Rao Doppa"], "title": "An Exploratory Study of Bayesian Prompt Optimization for Test-Driven Code Generation with Large Language Models", "comment": "20 pages, 13 figures", "summary": "We consider the task of generating functionally correct code using large language models (LLMs). The correctness of generated code is influenced by the prompt used to query the given base LLM. We formulate the problem of finding the appropriate prompt as combinatorial search process and propose a Bayesian optimization (BO) approach referred to as {\\em BO for Code GENeration (BODE-GEN)}. BODE-GEN performs an adaptive data-driven search over prompts guided by training data in the form of prompts tried and the functional accuracy of the generated code over a set of given test cases. The key insight is to perform BO in continuous embedding space by using an auxiliary LLM to bridge the gap between discrete prompt space and continuous embedding space. We leverage two synergistic ideas, namely, random projections and dimensionality scaled priors, to build effective Gaussian process based surrogate models over the high-dimensional embedding space. Our experiments on the HumanEval+ benchmark using multiple base LLMs show that BODE-GEN can improve performance in terms of code generation accuracy compared to fixed prompts and manual prompt engineering. Additionally, we demonstrate that BODE-GEN is sample-efficient, requiring relatively few iterations of BO to demonstrate improvements in code accuracy.", "AI": {"tldr": "BODE-GEN\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u8fde\u7eed\u5d4c\u5165\u7a7a\u95f4\u4e2d\u641c\u7d22\u6700\u4f18\u63d0\u793a\uff0c\u901a\u8fc7\u8f85\u52a9LLM\u8fde\u63a5\u79bb\u6563\u63d0\u793a\u7a7a\u95f4\uff0c\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u51c6\u786e\u6027", "motivation": "LLM\u751f\u6210\u7684\u4ee3\u7801\u6b63\u786e\u6027\u53d7\u63d0\u793a\u5f71\u54cd\uff0c\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\u8017\u65f6\u4e14\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7684\u63d0\u793a\u641c\u7d22\u65b9\u6cd5", "method": "\u63d0\u51faBODE-GEN\u6846\u67b6\uff1a1) \u4f7f\u7528\u8f85\u52a9LLM\u5c06\u79bb\u6563\u63d0\u793a\u6620\u5c04\u5230\u8fde\u7eed\u5d4c\u5165\u7a7a\u95f4\uff1b2) \u91c7\u7528\u968f\u673a\u6295\u5f71\u548c\u7ef4\u5ea6\u7f29\u653e\u5148\u9a8c\u6784\u5efa\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u6a21\u578b\uff1b3) \u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u8d1d\u53f6\u65af\u4f18\u5316\u641c\u7d22\u6700\u4f18\u63d0\u793a", "result": "\u5728HumanEval+\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBODE-GEN\u76f8\u6bd4\u56fa\u5b9a\u63d0\u793a\u548c\u624b\u52a8\u63d0\u793a\u5de5\u7a0b\u80fd\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u51c6\u786e\u6027\uff0c\u4e14\u6837\u672c\u6548\u7387\u9ad8\uff0c\u53ea\u9700\u8f83\u5c11BO\u8fed\u4ee3\u5c31\u80fd\u6539\u5584\u6027\u80fd", "conclusion": "BODE-GEN\u901a\u8fc7\u5c06\u63d0\u793a\u641c\u7d22\u95ee\u9898\u8f6c\u5316\u4e3a\u8fde\u7eed\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u95ee\u9898\uff0c\u6709\u6548\u63d0\u9ad8\u4e86LLM\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u81ea\u52a8\u5316\u63d0\u793a\u5de5\u7a0b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def", "topic": "code agent"}}
{"id": "2512.15148", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.15148", "abs": "https://arxiv.org/abs/2512.15148", "authors": ["Hang Yu", "Yuzhou Lai", "Li Zhang", "Xiaoli Lian", "Fang Liu", "Yanrui Dong", "Ting Zhang", "Zhi Jin", "David Lo"], "title": "Aligning Academia with Industry: An Empirical Study of Industrial Needs and Academic Capabilities in AI-Driven Software Engineering", "comment": null, "summary": "The rapid advancement of large language models (LLMs) is fundamentally reshaping software engineering (SE), driving a paradigm shift in both academic research and industrial practice. While top-tier SE venues continue to show sustained or emerging focus on areas like automated testing and program repair, with researchers worldwide reporting continuous performance gains, the alignment of these academic advances with real industrial needs remains unclear. To bridge this gap, we first conduct a systematic analysis of 1,367 papers published in FSE, ASE, and ICSE between 2022 and 2025, identifying key research topics, commonly used benchmarks, industrial relevance, and open-source availability. We then carry out an empirical survey across 17 organizations, collecting 282 responses on six prominent topics, i.e., program analysis, automated testing, code generation/completion, issue resolution, pre-trained code models, and dependency management, through structured questionnaires. By contrasting academic capabilities with industrial feedback, we derive seven critical implications, highlighting under-addressed challenges in software requirements and architecture, the reliability and explainability of intelligent SE approaches, input assumptions in academic research, practical evaluation tensions, and ethical considerations. This study aims to refocus academic attention on these important yet under-explored problems and to guide future SE research toward greater industrial impact.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u5206\u67901367\u7bc7\u9876\u7ea7\u8f6f\u4ef6\u5de5\u7a0b\u4f1a\u8bae\u8bba\u6587\uff082022-2025\uff09\u548c17\u4e2a\u7ec4\u7ec7\u7684282\u4efd\u5de5\u4e1a\u8c03\u67e5\uff0c\u63ed\u793a\u4e86\u5b66\u672f\u7814\u7a76\u4e0e\u5de5\u4e1a\u9700\u6c42\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e03\u4e2a\u5173\u952e\u542f\u793a\u6765\u6307\u5bfc\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6b63\u5728\u91cd\u5851\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\uff0c\u4f46\u5b66\u672f\u7814\u7a76\u7684\u8fdb\u5c55\u4e0e\u5de5\u4e1a\u5b9e\u9645\u9700\u6c42\u4e4b\u95f4\u7684\u5bf9\u9f50\u7a0b\u5ea6\u4e0d\u660e\u786e\u3002\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u5b66\u672f\u8bba\u6587\u548c\u5de5\u4e1a\u8c03\u67e5\u6765\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "1. \u5bf9FSE\u3001ASE\u548cICSE\u4f1a\u8bae\u57282022-2025\u5e74\u95f4\u53d1\u8868\u76841367\u7bc7\u8bba\u6587\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u8bc6\u522b\u7814\u7a76\u4e3b\u9898\u3001\u5e38\u7528\u57fa\u51c6\u3001\u5de5\u4e1a\u76f8\u5173\u6027\u548c\u5f00\u6e90\u53ef\u7528\u6027\uff1b2. \u572817\u4e2a\u7ec4\u7ec7\u4e2d\u8fdb\u884c\u5b9e\u8bc1\u8c03\u67e5\uff0c\u6536\u96c6282\u4efd\u5173\u4e8e\u516d\u4e2a\u5173\u952e\u4e3b\u9898\uff08\u7a0b\u5e8f\u5206\u6790\u3001\u81ea\u52a8\u5316\u6d4b\u8bd5\u3001\u4ee3\u7801\u751f\u6210/\u8865\u5168\u3001\u95ee\u9898\u89e3\u51b3\u3001\u9884\u8bad\u7ec3\u4ee3\u7801\u6a21\u578b\u3001\u4f9d\u8d56\u7ba1\u7406\uff09\u7684\u7ed3\u6784\u5316\u95ee\u5377\u53cd\u9988\u3002", "result": "\u901a\u8fc7\u5bf9\u6bd4\u5b66\u672f\u80fd\u529b\u4e0e\u5de5\u4e1a\u53cd\u9988\uff0c\u53d1\u73b0\u4e86\u4e03\u4e2a\u5173\u952e\u542f\u793a\uff1a\u8f6f\u4ef6\u9700\u6c42\u548c\u67b6\u6784\u65b9\u9762\u7684\u6311\u6218\u672a\u5f97\u5230\u5145\u5206\u89e3\u51b3\u3001\u667a\u80fd\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u3001\u5b66\u672f\u7814\u7a76\u7684\u8f93\u5165\u5047\u8bbe\u3001\u5b9e\u9645\u8bc4\u4f30\u4e2d\u7684\u77db\u76fe\u4ee5\u53ca\u4f26\u7406\u8003\u8651\u3002", "conclusion": "\u7814\u7a76\u65e8\u5728\u91cd\u65b0\u805a\u7126\u5b66\u672f\u754c\u5bf9\u8fd9\u4e9b\u91cd\u8981\u4f46\u672a\u5145\u5206\u63a2\u7d22\u95ee\u9898\u7684\u5173\u6ce8\uff0c\u5e76\u6307\u5bfc\u672a\u6765\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u671d\u7740\u66f4\u5927\u7684\u5de5\u4e1a\u5f71\u54cd\u529b\u65b9\u5411\u53d1\u5c55\u3002", "topic": "agent analysis"}}
{"id": "2512.15374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15374", "abs": "https://arxiv.org/abs/2512.15374", "authors": ["Zehua Pei", "Hui-Ling Zhen", "Shixiong Kai", "Sinno Jialin Pan", "Yunhe Wang", "Mingxuan Yuan", "Bei Yu"], "title": "SCOPE: Prompt Evolution for Enhancing Agent Effectiveness", "comment": null, "summary": "Large Language Model (LLM) agents are increasingly deployed in environments that generate massive, dynamic contexts. However, a critical bottleneck remains: while agents have access to this context, their static prompts lack the mechanisms to manage it effectively, leading to recurring Corrective and Enhancement failures. To address this capability gap, we introduce \\textbf{SCOPE} (Self-evolving Context Optimization via Prompt Evolution). SCOPE frames context management as an \\textit{online optimization} problem, synthesizing guidelines from execution traces to automatically evolve the agent's prompt. We propose a Dual-Stream mechanism that balances tactical specificity (resolving immediate errors) with strategic generality (evolving long-term principles). Furthermore, we introduce Perspective-Driven Exploration to maximize strategy coverage, increasing the likelihood that the agent has the correct strategy for any given task. Experiments on the HLE benchmark show that SCOPE improves task success rates from 14.23\\% to 38.64\\% without human intervention. We make our code publicly available at https://github.com/JarvisPei/SCOPE.", "AI": {"tldr": "SCOPE\u901a\u8fc7\u81ea\u52a8\u6f14\u5316\u63d0\u793a\u6765\u4f18\u5316LLM\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\uff0c\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u89c6\u4e3a\u5728\u7ebf\u4f18\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u53cc\u6d41\u673a\u5236\u5e73\u8861\u6218\u672f\u7279\u5b9a\u6027\u548c\u6218\u7565\u901a\u7528\u6027\uff0c\u5728HLE\u57fa\u51c6\u4e0a\u5c06\u4efb\u52a1\u6210\u529f\u7387\u4ece14.23%\u63d0\u5347\u81f338.64%\u3002", "motivation": "LLM\u4ee3\u7406\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9762\u4e34\u4e0a\u4e0b\u6587\u7ba1\u7406\u74f6\u9888\uff0c\u9759\u6001\u63d0\u793a\u7f3a\u4e4f\u6709\u6548\u7ba1\u7406\u673a\u5236\uff0c\u5bfc\u81f4\u9891\u7e41\u7684\u7ea0\u6b63\u548c\u589e\u5f3a\u5931\u8d25\u3002\u9700\u8981\u89e3\u51b3\u4ee3\u7406\u80fd\u529b\u5dee\u8ddd\uff0c\u4f7f\u5176\u80fd\u6709\u6548\u5904\u7406\u5927\u89c4\u6a21\u52a8\u6001\u4e0a\u4e0b\u6587\u3002", "method": "\u63d0\u51faSCOPE\u6846\u67b6\uff0c\u5c06\u4e0a\u4e0b\u6587\u7ba1\u7406\u89c6\u4e3a\u5728\u7ebf\u4f18\u5316\u95ee\u9898\uff0c\u4ece\u6267\u884c\u8f68\u8ff9\u4e2d\u5408\u6210\u6307\u5bfc\u539f\u5219\u6765\u81ea\u52a8\u6f14\u5316\u4ee3\u7406\u63d0\u793a\u3002\u91c7\u7528\u53cc\u6d41\u673a\u5236\u5e73\u8861\u6218\u672f\u7279\u5b9a\u6027\uff08\u89e3\u51b3\u5373\u65f6\u9519\u8bef\uff09\u548c\u6218\u7565\u901a\u7528\u6027\uff08\u6f14\u5316\u957f\u671f\u539f\u5219\uff09\uff0c\u5e76\u5f15\u5165\u89c6\u89d2\u9a71\u52a8\u63a2\u7d22\u6700\u5927\u5316\u7b56\u7565\u8986\u76d6\u3002", "result": "\u5728HLE\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSCOPE\u5c06\u4efb\u52a1\u6210\u529f\u7387\u4ece14.23%\u663e\u8457\u63d0\u5347\u81f338.64%\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002\u4ee3\u7801\u5df2\u516c\u5f00\u5728GitHub\u4e0a\u3002", "conclusion": "SCOPE\u901a\u8fc7\u81ea\u52a8\u6f14\u5316\u63d0\u793a\u6709\u6548\u89e3\u51b3\u4e86LLM\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u4e3a\u4ee3\u7406\u7684\u81ea\u6211\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "topic": "agent analysis"}}
{"id": "2512.15274", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15274", "abs": "https://arxiv.org/abs/2512.15274", "authors": ["Yiliu Sun", "Zicheng Zhao", "Yang Wei", "Yanfang Zhang", "Chen Gong"], "title": "Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning", "comment": "Accepted by AAAI 2026", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reasoning. This uniform training strategy spends substantial effort on optimizing low-return tokens, which in turn impedes the potential improvement from high-return tokens and reduces overall training effectiveness. To address this issue, we propose a novel RLVR approach called Progressive Prefix-token Policy Optimization (PPPO), which highlights the significance of the prefix segment of generated outputs. Specifically, inspired by the well-established human thinking theory of Path Dependence, where early-stage thoughts substantially constrain subsequent thinking trajectory, we identify an analogous phenomenon in LLM reasoning termed Beginning Lock-in Effect (BLE). PPPO leverages this finding by focusing its optimization objective on the prefix reasoning process of LLMs. This targeted optimization strategy can positively influence subsequent reasoning processes, and ultimately improve final results. To improve the learning effectiveness of LLMs on how to start reasoning with high quality, PPPO introduces two training strategies: (a) Progressive Prefix Retention, which shapes a progressive learning process by increasing the proportion of retained prefix tokens during training; (b) Continuation Accumulated Reward, which mitigates reward bias by sampling multiple continuations for one prefix token sequence, and accumulating their scores as the reward signal. Extensive experimental results on various reasoning tasks demonstrate that our proposed PPPO outperforms representative RLVR methods, with the accuracy improvements of 18.02% on only 26.17% training tokens.", "AI": {"tldr": "PPPO\u662f\u4e00\u79cd\u65b0\u7684RLVR\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u4f18\u5316LLM\u63a8\u7406\u8f93\u51fa\u7684\u524d\u7f00token\uff0c\u901a\u8fc7\u6e10\u8fdb\u5f0f\u524d\u7f00\u4fdd\u7559\u548c\u5ef6\u7eed\u7d2f\u79ef\u5956\u52b1\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709RLVR\u65b9\u6cd5\u5bf9\u6240\u6709\u751f\u6210token\u8fdb\u884c\u7edf\u4e00\u8bad\u7ec3\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540ctoken\u5bf9\u63a8\u7406\u8d21\u732e\u7684\u5dee\u5f02\u3002\u7279\u522b\u662f\u524d\u7f00token\u5bf9\u540e\u7eed\u63a8\u7406\u8fc7\u7a0b\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u672a\u80fd\u9488\u5bf9\u6027\u4f18\u5316\uff0c\u5bfc\u81f4\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faPPPO\u65b9\u6cd5\uff0c\u57fa\u4e8e\"\u8def\u5f84\u4f9d\u8d56\"\u7406\u8bba\u548c\"\u8d77\u59cb\u9501\u5b9a\u6548\u5e94\"\uff0c\u4e13\u6ce8\u4e8e\u4f18\u5316LLM\u63a8\u7406\u7684\u524d\u7f00\u8fc7\u7a0b\u3002\u91c7\u7528\u4e24\u79cd\u8bad\u7ec3\u7b56\u7565\uff1a1) \u6e10\u8fdb\u5f0f\u524d\u7f00\u4fdd\u7559\uff1a\u9010\u6b65\u589e\u52a0\u8bad\u7ec3\u4e2d\u4fdd\u7559\u7684\u524d\u7f00token\u6bd4\u4f8b\uff1b2) \u5ef6\u7eed\u7d2f\u79ef\u5956\u52b1\uff1a\u5bf9\u540c\u4e00\u524d\u7f00\u5e8f\u5217\u91c7\u6837\u591a\u4e2a\u5ef6\u7eed\uff0c\u7d2f\u79ef\u5176\u5f97\u5206\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u3002", "result": "\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPPPO\u663e\u8457\u4f18\u4e8e\u73b0\u6709RLVR\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u752826.17%\u7684\u8bad\u7ec3token\u5c31\u5b9e\u73b0\u4e8618.02%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "PPPO\u901a\u8fc7\u9488\u5bf9\u6027\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u7684\u524d\u7f00token\uff0c\u6709\u6548\u63d0\u5347\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u9a8c\u8bc1\u4e86\"\u8d77\u59cb\u9501\u5b9a\u6548\u5e94\"\u5728LLM\u63a8\u7406\u4e2d\u7684\u91cd\u8981\u6027\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.15302", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15302", "abs": "https://arxiv.org/abs/2512.15302", "authors": ["Xiaotian Zhang", "Yuan Wang", "Ruizhe Chen", "Zeya Wang", "Runchen Hou", "Zuozhu Liu"], "title": "Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues", "comment": null, "summary": "The deployment of Large Language Models (LLMs) in interactive systems necessitates a deep alignment with the nuanced and dynamic preferences of individual users. Current alignment techniques predominantly address universal human values or static, single-turn preferences, thereby failing to address the critical needs of long-term personalization and the initial user cold-start problem. To bridge this gap, we propose PersonalAgent, a novel user-centric lifelong agent designed to continuously infer and adapt to user preferences. PersonalAgent constructs and dynamically refines a unified user profile by decomposing dialogues into single-turn interactions, framing preference inference as a sequential decision-making task. Experiments show that PersonalAgent achieves superior performance over strong prompt-based and policy optimization baselines, not only in idealized but also in noisy conversational contexts, while preserving cross-session preference consistency. Furthermore, human evaluation confirms that PersonalAgent excels at capturing user preferences naturally and coherently. Our findings underscore the importance of lifelong personalization for developing more inclusive and adaptive conversational agents. Our code is available here.", "AI": {"tldr": "PersonalAgent\u662f\u4e00\u4e2a\u9762\u5411\u7528\u6237\u7ec8\u8eab\u5b66\u4e60\u7684\u5bf9\u8bdd\u4ee3\u7406\uff0c\u901a\u8fc7\u5206\u89e3\u5bf9\u8bdd\u4e3a\u5355\u8f6e\u4ea4\u4e92\u5e76\u6784\u5efa\u52a8\u6001\u7528\u6237\u753b\u50cf\uff0c\u6301\u7eed\u63a8\u65ad\u548c\u9002\u5e94\u7528\u6237\u504f\u597d\uff0c\u89e3\u51b3\u4e86\u957f\u671f\u4e2a\u6027\u5316\u9700\u6c42\u548c\u51b7\u542f\u52a8\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u901a\u7528\u4eba\u7c7b\u4ef7\u503c\u89c2\u6216\u9759\u6001\u5355\u8f6e\u504f\u597d\uff0c\u65e0\u6cd5\u6ee1\u8db3\u957f\u671f\u4e2a\u6027\u5316\u9700\u6c42\u548c\u7528\u6237\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6301\u7eed\u9002\u5e94\u7528\u6237\u504f\u597d\u7684\u7cfb\u7edf\u3002", "method": "\u5c06\u5bf9\u8bdd\u5206\u89e3\u4e3a\u5355\u8f6e\u4ea4\u4e92\uff0c\u6784\u5efa\u7edf\u4e00\u7528\u6237\u753b\u50cf\u5e76\u52a8\u6001\u4f18\u5316\uff0c\u5c06\u504f\u597d\u63a8\u65ad\u5efa\u6a21\u4e3a\u5e8f\u5217\u51b3\u7b56\u4efb\u52a1\uff0c\u5b9e\u73b0\u7ec8\u8eab\u5b66\u4e60\u548c\u4e2a\u6027\u5316\u9002\u5e94\u3002", "result": "\u5728\u7406\u60f3\u548c\u5608\u6742\u5bf9\u8bdd\u73af\u5883\u4e2d\u5747\u4f18\u4e8e\u5f3a\u63d0\u793a\u57fa\u7ebf\u548c\u7b56\u7565\u4f18\u5316\u57fa\u7ebf\uff0c\u4fdd\u6301\u8de8\u4f1a\u8bdd\u504f\u597d\u4e00\u81f4\u6027\uff0c\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u80fd\u81ea\u7136\u8fde\u8d2f\u5730\u6355\u6349\u7528\u6237\u504f\u597d\u3002", "conclusion": "\u7ec8\u8eab\u4e2a\u6027\u5316\u5bf9\u4e8e\u5f00\u53d1\u66f4\u5177\u5305\u5bb9\u6027\u548c\u9002\u5e94\u6027\u7684\u5bf9\u8bdd\u4ee3\u7406\u81f3\u5173\u91cd\u8981\uff0cPersonalAgent\u5c55\u793a\u4e86\u6301\u7eed\u9002\u5e94\u7528\u6237\u504f\u597d\u7684\u6709\u6548\u6027\u3002", "topic": "agent analysis"}}
{"id": "2512.15466", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15466", "abs": "https://arxiv.org/abs/2512.15466", "authors": ["Robert Heum\u00fcller", "Frank Ortmeier"], "title": "On Assessing the Relevance of Code Reviews Authored by Generative Models", "comment": "Replication Package: https://github.com/robert-heumueller-ovgu/repl-generative-review-relevance", "summary": "The use of large language models like ChatGPT in code review offers promising efficiency gains but also raises concerns about correctness and safety. Existing evaluation methods for code review generation either rely on automatic comparisons to a single ground truth, which fails to capture the variability of human perspectives, or on subjective assessments of \"usefulness\", a highly ambiguous concept. We propose a novel evaluation approach based on what we call multi-subjective ranking. Using a dataset of 280 self-contained code review requests and corresponding comments from CodeReview StackExchange, multiple human judges ranked the quality of ChatGPT-generated comments alongside the top human responses from the platform. Results show that ChatGPT's comments were ranked significantly better than human ones, even surpassing StackExchange's accepted answers. Going further, our proposed method motivates and enables more meaningful assessments of generative AI's performance in code review, while also raising awareness of potential risks of unchecked integration into review processes.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u4e3b\u89c2\u6392\u540d\u7684\u4ee3\u7801\u5ba1\u67e5\u8bc4\u4f30\u65b9\u6cd5\uff0c\u53d1\u73b0ChatGPT\u751f\u6210\u7684\u8bc4\u8bba\u8d28\u91cf\u663e\u8457\u4f18\u4e8e\u4eba\u7c7b\u8bc4\u8bba\uff0c\u751a\u81f3\u8d85\u8fc7StackExchange\u7684\u91c7\u7eb3\u7b54\u6848", "motivation": "\u73b0\u6709\u4ee3\u7801\u5ba1\u67e5\u751f\u6210\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff1a\u8981\u4e48\u4f9d\u8d56\u4e0e\u5355\u4e00\u6807\u51c6\u7b54\u6848\u7684\u81ea\u52a8\u6bd4\u8f83\uff0c\u65e0\u6cd5\u6355\u6349\u4eba\u7c7b\u89c2\u70b9\u7684\u591a\u6837\u6027\uff1b\u8981\u4e48\u4f9d\u8d56\"\u6709\u7528\u6027\"\u7684\u4e3b\u89c2\u8bc4\u4f30\uff0c\u8fd9\u4e2a\u6982\u5ff5\u8fc7\u4e8e\u6a21\u7cca", "method": "\u63d0\u51fa\u591a\u4e3b\u89c2\u6392\u540d\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4f7f\u7528CodeReview StackExchange\u7684280\u4e2a\u72ec\u7acb\u4ee3\u7801\u5ba1\u67e5\u8bf7\u6c42\u548c\u5bf9\u5e94\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u8ba9\u591a\u4f4d\u4eba\u7c7b\u8bc4\u59d4\u5bf9ChatGPT\u751f\u6210\u7684\u8bc4\u8bba\u548c\u5e73\u53f0\u4e0a\u7684\u9876\u7ea7\u4eba\u7c7b\u56de\u7b54\u8fdb\u884c\u8d28\u91cf\u6392\u540d", "result": "ChatGPT\u7684\u8bc4\u8bba\u6392\u540d\u663e\u8457\u4f18\u4e8e\u4eba\u7c7b\u8bc4\u8bba\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86StackExchange\u7684\u91c7\u7eb3\u7b54\u6848", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5bf9\u751f\u6210\u5f0fAI\u5728\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u6027\u80fd\u8fdb\u884c\u66f4\u6709\u610f\u4e49\u7684\u8bc4\u4f30\uff0c\u540c\u65f6\u63d0\u9ad8\u5bf9\u65e0\u9650\u5236\u96c6\u6210\u5230\u5ba1\u67e5\u6d41\u7a0b\u4e2d\u6f5c\u5728\u98ce\u9669\u7684\u8ba4\u8bc6", "topic": "agent analysis"}}
{"id": "2512.15584", "categories": ["cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.15584", "abs": "https://arxiv.org/abs/2512.15584", "authors": ["Daniel A. Herrmann", "Abinav Chari", "Isabelle Qian", "Sree Sharvesh", "B. A. Levinstein"], "title": "A Decision-Theoretic Approach for Managing Misalignment", "comment": "Second Conference of the International Association for Safe and Ethical Artificial Intelligence (IASEAI '26)", "summary": "When should we delegate decisions to AI systems? While the value alignment literature has developed techniques for shaping AI values, less attention has been paid to how to determine, under uncertainty, when imperfect alignment is good enough to justify delegation. We argue that rational delegation requires balancing an agent's value (mis)alignment with its epistemic accuracy and its reach (the acts it has available). This paper introduces a formal, decision-theoretic framework to analyze this tradeoff precisely accounting for a principal's uncertainty about these factors. Our analysis reveals a sharp distinction between two delegation scenarios. First, universal delegation (trusting an agent with any problem) demands near-perfect value alignment and total epistemic trust, conditions rarely met in practice. Second, we show that context-specific delegation can be optimal even with significant misalignment. An agent's superior accuracy or expanded reach may grant access to better overall decision problems, making delegation rational in expectation. We develop a novel scoring framework to quantify this ex ante decision. Ultimately, our work provides a principled method for determining when an AI is aligned enough for a given context, shifting the focus from achieving perfect alignment to managing the risks and rewards of delegation under uncertainty.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u51b3\u7b56\u7406\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u786e\u5b9a\u4f55\u65f6\u5c06\u51b3\u7b56\u59d4\u6258\u7ed9AI\u7cfb\u7edf\uff0c\u5f3a\u8c03\u9700\u8981\u5e73\u8861\u4ef7\u503c\u5bf9\u9f50\u3001\u8ba4\u77e5\u51c6\u786e\u6027\u548c\u884c\u52a8\u8303\u56f4\uff0c\u5e76\u533a\u5206\u4e86\u901a\u7528\u59d4\u6258\u548c\u4e0a\u4e0b\u6587\u7279\u5b9a\u59d4\u6258\u7684\u4e0d\u540c\u8981\u6c42\u3002", "motivation": "\u5f53\u524d\u4ef7\u503c\u5bf9\u9f50\u6587\u732e\u4e3b\u8981\u5173\u6ce8\u5982\u4f55\u5851\u9020AI\u7684\u4ef7\u503c\u89c2\uff0c\u4f46\u8f83\u5c11\u7814\u7a76\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u5982\u4f55\u786e\u5b9a\u4e0d\u5b8c\u7f8e\u7684\u5bf9\u9f50\u4f55\u65f6\u8db3\u591f\u597d\u4ee5\u8bc1\u660e\u59d4\u6258\u7684\u5408\u7406\u6027\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u51b3\u5b9a\u4f55\u65f6AI\u5728\u7279\u5b9a\u4e0a\u4e0b\u6587\u4e2d\u8db3\u591f\u5bf9\u9f50\uff0c\u4ece\u800c\u5c06\u91cd\u70b9\u4ece\u5b9e\u73b0\u5b8c\u7f8e\u5bf9\u9f50\u8f6c\u5411\u7ba1\u7406\u59d4\u6258\u7684\u98ce\u9669\u548c\u56de\u62a5\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u6b63\u5f0f\u7684\u51b3\u7b56\u7406\u8bba\u6846\u67b6\uff0c\u7cbe\u786e\u5206\u6790\u4ef7\u503c\u5bf9\u9f50\u3001\u8ba4\u77e5\u51c6\u786e\u6027\u548c\u884c\u52a8\u8303\u56f4\u4e4b\u95f4\u7684\u6743\u8861\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u8bc4\u5206\u6846\u67b6\u6765\u91cf\u5316\u4e8b\u524d\u51b3\u7b56\uff0c\u533a\u5206\u901a\u7528\u59d4\u6258\u548c\u4e0a\u4e0b\u6587\u7279\u5b9a\u59d4\u6258\u4e24\u79cd\u573a\u666f\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86\u4e24\u79cd\u59d4\u6258\u573a\u666f\u7684\u660e\u663e\u533a\u522b\uff1a\u901a\u7528\u59d4\u6258\u9700\u8981\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u4ef7\u503c\u5bf9\u9f50\u548c\u5b8c\u5168\u7684\u8ba4\u77e5\u4fe1\u4efb\uff08\u5b9e\u8df5\u4e2d\u5f88\u5c11\u6ee1\u8db3\uff09\uff0c\u800c\u4e0a\u4e0b\u6587\u7279\u5b9a\u59d4\u6258\u5373\u4f7f\u5728\u663e\u8457\u4e0d\u5bf9\u9f50\u7684\u60c5\u51b5\u4e0b\u4e5f\u53ef\u80fd\u662f\u6700\u4f18\u7684\u3002AI\u7684\u4f18\u8d8a\u51c6\u786e\u6027\u6216\u6269\u5c55\u7684\u884c\u52a8\u8303\u56f4\u53ef\u80fd\u63d0\u4f9b\u66f4\u597d\u7684\u6574\u4f53\u51b3\u7b56\u95ee\u9898\uff0c\u4f7f\u5f97\u59d4\u6258\u5728\u671f\u671b\u4e0a\u662f\u5408\u7406\u7684\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u65b9\u6cd5\u6765\u786e\u5b9aAI\u5728\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u4e2d\u662f\u5426\u8db3\u591f\u5bf9\u9f50\uff0c\u5c06\u91cd\u70b9\u4ece\u5b9e\u73b0\u5b8c\u7f8e\u5bf9\u9f50\u8f6c\u5411\u7ba1\u7406\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u59d4\u6258\u98ce\u9669\u548c\u56de\u62a5\u3002\u4e0a\u4e0b\u6587\u7279\u5b9a\u7684\u59d4\u6258\u53ef\u4ee5\u5728\u5b58\u5728\u663e\u8457\u4e0d\u5bf9\u9f50\u7684\u60c5\u51b5\u4e0b\u4ecd\u7136\u662f\u6700\u4f18\u7684\u3002", "topic": "agent analysis"}}
{"id": "2512.15468", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.15468", "abs": "https://arxiv.org/abs/2512.15468", "authors": ["Hua Yang", "Alejandro Velasco", "Thanh Le-Cong", "Md Nazmul Haque", "Bowen Xu", "Denys Poshyvanyk"], "title": "How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?", "comment": "13 pages, 3 figures", "summary": "The success of large language models for code relies on vast amounts of code data, including public open-source repositories, such as GitHub, and private, confidential code from companies. This raises concerns about intellectual property compliance and the potential unauthorized use of license-restricted code. While membership inference (MI) techniques have been proposed to detect such unauthorized usage, their effectiveness can be undermined by semantically equivalent code transformation techniques, which modify code syntax while preserving semantic.\n  In this work, we systematically investigate whether semantically equivalent code transformation rules might be leveraged to evade MI detection. The results reveal that model accuracy drops by only 1.5% in the worst case for each rule, demonstrating that transformed datasets can effectively serve as substitutes for fine-tuning. Additionally, we find that one of the rules (RenameVariable) reduces MI success by 10.19%, highlighting its potential to obscure the presence of restricted code. To validate these findings, we conduct a causal analysis confirming that variable renaming has the strongest causal effect in disrupting MI detection. Notably, we find that combining multiple transformations does not further reduce MI effectiveness. Our results expose a critical loophole in license compliance enforcement for training large language models for code, showing that MI detection can be substantially weakened by transformation-based obfuscation techniques.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u8bed\u4e49\u7b49\u4ef7\u7684\u4ee3\u7801\u8f6c\u6362\u6280\u672f\uff08\u7279\u522b\u662f\u53d8\u91cf\u91cd\u547d\u540d\uff09\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u6210\u5458\u63a8\u65ad\u68c0\u6d4b\u7684\u6709\u6548\u6027\uff0c\u66b4\u9732\u4e86\u5927\u578b\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u8bb8\u53ef\u8bc1\u5408\u89c4\u6027\u6267\u884c\u7684\u6f0f\u6d1e\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4f7f\u7528\u5927\u91cf\u4ee3\u7801\u6570\u636e\uff08\u5305\u62ec\u5f00\u6e90\u548c\u79c1\u6709\u4ee3\u7801\uff09\uff0c\u5f15\u53d1\u4e86\u77e5\u8bc6\u4ea7\u6743\u5408\u89c4\u95ee\u9898\u3002\u867d\u7136\u5df2\u6709\u6210\u5458\u63a8\u65ad\u6280\u672f\u6765\u68c0\u6d4b\u672a\u7ecf\u6388\u6743\u7684\u4ee3\u7801\u4f7f\u7528\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u53ef\u80fd\u88ab\u8bed\u4e49\u7b49\u4ef7\u7684\u4ee3\u7801\u8f6c\u6362\u6280\u672f\u89c4\u907f\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u8bed\u4e49\u7b49\u4ef7\u4ee3\u7801\u8f6c\u6362\u89c4\u5219\u662f\u5426\u53ef\u7528\u4e8e\u89c4\u907f\u6210\u5458\u63a8\u65ad\u68c0\u6d4b\uff0c\u8bc4\u4f30\u4e0d\u540c\u8f6c\u6362\u89c4\u5219\u5bf9\u6a21\u578b\u51c6\u786e\u6027\u548cMI\u68c0\u6d4b\u6210\u529f\u7387\u7684\u5f71\u54cd\uff0c\u5e76\u8fdb\u884c\u56e0\u679c\u5206\u6790\u9a8c\u8bc1\u3002", "result": "1. \u6bcf\u4e2a\u8f6c\u6362\u89c4\u5219\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u4ec5\u4f7f\u6a21\u578b\u51c6\u786e\u7387\u4e0b\u964d1.5%\uff0c\u8f6c\u6362\u540e\u7684\u6570\u636e\u96c6\u53ef\u6709\u6548\u7528\u4e8e\u5fae\u8c03\uff1b2. RenameVariable\u89c4\u5219\u4f7fMI\u6210\u529f\u7387\u964d\u4f4e10.19%\uff1b3. \u56e0\u679c\u5206\u6790\u786e\u8ba4\u53d8\u91cf\u91cd\u547d\u540d\u5bf9\u7834\u574fMI\u68c0\u6d4b\u5177\u6709\u6700\u5f3a\u56e0\u679c\u6548\u5e94\uff1b4. \u7ec4\u5408\u591a\u4e2a\u8f6c\u6362\u4e0d\u4f1a\u8fdb\u4e00\u6b65\u964d\u4f4eMI\u6709\u6548\u6027\u3002", "conclusion": "\u8bed\u4e49\u7b49\u4ef7\u4ee3\u7801\u8f6c\u6362\uff08\u7279\u522b\u662f\u53d8\u91cf\u91cd\u547d\u540d\uff09\u53ef\u663e\u8457\u524a\u5f31\u6210\u5458\u63a8\u65ad\u68c0\u6d4b\uff0c\u66b4\u9732\u4e86\u4ee3\u7801\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u8bb8\u53ef\u8bc1\u5408\u89c4\u6027\u6267\u884c\u7684\u91cd\u5927\u6f0f\u6d1e\uff0c\u8f6c\u6362\u5f0f\u6df7\u6dc6\u6280\u672f\u53ef\u80fd\u88ab\u6ee5\u7528\u4ee5\u89c4\u907f\u68c0\u6d4b\u3002", "topic": "code agent"}}
{"id": "2512.15699", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.15699", "abs": "https://arxiv.org/abs/2512.15699", "authors": ["Qiuyang Mang", "Wenhao Chai", "Zhifei Li", "Huanzhi Mao", "Shang Zhou", "Alexander Du", "Hanchen Li", "Shu Liu", "Edwin Chen", "Yichuan Wang", "Xieting Chu", "Zerui Cheng", "Yuan Xu", "Tian Xia", "Zirui Wang", "Tianneng Shi", "Jianzhu Yao", "Yilong Zhao", "Qizheng Zhang", "Charlie Ruan", "Zeyu Shen", "Kaiyuan Liu", "Runyuan He", "Dong Xing", "Zerui Li", "Zirong Zeng", "Yige Jiang", "Lufeng Cheng", "Ziyi Zhao", "Youran Sun", "Wesley Zheng", "Meiyuwang Zhang", "Ruyi Ji", "Xuechang Tu", "Zihan Zheng", "Zexing Chen", "Kangyang Zhou", "Zhaozi Wang", "Jingbang Chen", "Aleksandra Korolova", "Peter Henderson", "Pramod Viswanath", "Vijay Ganesh", "Saining Xie", "Zhuang Liu", "Dawn Song", "Sewon Min", "Ion Stoica", "Joseph E. Gonzalez", "Jingbo Shang", "Alvin Cheung"], "title": "FrontierCS: Evolving Challenges for Evolving Intelligence", "comment": "Code with instruction: https://github.com/FrontierCS/Frontier-CS", "summary": "We introduce FrontierCS, a benchmark of 156 open-ended problems across diverse areas of computer science, designed and reviewed by experts, including CS PhDs and top-tier competitive programming participants and problem setters. Unlike existing benchmarks that focus on tasks with known optimal solutions, FrontierCS targets problems where the optimal solution is unknown, but the quality of a solution can be objectively evaluated. Models solve these tasks by implementing executable programs rather than outputting a direct answer. FrontierCS includes algorithmic problems, which are often NP-hard variants of competitive programming problems with objective partial scoring, and research problems with the same property. For each problem we provide an expert reference solution and an automatic evaluator. Combining open-ended design, measurable progress, and expert curation, FrontierCS provides a benchmark at the frontier of computer-science difficulty. Empirically, we find that frontier reasoning models still lag far behind human experts on both the algorithmic and research tracks, that increasing reasoning budgets alone does not close this gap, and that models often over-optimize for generating merely workable code instead of discovering high-quality algorithms and system designs.", "AI": {"tldr": "FrontierCS\u662f\u4e00\u4e2a\u5305\u542b156\u4e2a\u5f00\u653e\u5f0f\u8ba1\u7b97\u673a\u79d1\u5b66\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u7b97\u6cd5\u548c\u7814\u7a76\u95ee\u9898\uff0c\u7279\u70b9\u662f\u95ee\u9898\u7684\u6700\u4f18\u89e3\u672a\u77e5\u4f46\u53ef\u5ba2\u89c2\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\uff0c\u6a21\u578b\u901a\u8fc7\u5b9e\u73b0\u53ef\u6267\u884c\u7a0b\u5e8f\u800c\u975e\u76f4\u63a5\u8f93\u51fa\u7b54\u6848\u6765\u89e3\u51b3\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u5df2\u77e5\u6700\u4f18\u89e3\u7684\u4efb\u52a1\uff0c\u7f3a\u4e4f\u9488\u5bf9\u6700\u4f18\u89e3\u672a\u77e5\u4f46\u53ef\u5ba2\u89c2\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u7684\u5f00\u653e\u5f0f\u95ee\u9898\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u9700\u8981\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u8861\u91cf\u6a21\u578b\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u524d\u6cbf\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u7684\u57fa\u51c6\u3002", "method": "\u521b\u5efa\u5305\u542b156\u4e2a\u5f00\u653e\u5f0f\u95ee\u9898\u7684\u57fa\u51c6\uff0c\u6db5\u76d6\u7b97\u6cd5\u95ee\u9898\uff08\u901a\u5e38\u662fNP\u96be\u95ee\u9898\u7684\u53d8\u4f53\uff09\u548c\u7814\u7a76\u95ee\u9898\u3002\u6bcf\u4e2a\u95ee\u9898\u63d0\u4f9b\u4e13\u5bb6\u53c2\u8003\u89e3\u51b3\u65b9\u6848\u548c\u81ea\u52a8\u8bc4\u4f30\u5668\u3002\u95ee\u9898\u7531CS\u535a\u58eb\u3001\u9876\u7ea7\u7ade\u8d5b\u7f16\u7a0b\u53c2\u4e0e\u8005\u548c\u51fa\u9898\u8005\u8bbe\u8ba1\u548c\u8bc4\u5ba1\u3002", "result": "\u524d\u6cbf\u63a8\u7406\u6a21\u578b\u5728\u7b97\u6cd5\u548c\u7814\u7a76\u8d5b\u9053\u4e0a\u4ecd\u8fdc\u843d\u540e\u4e8e\u4eba\u7c7b\u4e13\u5bb6\uff1b\u4ec5\u589e\u52a0\u63a8\u7406\u9884\u7b97\u65e0\u6cd5\u7f29\u5c0f\u8fd9\u4e00\u5dee\u8ddd\uff1b\u6a21\u578b\u5f80\u5f80\u8fc7\u5ea6\u4f18\u5316\u751f\u6210\u4ec5\u80fd\u5de5\u4f5c\u7684\u4ee3\u7801\uff0c\u800c\u975e\u53d1\u73b0\u9ad8\u8d28\u91cf\u7b97\u6cd5\u548c\u7cfb\u7edf\u8bbe\u8ba1\u3002", "conclusion": "FrontierCS\u4e3a\u8bc4\u4f30\u6a21\u578b\u5728\u8ba1\u7b97\u673a\u79d1\u5b66\u524d\u6cbf\u95ee\u9898\u4e0a\u7684\u89e3\u51b3\u80fd\u529b\u63d0\u4f9b\u4e86\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u95ee\u9898\u89e3\u51b3\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u8868\u660e\u9700\u8981\u8d85\u8d8a\u4ee3\u7801\u751f\u6210\u7684\u65b0\u65b9\u6cd5\u6765\u5b9e\u73b0\u771f\u6b63\u7684\u7b97\u6cd5\u521b\u65b0\u3002", "topic": "swe benchmark"}}
{"id": "2512.14895", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14895", "abs": "https://arxiv.org/abs/2512.14895", "authors": ["Niklas Lauffer", "Xiang Deng", "Srivatsa Kundurthy", "Brad Kenstler", "Jeff Da"], "title": "Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections", "comment": null, "summary": "A popular paradigm for training LM agents relies on imitation learning, fine-tuning on expert trajectories. However, we show that the off-policy nature of imitation learning for multi-turn LM agents suffers from the fundamental limitation known as covariate shift: as the student policy's behavior diverges from the expert's, it encounters states not present in the training data, reducing the effectiveness of fine-tuning. Taking inspiration from the classic DAgger algorithm, we propose a novel data generation methodology for addressing covariate shift for multi-turn LLM training. We introduce on-policy expert corrections (OECs), partially on-policy data generated by starting rollouts with a student model and then switching to an expert model part way through the trajectory. We explore the effectiveness of our data generation technique in the domain of software engineering (SWE) tasks, a multi-turn setting where LLM agents must interact with a development environment to fix software bugs. Our experiments compare OEC data against various other on-policy and imitation learning approaches on SWE agent problems and train models using a common rejection sampling (i.e., using environment reward) combined with supervised fine-tuning technique. Experiments find that OEC trajectories show a relative 14% and 13% improvement over traditional imitation learning in the 7b and 32b setting, respectively, on SWE-bench verified. Our results demonstrate the need for combining expert demonstrations with on-policy data for effective multi-turn LM agent training.", "AI": {"tldr": "\u63d0\u51faOEC\u65b9\u6cd5\u89e3\u51b3\u591a\u8f6eLLM\u4ee3\u7406\u8bad\u7ec3\u4e2d\u7684\u534f\u53d8\u91cf\u504f\u79fb\u95ee\u9898\uff0c\u901a\u8fc7\u5728\u5b66\u751f\u6a21\u578b\u8f68\u8ff9\u4e2d\u5207\u6362\u4e13\u5bb6\u6a21\u578b\u751f\u6210\u90e8\u5206\u5728\u7ebf\u6570\u636e\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u76f8\u6bd4\u4f20\u7edf\u6a21\u4eff\u5b66\u4e60\u63d0\u534714%\u6027\u80fd", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6a21\u4eff\u5b66\u4e60\u7684LM\u4ee3\u7406\u8bad\u7ec3\u5728\u591a\u8f6e\u4ea4\u4e92\u4e2d\u5b58\u5728\u534f\u53d8\u91cf\u504f\u79fb\u95ee\u9898\uff1a\u5b66\u751f\u7b56\u7565\u504f\u79bb\u4e13\u5bb6\u884c\u4e3a\u65f6\uff0c\u4f1a\u9047\u5230\u8bad\u7ec3\u6570\u636e\u4e2d\u672a\u51fa\u73b0\u7684\u72b6\u6001\uff0c\u964d\u4f4e\u5fae\u8c03\u6548\u679c", "method": "\u63d0\u51fa\u5728\u7ebf\u4e13\u5bb6\u4fee\u6b63(OEC)\u6570\u636e\u751f\u6210\u65b9\u6cd5\uff1a\u4ece\u5b66\u751f\u6a21\u578b\u5f00\u59cb\u751f\u6210\u8f68\u8ff9\uff0c\u4e2d\u9014\u5207\u6362\u5230\u4e13\u5bb6\u6a21\u578b\u5b8c\u6210\u5269\u4f59\u90e8\u5206\uff0c\u751f\u6210\u90e8\u5206\u5728\u7ebf\u6570\u636e\u3002\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\uff0c\u7ed3\u5408\u62d2\u7edd\u91c7\u6837\u548c\u76d1\u7763\u5fae\u8c03\u6280\u672f\u8fdb\u884c\u8bad\u7ec3", "result": "\u5728SWE-bench\u9a8c\u8bc1\u96c6\u4e0a\uff0cOEC\u8f68\u8ff9\u76f8\u6bd4\u4f20\u7edf\u6a21\u4eff\u5b66\u4e60\u57287b\u548c32b\u6a21\u578b\u4e0a\u5206\u522b\u5b9e\u73b014%\u548c13%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u8bc1\u660e\u7ed3\u5408\u4e13\u5bb6\u6f14\u793a\u548c\u5728\u7ebf\u6570\u636e\u5bf9\u591a\u8f6eLM\u4ee3\u7406\u8bad\u7ec3\u7684\u91cd\u8981\u6027", "conclusion": "\u591a\u8f6eLM\u4ee3\u7406\u8bad\u7ec3\u9700\u8981\u7ed3\u5408\u4e13\u5bb6\u6f14\u793a\u548c\u5728\u7ebf\u6570\u636e\uff0cOEC\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u534f\u53d8\u91cf\u504f\u79fb\u95ee\u9898\uff0c\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u6027\u80fd", "topic": "swe application"}}
{"id": "2512.15617", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15617", "abs": "https://arxiv.org/abs/2512.15617", "authors": ["Kester Clegg", "Richard Hawkins", "Ibrahim Habli", "Tom Lawton"], "title": "Evaluating Metrics for Safety with LLM-as-Judges", "comment": null, "summary": "LLMs (Large Language Models) are increasingly used in text processing pipelines to intelligently respond to a variety of inputs and generation tasks. This raises the possibility of replacing human roles that bottleneck existing information flows, either due to insufficient staff or process complexity. However, LLMs make mistakes and some processing roles are safety critical. For example, triaging post-operative care to patients based on hospital referral letters, or updating site access schedules in nuclear facilities for work crews. If we want to introduce LLMs into critical information flows that were previously performed by humans, how can we make them safe and reliable? Rather than make performative claims about augmented generation frameworks or graph-based techniques, this paper argues that the safety argument should focus on the type of evidence we get from evaluation points in LLM processes, particularly in frameworks that employ LLM-as-Judges (LaJ) evaluators. This paper argues that although we cannot get deterministic evaluations from many natural language processing tasks, by adopting a basket of weighted metrics it may be possible to lower the risk of errors within an evaluation, use context sensitivity to define error severity and design confidence thresholds that trigger human review of critical LaJ judgments when concordance across evaluators is low.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u5982\u4f55\u5728\u5b89\u5168\u5173\u952e\u7684\u4fe1\u606f\u5904\u7406\u6d41\u7a0b\u4e2d\u5b89\u5168\u53ef\u9760\u5730\u5f15\u5165LLM\uff0c\u63d0\u51fa\u901a\u8fc7\u52a0\u6743\u6307\u6807\u7ec4\u5408\u3001\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u9519\u8bef\u4e25\u91cd\u6027\u5b9a\u4e49\u4ee5\u53ca\u7f6e\u4fe1\u5ea6\u9608\u503c\u6765\u964d\u4f4eLLM-as-Judge\u8bc4\u4f30\u4e2d\u7684\u98ce\u9669\u3002", "motivation": "LLM\u8d8a\u6765\u8d8a\u591a\u5730\u7528\u4e8e\u6587\u672c\u5904\u7406\u6d41\u7a0b\uff0c\u53ef\u80fd\u66ff\u4ee3\u4eba\u529b\u74f6\u9888\uff0c\u4f46LLM\u4f1a\u72af\u9519\u4e14\u67d0\u4e9b\u5904\u7406\u89d2\u8272\u662f\u5b89\u5168\u5173\u952e\u7684\u3002\u5982\u4f55\u5728\u4e4b\u524d\u7531\u4eba\u7c7b\u6267\u884c\u7684\u5173\u952e\u4fe1\u606f\u6d41\u4e2d\u5b89\u5168\u5f15\u5165LLM\uff1f", "method": "\u4e3b\u5f20\u5b89\u5168\u8bba\u8bc1\u5e94\u805a\u7126\u4e8eLLM\u6d41\u7a0b\u4e2d\u8bc4\u4f30\u70b9\u63d0\u4f9b\u7684\u8bc1\u636e\u7c7b\u578b\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528LLM-as-Judge\u8bc4\u4f30\u5668\u7684\u6846\u67b6\u4e2d\u3002\u91c7\u7528\u52a0\u6743\u6307\u6807\u7ec4\u5408\u6765\u964d\u4f4e\u8bc4\u4f30\u9519\u8bef\u98ce\u9669\uff0c\u4f7f\u7528\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u5b9a\u4e49\u9519\u8bef\u4e25\u91cd\u6027\uff0c\u8bbe\u8ba1\u7f6e\u4fe1\u5ea6\u9608\u503c\u5728\u8bc4\u4f30\u8005\u4e00\u81f4\u6027\u4f4e\u65f6\u89e6\u53d1\u4eba\u5de5\u5ba1\u67e5\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b9\u6cd5\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6307\u6807\u8bc4\u4f30\u3001\u9519\u8bef\u4e25\u91cd\u6027\u5206\u7ea7\u548c\u7f6e\u4fe1\u5ea6\u89e6\u53d1\u673a\u5236\uff0c\u53ef\u4ee5\u5728\u65e0\u6cd5\u83b7\u5f97\u786e\u5b9a\u6027\u8bc4\u4f30\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u63d0\u9ad8LLM\u5728\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u867d\u7136\u65e0\u6cd5\u4ece\u8bb8\u591a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u83b7\u5f97\u786e\u5b9a\u6027\u8bc4\u4f30\uff0c\u4f46\u901a\u8fc7\u91c7\u7528\u52a0\u6743\u6307\u6807\u7ec4\u5408\u3001\u4e0a\u4e0b\u6587\u654f\u611f\u7684\u9519\u8bef\u4e25\u91cd\u6027\u5b9a\u4e49\u548c\u7f6e\u4fe1\u5ea6\u9608\u503c\uff0c\u53ef\u4ee5\u964d\u4f4eLLM-as-Judge\u8bc4\u4f30\u4e2d\u7684\u98ce\u9669\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u5e94\u7528\u4e2d\u5f15\u5165LLM\u63d0\u4f9b\u53ef\u884c\u8def\u5f84\u3002", "topic": "agent analysis"}}
{"id": "2512.15000", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15000", "abs": "https://arxiv.org/abs/2512.15000", "authors": ["Ruiyi Zhang", "Peijia Qin", "Qi Cao", "Pengtao Xie"], "title": "DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding", "comment": null, "summary": "Process Reward Models (PRMs) have become essential for improving Large Language Models (LLMs) via test-time scaling, yet their effectiveness in coding remains limited due to the lack of meaningful step decompositions in code and the noise of Monte-Carlo-generated partial labels. We propose DreamPRM-Code, a coding-focused PRM that treats functions as reasoning steps using a Chain-of-Function prompting strategy to induce modular code generation, enabling PRM training and application analogous to mathematical reasoning tasks. To address label noise, DreamPRM-Code introduces a meta-learning-based correction mechanism that leverages clean final-solution unit-test labels and performs bi-level optimization to refine intermediate labels. Applying on test-time scaling, DreamPRM-Code achieved state-of-the-art performance on LiveCodeBench with 80.9 pass@1 rate, surpassing OpenAI o4-mini.", "AI": {"tldr": "DreamPRM-Code\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4ee3\u7801\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u51fd\u6570\u4f5c\u4e3a\u63a8\u7406\u6b65\u9aa4\u5e76\u4f7f\u7528\u94fe\u5f0f\u51fd\u6570\u63d0\u793a\u7b56\u7565\u6765\u8bf1\u5bfc\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\uff0c\u540c\u65f6\u5f15\u5165\u5143\u5b66\u4e60\u6821\u6b63\u673a\u5236\u6765\u51cf\u5c11\u6807\u7b7e\u566a\u58f0\uff0c\u5728LiveCodeBench\u4e0a\u5b9e\u73b0\u4e8680.9%\u7684pass@1\u7387\u3002", "motivation": "\u5f53\u524d\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5728\u4ee3\u7801\u4efb\u52a1\u4e2d\u6548\u679c\u6709\u9650\uff0c\u4e3b\u8981\u56e0\u4e3a\u4ee3\u7801\u7f3a\u4e4f\u6709\u610f\u4e49\u7684\u6b65\u9aa4\u5206\u89e3\uff0c\u4ee5\u53ca\u8499\u7279\u5361\u6d1b\u751f\u6210\u7684\u4e2d\u95f4\u6807\u7b7e\u5b58\u5728\u566a\u58f0\u95ee\u9898\u3002", "method": "1. \u5c06\u51fd\u6570\u89c6\u4e3a\u63a8\u7406\u6b65\u9aa4\uff0c\u91c7\u7528\u94fe\u5f0f\u51fd\u6570\u63d0\u793a\u7b56\u7565\u8bf1\u5bfc\u6a21\u5757\u5316\u4ee3\u7801\u751f\u6210\uff1b2. \u5f15\u5165\u57fa\u4e8e\u5143\u5b66\u4e60\u7684\u6821\u6b63\u673a\u5236\uff0c\u5229\u7528\u5e72\u51c0\u7684\u6700\u7ec8\u89e3\u51b3\u65b9\u6848\u5355\u5143\u6d4b\u8bd5\u6807\u7b7e\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u6765\u7cbe\u70bc\u4e2d\u95f4\u6807\u7b7e\u3002", "result": "\u5728LiveCodeBench\u4e0a\u5b9e\u73b0\u4e8680.9%\u7684pass@1\u7387\uff0c\u8d85\u8d8a\u4e86OpenAI o4-mini\uff0c\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "DreamPRM-Code\u901a\u8fc7\u521b\u65b0\u7684\u51fd\u6570\u7ea7\u6b65\u9aa4\u5206\u89e3\u548c\u6807\u7b7e\u6821\u6b63\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5728\u4ee3\u7801\u4efb\u52a1\u4e2d\u7684\u6548\u679c\uff0c\u4e3a\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u65b9\u6cd5\u3002", "topic": "code agent"}}
{"id": "2512.15674", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15674", "abs": "https://arxiv.org/abs/2512.15674", "authors": ["Adam Karvonen", "James Chua", "Cl\u00e9ment Dumas", "Kit Fraser-Taliente", "Subhash Kantamneni", "Julian Minder", "Euan Ong", "Arnab Sen Sharma", "Daniel Wen", "Owain Evans", "Samuel Marks"], "title": "Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers", "comment": "36 pages", "summary": "Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u6fc0\u6d3b\u9884\u8a00\u673a\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u6837\u5316\u8bad\u7ec3\u8ba9LLM\u80fd\u591f\u76f4\u63a5\u8bfb\u53d6\u5176\u4ed6LLM\u7684\u6fc0\u6d3b\u72b6\u6001\u5e76\u56de\u7b54\u81ea\u7136\u8bed\u8a00\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u4f20\u7edf\u767d\u76d2\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u6fc0\u6d3b\u7406\u89e3\u65b9\u6cd5\u901a\u5e38\u590d\u6742\u4e14\u4e13\u7528\uff0c\u800cLatentQA\u65b9\u6cd5\u867d\u7136\u7b80\u5355\u4f46\u5c40\u9650\u4e8e\u72ed\u7a84\u4efb\u52a1\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u901a\u7528\u5316\u7684\u6fc0\u6d3b\u7406\u89e3\u80fd\u529b\uff0c\u7814\u7a76\u8bad\u7ec3\u6570\u636e\u591a\u6837\u6027\u5982\u4f55\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u91c7\u7528LatentQA\u65b9\u6cd5\u8bad\u7ec3\u6fc0\u6d3b\u9884\u8a00\u673a\uff0c\u8ba9LLM\u80fd\u591f\u63a5\u53d7\u5176\u4ed6LLM\u7684\u6fc0\u6d3b\u72b6\u6001\u4f5c\u4e3a\u8f93\u5165\u5e76\u56de\u7b54\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u3002\u901a\u8fc7\u591a\u6837\u5316\u8bad\u7ec3\u6570\u636e\u96c6\uff08\u5305\u62ec\u5206\u7c7b\u4efb\u52a1\u548c\u81ea\u76d1\u7763\u4e0a\u4e0b\u6587\u9884\u6d4b\u4efb\u52a1\uff09\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u6fc0\u6d3b\u9884\u8a00\u673a\u80fd\u591f\u6062\u590d\u5fae\u8c03\u6a21\u578b\u4e2d\u672a\u51fa\u73b0\u5728\u8f93\u5165\u6587\u672c\u7684\u4fe1\u606f\uff08\u5982\u4f20\u8bb0\u77e5\u8bc6\u6216\u6076\u610f\u503e\u5411\uff09\u3002\u5728\u56db\u4e2a\u4e0b\u6e38\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0c\u6700\u4f73AO\u6a21\u578b\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u4f20\u7edf\u767d\u76d2\u57fa\u7ebf\uff0c\u57283/4\u4efb\u52a1\u4e2d\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u591a\u6837\u5316\u8bad\u7ec3\u4f7fLLM\u83b7\u5f97\u4e86\u901a\u7528\u7684\u6fc0\u6d3b\u72b6\u6001\u8bed\u8a00\u5316\u80fd\u529b\uff0c\u80fd\u591f\u6709\u6548\u7406\u89e3\u5e76\u63cf\u8ff0\u5176\u4ed6LLM\u7684\u5185\u90e8\u8868\u793a\uff0c\u4e3a\u6a21\u578b\u89e3\u91ca\u63d0\u4f9b\u4e86\u66f4\u7b80\u5355\u6709\u6548\u7684\u9014\u5f84\u3002", "topic": "agent analysis"}}
{"id": "2512.15036", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15036", "abs": "https://arxiv.org/abs/2512.15036", "authors": ["Chenxiao Gao", "Haotian Sun", "Na Li", "Dale Schuurmans", "Bo Dai"], "title": "Spectral Representation-based Reinforcement Learning", "comment": null, "summary": "In real-world applications with large state and action spaces, reinforcement learning (RL) typically employs function approximations to represent core components like the policies, value functions, and dynamics models. Although powerful approximations such as neural networks offer great expressiveness, they often present theoretical ambiguities, suffer from optimization instability and exploration difficulty, and incur substantial computational costs in practice. In this paper, we introduce the perspective of spectral representations as a solution to address these difficulties in RL. Stemming from the spectral decomposition of the transition operator, this framework yields an effective abstraction of the system dynamics for subsequent policy optimization while also providing a clear theoretical characterization. We reveal how to construct spectral representations for transition operators that possess latent variable structures or energy-based structures, which implies different learning methods to extract spectral representations from data. Notably, each of these learning methods realizes an effective RL algorithm under this framework. We also provably extend this spectral view to partially observable MDPs. Finally, we validate these algorithms on over 20 challenging tasks from the DeepMind Control Suite, where they achieve performances comparable or superior to current state-of-the-art model-free and model-based baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c31\u8868\u793a\u7684\u65b0\u89c6\u89d2\u6765\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u51fd\u6570\u903c\u8fd1\u7684\u6311\u6218\uff0c\u901a\u8fc7\u8c31\u5206\u89e3\u8f6c\u79fb\u7b97\u5b50\u6765\u62bd\u8c61\u7cfb\u7edf\u52a8\u6001\uff0c\u5e76\u5728DeepMind Control Suite\u768420\u591a\u4e2a\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u5927\u578b\u72b6\u6001\u548c\u52a8\u4f5c\u7a7a\u95f4\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u4f7f\u7528\u51fd\u6570\u903c\u8fd1\u6765\u8868\u793a\u7b56\u7565\u3001\u4ef7\u503c\u51fd\u6570\u548c\u52a8\u6001\u6a21\u578b\u7b49\u6838\u5fc3\u7ec4\u4ef6\u3002\u867d\u7136\u795e\u7ecf\u7f51\u7edc\u7b49\u5f3a\u5927\u903c\u8fd1\u5668\u5177\u6709\u5f88\u597d\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u7406\u8bba\u6a21\u7cca\u6027\u3001\u4f18\u5316\u4e0d\u7a33\u5b9a\u3001\u63a2\u7d22\u56f0\u96be\u4ee5\u53ca\u8ba1\u7b97\u6210\u672c\u9ad8\u7b49\u95ee\u9898\u3002", "method": "\u5f15\u5165\u8c31\u8868\u793a\u89c6\u89d2\uff0c\u57fa\u4e8e\u8f6c\u79fb\u7b97\u5b50\u7684\u8c31\u5206\u89e3\u6784\u5efa\u6846\u67b6\u3002\u5c55\u793a\u4e86\u5982\u4f55\u4e3a\u5177\u6709\u9690\u53d8\u91cf\u7ed3\u6784\u6216\u57fa\u4e8e\u80fd\u91cf\u7ed3\u6784\u7684\u8f6c\u79fb\u7b97\u5b50\u6784\u5efa\u8c31\u8868\u793a\uff0c\u5e76\u63d0\u51fa\u4e86\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u8c31\u8868\u793a\u7684\u4e0d\u540c\u5b66\u4e60\u65b9\u6cd5\u3002\u8fd8\u5c06\u8be5\u8c31\u89c6\u89d2\u6269\u5c55\u5230\u90e8\u5206\u53ef\u89c2\u6d4bMDPs\u3002", "result": "\u5728DeepMind Control Suite\u768420\u591a\u4e2a\u6311\u6218\u6027\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u7b97\u6cd5\uff0c\u6027\u80fd\u8fbe\u5230\u6216\u8d85\u8fc7\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6a21\u578b\u65e0\u5173\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8c31\u8868\u793a\u6846\u67b6\u4e3a\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u51fd\u6570\u903c\u8fd1\u7684\u56f0\u96be\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u65e2\u80fd\u6709\u6548\u62bd\u8c61\u7cfb\u7edf\u52a8\u6001\u7528\u4e8e\u7b56\u7565\u4f18\u5316\uff0c\u53c8\u80fd\u63d0\u4f9b\u6e05\u6670\u7684\u7406\u8bba\u7279\u5f81\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.15068", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15068", "abs": "https://arxiv.org/abs/2512.15068", "authors": ["Debu Sinha"], "title": "The Semantic Illusion: Certified Limits of Embedding-Based Hallucination Detection in RAG Systems", "comment": "12 pages, 2 figures, 6 tables", "summary": "Retrieval-Augmented Generation (RAG) systems remain susceptible to hallucinations despite grounding in retrieved evidence. Current detection methods rely on semantic similarity and natural language inference (NLI), but their fundamental limitations have not been rigorously characterized. We apply conformal prediction to hallucination detection, providing finite-sample coverage guarantees that enable precise quantification of detection capabilities. Using calibration sets of approximately 600 examples, we achieve 94% coverage with 0% false positive rate on synthetic hallucinations (Natural Questions). However, on three real hallucination benchmarks spanning multiple LLMs (GPT-4, ChatGPT, GPT-3, Llama-2, Mistral), embedding-based methods - including state-of-the-art OpenAI text-embedding-3-large and cross-encoder models - exhibit unacceptable false positive rates: 100% on HaluEval, 88% on RAGTruth, and 50% on WikiBio. Crucially, GPT-4 as an LLM judge achieves only 7% FPR (95% CI: [3.4%, 13.7%]) on the same data, proving the task is solvable through reasoning. We term this the \"semantic illusion\": semantically plausible hallucinations preserve similarity to source documents while introducing factual errors invisible to embeddings. This limitation persists across embedding architectures, LLM generators, and task types, suggesting embedding-based detection is insufficient for production RAG deployment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u57fa\u4e8e\u5d4c\u5165\u7684RAG\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\uff0c\u63d0\u51fa\u4e86\"\u8bed\u4e49\u5e7b\u89c9\"\u6982\u5ff5\uff0c\u5e76\u8bc1\u660eGPT-4\u4f5c\u4e3aLLM\u6cd5\u5b98\u80fd\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u5c3d\u7ba1RAG\u7cfb\u7edf\u57fa\u4e8e\u68c0\u7d22\u8bc1\u636e\uff0c\u4f46\u4ecd\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u3002\u5f53\u524d\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u7684\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\uff0c\u4f46\u5c1a\u672a\u88ab\u4e25\u683c\u8868\u5f81\u3002", "method": "\u5e94\u7528\u7b26\u5408\u6027\u9884\u6d4b\u8fdb\u884c\u5e7b\u89c9\u68c0\u6d4b\uff0c\u63d0\u4f9b\u6709\u9650\u6837\u672c\u8986\u76d6\u4fdd\u8bc1\u3002\u5728\u591a\u4e2a\u771f\u5b9e\u5e7b\u89c9\u57fa\u51c6\u4e0a\u6d4b\u8bd5\u4e86\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\uff08\u5305\u62ec\u6700\u5148\u8fdb\u7684OpenAI text-embedding-3-large\u548c\u4ea4\u53c9\u7f16\u7801\u5668\u6a21\u578b\uff09\u548cGPT-4\u4f5c\u4e3aLLM\u6cd5\u5b98\u3002", "result": "\u5728\u5408\u6210\u5e7b\u89c9\u4e0a\u8fbe\u523094%\u8986\u76d6\u7387\u548c0%\u8bef\u62a5\u7387\uff0c\u4f46\u5728\u4e09\u4e2a\u771f\u5b9e\u5e7b\u89c9\u57fa\u51c6\u4e0a\uff0c\u57fa\u4e8e\u5d4c\u5165\u7684\u65b9\u6cd5\u8bef\u62a5\u7387\u6781\u9ad8\uff08HaluEval 100%\u3001RAGTruth 88%\u3001WikiBio 50%\uff09\u3002GPT-4\u4f5c\u4e3aLLM\u6cd5\u5b98\u4ec57%\u8bef\u62a5\u7387\uff0c\u8bc1\u660e\u4efb\u52a1\u53ef\u901a\u8fc7\u63a8\u7406\u89e3\u51b3\u3002", "conclusion": "\u63d0\u51fa\u4e86\"\u8bed\u4e49\u5e7b\u89c9\"\u6982\u5ff5\uff1a\u8bed\u4e49\u4e0a\u5408\u7406\u7684\u5e7b\u89c9\u4fdd\u6301\u4e0e\u6e90\u6587\u6863\u7684\u76f8\u4f3c\u6027\uff0c\u540c\u65f6\u5f15\u5165\u5d4c\u5165\u65e0\u6cd5\u68c0\u6d4b\u7684\u4e8b\u5b9e\u9519\u8bef\u3002\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u6d4b\u65b9\u6cd5\u5728\u591a\u79cd\u67b6\u6784\u548c\u4efb\u52a1\u7c7b\u578b\u4e2d\u6301\u7eed\u5b58\u5728\u5c40\u9650\uff0c\u4e0d\u9002\u5408\u751f\u4ea7\u7ea7RAG\u90e8\u7f72\u3002", "topic": "agent analysis"}}
{"id": "2512.15176", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15176", "abs": "https://arxiv.org/abs/2512.15176", "authors": ["Zicong Cheng", "Guo-Wei Yang", "Jia Li", "Zhijie Deng", "Meng-Hao Guo", "Shi-Min Hu"], "title": "DEER: Draft with Diffusion, Verify with Autoregressive Models", "comment": "Homepage : https://czc726.github.io/DEER/", "summary": "Efficiency, as a critical practical challenge for LLM-driven agentic and reasoning systems, is increasingly constrained by the inherent latency of autoregressive (AR) decoding. Speculative decoding mitigates this cost through a draft-verify scheme, yet existing approaches rely on AR draft models (a.k.a., drafters), which introduce two fundamental issues: (1) step-wise uncertainty accumulation leads to a progressive collapse of trust between the target model and the drafter, and (2) inherently sequential decoding of AR drafters. Together, these factors cause limited speedups. In this paper, we show that a diffusion large language model (dLLM) drafters can naturally overcome these issues through its fundamentally different probabilistic modeling and efficient parallel decoding strategy. Building on this insight, we introduce DEER, an efficient speculative decoding framework that drafts with diffusion and verifies with AR models. To enable high-quality drafting, DEER employs a two-stage training pipeline to align the dLLM-based drafters with the target AR model, and further adopts single-step decoding to generate long draft segments. Experiments show DEER reaches draft acceptance lengths of up to 32 tokens, far surpassing the 10 tokens achieved by EAGLE-3. Moreover, on HumanEval with Qwen3-30B-A3B, DEER attains a 5.54x speedup, while EAGLE-3 achieves only 2.41x. Code, model, demo, etc, will be available at https://czc726.github.io/DEER/", "AI": {"tldr": "DEER\u63d0\u51fa\u4f7f\u7528\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8349\u7a3f\u5668\uff0c\u901a\u8fc7\u5e76\u884c\u89e3\u7801\u751f\u6210\u957f\u8349\u7a3f\u6bb5\uff0c\u663e\u8457\u63d0\u5347\u63a8\u6d4b\u89e3\u7801\u6548\u7387\uff0c\u5728HumanEval\u4e0a\u8fbe\u52305.54\u500d\u52a0\u901f\u3002", "motivation": "\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u4f9d\u8d56\u81ea\u56de\u5f52\u8349\u7a3f\u6a21\u578b\uff0c\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u95ee\u9898\uff1a1\uff09\u9010\u6b65\u4e0d\u786e\u5b9a\u6027\u7d2f\u79ef\u5bfc\u81f4\u76ee\u6807\u6a21\u578b\u4e0e\u8349\u7a3f\u5668\u4e4b\u95f4\u4fe1\u4efb\u9010\u6e10\u5d29\u6e83\uff1b2\uff09\u81ea\u56de\u5f52\u8349\u7a3f\u5668\u7684\u56fa\u6709\u987a\u5e8f\u89e3\u7801\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u52a0\u901f\u6548\u679c\u3002", "method": "\u63d0\u51faDEER\u6846\u67b6\uff0c\u4f7f\u7528\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8349\u7a3f\u5668\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\u5bf9\u9f50\u6269\u6563\u8349\u7a3f\u5668\u4e0e\u76ee\u6807\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u5355\u6b65\u89e3\u7801\u751f\u6210\u957f\u8349\u7a3f\u6bb5\u3002", "result": "DEER\u8fbe\u523032\u4e2atoken\u7684\u8349\u7a3f\u63a5\u53d7\u957f\u5ea6\uff0c\u8fdc\u8d85EAGLE-3\u768410\u4e2atoken\u3002\u5728HumanEval\u4e0a\u4f7f\u7528Qwen3-30B-A3B\u8fbe\u52305.54\u500d\u52a0\u901f\uff0c\u800cEAGLE-3\u4ec52.41\u500d\u3002", "conclusion": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u8349\u7a3f\u5668\u80fd\u81ea\u7136\u514b\u670d\u81ea\u56de\u5f52\u8349\u7a3f\u5668\u7684\u6839\u672c\u95ee\u9898\uff0c\u901a\u8fc7\u5e76\u884c\u89e3\u7801\u7b56\u7565\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u63a8\u6d4b\u89e3\u7801\uff0c\u663e\u8457\u63d0\u5347LLM\u9a71\u52a8\u7cfb\u7edf\u7684\u63a8\u7406\u6548\u7387\u3002", "topic": "agent analysis"}}
{"id": "2512.15405", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15405", "abs": "https://arxiv.org/abs/2512.15405", "authors": ["Jianfei Ma", "Wee Sun Lee"], "title": "EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning", "comment": null, "summary": "At the boundary between the known and the unknown, an agent inevitably confronts the dilemma of whether to explore or to exploit. Epistemic uncertainty reflects such boundaries, representing systematic uncertainty due to limited knowledge. In this paper, we propose a Bayesian reinforcement learning (RL) algorithm, $\\texttt{EUBRL}$, which leverages epistemic guidance to achieve principled exploration. This guidance adaptively reduces per-step regret arising from estimation errors. We establish nearly minimax-optimal regret and sample complexity guarantees for a class of sufficiently expressive priors in infinite-horizon discounted MDPs. Empirically, we evaluate $\\texttt{EUBRL}$ on tasks characterized by sparse rewards, long horizons, and stochasticity. Results demonstrate that $\\texttt{EUBRL}$ achieves superior sample efficiency, scalability, and consistency.", "AI": {"tldr": "\u63d0\u51faEUBRL\u7b97\u6cd5\uff0c\u5229\u7528\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6307\u5bfc\u63a2\u7d22\uff0c\u5728\u65e0\u9650\u65f6\u57df\u6298\u6263MDP\u4e2d\u5b9e\u73b0\u63a5\u8fd1\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7684\u9057\u61be\u548c\u6837\u672c\u590d\u6742\u5ea6", "motivation": "\u667a\u80fd\u4f53\u5728\u5df2\u77e5\u4e0e\u672a\u77e5\u8fb9\u754c\u9762\u4e34\u63a2\u7d22-\u5229\u7528\u56f0\u5883\uff0c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u53cd\u6620\u4e86\u77e5\u8bc6\u6709\u9650\u5bfc\u81f4\u7684\u7cfb\u7edf\u6027\u4e0d\u786e\u5b9a\u6027\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u8ba4\u77e5\u6307\u5bfc\u5b9e\u73b0\u539f\u5219\u6027\u63a2\u7d22\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5EUBRL\uff0c\u5229\u7528\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6307\u5bfc\u63a2\u7d22\uff0c\u81ea\u9002\u5e94\u51cf\u5c11\u7531\u4f30\u8ba1\u8bef\u5dee\u5f15\u8d77\u7684\u6bcf\u6b65\u9057\u61be\u3002\u7b97\u6cd5\u9002\u7528\u4e8e\u5177\u6709\u5145\u5206\u8868\u8fbe\u80fd\u529b\u5148\u9a8c\u7684\u65e0\u9650\u65f6\u57df\u6298\u6263MDP\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eEUBRL\u5728\u65e0\u9650\u65f6\u57df\u6298\u6263MDP\u4e2d\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6781\u5c0f\u6781\u5927\u6700\u4f18\u7684\u9057\u61be\u548c\u6837\u672c\u590d\u6742\u5ea6\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u5728\u7a00\u758f\u5956\u52b1\u3001\u957f\u65f6\u57df\u548c\u968f\u673a\u6027\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u4f18\u8d8a\u6837\u672c\u6548\u7387\u3001\u53ef\u6269\u5c55\u6027\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "EUBRL\u901a\u8fc7\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6307\u5bfc\u5b9e\u73b0\u4e86\u539f\u5219\u6027\u63a2\u7d22\uff0c\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22-\u5229\u7528\u56f0\u5883\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.15430", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15430", "abs": "https://arxiv.org/abs/2512.15430", "authors": ["Quanxi Zhou", "Wencan Mao", "Manabu Tsukada", "John C. S. Lui", "Yusheng Ji"], "title": "FM-EAC: Feature Model-based Enhanced Actor-Critic for Multi-Task Control in Dynamic Environments", "comment": null, "summary": "Model-based reinforcement learning (MBRL) and model-free reinforcement learning (MFRL) evolve along distinct paths but converge in the design of Dyna-Q [1]. However, modern RL methods still struggle with effective transferability across tasks and scenarios. Motivated by this limitation, we propose a generalized algorithm, Feature Model-Based Enhanced Actor-Critic (FM-EAC), that integrates planning, acting, and learning for multi-task control in dynamic environments. FM-EAC combines the strengths of MBRL and MFRL and improves generalizability through the use of novel feature-based models and an enhanced actor-critic framework. Simulations in both urban and agricultural applications demonstrate that FM-EAC consistently outperforms many state-of-the-art MBRL and MFRL methods. More importantly, different sub-networks can be customized within FM-EAC according to user-specific requirements.", "AI": {"tldr": "\u63d0\u51faFM-EAC\u7b97\u6cd5\uff0c\u7ed3\u5408\u57fa\u4e8e\u6a21\u578b\u548c\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u7279\u5f81\u6a21\u578b\u548c\u589e\u5f3a\u7684actor-critic\u6846\u67b6\u63d0\u5347\u591a\u4efb\u52a1\u63a7\u5236\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u4ee3\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u8de8\u4efb\u52a1\u548c\u573a\u666f\u7684\u6709\u6548\u8fc1\u79fb\u6027\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u56f0\u96be\uff0c\u5c3d\u7ba1\u57fa\u4e8e\u6a21\u578b\u548c\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u5728Dyna-Q\u4e2d\u6709\u6240\u878d\u5408\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faFM-EAC\uff08\u7279\u5f81\u6a21\u578b\u589e\u5f3aactor-critic\uff09\u7b97\u6cd5\uff0c\u6574\u5408\u89c4\u5212\u3001\u884c\u52a8\u548c\u5b66\u4e60\uff0c\u4f7f\u7528\u65b0\u9896\u7684\u7279\u5f81\u6a21\u578b\u548c\u589e\u5f3a\u7684actor-critic\u6846\u67b6\uff0c\u652f\u6301\u6839\u636e\u7528\u6237\u9700\u6c42\u5b9a\u5236\u5b50\u7f51\u7edc\u3002", "result": "\u5728\u57ce\u5e02\u548c\u519c\u4e1a\u5e94\u7528\u4eff\u771f\u4e2d\uff0cFM-EAC\u6301\u7eed\u4f18\u4e8e\u591a\u79cd\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u6a21\u578b\u548c\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "FM-EAC\u6210\u529f\u7ed3\u5408\u4e86\u57fa\u4e8e\u6a21\u578b\u548c\u65e0\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u52bf\uff0c\u901a\u8fc7\u7279\u5f81\u6a21\u578b\u548c\u589e\u5f3a\u7684actor-critic\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u63a7\u5236\u7684\u6cdb\u5316\u80fd\u529b\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.15596", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15596", "abs": "https://arxiv.org/abs/2512.15596", "authors": ["Shuibai Zhang", "Fred Zhangzhi Peng", "Yiheng Zhang", "Jin Pan", "Grigorios G. Chrysos"], "title": "Corrective Diffusion Language Models", "comment": "18 pages", "summary": "Diffusion language models are structurally well-suited for iterative error correction, as their non-causal denoising dynamics allow arbitrary positions in a sequence to be revised. However, standard masked diffusion language model (MDLM) training fails to reliably induce this behavior, as models often cannot identify unreliable tokens in a complete input, rendering confidence-guided refinement ineffective. We study corrective behavior in diffusion language models, defined as the ability to assign lower confidence to incorrect tokens and iteratively refine them while preserving correct content. We show that this capability is not induced by conventional masked diffusion objectives and propose a correction-oriented post-training principle that explicitly supervises visible incorrect tokens, enabling error-aware confidence and targeted refinement. To evaluate corrective behavior, we introduce the Code Revision Benchmark (CRB), a controllable and executable benchmark for assessing error localization and in-place correction. Experiments on code revision tasks and controlled settings demonstrate that models trained with our approach substantially outperform standard MDLMs in correction scenarios, while also improving pure completion performance. Our code is publicly available at https://github.com/zhangshuibai/CDLM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u6821\u6b63\u5bfc\u5411\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u76d1\u7763\u53ef\u89c1\u7684\u9519\u8bef\u6807\u8bb0\u6765\u63d0\u5347\u9519\u8bef\u5b9a\u4f4d\u548c\u8fed\u4ee3\u4fee\u6b63\u80fd\u529b\uff0c\u5e76\u5728\u4ee3\u7801\u4fee\u8ba2\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u6784\u4e0a\u9002\u5408\u8fed\u4ee3\u9519\u8bef\u4fee\u6b63\uff0c\u4f46\u6807\u51c6\u7684\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65e0\u6cd5\u53ef\u9760\u5730\u8bf1\u5bfc\u8fd9\u79cd\u6821\u6b63\u884c\u4e3a\uff0c\u56e0\u4e3a\u6a21\u578b\u5e38\u5e38\u65e0\u6cd5\u8bc6\u522b\u5b8c\u6574\u8f93\u5165\u4e2d\u7684\u4e0d\u53ef\u9760\u6807\u8bb0\uff0c\u5bfc\u81f4\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u4fee\u6b63\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u6821\u6b63\u5bfc\u5411\u7684\u540e\u8bad\u7ec3\u539f\u5219\uff0c\u663e\u5f0f\u76d1\u7763\u53ef\u89c1\u7684\u9519\u8bef\u6807\u8bb0\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u9519\u8bef\u611f\u77e5\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u548c\u9488\u5bf9\u6027\u4fee\u6b63\u3002\u540c\u65f6\u5f15\u5165\u4e86\u4ee3\u7801\u4fee\u8ba2\u57fa\u51c6\uff08CRB\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u53ef\u63a7\u4e14\u53ef\u6267\u884c\u7684\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u9519\u8bef\u5b9a\u4f4d\u548c\u539f\u5730\u4fee\u6b63\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u65b9\u6cd5\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6821\u6b63\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u63a9\u7801\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4e5f\u5728\u7eaf\u5b8c\u6210\u4efb\u52a1\u4e0a\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u6821\u6b63\u5bfc\u5411\u7684\u8bad\u7ec3\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u9519\u8bef\u4fee\u6b63\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u53ef\u9760\u5730\u8bc6\u522b\u548c\u4fee\u6b63\u9519\u8bef\u6807\u8bb0\uff0c\u540c\u65f6\u4fdd\u6301\u6b63\u786e\u5185\u5bb9\u4e0d\u53d8\u3002", "topic": "code agent"}}
{"id": "2512.15605", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.15605", "abs": "https://arxiv.org/abs/2512.15605", "authors": ["Mathieu Blondel", "Michael E. Sander", "Germain Vivier-Ardisson", "Tianlin Liu", "Vincent Roulet"], "title": "Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction", "comment": null, "summary": "Autoregressive models (ARMs) currently constitute the dominant paradigm for large language models (LLMs). Energy-based models (EBMs) represent another class of models, which have historically been less prevalent in LLM development, yet naturally characterize the optimal policy in post-training alignment. In this paper, we provide a unified view of these two model classes. Taking the chain rule of probability as a starting point, we establish an explicit bijection between ARMs and EBMs in function space, which we show to correspond to a special case of the soft Bellman equation in maximum entropy reinforcement learning. Building upon this bijection, we derive the equivalence between supervised learning of ARMs and EBMs. Furthermore, we analyze the distillation of EBMs into ARMs by providing theoretical error bounds. Our results provide insights into the ability of ARMs to plan ahead, despite being based on the next-token prediction paradigm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u7acb\u4e86\u81ea\u56de\u5f52\u6a21\u578b\uff08ARMs\uff09\u4e0e\u80fd\u91cf\u6a21\u578b\uff08EBMs\uff09\u4e4b\u95f4\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e24\u8005\u5728\u51fd\u6570\u7a7a\u95f4\u5b58\u5728\u663e\u5f0f\u53cc\u5c04\u5173\u7cfb\uff0c\u5e76\u63a8\u5bfc\u4e86\u76d1\u7763\u5b66\u4e60\u7684\u7b49\u4ef7\u6027\u4ee5\u53caEBMs\u84b8\u998f\u5230ARMs\u7684\u7406\u8bba\u8bef\u5dee\u754c\u3002", "motivation": "\u81ea\u56de\u5f52\u6a21\u578b\u662f\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u6d41\u8303\u5f0f\uff0c\u800c\u80fd\u91cf\u6a21\u578b\u867d\u7136\u5728LLM\u5f00\u53d1\u4e2d\u8f83\u5c11\u4f7f\u7528\uff0c\u4f46\u5929\u7136\u8868\u5f81\u4e86\u540e\u8bad\u7ec3\u5bf9\u9f50\u4e2d\u7684\u6700\u4f18\u7b56\u7565\u3002\u4f5c\u8005\u5e0c\u671b\u5efa\u7acb\u8fd9\u4e24\u7c7b\u6a21\u578b\u4e4b\u95f4\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u4ee5\u6df1\u5165\u7406\u89e3ARMs\u7684\u89c4\u5212\u80fd\u529b\u3002", "method": "\u4ece\u6982\u7387\u94fe\u5f0f\u6cd5\u5219\u51fa\u53d1\uff0c\u5728\u51fd\u6570\u7a7a\u95f4\u4e2d\u5efa\u7acbARMs\u4e0eEBMs\u4e4b\u95f4\u7684\u663e\u5f0f\u53cc\u5c04\u5173\u7cfb\uff0c\u8bc1\u660e\u8be5\u5173\u7cfb\u5bf9\u5e94\u6700\u5927\u71b5\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8f6f\u8d1d\u5c14\u66fc\u65b9\u7a0b\u7279\u4f8b\u3002\u5728\u6b64\u57fa\u7840\u4e0a\u63a8\u5bfc\u76d1\u7763\u5b66\u4e60\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u5206\u6790EBMs\u84b8\u998f\u5230ARMs\u7684\u7406\u8bba\u8bef\u5dee\u754c\u3002", "result": "\u5efa\u7acb\u4e86ARMs\u4e0eEBMs\u4e4b\u95f4\u7684\u7edf\u4e00\u7406\u8bba\u6846\u67b6\uff0c\u8bc1\u660e\u4e86\u76d1\u7763\u5b66\u4e60\u7684\u7b49\u4ef7\u6027\uff0c\u63d0\u4f9b\u4e86EBMs\u84b8\u998f\u5230ARMs\u7684\u7406\u8bba\u8bef\u5dee\u754c\uff0c\u4e3a\u7406\u89e3ARMs\u57fa\u4e8e\u4e0b\u4e00\u4e2atoken\u9884\u6d4b\u8303\u5f0f\u5374\u5177\u5907\u89c4\u5212\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u81ea\u56de\u5f52\u6a21\u578b\u548c\u80fd\u91cf\u6a21\u578b\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u6df1\u5c42\u8054\u7cfb\uff0c\u4e3a\u7406\u89e3ARMs\u7684\u89c4\u5212\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u4e3a\u6a21\u578b\u84b8\u998f\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002", "topic": "agent analysis"}}
{"id": "tldr.2512.3bdf0e91", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.testingcatalog.com%2Fanthropic-testing-new-agentic-tasks-mode-for-claude%2F%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/oc3GK8TYK9HiUUxE5Xorzpo0j1FhTSypXnB1D649nr8=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.testingcatalog.com%2Fanthropic-testing-new-agentic-tasks-mode-for-claude%2F%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/oc3GK8TYK9HiUUxE5Xorzpo0j1FhTSypXnB1D649nr8=436", "authors": ["TLDR Newsletter"], "title": "Anthropic preparing new Agentic Tasks Mode for Claude", "comment": "Source: TLDR Newsletter, Date: 2025-12-16, Reading time: 2 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.testingcatalog.com%2Fanthropic-testing-new-agentic-tasks-mode-for-claude%2F%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/oc3GK8TYK9HiUUxE5Xorzpo0j1FhTSypXnB1D649nr8=436", "summary": "Anthropic preparing new Agentic Tasks Mode for Claude (2 minute read) Anthropic is testing a new interface for tasks in Claude's Agent mode. It is also introducing new modes for research, analysis, writing, and building. The updated interface introduces a toggle that allows users to switch between classic chat and agent modes. Screenshots of the new interface are available in the article.", "source": "tldr", "AI": {"tldr": "Anthropic\u6b63\u5728\u4e3aClaude\u7684Agent\u6a21\u5f0f\u6d4b\u8bd5\u65b0\u7684\u4efb\u52a1\u754c\u9762\uff0c\u589e\u52a0\u4e86\u7814\u7a76\u3001\u5206\u6790\u3001\u5199\u4f5c\u548c\u6784\u5efa\u7b49\u65b0\u6a21\u5f0f\uff0c\u5e76\u63d0\u4f9b\u7ecf\u5178\u804a\u5929\u4e0eAgent\u6a21\u5f0f\u4e4b\u95f4\u7684\u5207\u6362\u529f\u80fd\u3002", "motivation": "Anthropic\u5e0c\u671b\u6539\u8fdbClaude\u7684Agent\u6a21\u5f0f\u7528\u6237\u4f53\u9a8c\uff0c\u901a\u8fc7\u66f4\u76f4\u89c2\u7684\u754c\u9762\u8bbe\u8ba1\u548c\u4e13\u95e8\u7684\u4efb\u52a1\u6a21\u5f0f\uff0c\u8ba9\u7528\u6237\u80fd\u66f4\u9ad8\u6548\u5730\u4f7f\u7528Claude\u8fdb\u884c\u4e0d\u540c\u7c7b\u578b\u7684\u4efb\u52a1\u5904\u7406\u3002", "method": "\u5f00\u53d1\u65b0\u7684\u4efb\u52a1\u754c\u9762\uff0c\u5f15\u5165\u7814\u7a76\u3001\u5206\u6790\u3001\u5199\u4f5c\u3001\u6784\u5efa\u7b49\u4e13\u95e8\u6a21\u5f0f\uff0c\u5e76\u6dfb\u52a0\u7ecf\u5178\u804a\u5929\u4e0eAgent\u6a21\u5f0f\u4e4b\u95f4\u7684\u5207\u6362\u529f\u80fd\uff0c\u901a\u8fc7\u754c\u9762\u622a\u56fe\u5c55\u793a\u65b0\u8bbe\u8ba1\u3002", "result": "\u65b0\u7684Agentic Tasks Mode\u754c\u9762\u6b63\u5728\u6d4b\u8bd5\u4e2d\uff0c\u63d0\u4f9b\u4e86\u66f4\u76f4\u89c2\u7684\u4efb\u52a1\u5207\u6362\u548c\u6a21\u5f0f\u9009\u62e9\u529f\u80fd\uff0c\u6539\u5584\u4e86\u7528\u6237\u4e0eClaude Agent\u7684\u4ea4\u4e92\u4f53\u9a8c\u3002", "conclusion": "Anthropic\u901a\u8fc7\u754c\u9762\u6539\u8fdb\u589e\u5f3a\u4e86Claude Agent\u6a21\u5f0f\u7684\u529f\u80fd\u6027\u548c\u6613\u7528\u6027\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u4e13\u4e1a\u5316\u7684\u4efb\u52a1\u5904\u7406\u5de5\u5177\u3002", "topic": "code agent"}}
{"id": "tldr.2512.39cd484c", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.ashpreetbedi.com%2Farticles%2Fsql-agent%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/P2vRZqAsbDazM2meKY4LJOV_8L_0WCijnTPVb36LeK8=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.ashpreetbedi.com%2Farticles%2Fsql-agent%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/P2vRZqAsbDazM2meKY4LJOV_8L_0WCijnTPVb36LeK8=436", "authors": ["TLDR Newsletter"], "title": "Self Improving Agent with Dynamic Context and Continuous Learning", "comment": "Source: TLDR Newsletter, Date: 2025-12-16, Reading time: 11 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.ashpreetbedi.com%2Farticles%2Fsql-agent%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/P2vRZqAsbDazM2meKY4LJOV_8L_0WCijnTPVb36LeK8=436", "summary": "Self Improving Agent with Dynamic Context and Continuous Learning (11 minute read) This guide walks readers through how to build a self-improving Text-to-SQL agent using dynamic context and 'poor-man's continuous learning'. The agent answers questions by retrieving data from a knowledge base. It learns from successful runs by adding to the knowledge base, creating a self-improving feedback loop. A video that shows the agent in action is available at the end of the article.", "source": "tldr", "AI": {"tldr": "\u6784\u5efa\u4e00\u4e2a\u4f7f\u7528\u52a8\u6001\u4e0a\u4e0b\u6587\u548c\"\u7a77\u4eba\u7248\u6301\u7eed\u5b66\u4e60\"\u7684\u81ea\u6211\u6539\u8fdbText-to-SQL\u4ee3\u7406\uff0c\u8be5\u4ee3\u7406\u901a\u8fc7\u68c0\u7d22\u77e5\u8bc6\u5e93\u56de\u7b54\u95ee\u9898\uff0c\u5e76\u4ece\u6210\u529f\u8fd0\u884c\u4e2d\u5b66\u4e60\u4ee5\u6269\u5c55\u77e5\u8bc6\u5e93\uff0c\u5f62\u6210\u81ea\u6211\u6539\u8fdb\u7684\u53cd\u9988\u5faa\u73af\u3002", "motivation": "\u4f20\u7edfText-to-SQL\u4ee3\u7406\u901a\u5e38\u7f3a\u4e4f\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u7684\u80fd\u529b\uff0c\u6bcf\u6b21\u67e5\u8be2\u90fd\u662f\u72ec\u7acb\u7684\u3002\u672c\u6587\u65e8\u5728\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u4ece\u6210\u529f\u6267\u884c\u4e2d\u5b66\u4e60\u5e76\u6301\u7eed\u6539\u8fdb\u7684\u667a\u80fd\u4ee3\u7406\uff0c\u901a\u8fc7\u6784\u5efa\u81ea\u6211\u6539\u8fdb\u7684\u53cd\u9988\u5faa\u73af\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u91c7\u7528\u52a8\u6001\u4e0a\u4e0b\u6587\u673a\u5236\u548c\"\u7a77\u4eba\u7248\u6301\u7eed\u5b66\u4e60\"\u65b9\u6cd5\u3002\u4ee3\u7406\u901a\u8fc7\u68c0\u7d22\u77e5\u8bc6\u5e93\u6765\u56de\u7b54SQL\u67e5\u8be2\u95ee\u9898\uff0c\u5f53\u6210\u529f\u6267\u884c\u67e5\u8be2\u540e\uff0c\u5c06\u76f8\u5173\u4e0a\u4e0b\u6587\u548c\u89e3\u51b3\u65b9\u6848\u6dfb\u52a0\u5230\u77e5\u8bc6\u5e93\u4e2d\uff0c\u5f62\u6210\u6301\u7eed\u5b66\u4e60\u7684\u5faa\u73af\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u9700\u8981\u590d\u6742\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u800c\u662f\u901a\u8fc7\u7b80\u5355\u7684\u77e5\u8bc6\u79ef\u7d2f\u5b9e\u73b0\u81ea\u6211\u6539\u8fdb\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u80fd\u591f\u81ea\u6211\u6539\u8fdb\u7684Text-to-SQL\u4ee3\u7406\u7cfb\u7edf\u3002\u4ee3\u7406\u80fd\u591f\u4ece\u5386\u53f2\u6210\u529f\u6848\u4f8b\u4e2d\u5b66\u4e60\uff0c\u968f\u7740\u4f7f\u7528\u65f6\u95f4\u7684\u589e\u52a0\uff0c\u5176\u56de\u7b54\u51c6\u786e\u6027\u548c\u6548\u7387\u4f1a\u9010\u6b65\u63d0\u5347\u3002\u6587\u7ae0\u63d0\u4f9b\u4e86\u6f14\u793a\u89c6\u9891\u5c55\u793a\u4ee3\u7406\u7684\u5b9e\u9645\u8fd0\u884c\u6548\u679c\u3002", "conclusion": "\u901a\u8fc7\u52a8\u6001\u4e0a\u4e0b\u6587\u548c\u7b80\u5355\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6784\u5efa\u6709\u6548\u7684\u81ea\u6211\u6539\u8fdbText-to-SQL\u4ee3\u7406\u3002\u8fd9\u79cd\"\u7a77\u4eba\u7248\"\u65b9\u6cd5\u867d\u7136\u7b80\u5355\uff0c\u4f46\u80fd\u591f\u5b9e\u73b0\u4ee3\u7406\u6027\u80fd\u7684\u6301\u7eed\u63d0\u5347\uff0c\u4e3a\u6784\u5efa\u66f4\u667a\u80fd\u7684\u6570\u636e\u5e93\u67e5\u8be2\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002", "topic": "code agent"}}
{"id": "tldr.2512.0acc1060", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2F200k-tokens-is-plenty%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/03KXkMBBzWF85mzkEnCcRDha2osuQhyLu6rMFPy2uoA=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2F200k-tokens-is-plenty%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/03KXkMBBzWF85mzkEnCcRDha2osuQhyLu6rMFPy2uoA=436", "authors": ["TLDR Newsletter"], "title": "200k Tokens Is Plenty", "comment": "Source: TLDR Newsletter, Date: 2025-12-16, Reading time: 6 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2F200k-tokens-is-plenty%3Futm_source=tldrai/1/0100019b278508dd-bc1490d3-afb7-429a-91e5-642c70b93734-000000/03KXkMBBzWF85mzkEnCcRDha2osuQhyLu6rMFPy2uoA=436", "summary": "200k Tokens Is Plenty (6 minute read) Claude Opus 4.5 is considered the best model for coding, and it only has a context window of roughly 200,000 tokens. While some people feel like that is not a lot, that can be plenty for developers who use short threads. The best threads are short, with just the right amount of context. The longer the conversation, the more an agent's context window gets filled up with junk. You only need to give agents the context they need to get the job done, and no more.", "source": "tldr", "AI": {"tldr": "Claude Opus 4.5\u768420\u4e07token\u4e0a\u4e0b\u6587\u7a97\u53e3\u5bf9\u7f16\u7801\u4efb\u52a1\u8db3\u591f\uff0c\u56e0\u4e3a\u6700\u4f73\u5bf9\u8bdd\u7ebf\u7a0b\u5e94\u8be5\u7b80\u77ed\u4e14\u53ea\u5305\u542b\u5fc5\u8981\u4e0a\u4e0b\u6587\uff0c\u907f\u514d\u4e0a\u4e0b\u6587\u7a97\u53e3\u88ab\u65e0\u7528\u4fe1\u606f\u586b\u6ee1\u3002", "motivation": "\u9488\u5bf9\u6709\u4eba\u8ba4\u4e3a20\u4e07token\u4e0a\u4e0b\u6587\u7a97\u53e3\u4e0d\u591f\u5927\u7684\u89c2\u70b9\uff0c\u4f5c\u8005\u8ba4\u4e3a\u5bf9\u4e8e\u7f16\u7801\u4efb\u52a1\u6765\u8bf4\u8fd9\u5df2\u7ecf\u8db3\u591f\uff0c\u5173\u952e\u5728\u4e8e\u5982\u4f55\u6709\u6548\u4f7f\u7528\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002", "method": "\u901a\u8fc7\u5206\u6790Claude Opus 4.5\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\uff0c\u5f3a\u8c03\u7b80\u77ed\u5bf9\u8bdd\u7ebf\u7a0b\u7684\u91cd\u8981\u6027\uff0c\u5efa\u8bae\u53ea\u63d0\u4f9b\u5b8c\u6210\u4efb\u52a1\u6240\u9700\u7684\u5fc5\u8981\u4e0a\u4e0b\u6587\u3002", "result": "20\u4e07token\u7684\u4e0a\u4e0b\u6587\u7a97\u53e3\u5bf9\u4e8e\u7f16\u7801\u4efb\u52a1\u6765\u8bf4\u662f\u5145\u8db3\u7684\uff0c\u5173\u952e\u5728\u4e8e\u4fdd\u6301\u5bf9\u8bdd\u7ebf\u7a0b\u7b80\u77ed\uff0c\u53ea\u5305\u542b\u76f8\u5173\u4e0a\u4e0b\u6587\uff0c\u907f\u514d\u4e0a\u4e0b\u6587\u7a97\u53e3\u88ab\u65e0\u7528\u4fe1\u606f\u5360\u7528\u3002", "conclusion": "\u5bf9\u4e8e\u5f00\u53d1\u8005\u6765\u8bf4\uff0cClaude Opus 4.5\u768420\u4e07token\u4e0a\u4e0b\u6587\u7a97\u53e3\u5b8c\u5168\u8db3\u591f\uff0c\u5173\u952e\u5728\u4e8e\u4f7f\u7528\u7b80\u77ed\u3001\u6709\u9488\u5bf9\u6027\u7684\u5bf9\u8bdd\u7ebf\u7a0b\uff0c\u53ea\u63d0\u4f9b\u5fc5\u8981\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "topic": "code agent"}}
{"id": "tldr.2512.735ae07d", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2FMoonshotAI%2Fkimi-cli%3Futm_source=tldrdevops/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/X5JpfyYnBeG039vhkFAMlip-hMxYr0uuLoG9EZAivH0=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2FMoonshotAI%2Fkimi-cli%3Futm_source=tldrdevops/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/X5JpfyYnBeG039vhkFAMlip-hMxYr0uuLoG9EZAivH0=436", "authors": ["TLDR Newsletter"], "title": "Kimi CLI", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2FMoonshotAI%2Fkimi-cli%3Futm_source=tldrdevops/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/X5JpfyYnBeG039vhkFAMlip-hMxYr0uuLoG9EZAivH0=436", "summary": "Kimi CLI (GitHub Repo) Kimi CLI, a new command-line interface agent for software development and terminal operations, has been released in technical preview. This Python package, installable via `uv`, functions as both a coding agent and a shell, offering integrations with ACP-compatible editors like Zed and JetBrains, as well as Zsh.", "source": "tldr", "AI": {"tldr": "Kimi CLI\u662f\u4e00\u4e2a\u65b0\u7684\u547d\u4ee4\u884c\u754c\u9762\u4ee3\u7406\uff0c\u7528\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u548c\u7ec8\u7aef\u64cd\u4f5c\uff0c\u53ef\u4f5c\u4e3a\u7f16\u7801\u4ee3\u7406\u548cshell\u4f7f\u7528\uff0c\u652f\u6301ACP\u517c\u5bb9\u7f16\u8f91\u5668\u96c6\u6210\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u96c6\u6210\u7684\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u5c06AI\u7f16\u7801\u52a9\u624b\u529f\u80fd\u4e0e\u7ec8\u7aef\u64cd\u4f5c\u76f8\u7ed3\u5408\uff0c\u63d0\u9ad8\u5f00\u53d1\u8005\u5728\u8f6f\u4ef6\u5f00\u53d1\u548c\u65e5\u5e38\u7ec8\u7aef\u4efb\u52a1\u4e2d\u7684\u6548\u7387\u3002", "method": "\u5f00\u53d1Python\u5305\u4f5c\u4e3a\u547d\u4ee4\u884c\u754c\u9762\u4ee3\u7406\uff0c\u63d0\u4f9b\u7f16\u7801\u4ee3\u7406\u548cshell\u529f\u80fd\uff0c\u96c6\u6210ACP\u517c\u5bb9\u7f16\u8f91\u5668\uff08\u5982Zed\u548cJetBrains\uff09\u4ee5\u53caZsh\u3002", "result": "\u53d1\u5e03\u4e86Kimi CLI\u6280\u672f\u9884\u89c8\u7248\uff0c\u53ef\u901a\u8fc7uv\u5b89\u88c5\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684AI\u8f85\u52a9\u5f00\u53d1\u548c\u7ec8\u7aef\u64cd\u4f5c\u4f53\u9a8c\u3002", "conclusion": "Kimi CLI\u6210\u529f\u521b\u5efa\u4e86\u4e00\u4e2a\u96c6\u6210\u7684\u5f00\u53d1\u5de5\u5177\uff0c\u5c06AI\u7f16\u7801\u52a9\u624b\u4e0e\u7ec8\u7aefshell\u529f\u80fd\u7ed3\u5408\uff0c\u6709\u671b\u63d0\u5347\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u7684\u6548\u7387\u3002", "topic": "code agent"}}
{"id": "tldr.2512.cef92fdb", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Faws-reinvent-kiro-docker-sandboxes-mcp-catalog%2F%3Futm_source=tldrdevops/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/xAFCer5Ehib3T1kOQfIhk_Tmei3_Thu8e1XBu3m9emQ=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Faws-reinvent-kiro-docker-sandboxes-mcp-catalog%2F%3Futm_source=tldrdevops/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/xAFCer5Ehib3T1kOQfIhk_Tmei3_Thu8e1XBu3m9emQ=436", "authors": ["TLDR Newsletter"], "title": "Highlights from AWS re:Invent: Supercharging Kiro with Docker Sandboxes and MCP Catalog", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Reading time: 5 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.docker.com%2Fblog%2Faws-reinvent-kiro-docker-sandboxes-mcp-catalog%2F%3Futm_source=tldrdevops/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/xAFCer5Ehib3T1kOQfIhk_Tmei3_Thu8e1XBu3m9emQ=436", "summary": "Highlights from AWS re:Invent: Supercharging Kiro with Docker Sandboxes and MCP Catalog (5 minute read) Docker Sandboxes and the MCP Toolkit can run AI agents like Kiro in isolated containers, preventing access to host files and credentials while enabling safe code changes, testing, and tool use.", "source": "tldr", "AI": {"tldr": "AWS re:Invent\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528Docker\u6c99\u7bb1\u548cMCP\u5de5\u5177\u5305\u6765\u5b89\u5168\u8fd0\u884cKiro\u7b49AI\u4ee3\u7406\uff0c\u901a\u8fc7\u5bb9\u5668\u9694\u79bb\u4fdd\u62a4\u4e3b\u673a\u6587\u4ef6\u4e0e\u51ed\u8bc1\uff0c\u540c\u65f6\u652f\u6301\u5b89\u5168\u7684\u4ee3\u7801\u4fee\u6539\u3001\u6d4b\u8bd5\u548c\u5de5\u5177\u4f7f\u7528\u3002", "motivation": "AI\u4ee3\u7406\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u4f46\u76f4\u63a5\u8fd0\u884c\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u53ef\u80fd\u8bbf\u95ee\u4e3b\u673a\u654f\u611f\u6587\u4ef6\u548c\u51ed\u8bc1\u3002\u9700\u8981\u4e00\u79cd\u5b89\u5168\u673a\u5236\u6765\u9694\u79bbAI\u4ee3\u7406\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u529f\u80fd\u5b8c\u6574\u6027\u3002", "method": "\u91c7\u7528Docker\u6c99\u7bb1\u6280\u672f\u521b\u5efa\u9694\u79bb\u5bb9\u5668\u73af\u5883\uff0c\u7ed3\u5408MCP\uff08Model Context Protocol\uff09\u5de5\u5177\u5305\uff0c\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u5b89\u5168\u7684\u8fd0\u884c\u73af\u5883\uff0c\u9650\u5236\u5bf9\u4e3b\u673a\u7cfb\u7edf\u7684\u8bbf\u95ee\u6743\u9650\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86Kiro\u7b49AI\u4ee3\u7406\u5728\u9694\u79bb\u5bb9\u5668\u4e2d\u7684\u5b89\u5168\u8fd0\u884c\uff0c\u9632\u6b62\u4e86\u5bf9\u4e3b\u673a\u6587\u4ef6\u548c\u51ed\u8bc1\u7684\u8bbf\u95ee\uff0c\u540c\u65f6\u652f\u6301\u4ee3\u7801\u4fee\u6539\u3001\u6d4b\u8bd5\u548c\u5de5\u5177\u4f7f\u7528\u7684\u5b8c\u6574\u529f\u80fd\u3002", "conclusion": "Docker\u6c99\u7bb1\u4e0eMCP\u5de5\u5177\u5305\u7684\u7ed3\u5408\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u9760\u7684\u8fd0\u884c\u73af\u5883\uff0c\u662fAI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u7684\u91cd\u8981\u57fa\u7840\u8bbe\u65bd\u6539\u8fdb\u3002", "topic": "code agent"}}
{"id": "tldr.2512.89defa9b", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdevops%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/tnTGvuyGkqPd7XRdrihuXWCZ7jX9DfYKksGh-sqI-04=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdevops%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/tnTGvuyGkqPd7XRdrihuXWCZ7jX9DfYKksGh-sqI-04=436", "authors": ["TLDR Newsletter"], "title": "advertise with us", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdevops%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/tnTGvuyGkqPd7XRdrihuXWCZ7jX9DfYKksGh-sqI-04=436", "summary": "Highlights from AWS re:Invent: Supercharging Kiro with Docker Sandboxes and MCP Catalog (5 minute read) Docker Sandboxes and the MCP Toolkit can run AI agents like Kiro in isolated containers, preventing access to host files and credentials while enabling safe code changes, testing, and tool use.", "source": "tldr", "AI": {"tldr": "AWS re:Invent\u5c55\u793a\u7684Docker\u6c99\u7bb1\u548cMCP\u5de5\u5177\u5305\u80fd\u8ba9Kiro\u7b49AI\u4ee3\u7406\u5728\u9694\u79bb\u5bb9\u5668\u4e2d\u8fd0\u884c\uff0c\u4fdd\u62a4\u4e3b\u673a\u6587\u4ef6\u5b89\u5168\u7684\u540c\u65f6\u652f\u6301\u5b89\u5168\u4ee3\u7801\u4fee\u6539\u3001\u6d4b\u8bd5\u548c\u5de5\u5177\u4f7f\u7528\u3002", "motivation": "\u89e3\u51b3AI\u4ee3\u7406\u5728\u8fd0\u884c\u65f6\u7684\u5b89\u5168\u95ee\u9898\uff0c\u9632\u6b62\u5176\u8bbf\u95ee\u4e3b\u673a\u654f\u611f\u6587\u4ef6\u548c\u51ed\u8bc1\uff0c\u540c\u65f6\u63d0\u4f9b\u5b89\u5168\u7684\u4ee3\u7801\u4fee\u6539\u548c\u6d4b\u8bd5\u73af\u5883\u3002", "method": "\u4f7f\u7528Docker\u6c99\u7bb1\u6280\u672f\u521b\u5efa\u9694\u79bb\u5bb9\u5668\u73af\u5883\uff0c\u7ed3\u5408MCP\uff08Model Context Protocol\uff09\u5de5\u5177\u5305\u6765\u7ba1\u7406AI\u4ee3\u7406\u7684\u8fd0\u884c\u73af\u5883\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86Kiro\u7b49AI\u4ee3\u7406\u5728\u9694\u79bb\u5bb9\u5668\u4e2d\u7684\u5b89\u5168\u8fd0\u884c\uff0c\u65e2\u80fd\u6267\u884c\u4ee3\u7801\u4fee\u6539\u548c\u6d4b\u8bd5\uff0c\u53c8\u80fd\u9632\u6b62\u5bf9\u4e3b\u673a\u7cfb\u7edf\u7684\u5b89\u5168\u5a01\u80c1\u3002", "conclusion": "Docker\u6c99\u7bb1\u548cMCP\u5de5\u5177\u5305\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u9760\u7684\u8fd0\u884c\u73af\u5883\uff0c\u662fAI\u4ee3\u7406\u90e8\u7f72\u7684\u91cd\u8981\u6280\u672f\u65b9\u6848\u3002", "topic": "code agent"}}
{"id": "tldr.2512.9fecf82b", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/a3Yi6tKpEN7Ks-GS5FF9TVpYjHy407GAJNtUQlW_BQI=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/a3Yi6tKpEN7Ks-GS5FF9TVpYjHy407GAJNtUQlW_BQI=436", "authors": ["TLDR Newsletter"], "title": "create your own role", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/a3Yi6tKpEN7Ks-GS5FF9TVpYjHy407GAJNtUQlW_BQI=436", "summary": "Highlights from AWS re:Invent: Supercharging Kiro with Docker Sandboxes and MCP Catalog (5 minute read) Docker Sandboxes and the MCP Toolkit can run AI agents like Kiro in isolated containers, preventing access to host files and credentials while enabling safe code changes, testing, and tool use.", "source": "tldr", "AI": {"tldr": "AWS re:Invent\u5c55\u793a\u4e86\u5982\u4f55\u5229\u7528Docker\u6c99\u7bb1\u548cMCP\u5de5\u5177\u5305\u5b89\u5168\u8fd0\u884cKiro\u7b49AI\u4ee3\u7406\uff0c\u901a\u8fc7\u5bb9\u5668\u9694\u79bb\u4fdd\u62a4\u4e3b\u673a\u6587\u4ef6\u4e0e\u51ed\u8bc1\uff0c\u540c\u65f6\u652f\u6301\u5b89\u5168\u4ee3\u7801\u4fee\u6539\u3001\u6d4b\u8bd5\u548c\u5de5\u5177\u4f7f\u7528\u3002", "motivation": "\u89e3\u51b3AI\u4ee3\u7406\u5728\u8fd0\u884c\u65f6\u7684\u5b89\u5168\u95ee\u9898\uff0c\u9632\u6b62\u5176\u5bf9\u4e3b\u673a\u7cfb\u7edf\u9020\u6210\u6f5c\u5728\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u5176\u529f\u80fd\u5b8c\u6574\u6027\u3002", "method": "\u91c7\u7528Docker\u5bb9\u5668\u6280\u672f\u521b\u5efa\u9694\u79bb\u7684\u6c99\u7bb1\u73af\u5883\uff0c\u7ed3\u5408MCP\uff08Model Context Protocol\uff09\u5de5\u5177\u5305\uff0c\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u5b89\u5168\u7684\u8fd0\u884c\u73af\u5883\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86Kiro\u7b49AI\u4ee3\u7406\u5728\u9694\u79bb\u5bb9\u5668\u4e2d\u7684\u5b89\u5168\u8fd0\u884c\uff0c\u65e2\u80fd\u9632\u6b62\u5bf9\u4e3b\u673a\u7cfb\u7edf\u7684\u8bbf\u95ee\uff0c\u53c8\u80fd\u652f\u6301\u4ee3\u7801\u4fee\u6539\u3001\u6d4b\u8bd5\u548c\u5de5\u5177\u4f7f\u7528\u7b49\u6838\u5fc3\u529f\u80fd\u3002", "conclusion": "Docker\u6c99\u7bb1\u4e0eMCP\u5de5\u5177\u5305\u7684\u7ed3\u5408\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u9760\u7684\u8fd0\u884c\u73af\u5883\uff0c\u662fAI\u5e94\u7528\u90e8\u7f72\u7684\u91cd\u8981\u6280\u672f\u65b9\u6848\u3002", "topic": "code agent"}}
{"id": "tldr.2512.a3cc43c7", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/VIYZloFpxgfh4pdFvA0XUf4O6DV2RTzv9Iyh0SPWf7c=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/VIYZloFpxgfh4pdFvA0XUf4O6DV2RTzv9Iyh0SPWf7c=436", "authors": ["TLDR Newsletter"], "title": "Inc.'s Best Bootstrapped businesses", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b2c33d7af-ee3622ca-1307-4c46-8d32-a21f41192fea-000000/VIYZloFpxgfh4pdFvA0XUf4O6DV2RTzv9Iyh0SPWf7c=436", "summary": "Highlights from AWS re:Invent: Supercharging Kiro with Docker Sandboxes and MCP Catalog (5 minute read) Docker Sandboxes and the MCP Toolkit can run AI agents like Kiro in isolated containers, preventing access to host files and credentials while enabling safe code changes, testing, and tool use.", "source": "tldr", "AI": {"tldr": "AWS re:Invent\u5c55\u793a\u5982\u4f55\u901a\u8fc7Docker\u6c99\u7bb1\u548cMCP\u5de5\u5177\u5305\u589e\u5f3aKiro AI\u4ee3\u7406\uff0c\u5b9e\u73b0\u5b89\u5168\u9694\u79bb\u8fd0\u884c", "motivation": "AI\u4ee3\u7406\u5728\u8fd0\u884c\u4ee3\u7801\u548c\u4f7f\u7528\u5de5\u5177\u65f6\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u9632\u6b62\u5bf9\u4e3b\u673a\u6587\u4ef6\u548c\u51ed\u8bc1\u7684\u8bbf\u95ee\uff0c\u540c\u65f6\u652f\u6301\u5b89\u5168\u7684\u4ee3\u7801\u4fee\u6539\u548c\u6d4b\u8bd5", "method": "\u4f7f\u7528Docker\u6c99\u7bb1\u63d0\u4f9b\u9694\u79bb\u5bb9\u5668\u73af\u5883\uff0c\u7ed3\u5408MCP\uff08Model Context Protocol\uff09\u5de5\u5177\u5305\uff0c\u8ba9AI\u4ee3\u7406\u5728\u53d7\u63a7\u73af\u5883\u4e2d\u8fd0\u884c", "result": "Kiro\u7b49AI\u4ee3\u7406\u80fd\u591f\u5728\u9694\u79bb\u5bb9\u5668\u4e2d\u5b89\u5168\u8fd0\u884c\uff0c\u9632\u6b62\u5bf9\u4e3b\u673a\u7cfb\u7edf\u7684\u8bbf\u95ee\uff0c\u540c\u65f6\u652f\u6301\u4ee3\u7801\u4fee\u6539\u3001\u6d4b\u8bd5\u548c\u5de5\u5177\u4f7f\u7528", "conclusion": "Docker\u6c99\u7bb1\u548cMCP\u5de5\u5177\u5305\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u4e86\u5b89\u5168\u53ef\u9760\u7684\u8fd0\u884c\u73af\u5883\uff0c\u662fAI\u4ee3\u7406\u90e8\u7f72\u7684\u91cd\u8981\u6280\u672f\u65b9\u6848", "topic": "code agent"}}
{"id": "tldr.2512.95d127c7", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fvercel.com%2Fblog%2Fhow-to-prompt-v0%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/iS8cnyVbYpFyEao25lxuaPZAvyeFFWx6EahqWhvZ5J0=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fvercel.com%2Fblog%2Fhow-to-prompt-v0%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/iS8cnyVbYpFyEao25lxuaPZAvyeFFWx6EahqWhvZ5J0=436", "authors": ["TLDR Newsletter"], "title": "How to prompt v0", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fvercel.com%2Fblog%2Fhow-to-prompt-v0%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/iS8cnyVbYpFyEao25lxuaPZAvyeFFWx6EahqWhvZ5J0=436", "summary": "How to prompt v0 (4 minute read) When prompting v0 to build web apps or components, it's important to know three core methods: specify the product service (components, data, and actions), define the context of use (who, when, and for what outcome), and outline constraints and taste (style, platform, and layout). By providing these specific details, v0 can generate faster, make smarter UX decisions, and create cleaner, more maintainable code.", "source": "tldr", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5982\u4f55\u6709\u6548\u63d0\u793av0\u6784\u5efaWeb\u5e94\u7528\u6216\u7ec4\u4ef6\u7684\u4e09\u4e2a\u6838\u5fc3\u65b9\u6cd5\uff1a\u6307\u5b9a\u4ea7\u54c1\u670d\u52a1\u3001\u5b9a\u4e49\u4f7f\u7528\u4e0a\u4e0b\u6587\u3001\u4ee5\u53ca\u6982\u8ff0\u7ea6\u675f\u548c\u504f\u597d\uff0c\u4ee5\u63d0\u5347\u751f\u6210\u901f\u5ea6\u3001UX\u51b3\u7b56\u548c\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "\u4e3a\u4e86\u5e2e\u52a9\u7528\u6237\u66f4\u6709\u6548\u5730\u4f7f\u7528v0\u5de5\u5177\u751f\u6210Web\u5e94\u7528\u548c\u7ec4\u4ef6\uff0c\u63d0\u9ad8\u751f\u6210\u6548\u7387\u3001\u6539\u5584\u7528\u6237\u4f53\u9a8c\u51b3\u7b56\u5e76\u4ea7\u51fa\u66f4\u6e05\u6670\u53ef\u7ef4\u62a4\u7684\u4ee3\u7801\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u4e2a\u6838\u5fc3\u63d0\u793a\u65b9\u6cd5\uff1a1) \u6307\u5b9a\u4ea7\u54c1\u670d\u52a1\uff08\u7ec4\u4ef6\u3001\u6570\u636e\u548c\u64cd\u4f5c\uff09\uff1b2) \u5b9a\u4e49\u4f7f\u7528\u4e0a\u4e0b\u6587\uff08\u7528\u6237\u3001\u65f6\u673a\u548c\u9884\u671f\u7ed3\u679c\uff09\uff1b3) \u6982\u8ff0\u7ea6\u675f\u548c\u504f\u597d\uff08\u6837\u5f0f\u3001\u5e73\u53f0\u548c\u5e03\u5c40\uff09\u3002", "result": "\u901a\u8fc7\u5e94\u7528\u8fd9\u4e9b\u5177\u4f53\u7684\u63d0\u793a\u65b9\u6cd5\uff0cv0\u80fd\u591f\u66f4\u5feb\u5730\u751f\u6210\u4ee3\u7801\uff0c\u505a\u51fa\u66f4\u667a\u80fd\u7684UX\u51b3\u7b56\uff0c\u5e76\u521b\u5efa\u66f4\u6e05\u6670\u3001\u66f4\u6613\u7ef4\u62a4\u7684\u4ee3\u7801\u3002", "conclusion": "\u6709\u6548\u7684\u63d0\u793a\u7b56\u7565\u5bf9\u4e8e\u4f18\u5316v0\u751f\u6210Web\u5e94\u7528\u548c\u7ec4\u4ef6\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u4e09\u4e2a\u6838\u5fc3\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u7684\u6307\u5bfc\u6846\u67b6\u3002", "topic": "code agent"}}
{"id": "tldr.2512.54ef9348", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmays.co%2Foptimizing-claude-code%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/0xx7Gh_qbQnE2LmkaPoYhphDhEcmrGb6Hv_wxXNTOko=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmays.co%2Foptimizing-claude-code%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/0xx7Gh_qbQnE2LmkaPoYhphDhEcmrGb6Hv_wxXNTOko=436", "authors": ["TLDR Newsletter"], "title": "Optimizing Claude Code", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Reading time: 12 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmays.co%2Foptimizing-claude-code%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/0xx7Gh_qbQnE2LmkaPoYhphDhEcmrGb6Hv_wxXNTOko=436", "summary": "Optimizing Claude Code (12 minute read) Claude Code can be customized with skills, plugins, commands, and configuration files. While the defaults are remarkably capable, the system can be adjusted to fit any workflow - the difference is like hiring a talented generalist versus hiring someone who's worked at your company for years. This guide teaches readers how to optimize the assistant so it matches their style. It can take some time to optimize Claude, but doing so means you won't have to c...", "source": "tldr", "AI": {"tldr": "\u4e00\u7bc7\u5173\u4e8e\u5982\u4f55\u4f18\u5316Claude\u4ee3\u7801\u52a9\u624b\u7684\u6307\u5357\uff0c\u901a\u8fc7\u5b9a\u5236\u6280\u80fd\u3001\u63d2\u4ef6\u3001\u547d\u4ee4\u548c\u914d\u7f6e\u6587\u4ef6\u6765\u5339\u914d\u7528\u6237\u7684\u5de5\u4f5c\u6d41\u7a0b\u548c\u98ce\u683c", "motivation": "\u9ed8\u8ba4\u7684Claude\u4ee3\u7801\u52a9\u624b\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u901a\u8fc7\u5b9a\u5236\u5316\u53ef\u4ee5\u4f7f\u5176\u66f4\u8d34\u5408\u7279\u5b9a\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5c31\u50cf\u4ece\u96c7\u4f63\u901a\u624d\u8f6c\u53d8\u4e3a\u96c7\u4f63\u719f\u6089\u516c\u53f8\u5185\u90e8\u6d41\u7a0b\u7684\u4e13\u5bb6", "method": "\u901a\u8fc7\u5b9a\u5236\u6280\u80fd\u3001\u63d2\u4ef6\u3001\u547d\u4ee4\u548c\u914d\u7f6e\u6587\u4ef6\u6765\u4f18\u5316Claude\u4ee3\u7801\u52a9\u624b\uff0c\u4f7f\u5176\u9002\u5e94\u7279\u5b9a\u7684\u5de5\u4f5c\u98ce\u683c\u548c\u9700\u6c42", "result": "\u4f18\u5316\u540e\u7684Claude\u4ee3\u7801\u52a9\u624b\u80fd\u591f\u66f4\u597d\u5730\u5339\u914d\u7528\u6237\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u51cf\u5c11\u91cd\u590d\u6027\u6307\u4ee4\uff0c\u63d0\u9ad8\u5de5\u4f5c\u6548\u7387", "conclusion": "\u867d\u7136\u4f18\u5316Claude\u9700\u8981\u6295\u5165\u65f6\u95f4\uff0c\u4f46\u957f\u671f\u6765\u770b\u80fd\u591f\u663e\u8457\u63d0\u5347\u5de5\u4f5c\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c", "topic": "code agent"}}
{"id": "tldr.2512.9b2401e7", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.skyramp.dev%2F%3Futm_campaign=Beta1225%26utm_source=tldrdev%26utm_medium=newsletter/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/HbJCPwczgMoWdpqt1Cz5xvla9iS9HDnBLPzWR8tQUes=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.skyramp.dev%2F%3Futm_campaign=Beta1225%26utm_source=tldrdev%26utm_medium=newsletter/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/HbJCPwczgMoWdpqt1Cz5xvla9iS9HDnBLPzWR8tQUes=436", "authors": ["TLDR Newsletter"], "title": "Skyramp: Deterministic testing, powered by AI", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.skyramp.dev%2F%3Futm_campaign=Beta1225%26utm_source=tldrdev%26utm_medium=newsletter/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/HbJCPwczgMoWdpqt1Cz5xvla9iS9HDnBLPzWR8tQUes=436", "summary": "Skyramp: Deterministic testing, powered by AI (Sponsor) Automated testing that's conversational, intelligent, and deterministic. Skyramp blends AI orchestration with specification-driven design to generate production-ready tests from natural language. Join the beta in Cursor or VS Code", "source": "tldr", "AI": {"tldr": "Skyramp\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u786e\u5b9a\u6027\u6d4b\u8bd5\u5de5\u5177\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u751f\u4ea7\u5c31\u7eea\u7684\u6d4b\u8bd5\u7528\u4f8b", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6d4b\u8bd5\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u624b\u52a8\u7f16\u5199\u6d4b\u8bd5\u4ee3\u7801\u7684\u95ee\u9898\uff0c\u901a\u8fc7AI\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u8986\u76d6\u7387", "method": "\u7ed3\u5408AI\u7f16\u6392\u548c\u89c4\u8303\u9a71\u52a8\u8bbe\u8ba1\uff0c\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u751f\u4ea7\u5c31\u7eea\u7684\u6d4b\u8bd5\u7528\u4f8b", "result": "\u63d0\u4f9b\u5728Cursor\u548cVS Code\u4e2d\u7684beta\u7248\u672c\uff0c\u5b9e\u73b0\u5bf9\u8bdd\u5f0f\u3001\u667a\u80fd\u5316\u548c\u786e\u5b9a\u6027\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5", "conclusion": "Skyramp\u901a\u8fc7AI\u6280\u672f\u9769\u65b0\u8f6f\u4ef6\u6d4b\u8bd5\u6d41\u7a0b\uff0c\u4f7f\u6d4b\u8bd5\u751f\u6210\u66f4\u52a0\u667a\u80fd\u5316\u548c\u9ad8\u6548", "topic": "swe application"}}
{"id": "tldr.2512.9b50e790", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fa2ui.org%2F%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/GkSxGAvmLoAsfWIoFVAGKAxQcVn13J8y_J9Fy9mnN1Y=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fa2ui.org%2F%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/GkSxGAvmLoAsfWIoFVAGKAxQcVn13J8y_J9Fy9mnN1Y=436", "authors": ["TLDR Newsletter"], "title": "A2UI", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fa2ui.org%2F%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/GkSxGAvmLoAsfWIoFVAGKAxQcVn13J8y_J9Fy9mnN1Y=436", "summary": "A2UI (Website) A2UI is a protocol that lets AI agents generate interactive user interfaces for web, mobile, and desktop applications by sending declarative component descriptions rather than executable code.", "source": "tldr", "AI": {"tldr": "A2UI\u662f\u4e00\u4e2a\u534f\u8bae\uff0c\u8ba9AI\u4ee3\u7406\u901a\u8fc7\u53d1\u9001\u58f0\u660e\u5f0f\u7ec4\u4ef6\u63cf\u8ff0\u800c\u975e\u53ef\u6267\u884c\u4ee3\u7801\u6765\u4e3aWeb\u3001\u79fb\u52a8\u548c\u684c\u9762\u5e94\u7528\u751f\u6210\u4ea4\u4e92\u5f0f\u7528\u6237\u754c\u9762\u3002", "motivation": "\u5f53\u524dAI\u4ee3\u7406\u751f\u6210UI\u901a\u5e38\u9700\u8981\u751f\u6210\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u8fd9\u5b58\u5728\u590d\u6742\u6027\u3001\u5b89\u5168\u6027\u548c\u8de8\u5e73\u53f0\u517c\u5bb9\u6027\u95ee\u9898\u3002A2UI\u65e8\u5728\u901a\u8fc7\u58f0\u660e\u5f0f\u63cf\u8ff0\u7b80\u5316AI\u4ee3\u7406\u751f\u6210\u4ea4\u4e92\u5f0f\u754c\u9762\u7684\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faA2UI\u534f\u8bae\uff0c\u5b9a\u4e49\u4e86\u4e00\u79cd\u58f0\u660e\u5f0f\u7ec4\u4ef6\u63cf\u8ff0\u8bed\u8a00\uff0cAI\u4ee3\u7406\u53ef\u4ee5\u901a\u8fc7\u53d1\u9001\u7ed3\u6784\u5316\u63cf\u8ff0\u6765\u6307\u5b9aUI\u7ec4\u4ef6\uff0c\u800c\u4e0d\u662f\u751f\u6210\u5177\u4f53\u4ee3\u7801\u3002\u8be5\u534f\u8bae\u652f\u6301Web\u3001\u79fb\u52a8\u548c\u684c\u9762\u5e94\u7528\u7684\u8de8\u5e73\u53f0\u754c\u9762\u751f\u6210\u3002", "result": "A2UI\u534f\u8bae\u80fd\u591f\u4f7fAI\u4ee3\u7406\u66f4\u9ad8\u6548\u5730\u751f\u6210\u4ea4\u4e92\u5f0f\u7528\u6237\u754c\u9762\uff0c\u51cf\u5c11\u4e86\u4ee3\u7801\u751f\u6210\u590d\u6742\u6027\uff0c\u63d0\u9ad8\u4e86\u8de8\u5e73\u53f0\u517c\u5bb9\u6027\uff0c\u5e76\u589e\u5f3a\u4e86\u5b89\u5168\u6027\u3002", "conclusion": "A2UI\u4e3aAI\u4ee3\u7406\u751f\u6210\u7528\u6237\u754c\u9762\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u66f4\u5b89\u5168\u3001\u66f4\u8de8\u5e73\u53f0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u58f0\u660e\u5f0f\u63cf\u8ff0\u800c\u975e\u53ef\u6267\u884c\u4ee3\u7801\u7684\u65b9\u5f0f\u6539\u8fdb\u4e86\u73b0\u6709\u65b9\u6cd5\u3002", "topic": "code agent"}}
{"id": "tldr.2512.dd80e736", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.letta.com%2Fblog%2Fletta-code%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/tbIu4TLzja2wr4Wl1LUrXAY41SOvPL2h1gOWaiV2EIM=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.letta.com%2Fblog%2Fletta-code%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/tbIu4TLzja2wr4Wl1LUrXAY41SOvPL2h1gOWaiV2EIM=436", "authors": ["TLDR Newsletter"], "title": "Letta Code", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.letta.com%2Fblog%2Fletta-code%3Futm_source=tldrdev/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/tbIu4TLzja2wr4Wl1LUrXAY41SOvPL2h1gOWaiV2EIM=436", "summary": "Letta Code (Website) Letta Code is a memory-first coding agent designed for long-lived agents that continually learn and improve across independent sessions.", "source": "tldr", "AI": {"tldr": "Letta Code\u662f\u4e00\u4e2a\u9762\u5411\u957f\u671f\u8fd0\u884c\u4ee3\u7406\u7684\u4ee5\u5185\u5b58\u4f18\u5148\u7684\u7f16\u7801\u4ee3\u7406\u7cfb\u7edf\uff0c\u652f\u6301\u8de8\u72ec\u7acb\u4f1a\u8bdd\u7684\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb", "motivation": "\u5f53\u524d\u7f16\u7801\u4ee3\u7406\u901a\u5e38\u7f3a\u4e4f\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\uff0c\u65e0\u6cd5\u5728\u591a\u4e2a\u72ec\u7acb\u4f1a\u8bdd\u4e2d\u79ef\u7d2f\u77e5\u8bc6\u548c\u7ecf\u9a8c\uff0c\u9650\u5236\u4e86\u4ee3\u7406\u7684\u6301\u7eed\u6539\u8fdb\u80fd\u529b", "method": "\u91c7\u7528\u5185\u5b58\u4f18\u5148\u67b6\u6784\uff0c\u4e3a\u7f16\u7801\u4ee3\u7406\u8bbe\u8ba1\u4e13\u95e8\u7684\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u652f\u6301\u8de8\u4f1a\u8bdd\u7684\u77e5\u8bc6\u4fdd\u7559\u548c\u7ecf\u9a8c\u79ef\u7d2f", "result": "\u5f00\u53d1\u4e86Letta Code\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u957f\u671f\u8fd0\u884c\u7684\u7f16\u7801\u4ee3\u7406\uff0c\u80fd\u591f\u5728\u591a\u4e2a\u72ec\u7acb\u4f1a\u8bdd\u4e2d\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb", "conclusion": "\u5185\u5b58\u4f18\u5148\u7684\u67b6\u6784\u5bf9\u4e8e\u6784\u5efa\u957f\u671f\u8fd0\u884c\u7684\u7f16\u7801\u4ee3\u7406\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u4ee3\u7406\u7684\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u548c\u6027\u80fd", "topic": "code agent"}}
{"id": "tldr.2512.8e1c4db3", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdev%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/axscqZhoZLWW3TfM6NK0bNbEgGQ9qzIl_uS2E-02JMk=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdev%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/axscqZhoZLWW3TfM6NK0bNbEgGQ9qzIl_uS2E-02JMk=436", "authors": ["TLDR Newsletter"], "title": "advertise with us", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdev%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/axscqZhoZLWW3TfM6NK0bNbEgGQ9qzIl_uS2E-02JMk=436", "summary": "Letta Code (Website) Letta Code is a memory-first coding agent designed for long-lived agents that continually learn and improve across independent sessions.", "source": "tldr", "AI": {"tldr": "Letta Code\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bb0\u5fc6\u4f18\u5148\u7684\u7f16\u7801\u667a\u80fd\u4f53\uff0c\u4e13\u4e3a\u957f\u671f\u8fd0\u884c\u3001\u8de8\u72ec\u7acb\u4f1a\u8bdd\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1\u3002", "motivation": "\u5f53\u524d\u7f16\u7801\u667a\u80fd\u4f53\u901a\u5e38\u7f3a\u4e4f\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\uff0c\u65e0\u6cd5\u5728\u591a\u4e2a\u72ec\u7acb\u4f1a\u8bdd\u4e2d\u79ef\u7d2f\u77e5\u8bc6\u548c\u7ecf\u9a8c\u3002\u8fd9\u9650\u5236\u4e86\u667a\u80fd\u4f53\u5728\u957f\u671f\u4efb\u52a1\u4e2d\u7684\u6301\u7eed\u6539\u8fdb\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u8de8\u4f1a\u8bdd\u5b66\u4e60\u548c\u77e5\u8bc6\u79ef\u7d2f\u7684\u573a\u666f\u4e2d\u3002", "method": "\u91c7\u7528\u8bb0\u5fc6\u4f18\u5148\u7684\u8bbe\u8ba1\u7406\u5ff5\uff0c\u6784\u5efa\u5177\u6709\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\u7684\u7f16\u7801\u667a\u80fd\u4f53\u3002\u7cfb\u7edf\u80fd\u591f\u8de8\u72ec\u7acb\u4f1a\u8bdd\u5b58\u50a8\u548c\u68c0\u7d22\u7f16\u7801\u7ecf\u9a8c\u3001\u89e3\u51b3\u65b9\u6848\u548c\u6700\u4f73\u5b9e\u8df5\uff0c\u5b9e\u73b0\u77e5\u8bc6\u7684\u6301\u7eed\u79ef\u7d2f\u548c\u91cd\u7528\u3002", "result": "Letta Code\u80fd\u591f\u901a\u8fc7\u957f\u671f\u8bb0\u5fc6\u673a\u5236\u5728\u591a\u4e2a\u4f1a\u8bdd\u4e2d\u6301\u7eed\u6539\u8fdb\u7f16\u7801\u80fd\u529b\uff0c\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u548c\u6548\u7387\uff0c\u7279\u522b\u9002\u5408\u9700\u8981\u957f\u671f\u5b66\u4e60\u548c\u77e5\u8bc6\u79ef\u7d2f\u7684\u7f16\u7801\u4efb\u52a1\u3002", "conclusion": "\u8bb0\u5fc6\u4f18\u5148\u7684\u7f16\u7801\u667a\u80fd\u4f53\u8bbe\u8ba1\u662f\u5b9e\u73b0\u957f\u671f\u5b66\u4e60\u548c\u6301\u7eed\u6539\u8fdb\u7684\u5173\u952e\uff0cLetta Code\u4e3a\u6784\u5efa\u5177\u6709\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\u7684\u7f16\u7801\u52a9\u624b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "code agent"}}
{"id": "tldr.2512.fa825834", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/HqgFnPWL2Mj-QMQI2qeOsV0ERj0OAr83sx8ZBSIbENw=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/HqgFnPWL2Mj-QMQI2qeOsV0ERj0OAr83sx8ZBSIbENw=436", "authors": ["TLDR Newsletter"], "title": "create your own role", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fjobs.ashbyhq.com%2Ftldr.tech%2Fc227b917-a6a4-40ce-8950-d3e165357871/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/HqgFnPWL2Mj-QMQI2qeOsV0ERj0OAr83sx8ZBSIbENw=436", "summary": "Letta Code (Website) Letta Code is a memory-first coding agent designed for long-lived agents that continually learn and improve across independent sessions.", "source": "tldr", "AI": {"tldr": "Letta Code\u662f\u4e00\u4e2a\u57fa\u4e8e\u8bb0\u5fc6\u4f18\u5148\u7684\u7f16\u7801\u4ee3\u7406\uff0c\u4e13\u4e3a\u957f\u671f\u8fd0\u884c\u3001\u6301\u7eed\u5b66\u4e60\u548c\u8de8\u72ec\u7acb\u4f1a\u8bdd\u6539\u8fdb\u7684\u667a\u80fd\u4f53\u8bbe\u8ba1", "motivation": "\u73b0\u6709\u7f16\u7801\u4ee3\u7406\u901a\u5e38\u7f3a\u4e4f\u957f\u671f\u8bb0\u5fc6\u80fd\u529b\uff0c\u65e0\u6cd5\u5728\u591a\u4e2a\u72ec\u7acb\u4f1a\u8bdd\u4e2d\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bb0\u5fc6\u4f18\u5148\u7684\u67b6\u6784\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u79ef\u7d2f\u77e5\u8bc6\u5e76\u968f\u65f6\u95f4\u63d0\u5347\u6027\u80fd\u3002", "method": "\u91c7\u7528\u8bb0\u5fc6\u4f18\u5148\u7684\u8bbe\u8ba1\u7406\u5ff5\uff0c\u6784\u5efa\u957f\u671f\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u4f7f\u7f16\u7801\u4ee3\u7406\u80fd\u591f\u5728\u4e0d\u540c\u4f1a\u8bdd\u95f4\u4fdd\u6301\u548c\u5229\u7528\u5386\u53f2\u7ecf\u9a8c\u3002\u7cfb\u7edf\u53ef\u80fd\u5305\u62ec\u77e5\u8bc6\u5e93\u3001\u7ecf\u9a8c\u5b58\u50a8\u548c\u68c0\u7d22\u673a\u5236\uff0c\u652f\u6301\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb\u3002", "result": "Letta Code\u4f5c\u4e3a\u4e00\u4e2a\u957f\u671f\u8fd0\u884c\u7684\u7f16\u7801\u4ee3\u7406\uff0c\u80fd\u591f\u5728\u591a\u4e2a\u72ec\u7acb\u4f1a\u8bdd\u4e2d\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb\uff0c\u76f8\u6bd4\u4f20\u7edf\u4e00\u6b21\u6027\u4ee3\u7406\u5177\u6709\u66f4\u597d\u7684\u77e5\u8bc6\u79ef\u7d2f\u548c\u6027\u80fd\u63d0\u5347\u80fd\u529b\u3002", "conclusion": "\u8bb0\u5fc6\u4f18\u5148\u7684\u67b6\u6784\u5bf9\u4e8e\u6784\u5efa\u957f\u671f\u8fd0\u884c\u7684\u7f16\u7801\u4ee3\u7406\u81f3\u5173\u91cd\u8981\uff0cLetta Code\u5c55\u793a\u4e86\u901a\u8fc7\u6301\u7eed\u5b66\u4e60\u548c\u8de8\u4f1a\u8bdd\u77e5\u8bc6\u79ef\u7d2f\u6765\u63d0\u5347\u667a\u80fd\u4f53\u6027\u80fd\u7684\u6709\u6548\u9014\u5f84\u3002", "topic": "code agent"}}
{"id": "tldr.2512.5943d977", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/BRyDJEv3WZhhI6S8GIWJ6yNLeeo3aEaoqkpevpr0tQY=436", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/BRyDJEv3WZhhI6S8GIWJ6yNLeeo3aEaoqkpevpr0tQY=436", "authors": ["TLDR Newsletter"], "title": "Inc.'s Best Bootstrapped businesses", "comment": "Source: TLDR Newsletter, Date: 2025-12-17, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.linkedin.com%2Ffeed%2Fupdate%2Furn:li:activity:7401699691039830016%2F/1/0100019b2c4a2be1-17170461-eff7-4d37-a495-0e5db7e593ef-000000/BRyDJEv3WZhhI6S8GIWJ6yNLeeo3aEaoqkpevpr0tQY=436", "summary": "Letta Code (Website) Letta Code is a memory-first coding agent designed for long-lived agents that continually learn and improve across independent sessions.", "source": "tldr", "AI": {"tldr": "Letta Code\u662f\u4e00\u4e2a\u9762\u5411\u957f\u671f\u8fd0\u884c\u4ee3\u7406\u7684\u4ee5\u5185\u5b58\u4f18\u5148\u7684\u7f16\u7801\u4ee3\u7406\u7cfb\u7edf\uff0c\u65e8\u5728\u652f\u6301\u8de8\u72ec\u7acb\u4f1a\u8bdd\u7684\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb", "motivation": "\u73b0\u6709\u7684\u7f16\u7801\u4ee3\u7406\u901a\u5e38\u5728\u5355\u6b21\u4f1a\u8bdd\u4e2d\u8fd0\u884c\uff0c\u7f3a\u4e4f\u8de8\u4f1a\u8bdd\u7684\u6301\u7eed\u5b66\u4e60\u548c\u6539\u8fdb\u80fd\u529b\u3002\u5bf9\u4e8e\u9700\u8981\u957f\u671f\u8fd0\u884c\u3001\u4e0d\u65ad\u79ef\u7d2f\u77e5\u8bc6\u548c\u7ecf\u9a8c\u7684\u7f16\u7801\u4ee3\u7406\u6765\u8bf4\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8bb0\u5fc6\u5148\u524d\u7ecf\u9a8c\u5e76\u5728\u540e\u7eed\u4efb\u52a1\u4e2d\u5229\u7528\u8fd9\u4e9b\u77e5\u8bc6\u7684\u673a\u5236\u3002", "method": "\u91c7\u7528\"\u5185\u5b58\u4f18\u5148\"\u7684\u8bbe\u8ba1\u7406\u5ff5\uff0c\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u8de8\u4f1a\u8bdd\u5b58\u50a8\u548c\u68c0\u7d22\u7f16\u7801\u7ecf\u9a8c\u3001\u89e3\u51b3\u65b9\u6848\u548c\u77e5\u8bc6\u7684\u7cfb\u7edf\u3002\u4ee3\u7406\u901a\u8fc7\u8bb0\u5fc6\u673a\u5236\u4fdd\u5b58\u5386\u53f2\u4ea4\u4e92\u3001\u4ee3\u7801\u7247\u6bb5\u548c\u95ee\u9898\u89e3\u51b3\u7b56\u7565\uff0c\u5728\u540e\u7eed\u4efb\u52a1\u4e2d\u5229\u7528\u8fd9\u4e9b\u8bb0\u5fc6\u6765\u63d0\u9ad8\u6548\u7387\u548c\u4ee3\u7801\u8d28\u91cf\u3002", "result": "Letta Code\u80fd\u591f\u5b9e\u73b0\u8de8\u4f1a\u8bdd\u7684\u77e5\u8bc6\u79ef\u7d2f\u548c\u590d\u7528\uff0c\u957f\u671f\u8fd0\u884c\u7684\u4ee3\u7406\u80fd\u591f\u968f\u7740\u65f6\u95f4\u63a8\u79fb\u63d0\u9ad8\u7f16\u7801\u6548\u7387\u548c\u4ee3\u7801\u8d28\u91cf\uff0c\u51cf\u5c11\u91cd\u590d\u5de5\u4f5c\uff0c\u5e76\u5728\u7c7b\u4f3c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u5185\u5b58\u4f18\u5148\u7684\u8bbe\u8ba1\u4e3a\u7f16\u7801\u4ee3\u7406\u7684\u957f\u671f\u8fd0\u884c\u548c\u6301\u7eed\u6539\u8fdb\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u4ece\u5386\u53f2\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u5e76\u4e0d\u65ad\u63d0\u5347\u6027\u80fd\uff0c\u8fd9\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7f16\u7801\u4ee3\u7406\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "topic": "code agent"}}
{"id": "wechat.2512.a7eb2f3f", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzY0MDI1NjI1OA==&mid=2247489450&idx=1&sn=cb39a526bf081c475f79b4b3f361d49b&chksm=f13f109ce95f40b2e2a4df5521c89a197ab0a7ef5cf73838f45b29c21417ed003fb6d555fdd9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzY0MDI1NjI1OA==&mid=2247489450&idx=1&sn=cb39a526bf081c475f79b4b3f361d49b&chksm=f13f109ce95f40b2e2a4df5521c89a197ab0a7ef5cf73838f45b29c21417ed003fb6d555fdd9#rd", "authors": ["\u548c\u901aAI"], "title": "\u6269\u5c55<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6c38\u8fdc\u4e0d\u4f1a\u901a\u5411\u901a\u7528\u4eba\u5de5\u667a\u80fd", "comment": "Source: WeChat, Published: 2025-12-18 07:44:11", "summary": "\u5f3a\u5316\u5b66\u4e60\uff08\u4ee5\u53ca\u5176\u4ed6\u540e\u671f\u8bad\u7ec3\u65b9\u6cd5\uff09\u540c\u7406\u3002\u5b83\u65e0\u6cd5\u5c06\u667a\u80fd\u5d4c\u5165\u7cfb\u7edf\u5185\u90e8\uff0c\u81f3\u591a\u53ea\u80fd\u63d0\u53d6\u667a\u80fd\uff08\u672c\u6587\u5c06\u5256\u6790\u4e3a\u4f55\u5b83\u5728\u8fd9\u65b9\u9762\u5b9e\u9645\u4e0a\u4e5f\u505a\u5f97\u5f88\u7cdf\u7cd5\uff09\u3002\u9898\u5916\u8bdd\u4e00\u5219\u8da3\u95fb\uff1a\u963f\u5e0c\u4ec0\u00b7\u74e6\u65af\u74e6\u5c3c\uff08\u662f\u7684\uff0cTransformer\u7684\u521b\u9020\u8005\uff09\u56de\u6765\u4e86\u3002", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\uff08\u4ee5\u53ca\u5176\u4ed6\u540e\u671f\u8bad\u7ec3\u65b9\u6cd5\uff09\u540c\u7406\u3002\u5b83\u65e0\u6cd5\u5c06\u667a\u80fd\u5d4c\u5165\u7cfb\u7edf\u5185\u90e8\uff0c\u81f3\u591a\u53ea\u80fd\u63d0\u53d6\u667a\u80fd\uff08\u672c\u6587\u5c06\u5256\u6790\u4e3a\u4f55\u5b83\u5728\u8fd9\u65b9\u9762\u5b9e\u9645\u4e0a\u4e5f\u505a\u5f97\u5f88\u7cdf\u7cd5\uff09\u3002\u9898\u5916\u8bdd\u4e00\u5219\u8da3\u95fb\uff1a\u963f\u5e0c\u4ec0\u00b7\u74e6\u65af\u74e6\u5c3c\uff08\u662f\u7684\uff0cTransformer\u7684\u521b\u9020\u8005\uff09\u56de\u6765\u4e86\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.d9dc8d00", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU2NzkxMTQ5NQ==&mid=2247557808&idx=5&sn=335bf5f89523a4e38901afdc496365fe&chksm=fdb1a095077da24720d4dbd45394e397b3d309713f55b82e929ee1c56f89f448fee88c4c91b9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU2NzkxMTQ5NQ==&mid=2247557808&idx=5&sn=335bf5f89523a4e38901afdc496365fe&chksm=fdb1a095077da24720d4dbd45394e397b3d309713f55b82e929ee1c56f89f448fee88c4c91b9#rd", "authors": ["\u4e13\u77e5\u667a\u80fd\u9632\u52a1"], "title": "\u300a\u6307\u6325\u548c\u63a7\u5236<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u667a\u80fd\u4f53\u7684\u5bf9\u6297\u6027\u653b\u51fb\u300b", "comment": "Source: WeChat, Published: 2025-12-18 06:47:58", "summary": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u5df2\u88ab\u6210\u529f\u7528\u4e8e\u8bad\u7ec3\u300a\u661f\u9645\u4e89\u9738\u300b\u548c\u300aDoTAdota\u300b\u7b49\u51e0\u6b3e\u6218\u672f\u548c\u5373\u65f6\u6218\u7565\u6e38\u620f\u4e2d\u7684\u667a\u80fd\u4f53\uff0c\u8fd9\u4e9b\u6e38\u620f\u6d89\u53ca\u590d\u6742\u7684\u89c4\u5212\u548c\u51b3\u7b56\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u901a\u8fc7\u81ea\u6211\u535a\u5f08\u3001\u6a21\u4eff\u5b66\u4e60\u7b49\u6280\u672f\uff0c\u719f\u7ec3\u5730\u63d0\u51fa\u4e86\u4e0e\u7ecf\u9a8c\u4e30\u5bcc\u7684\u4eba\u7c7b\u73a9\u5bb6\u4e0d\u76f8", "AI": {"tldr": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u5df2\u88ab\u6210\u529f\u7528\u4e8e\u8bad\u7ec3\u300a\u661f\u9645\u4e89\u9738\u300b\u548c\u300aDoTAdota\u300b\u7b49\u51e0\u6b3e\u6218\u672f\u548c\u5373\u65f6\u6218\u7565\u6e38\u620f\u4e2d\u7684\u667a\u80fd\u4f53\uff0c\u8fd9\u4e9b\u6e38\u620f\u6d89\u53ca\u590d\u6742\u7684\u89c4\u5212\u548c\u51b3\u7b56\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u901a\u8fc7\u81ea\u6211\u535a\u5f08\u3001\u6a21\u4eff\u5b66\u4e60\u7b49\u6280\u672f\uff0c\u719f\u7ec3\u5730\u63d0\u51fa\u4e86\u4e0e\u7ecf\u9a8c\u4e30\u5bcc\u7684\u4eba\u7c7b\u73a9\u5bb6\u4e0d\u76f8", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.3cba1f5d", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkwNTgxMTgxNQ==&mid=2247484598&idx=1&sn=9216033949e9083a177b560af834e1f5&chksm=c1ac56c904b3ca8bf9510415f0a2c1a5ff57fcd49ae0f03e783c3a84e28944adb5cb058360ea#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkwNTgxMTgxNQ==&mid=2247484598&idx=1&sn=9216033949e9083a177b560af834e1f5&chksm=c1ac56c904b3ca8bf9510415f0a2c1a5ff57fcd49ae0f03e783c3a84e28944adb5cb058360ea#rd", "authors": ["\u667a\u6838\u5de5\u573a"], "title": "\u9996\u4e2a\u8bc1\u5b9e\u5728\u7ebf<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6709\u6548\u6027\u7684VLA\u6846\u67b6......", "comment": "Source: WeChat, Published: 2025-12-17 23:30:25", "summary": "\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u901a\u8fc7\u8bd5\u9519\u5b66\u4e60\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u6761\u6781\u5177\u6f5c\u529b\u7684\u9014\u5f84\u3002\u7136\u800c\uff0c\u5c06\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u65f6\uff0c\u9762\u4e34\u7740\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u7684\u96be\u9898\u3002", "AI": {"tldr": "\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u901a\u8fc7\u8bd5\u9519\u5b66\u4e60\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u6761\u6781\u5177\u6f5c\u529b\u7684\u9014\u5f84\u3002\u7136\u800c\uff0c\u5c06\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u65f6\uff0c\u9762\u4e34\u7740\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u4e2d\u63a2\u7d22\u6548\u7387\u4f4e\u4e0b\u7684\u96be\u9898\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.77fe2960", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIyMjE5Njk1Mw==&mid=2651252573&idx=1&sn=7c24da3fb3d659740f0acbaacbf323fb&chksm=f2bbfc038283d27dde3d0737274fa5d8c9502244b547d7e30859fbf625c3030937026d80108d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIyMjE5Njk1Mw==&mid=2651252573&idx=1&sn=7c24da3fb3d659740f0acbaacbf323fb&chksm=f2bbfc038283d27dde3d0737274fa5d8c9502244b547d7e30859fbf625c3030937026d80108d#rd", "authors": ["Machi"], "title": "\u5927\u6a21\u578b<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u524d\u6cbf\u6280\u672f\u7efc\u8ff0\uff1a\u4ece\u7406\u8bba\u5230\u5b9e\u8df5\u7684\u7cfb\u7edf\u6027\u6d1e\u5bdf", "comment": "Source: WeChat, Published: 2025-12-17 16:43:26", "summary": "\u672c\u6587\u7cfb\u7edf\u68b3\u74062025\u5e74\u5927\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u6db5\u76d6\u8bad\u7ec3\u7a33\u5b9a\u6027\u3001\u6570\u636e\u6548\u7387\u3001\u7b97\u6cd5\u521b\u65b0\u7b49\u6838\u5fc3\u8bae\u9898\u30021. \u8bad\u7ec3\u7a33\u5b9a\u6027\uff1aRLVR\u7684\u6838\u5fc3\u6311\u62181.1 GRPO\u8bad\u7ec3\u5d29\u6e83\u7684\u6839\u672c\u539f\u56e0", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u68b3\u74062025\u5e74\u5927\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u6db5\u76d6\u8bad\u7ec3\u7a33\u5b9a\u6027\u3001\u6570\u636e\u6548\u7387\u3001\u7b97\u6cd5\u521b\u65b0\u7b49\u6838\u5fc3\u8bae\u9898\u30021. \u8bad\u7ec3\u7a33\u5b9a\u6027\uff1aRLVR\u7684\u6838\u5fc3\u6311\u62181.1 GRPO\u8bad\u7ec3\u5d29\u6e83\u7684\u6839\u672c\u539f\u56e0", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.8560d4b5", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU5NjYyOTAyNg==&mid=2247483912&idx=1&sn=2e220a1f9ad35e8711dc45fcc64f1bf2&chksm=ff9ece0b85fa027828f1abaaaee42cb350b4d7fc0f89123d385241d5f43a3df2505894dd8af4#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU5NjYyOTAyNg==&mid=2247483912&idx=1&sn=2e220a1f9ad35e8711dc45fcc64f1bf2&chksm=ff9ece0b85fa027828f1abaaaee42cb350b4d7fc0f89123d385241d5f43a3df2505894dd8af4#rd", "authors": ["\u5b89\u5168\u6df1\u5ea6\u89c2\u5bdf"], "title": "\u5982\u4f55\u8bc4\u6d4b\u4e00\u4e2a<em class=\"highlight\">Agentic</em> SOC?", "comment": "Source: WeChat, Published: 2025-12-18 13:04:05", "summary": "\u7528\u6237\u89c6\u89d2\u7684Agentic AI\u7528\u4e8e\u5b89\u5168\u8fd0\u8425\u7684POC \u9a8c\u6536\u6e05\u5355\u6574\u7406\u4e86\u4e00\u4efdAgentic AI\u5728\u5b89\u5168\u8fd0\u8425\u9886\u57dfPOC \u9879\u76ee\u7684\u9a8c\u6536\u6e05\u5355\uff0c \u57fa\u4e8e\u613f\u610f\u57cb\u5355\u4ed8\u94b1\u7684\u7528\u6237\u89c6\u89d2\uff0c\u5206\u89e3\u6210\u56db\u4e2a\u7ef4\u5ea6\uff1a \u6280\u672f\u3001\u8fd0\u8425\u3001\u98ce\u9669\u3001\u7ec4\u7ec7 \u4e2d\u6700\u6838\u5fc3\u7684\u5185\u5bb9", "AI": {"tldr": "\u7528\u6237\u89c6\u89d2\u7684Agentic AI\u7528\u4e8e\u5b89\u5168\u8fd0\u8425\u7684POC \u9a8c\u6536\u6e05\u5355\u6574\u7406\u4e86\u4e00\u4efdAgentic AI\u5728\u5b89\u5168\u8fd0\u8425\u9886\u57dfPOC \u9879\u76ee\u7684\u9a8c\u6536\u6e05\u5355\uff0c \u57fa\u4e8e\u613f\u610f\u57cb\u5355\u4ed8\u94b1\u7684\u7528\u6237\u89c6\u89d2\uff0c\u5206\u89e3\u6210\u56db\u4e2a\u7ef4\u5ea6\uff1a \u6280\u672f\u3001\u8fd0\u8425\u3001\u98ce\u9669\u3001\u7ec4\u7ec7 \u4e2d\u6700\u6838\u5fc3\u7684\u5185\u5bb9", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.025743d0", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxNzU2NDgxNQ==&mid=2247484291&idx=1&sn=8de27988b1d03830afe4e8965fcc95a8&chksm=c0e2652936fbdb0d53cb9f9d46e8b2d848f10f35256da104d5cf838adb0697b38118b4d7ce1b#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxNzU2NDgxNQ==&mid=2247484291&idx=1&sn=8de27988b1d03830afe4e8965fcc95a8&chksm=c0e2652936fbdb0d53cb9f9d46e8b2d848f10f35256da104d5cf838adb0697b38118b4d7ce1b#rd", "authors": ["Oxo Security"], "title": "\u3010AI\u5b89\u5168\u3011OWASP <em class=\"highlight\">Agentic</em> AI Top 10 \u653b\u51fb\u9884\u8b66!", "comment": "Source: WeChat, Published: 2025-12-18 11:58:00", "summary": "Agentic AI \u5219\u5b8c\u5168\u4e0d\u540c\u3002\u667a\u80fd\u4f53\u4e0d\u518d\u4ec5\u4ec5\u662f\u751f\u6210\u5185\u5bb9\uff0c\u5b83\u4eec\u5177\u5907\u4e86\u81ea\u4e3b\u6027\uff08Autonomy\uff09\u3002\u5b83\u4eec\u53ef\u4ee5\uff1a \u89c4\u5212\uff08Plan\uff09\uff1a\u5c06\u4e00\u4e2a\u6a21\u7cca\u7684\u9ad8\u7ea7\u76ee\u6807\u62c6\u89e3\u4e3a\u5177\u4f53\u7684\u6267\u884c\u6b65\u9aa4\u3002", "AI": {"tldr": "Agentic AI \u5219\u5b8c\u5168\u4e0d\u540c\u3002\u667a\u80fd\u4f53\u4e0d\u518d\u4ec5\u4ec5\u662f\u751f\u6210\u5185\u5bb9\uff0c\u5b83\u4eec\u5177\u5907\u4e86\u81ea\u4e3b\u6027\uff08Autonomy\uff09\u3002\u5b83\u4eec\u53ef\u4ee5\uff1a \u89c4\u5212\uff08Plan\uff09\uff1a\u5c06\u4e00\u4e2a\u6a21\u7cca\u7684\u9ad8\u7ea7\u76ee\u6807\u62c6\u89e3\u4e3a\u5177\u4f53\u7684\u6267\u884c\u6b65\u9aa4\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.c54b1179", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA4MzEzMTA0NQ==&mid=2457472221&idx=1&sn=9105aaeedcbe9cd1c01a785cf1c7d7f6&chksm=89f8bebd8d7f664ea9e713bfd0fdfd5f7f0f8c4aff5e89a6371a4de5b9c32235e647ce29bb83#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA4MzEzMTA0NQ==&mid=2457472221&idx=1&sn=9105aaeedcbe9cd1c01a785cf1c7d7f6&chksm=89f8bebd8d7f664ea9e713bfd0fdfd5f7f0f8c4aff5e89a6371a4de5b9c32235e647ce29bb83#rd", "authors": ["\u5236\u9020AI\u6218\u7565\u4f19\u4f34"], "title": "2025-2026 \u9ea6\u80af\u9521 AI \u6218\u7565\u56de\u987e\u4e0e\u5c55\u671b\uff1a<em class=\"highlight\">Agentic</em> AI \u65f6\u4ee3\u7684\u5d1b\u8d77", "comment": "Source: WeChat, Published: 2025-12-18 09:41:54", "summary": "Agentic\u5e94\u7528\uff1a \u591a\u4ee3\u7406\u7cfb\u7edf\u534f\u540c\u5de5\u4f5c\uff0c\u4e00\u4e2a\u8d1f\u8d23\u6570\u636e\u63d0\u53d6\uff0c\u4e00\u4e2a\u8d1f\u8d23\u98ce\u9669\u8bc4\u5206\uff0c\u4e00\u4e2a\u8d1f\u8d23\u8d77\u8349\u62a5\u544a\uff0c\u4eba\u7c7b\u4ec5\u9700\u8fdb\u884c\u6700\u7ec8\u6218\u7565\u5ba1\u6838\u3002\u6210\u6548\uff1a \u751f\u4ea7\u529b\u63d0\u5347 20-60%\uff0c\u4fe1\u8d37\u5468\u8f6c\u901f\u5ea6\u63d0\u5347 30%\u3002", "AI": {"tldr": "Agentic\u5e94\u7528\uff1a \u591a\u4ee3\u7406\u7cfb\u7edf\u534f\u540c\u5de5\u4f5c\uff0c\u4e00\u4e2a\u8d1f\u8d23\u6570\u636e\u63d0\u53d6\uff0c\u4e00\u4e2a\u8d1f\u8d23\u98ce\u9669\u8bc4\u5206\uff0c\u4e00\u4e2a\u8d1f\u8d23\u8d77\u8349\u62a5\u544a\uff0c\u4eba\u7c7b\u4ec5\u9700\u8fdb\u884c\u6700\u7ec8\u6218\u7565\u5ba1\u6838\u3002\u6210\u6548\uff1a \u751f\u4ea7\u529b\u63d0\u5347 20-60%\uff0c\u4fe1\u8d37\u5468\u8f6c\u901f\u5ea6\u63d0\u5347 30%\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.208e4e85", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg2MzAwNzM0NQ==&mid=2247492708&idx=1&sn=0e0779d59cb678a7f04e26a39b6c4955&chksm=cf628e382b7d280402469018fc8e1e751699bb2193f48c0a3acf2b8868bb32b96af34195f700#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg2MzAwNzM0NQ==&mid=2247492708&idx=1&sn=0e0779d59cb678a7f04e26a39b6c4955&chksm=cf628e382b7d280402469018fc8e1e751699bb2193f48c0a3acf2b8868bb32b96af34195f700#rd", "authors": ["QuantML"], "title": "\u4eba\u5927 x \u6e05\u534e | DeepAnalyze\uff1a\u5982\u4f55\u6253\u9020\u6570\u636e\u5206\u6790\u7684\u201c<em class=\"highlight\">Agentic</em> AI\u201d\uff1f", "comment": "Source: WeChat, Published: 2025-12-18 09:39:34", "summary": "\u4eca\u5929\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u7684\u8fd9\u7bc7\u4eba\u5927\u4e0e\u6e05\u534e\u56e2\u961f\u7684\u8bba\u6587 \u300aDeepAnalyze\uff1a Agentic Large Language Models for Autonomous Data Science\u300b\uff0c\u641e\u51fa\u4e86\u4e00\u4e2a 80\u4ebf\u53c2\u6570\uff088B\uff09 \u7684\u6a21\u578b\uff0c\u5728\u5168\u81ea\u52a8\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u4e0a\uff0c\u53d6\u5f97\u4e86\u76f8\u5f53\u4e0d\u9519\u7684\u7ed3\u679c \u3002", "AI": {"tldr": "\u4eca\u5929\u7ed9\u5927\u5bb6\u4ecb\u7ecd\u7684\u8fd9\u7bc7\u4eba\u5927\u4e0e\u6e05\u534e\u56e2\u961f\u7684\u8bba\u6587 \u300aDeepAnalyze\uff1a Agentic Large Language Models for Autonomous Data Science\u300b\uff0c\u641e\u51fa\u4e86\u4e00\u4e2a 80\u4ebf\u53c2\u6570\uff088B\uff09 \u7684\u6a21\u578b\uff0c\u5728\u5168\u81ea\u52a8\u6570\u636e\u79d1\u5b66\u4efb\u52a1\u4e0a\uff0c\u53d6\u5f97\u4e86\u76f8\u5f53\u4e0d\u9519\u7684\u7ed3\u679c \u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.77694893", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyOTQyMjkzOA==&mid=2247501277&idx=1&sn=e0b9de2d1de74f5300abfa767bcd240b&chksm=c343ecd246ea804132472b9901cb3d9065f8ec0d52d14bd5f167d3f649f4b54b33263046b0dd#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyOTQyMjkzOA==&mid=2247501277&idx=1&sn=e0b9de2d1de74f5300abfa767bcd240b&chksm=c343ecd246ea804132472b9901cb3d9065f8ec0d52d14bd5f167d3f649f4b54b33263046b0dd#rd", "authors": ["\u5927\u8bdd\u6570\u667a"], "title": "\u5df4\u9002\u5f97\u677f\uff01<em class=\"highlight\">Agentic</em> AI\u4ece\u6982\u5ff5\u5230\u751f\u4ea7\uff0c\u8fd9\u4e9b\u5751\u5fc5\u987b\u907f\u5f00\uff01", "comment": "Source: WeChat, Published: 2025-12-18 06:00:26", "summary": "\u6982\u5ff5\u9636\u6bb5 vs \u751f\u4ea7\u73af\u5883\uff1a\u4e00\u905390%\u7684Agentic AI\u9879\u76ee\u8fc7\u4e0d\u53bb\u7684\u9e3f\u6c9f\u3002\u6982\u5ff5\u9636\u6bb5\uff1a Demo\u8dd1\u5f97\u98de\u5feb \u6295\u8d44\u4eba\u5f88\u6ee1\u610f \u56e2\u961f\u4fe1\u5fc3\u7206\u68da\u751f\u4ea7\u73af\u5883\uff1a Agent\u51b3\u7b56\u903b\u8f91\u6df7\u4e71\uff0c\u81ea\u4e3b\u6027\u53d8\u6210\"\u968f\u673a\u6027\"", "AI": {"tldr": "\u6982\u5ff5\u9636\u6bb5 vs \u751f\u4ea7\u73af\u5883\uff1a\u4e00\u905390%\u7684Agentic AI\u9879\u76ee\u8fc7\u4e0d\u53bb\u7684\u9e3f\u6c9f\u3002\u6982\u5ff5\u9636\u6bb5\uff1a Demo\u8dd1\u5f97\u98de\u5feb \u6295\u8d44\u4eba\u5f88\u6ee1\u610f \u56e2\u961f\u4fe1\u5fc3\u7206\u68da\u751f\u4ea7\u73af\u5883\uff1a Agent\u51b3\u7b56\u903b\u8f91\u6df7\u4e71\uff0c\u81ea\u4e3b\u6027\u53d8\u6210\"\u968f\u673a\u6027\"", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.4b18be01", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4NjU5NDUxNg==&mid=2247603892&idx=1&sn=850216656f5f968cdffc5c053b730aa0&chksm=ceabde69cf7fc52f5aa6d0a6fd254d86c1b1a1d9cb22a5ef6562fb0c740dc12f5af15f40bd2f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4NjU5NDUxNg==&mid=2247603892&idx=1&sn=850216656f5f968cdffc5c053b730aa0&chksm=ceabde69cf7fc52f5aa6d0a6fd254d86c1b1a1d9cb22a5ef6562fb0c740dc12f5af15f40bd2f#rd", "authors": ["\u4e9a\u9a6c\u900a\u4e91\u5f00\u53d1\u8005"], "title": "<em class=\"highlight\">Agentic</em> AI\u5b9e\u8df5\u6307\u5357\uff5c\u79d8\u7c4d\u4e09\uff1a\u6784\u5efaAgent\u8bb0\u5fc6\u6a21\u5757", "comment": "Source: WeChat, Published: 2025-12-18 03:06:30", "summary": "\u672c\u7cfb\u5217\u6587\u7ae0\u57fa\u4e8e\u5728\u591a\u4e2a\u9879\u76ee\u4e2d\u79ef\u7d2f\u7684Agent\u5e94\u7528\u6784\u5efa\u7ecf\u9a8c\uff0c\u5206\u4eabAgentic AI\u57fa\u7840\u8bbe\u65bd\u5b9e\u8df5\u7ecf\u9a8c\u5185\u5bb9\uff0c\u5e2e\u52a9\u60a8\u5168\u9762\u6df1\u5165\u5730\u638c\u63e1Agent\u6784\u5efa\u7684\u57fa\u672c\u73af\u8282\u3002\u4e0a\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e13\u7528\u6c99\u76d2\u73af\u5883\u7684\u5fc5\u8981\u6027\u4e0e\u5b9e\u8df5\u65b9\u6848\u3002", "AI": {"tldr": "\u672c\u7cfb\u5217\u6587\u7ae0\u57fa\u4e8e\u5728\u591a\u4e2a\u9879\u76ee\u4e2d\u79ef\u7d2f\u7684Agent\u5e94\u7528\u6784\u5efa\u7ecf\u9a8c\uff0c\u5206\u4eabAgentic AI\u57fa\u7840\u8bbe\u65bd\u5b9e\u8df5\u7ecf\u9a8c\u5185\u5bb9\uff0c\u5e2e\u52a9\u60a8\u5168\u9762\u6df1\u5165\u5730\u638c\u63e1Agent\u6784\u5efa\u7684\u57fa\u672c\u73af\u8282\u3002\u4e0a\u7bc7\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e13\u7528\u6c99\u76d2\u73af\u5883\u7684\u5fc5\u8981\u6027\u4e0e\u5b9e\u8df5\u65b9\u6848\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.36944a35", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA5NjMzODEwNQ==&mid=2650595987&idx=1&sn=107eff46209427706e48e6003c7c0b11&chksm=89cf451dcddfcc4596753e3b7b92307c03635f64e72bbfffb1e766fd27c7a04a24f8991667b3#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA5NjMzODEwNQ==&mid=2650595987&idx=1&sn=107eff46209427706e48e6003c7c0b11&chksm=89cf451dcddfcc4596753e3b7b92307c03635f64e72bbfffb1e766fd27c7a04a24f8991667b3#rd", "authors": ["\u738b\u5409\u4f1f"], "title": "\u4e00\u6587\u5f7b\u5e95\u5398\u6e05\uff1aAI Agent\u3001<em class=\"highlight\">Agentic</em> Workflow\u4e0e<em class=\"highlight\">Agentic</em> AI\uff08\u96446\u7bc7\u6838\u5fc3\u8bba\u6587\uff09", "comment": "Source: WeChat, Published: 2025-12-18 02:32:59", "summary": "Agentic WorkflowAgentic Workflow\u662f\u57fa\u4e8e\u4e00\u4e2a\u6216\u591a\u4e2aAI Agent\u6784\u5efa\u7684\u7ed3\u6784\u5316\u4efb\u52a1\u6267\u884c\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u901a\u8fc7\u4efb\u52a1\u62c6\u89e3\u3001\u89d2\u8272\u5206\u5de5\u3001\u6d41\u7a0b\u7f16\u6392\uff0c\u5c06\u590d\u6742\u76ee\u6807\u8f6c\u5316\u4e3a\u53ef\u843d\u5730\u7684\u5206\u6b65\u6267\u884c\u8def\u5f84\u3002", "AI": {"tldr": "Agentic WorkflowAgentic Workflow\u662f\u57fa\u4e8e\u4e00\u4e2a\u6216\u591a\u4e2aAI Agent\u6784\u5efa\u7684\u7ed3\u6784\u5316\u4efb\u52a1\u6267\u884c\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u901a\u8fc7\u4efb\u52a1\u62c6\u89e3\u3001\u89d2\u8272\u5206\u5de5\u3001\u6d41\u7a0b\u7f16\u6392\uff0c\u5c06\u590d\u6742\u76ee\u6807\u8f6c\u5316\u4e3a\u53ef\u843d\u5730\u7684\u5206\u6b65\u6267\u884c\u8def\u5f84\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.49be2d7f", "categories": ["wechat.article", "wechat.ai", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyMDYxNDA5Nw==&mid=2247484839&idx=1&sn=406d11b3409288eb8fd57e76c1d0e2f2&chksm=c0bc042499526a2ccb1b0f8b131cc390b5b1ae93fa79f960b79e765fdf020ab2431bfb06a0ff#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyMDYxNDA5Nw==&mid=2247484839&idx=1&sn=406d11b3409288eb8fd57e76c1d0e2f2&chksm=c0bc042499526a2ccb1b0f8b131cc390b5b1ae93fa79f960b79e765fdf020ab2431bfb06a0ff#rd", "authors": ["\u53f6\u884c\u5bbd"], "title": "<em class=\"highlight\">Agentic</em>\u8bbe\u8ba1\u6a21\u5f0f\uff085\uff09\uff1a\u5de5\u5177\u4f7f\u7528\uff08\u51fd\u6570\u8c03\u7528\uff09", "comment": "Source: WeChat, Published: 2025-12-17 14:38:00", "summary": "\u89c2\u5bdf/\u7ed3\u679c\uff1a\u5de5\u5177\u6267\u7684\u8f93\u51fa\u6216\u7ed3\u679c\u8fd4\u56de\u7ed9\u667a\u80fd\u4f53\u3002\u5927\u6a21\u578b\u5904\u7406\uff1a\u5927\u8bed\u8a00\u6a21\u578b\u63a5\u6536\u5de5\u5177\u7684\u8f93\u51fa\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u5e76\u7528\u5b83\u6765\u751f\u6210\u5bf9\u7528\u6237\u7684\u6700\u7ec8\u56de\u590d\uff0c\u6216\u51b3\u5b9a\u5de5\u4f5c\u6d41\u7684\u4e0b\u4e00\u6b65\uff08\u53ef\u80fd\u6d89\u53ca\u8c03\u7528\u53e6\u4e00\u4e2a\u5de5\u5177\u3001\u8fdb\u884c\u53cd\u601d\u6216\u63d0\u4f9b\u6700\u7ec8\u7b54\u6848\uff09", "AI": {"tldr": "\u89c2\u5bdf/\u7ed3\u679c\uff1a\u5de5\u5177\u6267\u7684\u8f93\u51fa\u6216\u7ed3\u679c\u8fd4\u56de\u7ed9\u667a\u80fd\u4f53\u3002\u5927\u6a21\u578b\u5904\u7406\uff1a\u5927\u8bed\u8a00\u6a21\u578b\u63a5\u6536\u5de5\u5177\u7684\u8f93\u51fa\u4f5c\u4e3a\u4e0a\u4e0b\u6587\uff0c\u5e76\u7528\u5b83\u6765\u751f\u6210\u5bf9\u7528\u6237\u7684\u6700\u7ec8\u56de\u590d\uff0c\u6216\u51b3\u5b9a\u5de5\u4f5c\u6d41\u7684\u4e0b\u4e00\u6b65\uff08\u53ef\u80fd\u6d89\u53ca\u8c03\u7528\u53e6\u4e00\u4e2a\u5de5\u5177\u3001\u8fdb\u884c\u53cd\u601d\u6216\u63d0\u4f9b\u6700\u7ec8\u7b54\u6848\uff09", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.8a7bd0b9", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzNzcwNzE1MA==&mid=2247582178&idx=3&sn=c1b57529b2444f33dc20cc5f603ef806&chksm=c3aab382e1ad6687c712c4633ee8857dc58cf145b7087b1fc8b75a993366be329753c297f688#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzNzcwNzE1MA==&mid=2247582178&idx=3&sn=c1b57529b2444f33dc20cc5f603ef806&chksm=c3aab382e1ad6687c712c4633ee8857dc58cf145b7087b1fc8b75a993366be329753c297f688#rd", "authors": ["\u6269\u5c55\u8ff7AIGC"], "title": "\u7a81\u53d1\uff01OpenAI\u5927\u795e\u59da\u987a\u96e8\uff0c\u4efb\u817e\u8baf\u9996\u5e2dAI\u79d1\u5b66\u5bb6", "comment": "Source: WeChat, Published: 2025-12-18 13:44:33", "summary": "\u800cOpenAI\u6700\u65b0\u7814\u7a76\u4e5f\u5370\u8bc1\u4e86\u8fd9\u4e00\u89c2\u70b9\uff1a\u8bc4\u6d4b\u65b9\u6cd5\u662f\u5f71\u54cd\u6a21\u578b\u5e7b\u89c9\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f18\u5316\u8bc4\u6d4b\u624b\u6bb5\u53ef\u8fdb\u4e00\u6b65\u91ca\u653e\u5927\u6a21\u578b\u7684\u6f5c\u529b\u3002\u8bba\u6587\u5730\u5740\uff1ahttps\uff1a//arxiv.org/pdf/2509.04664", "AI": {"tldr": "\u800cOpenAI\u6700\u65b0\u7814\u7a76\u4e5f\u5370\u8bc1\u4e86\u8fd9\u4e00\u89c2\u70b9\uff1a\u8bc4\u6d4b\u65b9\u6cd5\u662f\u5f71\u54cd\u6a21\u578b\u5e7b\u89c9\u7684\u5173\u952e\u56e0\u7d20\uff0c\u4f18\u5316\u8bc4\u6d4b\u624b\u6bb5\u53ef\u8fdb\u4e00\u6b65\u91ca\u653e\u5927\u6a21\u578b\u7684\u6f5c\u529b\u3002\u8bba\u6587\u5730\u5740\uff1ahttps\uff1a//arxiv.org/pdf/2509.04664", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.fac54bb5", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg3NDkyMTQ5Mw==&mid=2247499266&idx=1&sn=49b3de5059ee0380688ed012ce7355de&chksm=cf34470c6ce996a165273af80d1111948a545918c03340654a63f2a6274e8b5d428847076a7e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg3NDkyMTQ5Mw==&mid=2247499266&idx=1&sn=49b3de5059ee0380688ed012ce7355de&chksm=cf34470c6ce996a165273af80d1111948a545918c03340654a63f2a6274e8b5d428847076a7e#rd", "authors": ["\u6709\u65b0Newin"], "title": "\u8c46\u5305<em class=\"highlight\">\u5927\u6a21\u578b</em>\u65e5\u5747 tokens \u4f7f\u7528\u91cf\u8d85 50 \u4e07\u4ebf\uff01\u540c\u6bd4\u53bb\u5e74\u589e\u957f\u8d85\u5341\u500d", "comment": "Source: WeChat, Published: 2025-12-18 12:44:31", "summary": "\u56fe\uff1a\u8c46\u5305\u5927\u6a21\u578b1.8\u6d4b\u8bd5\u8868\u73b0 \u5728\u591a\u9879\u516c\u5f00\u8bc4\u6d4b\u4e2d\uff0c\u8c46\u53051.8\u5c55\u73b0\u51fa\u6781\u5177\u7ade\u4e89\u529b\u7684\u5168\u9762\u8868\u73b0\uff1a\u5728\u89c6\u89c9\u63a8\u7406\u3001\u901a\u7528\u89c6\u89c9\u95ee\u7b54\u3001\u7a7a\u95f4\u7406\u89e3\u53ca\u89c6\u9891\u7406\u89e3\u7b49\u4efb\u52a1\u4e2d\uff0c\u5747\u83b7\u5f97\u6700\u4f73\u6216\u63a5\u8fd1\u6700\u4f73\u6210\u7ee9\uff1b", "AI": {"tldr": "\u56fe\uff1a\u8c46\u5305\u5927\u6a21\u578b1.8\u6d4b\u8bd5\u8868\u73b0 \u5728\u591a\u9879\u516c\u5f00\u8bc4\u6d4b\u4e2d\uff0c\u8c46\u53051.8\u5c55\u73b0\u51fa\u6781\u5177\u7ade\u4e89\u529b\u7684\u5168\u9762\u8868\u73b0\uff1a\u5728\u89c6\u89c9\u63a8\u7406\u3001\u901a\u7528\u89c6\u89c9\u95ee\u7b54\u3001\u7a7a\u95f4\u7406\u89e3\u53ca\u89c6\u9891\u7406\u89e3\u7b49\u4efb\u52a1\u4e2d\uff0c\u5747\u83b7\u5f97\u6700\u4f73\u6216\u63a5\u8fd1\u6700\u4f73\u6210\u7ee9\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.337c6940", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzOTg3NTYxNw==&mid=2247497524&idx=3&sn=f37fea06ef76d33f7373db0d6f5319a7&chksm=c3e863616dabf401529a60717e1f888738c5bc5622f7db60532d283586491f45437271af11df#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzOTg3NTYxNw==&mid=2247497524&idx=3&sn=f37fea06ef76d33f7373db0d6f5319a7&chksm=c3e863616dabf401529a60717e1f888738c5bc5622f7db60532d283586491f45437271af11df#rd", "authors": ["\u5e7f\u5dde\u5e02\u9ec4\u57d4\u533a\u793e\u4f1a\u5de5\u4f5c\u8054\u5408\u4f1a"], "title": "\u4ea7\u4e1a\u89c4\u6a21\u8d85500\u4ebf\u5143\uff01AI\u4f01\u4e1a\u4e3a\u4f55\u624e\u5806\u9ec4\u57d4\uff1f", "comment": "Source: WeChat, Published: 2025-12-18 12:24:00", "summary": "\u25b3\u5357\u65b9\u7535\u7f51\u6570\u5b57\u7535\u7f51\u7814\u7a76\u9662\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5f00\u53d1\u4e0a\u7ebf\u5168\u56fd\u9996\u4e2a\u81ea\u4e3b\u53ef\u63a7\u7535\u529b\u5927\u6a21\u578b\u201c\u5927\u74e6\u7279\u201d \u56fe/\u5357\u65b9\u7535\u7f51 \u5728\u7b97\u529b\u65b9\u9762\uff0c\u9ec4\u57d4\u533a\u5e03\u5c40\u4e86\u4e00\u7cfb\u5217\u6570\u5b57\u65b0\u57fa\u5efa\uff0c\u5305\u62ec\u5efa\u6210\u7ca4\u6e2f\u6fb3\u5927\u6e7e\u533a\u667a\u80fd\u7b97\u529b\u4e2d\u5fc3\u3001\u843d\u5730\u5168\u7701\u9996\u4e2a\u201c\u4e1c\u6570\u897f\u7b97\u201d\u7ed3\u5bf9\u5b50\u5408", "AI": {"tldr": "\u25b3\u5357\u65b9\u7535\u7f51\u6570\u5b57\u7535\u7f51\u7814\u7a76\u9662\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5f00\u53d1\u4e0a\u7ebf\u5168\u56fd\u9996\u4e2a\u81ea\u4e3b\u53ef\u63a7\u7535\u529b\u5927\u6a21\u578b\u201c\u5927\u74e6\u7279\u201d \u56fe/\u5357\u65b9\u7535\u7f51 \u5728\u7b97\u529b\u65b9\u9762\uff0c\u9ec4\u57d4\u533a\u5e03\u5c40\u4e86\u4e00\u7cfb\u5217\u6570\u5b57\u65b0\u57fa\u5efa\uff0c\u5305\u62ec\u5efa\u6210\u7ca4\u6e2f\u6fb3\u5927\u6e7e\u533a\u667a\u80fd\u7b97\u529b\u4e2d\u5fc3\u3001\u843d\u5730\u5168\u7701\u9996\u4e2a\u201c\u4e1c\u6570\u897f\u7b97\u201d\u7ed3\u5bf9\u5b50\u5408", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.93d70d2e", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU4ODQwNTIxMw==&mid=2247568138&idx=4&sn=b57641769a5d95e0bad9aec9af441804&chksm=fcefd6c384430f7c2fd98b74d2ef0d11ca39ad418537114eb6d1db74316f91f81aad6cc46c47#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU4ODQwNTIxMw==&mid=2247568138&idx=4&sn=b57641769a5d95e0bad9aec9af441804&chksm=fcefd6c384430f7c2fd98b74d2ef0d11ca39ad418537114eb6d1db74316f91f81aad6cc46c47#rd", "authors": ["\u4eba\u5de5\u667a\u80fd\u4ea7\u4e1a\u94feunion"], "title": "\u3010\u62a5\u544a\u3011\u667a\u80fd\u4f53\u4e13\u9898\u56db\uff1a2025\u5e74\u4ece<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5230\u667a\u80fd\u4f53\u2014\u2014\u4eba\u5de5\u667a\u80fd\u573a\u666f\u7684\u6295\u8d44\u5c55\u671b\uff08\u9644PDF\u4e0b\u8f7d\uff09", "comment": "Source: WeChat, Published: 2025-12-18 12:20:41", "summary": "\u62a5\u544a\u6307\u51fa\uff0c\u5927\u6a21\u578b\u5b9e\u73b0\u4e86 \u201c\u5927\u6570\u636e + \u5927\u7b97\u529b + \u5f3a\u7b97\u6cd5\u201d \u7684\u878d\u5408\uff0c\u800c\u667a\u80fd\u4f53\u4f5c\u4e3a \u201c\u5927\u6a21\u578b + \u5de5\u5177 + \u573a\u666f\u201d \u7684\u96c6\u6210\u5f62\u6001\uff0c\u662f\u4eba\u5de5\u667a\u80fd\u4ece \u201c\u6280\u672f\u7a81\u7834\u201d \u8d70\u5411 \u201c\u4ea7\u4e1a\u843d\u5730\u201d \u7684\u5173\u952e\u8f7d\u4f53\uff0c\u5c06\u5728\u91d1\u878d\u3001\u519c\u4e1a\u3001\u77ff\u5c71\u3001\u533b\u7597\u7b49\u9886\u57df\u91cd\u5851\u751f\u4ea7", "AI": {"tldr": "\u62a5\u544a\u6307\u51fa\uff0c\u5927\u6a21\u578b\u5b9e\u73b0\u4e86 \u201c\u5927\u6570\u636e + \u5927\u7b97\u529b + \u5f3a\u7b97\u6cd5\u201d \u7684\u878d\u5408\uff0c\u800c\u667a\u80fd\u4f53\u4f5c\u4e3a \u201c\u5927\u6a21\u578b + \u5de5\u5177 + \u573a\u666f\u201d \u7684\u96c6\u6210\u5f62\u6001\uff0c\u662f\u4eba\u5de5\u667a\u80fd\u4ece \u201c\u6280\u672f\u7a81\u7834\u201d \u8d70\u5411 \u201c\u4ea7\u4e1a\u843d\u5730\u201d \u7684\u5173\u952e\u8f7d\u4f53\uff0c\u5c06\u5728\u91d1\u878d\u3001\u519c\u4e1a\u3001\u77ff\u5c71\u3001\u533b\u7597\u7b49\u9886\u57df\u91cd\u5851\u751f\u4ea7", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.d4da5026", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU0NDEyODkzMQ==&mid=2247562022&idx=3&sn=d518db2cf6af6b4fe256a5e721e6a8b1&chksm=fada97722572fa8358dd416e9cb31121a964f9c5fe909d83c8304661a2f81d3a3d4044a97ba0#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU0NDEyODkzMQ==&mid=2247562022&idx=3&sn=d518db2cf6af6b4fe256a5e721e6a8b1&chksm=fada97722572fa8358dd416e9cb31121a964f9c5fe909d83c8304661a2f81d3a3d4044a97ba0#rd", "authors": ["\u4e91\u6280\u672f"], "title": "\u4e9a\u4fe1\u79d1\u6280\u8f93\u4e86\uff011050\u4e07\u5143\uff0cAI<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5927\u5355\uff1a\u8054\u901a\u4e91\u4e2d\u6807", "comment": "Source: WeChat, Published: 2025-12-18 12:15:58", "summary": "\u5728\u96c6\u56e2\u8303\u56f4\u5185\uff0c\u4eba\u5de5\u667a\u80fd\u573a\u666f\u5b9e\u65bd\u7b49\u5de5\u4f5c\u524d\u666f\u5de8\u5927\uff0c\u672c\u9879\u76ee\u5c31\u662f\u5728\u96c6\u56e2\u516c\u53f8\u5927\u6a21\u578b\u4e3a\u57fa\u7840\u7684\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u9700\u6c42\u7684\u57fa\u7840\u4e0a\u5f62\u6210\u7684\u3002\u65e8\u5728\u4e3a\u4e2d\u56fd\u6d77\u6cb9\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u4eba\u5de5\u667a\u80fd\u5de5\u4f5c\u63d0\u4f9b\u6280\u672f\u652f\u6301\u670d\u52a1\uff0c\u627f\u63a5\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u573a\u666f\u5316\u5f00\u53d1\u670d\u52a1\u3002", "AI": {"tldr": "\u5728\u96c6\u56e2\u8303\u56f4\u5185\uff0c\u4eba\u5de5\u667a\u80fd\u573a\u666f\u5b9e\u65bd\u7b49\u5de5\u4f5c\u524d\u666f\u5de8\u5927\uff0c\u672c\u9879\u76ee\u5c31\u662f\u5728\u96c6\u56e2\u516c\u53f8\u5927\u6a21\u578b\u4e3a\u57fa\u7840\u7684\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u9700\u6c42\u7684\u57fa\u7840\u4e0a\u5f62\u6210\u7684\u3002\u65e8\u5728\u4e3a\u4e2d\u56fd\u6d77\u6cb9\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u4eba\u5de5\u667a\u80fd\u5de5\u4f5c\u63d0\u4f9b\u6280\u672f\u652f\u6301\u670d\u52a1\uff0c\u627f\u63a5\u57fa\u4e8e\u5927\u6a21\u578b\u7684\u573a\u666f\u5316\u5f00\u53d1\u670d\u52a1\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2512.55f4a157", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4MTc1MjY2Mw==&mid=2247497549&idx=3&sn=9139180da768050430c4e667f3e7223a&chksm=cec9ef0ad4d07edaef1b27c74754ccd82bc835735ddf7d7937b708030cdee43c599f945d175a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4MTc1MjY2Mw==&mid=2247497549&idx=3&sn=9139180da768050430c4e667f3e7223a&chksm=cec9ef0ad4d07edaef1b27c74754ccd82bc835735ddf7d7937b708030cdee43c599f945d175a#rd", "authors": ["\u79d1\u6280\u60c5\u62a5"], "title": "\u8c46\u5305<em class=\"highlight\">\u5927\u6a21\u578b</em>1.8\u53d1\u5e03\uff1a\u4e09\u5927\u80fd\u529b\u663e\u8457\u589e\u5f3a \u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b", "comment": "Source: WeChat, Published: 2025-12-18 12:04:00", "summary": "\u5feb\u79d1\u628012\u670818\u65e5\u6d88\u606f\uff0c\u5728\u4eca\u5929\u53ec\u5f00\u7684\u706b\u5c71\u5f15\u64ceForce\u539f\u52a8\u529b\u5927\u4f1a\u4e0a\uff0c\u8c46\u5305\u5927\u6a21\u578b1.8\u6b63\u5f0f\u53d1\u5e03\uff0c\u591a\u6a21\u6001Agent\u80fd\u529b\u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b\u3002\u636e\u4e86\u89e3\uff0c\u8c46\u5305\u5927\u6a21\u578b1.8\u9762\u5411\u591a\u6a21\u6001Agent\u573a\u666f\u8fdb\u884c\u4e86\u5b9a\u5411\u4f18\u5316\u3002", "AI": {"tldr": "\u5feb\u79d1\u628012\u670818\u65e5\u6d88\u606f\uff0c\u5728\u4eca\u5929\u53ec\u5f00\u7684\u706b\u5c71\u5f15\u64ceForce\u539f\u52a8\u529b\u5927\u4f1a\u4e0a\uff0c\u8c46\u5305\u5927\u6a21\u578b1.8\u6b63\u5f0f\u53d1\u5e03\uff0c\u591a\u6a21\u6001Agent\u80fd\u529b\u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b\u3002\u636e\u4e86\u89e3\uff0c\u8c46\u5305\u5927\u6a21\u578b1.8\u9762\u5411\u591a\u6a21\u6001Agent\u573a\u666f\u8fdb\u884c\u4e86\u5b9a\u5411\u4f18\u5316\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.ab0396ce", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5MzA3MzAzOQ==&mid=2655589292&idx=2&sn=241bc6a01b9cf25d8271e569a385c046&chksm=bcef3857deb8dc6883e3dbd5d2240a048d0b62fb1f53a9b78232abdae9582baeec5b411bd090#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5MzA3MzAzOQ==&mid=2655589292&idx=2&sn=241bc6a01b9cf25d8271e569a385c046&chksm=bcef3857deb8dc6883e3dbd5d2240a048d0b62fb1f53a9b78232abdae9582baeec5b411bd090#rd", "authors": ["\u91d1\u878d\u7535\u5b50\u5316"], "title": "<em class=\"highlight\">\u5927\u6a21\u578b</em>+RAG\uff1a\u6784\u5efa\u9ad8\u9002\u914d\u6027\u6d4b\u8bd5\u667a\u80fd\u4f53\u7684\u6838\u5fc3\u5b9e\u8df5", "comment": "Source: WeChat, Published: 2025-12-18 08:19:51", "summary": "1. \u7eaf\u5927\u6a21\u578b\u6d4b\u8bd5\u667a\u80fd\u4f53\u7684\u4e09\u5927\u81f4\u547d\u5c40\u9650 \u77e5\u8bc6\u65f6\u6548\u6027\u4e0e\u7248\u672c\u8131\u8282\uff1a\u901a\u7528\u5927\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u56fa\u5b9a\u65f6\u95f4\u7a97\u53e3\uff0c\u65e0\u6cd5\u540c\u6b65\u6d4b\u8bd5\u9879\u76ee\u7684\u52a8\u6001\u8fed\u4ee3\u9700\u6c42\u3002\u4f8b\u5982\u67d0\u7535\u5546\u9879\u76eeV2.1\u7248\u65b0\u589e\u201c\u4fe1\u521b\u9002\u914d\u6d4b\u8bd5\u89c4\u8303\u201d\uff08\u542b\u9e92\u9e9f\u7cfb\u7edf\u517c\u5bb9\u6027\u8981\u6c42\uff09\uff0c\u7eaf\u5927\u6a21", "AI": {"tldr": "1. \u7eaf\u5927\u6a21\u578b\u6d4b\u8bd5\u667a\u80fd\u4f53\u7684\u4e09\u5927\u81f4\u547d\u5c40\u9650 \u77e5\u8bc6\u65f6\u6548\u6027\u4e0e\u7248\u672c\u8131\u8282\uff1a\u901a\u7528\u5927\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u5b58\u5728\u56fa\u5b9a\u65f6\u95f4\u7a97\u53e3\uff0c\u65e0\u6cd5\u540c\u6b65\u6d4b\u8bd5\u9879\u76ee\u7684\u52a8\u6001\u8fed\u4ee3\u9700\u6c42\u3002\u4f8b\u5982\u67d0\u7535\u5546\u9879\u76eeV2.1\u7248\u65b0\u589e\u201c\u4fe1\u521b\u9002\u914d\u6d4b\u8bd5\u89c4\u8303\u201d\uff08\u542b\u9e92\u9e9f\u7cfb\u7edf\u517c\u5bb9\u6027\u8981\u6c42\uff09\uff0c\u7eaf\u5927\u6a21", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.5cc11880", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzMTY2MzMzMQ==&mid=2247485842&idx=1&sn=a121df5259c5e62f83797e568f804d7f&chksm=c38c4191af4c4c8daa7ed3b5710ac4f6942bdf6b4e1f41ac0ee1deedf9960704b01d33b8980e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzMTY2MzMzMQ==&mid=2247485842&idx=1&sn=a121df5259c5e62f83797e568f804d7f&chksm=c38c4191af4c4c8daa7ed3b5710ac4f6942bdf6b4e1f41ac0ee1deedf9960704b01d33b8980e#rd", "authors": ["\u8c46\u5305"], "title": "\u8c46\u5305<em class=\"highlight\">\u5927\u6a21\u578b</em>1.8\u53d1\u5e03\uff0cSeedance\u6a21\u578b\u540c\u6b65\u5347\u7ea7", "comment": "Source: WeChat, Published: 2025-12-18 08:12:27", "summary": "\u8c46\u5305\u5927\u6a21\u578b1.8\u591a\u6a21\u6001Agent\u80fd\u529b\u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b\u8c46\u5305\u5927\u6a21\u578b1.8\uff08Doubao-Seed-1.8\uff09\u9762\u5411\u591a\u6a21\u6001Agent\u573a\u666f\u8fdb\u884c\u4e86\u5b9a\u5411\u4f18\u5316\u3002\u5176\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3001\u590d\u6742\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u53caOS Agent\u80fd\u529b\u663e\u8457\u589e\u5f3a\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7684\u89c4\u5212\u4e0e\u6267\u884c\u6c34\u5e73", "AI": {"tldr": "\u8c46\u5305\u5927\u6a21\u578b1.8\u591a\u6a21\u6001Agent\u80fd\u529b\u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b\u8c46\u5305\u5927\u6a21\u578b1.8\uff08Doubao-Seed-1.8\uff09\u9762\u5411\u591a\u6a21\u6001Agent\u573a\u666f\u8fdb\u884c\u4e86\u5b9a\u5411\u4f18\u5316\u3002\u5176\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3001\u590d\u6742\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u53caOS Agent\u80fd\u529b\u663e\u8457\u589e\u5f3a\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7684\u89c4\u5212\u4e0e\u6267\u884c\u6c34\u5e73", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.c20fca3c", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU1MDgyNzk5Ng==&mid=2247492666&idx=1&sn=c59cbcc42fd874bc628c405adf357d26&chksm=faf3048d286b7779f31a557afdb4d0d21cb7eeffa84d1b4e93cf1147f0f1bbcbef51432232bf#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU1MDgyNzk5Ng==&mid=2247492666&idx=1&sn=c59cbcc42fd874bc628c405adf357d26&chksm=faf3048d286b7779f31a557afdb4d0d21cb7eeffa84d1b4e93cf1147f0f1bbcbef51432232bf#rd", "authors": ["\u5b57\u8282\u8df3\u52a8"], "title": "\u8c46\u5305<em class=\"highlight\">\u5927\u6a21\u578b</em>1.8\u53d1\u5e03\uff0cSeedance\u6a21\u578b\u540c\u6b65\u5347\u7ea7", "comment": "Source: WeChat, Published: 2025-12-18 07:59:50", "summary": "\u8c46\u5305\u5927\u6a21\u578b1.8\u591a\u6a21\u6001Agent\u80fd\u529b\u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b\u8c46\u5305\u5927\u6a21\u578b1.8\uff08Doubao-Seed-1.8\uff09\u9762\u5411\u591a\u6a21\u6001Agent\u573a\u666f\u8fdb\u884c\u4e86\u5b9a\u5411\u4f18\u5316\u3002\u5176\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3001\u590d\u6742\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u53caOS Agent\u80fd\u529b\u663e\u8457\u589e\u5f3a\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7684\u89c4\u5212\u4e0e\u6267\u884c\u6c34\u5e73", "AI": {"tldr": "\u8c46\u5305\u5927\u6a21\u578b1.8\u591a\u6a21\u6001Agent\u80fd\u529b\u5ab2\u7f8e\u5168\u7403\u9876\u5c16\u6a21\u578b\u8c46\u5305\u5927\u6a21\u578b1.8\uff08Doubao-Seed-1.8\uff09\u9762\u5411\u591a\u6a21\u6001Agent\u573a\u666f\u8fdb\u884c\u4e86\u5b9a\u5411\u4f18\u5316\u3002\u5176\u5de5\u5177\u8c03\u7528\u80fd\u529b\u3001\u590d\u6742\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u53caOS Agent\u80fd\u529b\u663e\u8457\u589e\u5f3a\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u7684\u89c4\u5212\u4e0e\u6267\u884c\u6c34\u5e73", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
