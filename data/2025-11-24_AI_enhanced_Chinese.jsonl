{"id": "2511.16708", "categories": ["cs.SE", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.16708", "abs": "https://arxiv.org/abs/2511.16708", "authors": ["Shreshth Rajan"], "title": "Multi-Agent Code Verification with Compound Vulnerability Detection", "comment": "18 pages, 3 figures, 9 tables", "summary": "LLMs generate buggy code: 29.6% of SWE-bench \"solved\" patches fail, 62% of BaxBench solutions have vulnerabilities, and existing tools only catch 65% of bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent when the agents look for different problems, confirmed by measuring agent correlation of p = 0.05--0.25. We also show that multiple vulnerabilities in the same code create exponentially more risk than previously thought--SQL injection plus exposed credentials creates 15x more danger (risk 300 vs. 20) than traditional models predict. Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method while running faster and without test execution. We tested 15 different agent combinations and found that using multiple agents improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to single agents, with gains of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and 4. The best two-agent combination reaches 79.3% accuracy. Testing on 300 real patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this practical for production use.", "AI": {"tldr": "CodeX-Verify\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u4f7f\u7528\u56db\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u68c0\u6d4b\u4e0d\u540c\u7c7b\u578b\u7684\u4ee3\u7801\u6f0f\u6d1e\u3002\u8be5\u7cfb\u7edf\u5728\u4e0d\u6267\u884c\u6d4b\u8bd5\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u6355\u83b776.1%\u7684\u6f0f\u6d1e\uff0c\u51c6\u786e\u7387\u4e0e\u6700\u4f73\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u4f46\u8fd0\u884c\u66f4\u5feb\u3002\u591a\u667a\u80fd\u4f53\u7ec4\u5408\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u5c06\u51c6\u786e\u7387\u4ece32.8%\u63d0\u5347\u81f372.4%\u3002", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7684\u4ee3\u7801\u5b58\u5728\u4e25\u91cd\u6f0f\u6d1e\u95ee\u9898\uff1aSWE-bench\u4e2d29.6%\u7684\u4fee\u590d\u8865\u4e01\u5931\u8d25\uff0cBaxBench\u4e2d62%\u7684\u89e3\u51b3\u65b9\u6848\u6709\u6f0f\u6d1e\uff0c\u73b0\u6709\u5de5\u5177\u53ea\u80fd\u6355\u83b765%\u7684\u6f0f\u6d1e\u4e14\u5047\u9633\u6027\u7387\u8fbe35%\u3002\u9700\u8981\u66f4\u6709\u6548\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u591a\u667a\u80fd\u4f53\u7cfb\u7edfCodeX-Verify\uff0c\u4f7f\u7528\u56db\u4e2a\u4e13\u95e8\u5316\u667a\u80fd\u4f53\u68c0\u6d4b\u4e0d\u540c\u7c7b\u578b\u7684\u6f0f\u6d1e\u3002\u901a\u8fc7\u6570\u5b66\u8bc1\u660e\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5f53\u667a\u80fd\u4f53\u5bfb\u627e\u4e0d\u540c\u95ee\u9898\u65f6\uff0c\u7ec4\u5408\u591a\u4e2a\u667a\u80fd\u4f53\u6bd4\u4efb\u4f55\u5355\u4e00\u667a\u80fd\u4f53\u80fd\u53d1\u73b0\u66f4\u591a\u6f0f\u6d1e\u3002", "result": "\u572899\u4e2a\u5e26\u9a8c\u8bc1\u6807\u7b7e\u7684\u4ee3\u7801\u6837\u672c\u4e0a\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u6355\u83b776.1%\u7684\u6f0f\u6d1e\uff0c\u4e0e\u6700\u4f73\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u4f46\u8fd0\u884c\u66f4\u5feb\u4e14\u65e0\u9700\u6d4b\u8bd5\u6267\u884c\u3002\u591a\u667a\u80fd\u4f53\u7ec4\u5408\u76f8\u6bd4\u5355\u667a\u80fd\u4f53\u5c06\u51c6\u786e\u7387\u63d0\u534739.7\u4e2a\u767e\u5206\u70b9\u3002\u6700\u4f73\u53cc\u667a\u80fd\u4f53\u7ec4\u5408\u8fbe\u523079.3%\u51c6\u786e\u7387\u3002\u5728300\u4e2a\u771f\u5b9e\u8865\u4e01\u4e0a\u6d4b\u8bd5\uff0c\u6bcf\u4e2a\u6837\u672c\u8fd0\u884c\u65f6\u95f4\u4f4e\u4e8e200ms\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u9ad8\u4ee3\u7801\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e14\u5177\u6709\u5b9e\u9645\u751f\u4ea7\u5e94\u7528\u4ef7\u503c\u3002\u591a\u4e2a\u6f0f\u6d1e\u5728\u540c\u4e00\u4ee3\u7801\u4e2d\u7684\u7ec4\u5408\u98ce\u9669\u6bd4\u4f20\u7edf\u6a21\u578b\u9884\u6d4b\u7684\u8981\u9ad8\u5f97\u591a\u3002", "topic": "code agent"}}
{"id": "2511.16858", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16858", "abs": "https://arxiv.org/abs/2511.16858", "authors": ["Toufique Ahmed", "Jatin Ganhotra", "Avraham Shinnar", "Martin Hirzel"], "title": "Is the Cure Still Worse Than the Disease? Test Overfitting by LLMs in Automated Program Repair", "comment": null, "summary": "Automated program repair has been shown to be susceptible to generating repaired code that passes on seen tests but fails on a hold-out set of hidden tests. This problem, dubbed test overfitting, has been identified and studied before the rise of large language models. We experimentally study how much test overfitting is still a problem today, using repository-level SWE-bench tasks.", "AI": {"tldr": "\u7814\u7a76\u6d4b\u8bd5\u8fc7\u62df\u5408\u5728\u5f53\u4eca\u4ee3\u7801\u4fee\u590d\u4e2d\u7684\u6301\u7eed\u6027\u95ee\u9898\uff0c\u4f7f\u7528SWE-bench\u4ed3\u5e93\u7ea7\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790", "motivation": "\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u5b58\u5728\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5373\u4fee\u590d\u540e\u7684\u4ee3\u7801\u80fd\u901a\u8fc7\u53ef\u89c1\u6d4b\u8bd5\u4f46\u5728\u9690\u85cf\u6d4b\u8bd5\u96c6\u4e0a\u5931\u8d25\u3002\u867d\u7136\u8fd9\u4e2a\u95ee\u9898\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5174\u8d77\u524d\u5df2\u88ab\u7814\u7a76\uff0c\u4f46\u9700\u8981\u9a8c\u8bc1\u5176\u5728\u5f53\u524d\u73af\u5883\u4e0b\u7684\u4e25\u91cd\u7a0b\u5ea6", "method": "\u4f7f\u7528SWE-bench\u4ed3\u5e93\u7ea7\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\u7814\u7a76\uff0c\u5206\u6790\u6d4b\u8bd5\u8fc7\u62df\u5408\u73b0\u8c61", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u6d4b\u8bd5\u8fc7\u62df\u5408\u95ee\u9898\u5728\u4eca\u5929\u4ecd\u7136\u5b58\u5728", "conclusion": "\u6d4b\u8bd5\u8fc7\u62df\u5408\u4ecd\u7136\u662f\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d\u4e2d\u9700\u8981\u5173\u6ce8\u7684\u91cd\u8981\u95ee\u9898", "topic": "swe benchmark"}}
{"id": "2511.16837", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16837", "abs": "https://arxiv.org/abs/2511.16837", "authors": ["Oliver Kramer"], "title": "Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs", "comment": "6 pages, Submitted to ESANN 2026", "summary": "Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.", "AI": {"tldr": "Cognitive BASIC\u662f\u4e00\u79cd\u57fa\u4e8eBASIC\u98ce\u683c\u7684\u63d0\u793a\u8bed\u8a00\u548c\u6a21\u578b\u5185\u89e3\u91ca\u5668\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u7ed3\u6784\u5316\u4e3a\u663e\u5f0f\u7684\u9010\u6b65\u6267\u884c\u8f68\u8ff9\u3002", "motivation": "\u53d7\u590d\u53e4BASIC\u7b80\u5355\u6027\u7684\u542f\u53d1\uff0c\u91cd\u65b0\u5229\u7528\u7f16\u53f7\u884c\u548c\u7b80\u5355\u547d\u4ee4\u4f5c\u4e3a\u53ef\u89e3\u91ca\u7684\u8ba4\u77e5\u63a7\u5236\u5c42\uff0c\u4f7fLLM\u63a8\u7406\u8fc7\u7a0b\u66f4\u52a0\u900f\u660e\u3002", "method": "\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u5668\u6587\u4ef6\u6307\u5b9a\u547d\u4ee4\u8bed\u4e49\u3001\u5185\u5b58\u66f4\u65b0\u548c\u65e5\u5fd7\u884c\u4e3a\uff0c\u901a\u8fc7\u5fc3\u7406\u6a21\u578b\u89e3\u91ca\u5668\u63d0\u53d6\u58f0\u660e\u6027\u548c\u7a0b\u5e8f\u6027\u77e5\u8bc6\uff0c\u68c0\u6d4b\u77db\u76fe\u5e76\u5728\u5fc5\u8981\u65f6\u4ea7\u751f\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u4e09\u4e2aLLM\u4e0a\u7684\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u6240\u6709\u6a21\u578b\u90fd\u80fd\u6267\u884cCognitive BASIC\u7a0b\u5e8f\uff0c\u6574\u4f53\u6027\u80fd\u5f3a\u52b2\u4f46\u4e0d\u5747\u5300\u3002", "conclusion": "Cognitive BASIC\u4e3aLLM\u63d0\u4f9b\u4e86\u7ed3\u6784\u5316\u7684\u63a8\u7406\u6846\u67b6\uff0c\u4f7f\u591a\u6b65\u63a8\u7406\u8fc7\u7a0b\u5728\u6a21\u578b\u5185\u90e8\u53d8\u5f97\u900f\u660e\u3002", "topic": "agent analysis"}}
{"id": "2511.17131", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17131", "abs": "https://arxiv.org/abs/2511.17131", "authors": ["Horia Cristescu", "Charles Park", "Trong Canh Nguyen", "Sergiu Talmacel", "Alexandru-Gabriel Ilie", "Stefan Adam"], "title": "UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task Accuracy to Operational Reliability", "comment": "18 pages, 8 figures, 5 tables. Benchmark comprising 226 tasks across two difficulty tiers. Code and benchmark available at https://github.com/UiPath/uipath_enterprise_benchmark", "summary": "While current Computer Use Agent (CUA) benchmarks measure task completion effectively, they provide limited assessment of enterprise deployment readiness, emphasizing functional correctness over the operational reliability required for production systems. We present UI-CUBE (UiPath Computer Use BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty tiers designed to expose fundamental architectural limitations in current CUAs. Our evaluation covers simple UI interactions (136 tasks) and complex workflows including copy-paste tasks (50 tasks) and enterprise application scenarios (40 tasks), with systematic interface variation coverage, multi-resolution testing and automated validation of task success through the application state. Evaluation of five state-of-the-art models reveals a sharp capability cliff rather than gradual performance degradation. Simple UI interactions achieve 67-85% success rates (compared to 97.9% human performance), but complex workflows drop precipitously to 9-19%. Human evaluators with no prior application experience achieve only 61.2% on complex tasks despite near-perfect performance on simple tasks, establishing realistic performance ceilings. This discontinuous performance pattern -- where agents achieve 68-87% of human performance on simple tasks but only 15-32% on complex workflows -- indicates fundamental architectural limitations in memory management, hierarchical planning, and state coordination rather than incremental capability gaps addressable through better training or prompting. UI-CUBE functions as an enterprise-readiness diagnostic, revealing that while current CUAs can manipulate individual interface elements, they cannot yet function as reliable workflow automation tools. These findings provide architectural insights essential for developing production-ready CUAs capable of managing complex, multi-step enterprise processes.", "AI": {"tldr": "UI-CUBE\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406(CUA)\u4f01\u4e1a\u90e8\u7f72\u51c6\u5907\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b226\u4e2a\u4efb\u52a1\uff0c\u63ed\u793a\u5f53\u524dCUA\u5728\u590d\u6742\u5de5\u4f5c\u6d41\u4e2d\u7684\u67b6\u6784\u5c40\u9650\u6027", "motivation": "\u73b0\u6709CUA\u57fa\u51c6\u4e3b\u8981\u5173\u6ce8\u529f\u80fd\u6b63\u786e\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4f01\u4e1a\u90e8\u7f72\u6240\u9700\u7684\u64cd\u4f5c\u53ef\u9760\u6027\u7684\u8bc4\u4f30\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u57fa\u51c6\u6765\u66b4\u9732CUA\u7684\u67b6\u6784\u9650\u5236", "method": "\u5f00\u53d1UI-CUBE\u57fa\u51c6\uff0c\u5305\u542b136\u4e2a\u7b80\u5355UI\u4ea4\u4e92\u4efb\u52a1\u300150\u4e2a\u590d\u5236\u7c98\u8d34\u4efb\u52a1\u548c40\u4e2a\u4f01\u4e1a\u5e94\u7528\u573a\u666f\u4efb\u52a1\uff0c\u901a\u8fc7\u7cfb\u7edf\u754c\u9762\u53d8\u5316\u8986\u76d6\u3001\u591a\u5206\u8fa8\u7387\u6d4b\u8bd5\u548c\u5e94\u7528\u72b6\u6001\u81ea\u52a8\u9a8c\u8bc1\u6765\u8bc4\u4f30\u4efb\u52a1\u6210\u529f\u7387", "result": "\u8bc4\u4f305\u4e2a\u6700\u5148\u8fdb\u6a21\u578b\u663e\u793a\u80fd\u529b\u65ad\u5d16\u5f0f\u4e0b\u964d\uff1a\u7b80\u5355UI\u4ea4\u4e92\u6210\u529f\u738767-85%\uff0c\u590d\u6742\u5de5\u4f5c\u6d41\u9aa4\u964d\u81f39-19%\uff1b\u4eba\u7c7b\u8bc4\u4f30\u8005\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u4ec561.2%\u6210\u529f\u7387", "conclusion": "\u5f53\u524dCUA\u867d\u7136\u80fd\u64cd\u4f5c\u5355\u4e2a\u754c\u9762\u5143\u7d20\uff0c\u4f46\u65e0\u6cd5\u4f5c\u4e3a\u53ef\u9760\u7684\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u5de5\u5177\uff0c\u5b58\u5728\u5185\u5b58\u7ba1\u7406\u3001\u5206\u5c42\u89c4\u5212\u548c\u72b6\u6001\u534f\u8c03\u7b49\u67b6\u6784\u9650\u5236", "topic": "agent analysis"}}
{"id": "2511.16767", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16767", "abs": "https://arxiv.org/abs/2511.16767", "authors": ["Haotian Xu", "Yuning You", "Tengfei Ma"], "title": "When Structure Doesn't Help: LLMs Do Not Read Text-Attributed Graphs as Effectively as We Expected", "comment": null, "summary": "Graphs provide a unified representation of semantic content and relational structure, making them a natural fit for domains such as molecular modeling, citation networks, and social graphs. Meanwhile, large language models (LLMs) have excelled at understanding natural language and integrating cross-modal signals, sparking interest in their potential for graph reasoning. Recent work has explored this by either designing template-based graph templates or using graph neural networks (GNNs) to encode structural information. In this study, we investigate how different strategies for encoding graph structure affect LLM performance on text-attributed graphs. Surprisingly, our systematic experiments reveal that: (i) LLMs leveraging only node textual descriptions already achieve strong performance across tasks; and (ii) most structural encoding strategies offer marginal or even negative gains. We show that explicit structural priors are often unnecessary and, in some cases, counterproductive when powerful language models are involved. This represents a significant departure from traditional graph learning paradigms and highlights the need to rethink how structure should be represented and utilized in the LLM era. Our study is to systematically challenge the foundational assumption that structure is inherently beneficial for LLM-based graph reasoning, opening the door to new, semantics-driven approaches for graph learning.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6587\u672c\u5c5e\u6027\u56fe\u4e0a\uff0c\u4ec5\u4f7f\u7528\u8282\u70b9\u6587\u672c\u63cf\u8ff0\u7684LLM\u5df2\u7ecf\u8868\u73b0\u51fa\u8272\uff0c\u5927\u591a\u6570\u7ed3\u6784\u7f16\u7801\u7b56\u7565\u5e26\u6765\u7684\u63d0\u5347\u6709\u9650\u751a\u81f3\u8d1f\u9762\uff0c\u8868\u660e\u5728\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u65f6\u4ee3\u9700\u8981\u91cd\u65b0\u601d\u8003\u7ed3\u6784\u8868\u793a\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u56fe\u7ed3\u6784\u7f16\u7801\u7b56\u7565\u5982\u4f55\u5f71\u54cdLLM\u5728\u6587\u672c\u5c5e\u6027\u56fe\u4e0a\u7684\u6027\u80fd\uff0c\u6311\u6218\u4f20\u7edf\u56fe\u5b66\u4e60\u4e2d\u7ed3\u6784\u5fc5\u7136\u6709\u76ca\u7684\u5047\u8bbe\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u5b9e\u9a8c\u6bd4\u8f83\u4e0d\u540c\u56fe\u7ed3\u6784\u7f16\u7801\u7b56\u7565\uff0c\u5305\u62ec\u4ec5\u4f7f\u7528\u8282\u70b9\u6587\u672c\u63cf\u8ff0\u3001\u6a21\u677f\u5316\u56fe\u8868\u793a\u548cGNN\u7f16\u7801\u7ed3\u6784\u4fe1\u606f\u7b49\u65b9\u6cd5\u3002", "result": "\u4ee4\u4eba\u60ca\u8bb6\u5730\u53d1\u73b0\uff1a(i)\u4ec5\u4f7f\u7528\u8282\u70b9\u6587\u672c\u63cf\u8ff0\u7684LLM\u5728\u5404\u9879\u4efb\u52a1\u4e2d\u5df2\u8868\u73b0\u4f18\u5f02\uff1b(ii)\u5927\u591a\u6570\u7ed3\u6784\u7f16\u7801\u7b56\u7565\u4ec5\u5e26\u6765\u8fb9\u9645\u6536\u76ca\u751a\u81f3\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "\u5f53\u4f7f\u7528\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u663e\u5f0f\u7684\u7ed3\u6784\u5148\u9a8c\u5f80\u5f80\u4e0d\u5fc5\u8981\u751a\u81f3\u9002\u5f97\u5176\u53cd\uff0c\u8fd9\u6807\u5fd7\u7740\u4e0e\u4f20\u7edf\u56fe\u5b66\u4e60\u8303\u5f0f\u7684\u91cd\u5927\u80cc\u79bb\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003LLM\u65f6\u4ee3\u7684\u7ed3\u6784\u8868\u793a\u65b9\u6cd5\u3002", "topic": "agent analysis"}}
{"id": "2511.16916", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16916", "abs": "https://arxiv.org/abs/2511.16916", "authors": ["Ye Han", "Lijun Zhang", "Dejian Meng", "Zhuang Zhang"], "title": "Hybrid Differential Reward: Combining Temporal Difference and Action Gradients for Efficient Multi-Agent Reinforcement Learning in Cooperative Driving", "comment": null, "summary": "In multi-vehicle cooperative driving tasks involving high-frequency continuous control, traditional state-based reward functions suffer from the issue of vanishing reward differences. This phenomenon results in a low signal-to-noise ratio (SNR) for policy gradients, significantly hindering algorithm convergence and performance improvement. To address this challenge, this paper proposes a novel Hybrid Differential Reward (HDR) mechanism. We first theoretically elucidate how the temporal quasi-steady nature of traffic states and the physical proximity of actions lead to the failure of traditional reward signals. Building on this analysis, the HDR framework innovatively integrates two complementary components: (1) a Temporal Difference Reward (TRD) based on a global potential function, which utilizes the evolutionary trend of potential energy to ensure optimal policy invariance and consistency with long-term objectives; and (2) an Action Gradient Reward (ARG), which directly measures the marginal utility of actions to provide a local guidance signal with a high SNR. Furthermore, we formulate the cooperative driving problem as a Multi-Agent Partially Observable Markov Game (POMDPG) with a time-varying agent set and provide a complete instantiation scheme for HDR within this framework. Extensive experiments conducted using both online planning (MCTS) and Multi-Agent Reinforcement Learning (QMIX, MAPPO, MADDPG) algorithms demonstrate that the HDR mechanism significantly improves convergence speed and policy stability. The results confirm that HDR guides agents to learn high-quality cooperative policies that effectively balance traffic efficiency and safety.", "AI": {"tldr": "\u63d0\u51fa\u6df7\u5408\u5dee\u5206\u5956\u52b1\u673a\u5236\u89e3\u51b3\u591a\u8f66\u534f\u540c\u9a7e\u9a76\u4e2d\u4f20\u7edf\u5956\u52b1\u51fd\u6570\u4fe1\u53f7\u6d88\u5931\u95ee\u9898\uff0c\u901a\u8fc7\u65f6\u95f4\u5dee\u5206\u5956\u52b1\u548c\u52a8\u4f5c\u68af\u5ea6\u5956\u52b1\u63d0\u9ad8\u7b56\u7565\u68af\u5ea6\u4fe1\u566a\u6bd4\uff0c\u663e\u8457\u63d0\u5347\u7b97\u6cd5\u6536\u655b\u901f\u5ea6\u548c\u7b56\u7565\u7a33\u5b9a\u6027\u3002", "motivation": "\u591a\u8f66\u534f\u540c\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0c\u4f20\u7edf\u57fa\u4e8e\u72b6\u6001\u7684\u5956\u52b1\u51fd\u6570\u5b58\u5728\u5956\u52b1\u5dee\u5f02\u6d88\u5931\u95ee\u9898\uff0c\u5bfc\u81f4\u7b56\u7565\u68af\u5ea6\u4fe1\u566a\u6bd4\u4f4e\uff0c\u4e25\u91cd\u5f71\u54cd\u7b97\u6cd5\u6536\u655b\u548c\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u5dee\u5206\u5956\u52b1\u673a\u5236\uff0c\u5305\u542b\u57fa\u4e8e\u5168\u5c40\u52bf\u51fd\u6570\u7684\u65f6\u95f4\u5dee\u5206\u5956\u52b1\u548c\u76f4\u63a5\u6d4b\u91cf\u52a8\u4f5c\u8fb9\u9645\u6548\u7528\u7684\u52a8\u4f5c\u68af\u5ea6\u5956\u52b1\uff0c\u5e76\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u6846\u67b6\u4e2d\u5b9e\u4f8b\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660eHDR\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u6536\u655b\u901f\u5ea6\u548c\u7b56\u7565\u7a33\u5b9a\u6027\uff0c\u5f15\u5bfc\u667a\u80fd\u4f53\u5b66\u4e60\u5230\u5e73\u8861\u4ea4\u901a\u6548\u7387\u548c\u5b89\u5168\u7684\u4f18\u8d28\u534f\u540c\u7b56\u7565\u3002", "conclusion": "HDR\u673a\u5236\u901a\u8fc7\u89e3\u51b3\u5956\u52b1\u4fe1\u53f7\u6d88\u5931\u95ee\u9898\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u8f66\u534f\u540c\u9a7e\u9a76\u4efb\u52a1\u7684\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.16997", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16997", "abs": "https://arxiv.org/abs/2511.16997", "authors": ["Qingbin Zeng", "Bingbing Fan", "Zhiyu Chen", "Sijian Ren", "Zhilun Zhou", "Xuhua Zhang", "Yuanyi Zhen", "Fengli Xu", "Yong Li", "Tie-Yan Liu"], "title": "MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists", "comment": "26 pages, 4 figures", "summary": "The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.", "AI": {"tldr": "MirrorMind\u662f\u4e00\u4e2a\u5206\u5c42\u8ba4\u77e5\u67b6\u6784\uff0c\u901a\u8fc7\u6574\u5408\u4e2a\u4f53\u8ba4\u77e5\u8f68\u8ff9\u548c\u96c6\u4f53\u5b66\u79d1\u8bb0\u5fc6\uff0c\u4f7fAI\u79d1\u5b66\u5bb6\u80fd\u591f\u8fdb\u884c\u7ed3\u6784\u5316\u3001\u4e2a\u6027\u5316\u7684\u79d1\u5b66\u63a8\u7406\u3002", "motivation": "\u73b0\u6709AI\u79d1\u5b66\u65b9\u6cd5\u5c06\u79d1\u5b66\u53d1\u73b0\u89c6\u4e3a\u5b64\u7acb\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u5ffd\u89c6\u4e86\u77e5\u8bc6\u751f\u4ea7\u7684\u793e\u4f1a\u6027\u548c\u5386\u53f2\u6027\u672c\u8d28\u3002\u4eba\u7c7b\u79d1\u5b66\u6d1e\u5bdf\u6765\u81ea\u4e2a\u4f53\u8ba4\u77e5\u8f68\u8ff9\u548c\u96c6\u4f53\u5b66\u79d1\u8bb0\u5fc6\u4e24\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u6765\u6e90\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u6846\u67b6\uff1a\u4e2a\u4f53\u5c42\u9762\u6784\u5efa\u7814\u7a76\u8005\u7684\u8ba4\u77e5\u6a21\u578b\uff08\u60c5\u666f\u3001\u8bed\u4e49\u3001\u4eba\u683c\u8bb0\u5fc6\uff09\uff1b\u9886\u57df\u5c42\u9762\u5c06\u96c6\u4f53\u77e5\u8bc6\u6620\u5c04\u4e3a\u5b66\u79d1\u6982\u5ff5\u56fe\uff1b\u8de8\u5b66\u79d1\u5c42\u9762\u4f5c\u4e3a\u6b63\u4ea4\u7f16\u6392\u5f15\u64ce\u3002\u67b6\u6784\u5c06\u8bb0\u5fc6\u5b58\u50a8\u4e0e\u667a\u80fd\u6267\u884c\u5206\u79bb\u3002", "result": "\u5728\u56db\u4e2a\u7efc\u5408\u4efb\u52a1\u4e2d\u8bc4\u4f30\uff1a\u4f5c\u8005\u7ea7\u8ba4\u77e5\u6a21\u62df\u3001\u4e92\u8865\u63a8\u7406\u3001\u8de8\u5b66\u79d1\u534f\u4f5c\u4fc3\u8fdb\u3001\u591a\u667a\u80fd\u4f53\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u3002\u7ed3\u679c\u663e\u793aMirrorMind\u8d85\u8d8a\u4e86\u7b80\u5355\u4e8b\u5b9e\u68c0\u7d22\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u3001\u4e2a\u6027\u5316\u7684\u6d1e\u5bdf\u751f\u6210\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u4e2a\u4f53\u8ba4\u77e5\u6df1\u5ea6\u548c\u96c6\u4f53\u5b66\u79d1\u5e7f\u5ea6\uff0cMirrorMind\u80fd\u591f\u8fdb\u884c\u7ed3\u6784\u6027\u3001\u4e2a\u6027\u5316\u7684\u79d1\u5b66\u63a8\u7406\uff0c\u63a8\u52a8AI\u79d1\u5b66\u5bb6\u8d85\u8d8a\u7b80\u5355\u4e8b\u5b9e\u68c0\u7d22\u3002", "topic": "agent analysis"}}
{"id": "2511.17330", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17330", "abs": "https://arxiv.org/abs/2511.17330", "authors": ["Haoxin Tu", "Huan Zhao", "Yahui Song", "Mehtab Zafar", "Ruijie Meng", "Abhik Roychoudhury"], "title": "Agentic Program Verification", "comment": "21 pages, 8 figures", "summary": "Automatically generated code is gaining traction recently, owing to the prevalence of Large Language Models (LLMs). Further, the AlphaProof initiative has demonstrated the possibility of using AI for general mathematical reasoning. Reasoning about computer programs (software) can be accomplished via general mathematical reasoning; however, it tends to be more structured and richer in contexts. This forms an attractive proposition, since then AI agents can be used to reason about voluminous code that gets generated by AI.\n  In this work, we present a first LLM agent, AutoRocq, for conducting program verification. Unlike past works, which rely on extensive training of LLMs on proof examples, our agent learns on-the-fly and improves the proof via an iterative refinement loop. The iterative improvement of the proof is achieved by the proof agent communicating with the Rocq (formerly Coq) theorem prover to get additional context and feedback. The final result of the iteration is a proof derivation checked by the Rocq theorem prover. In this way, our proof construction involves autonomous collaboration between the proof agent and the theorem prover. This autonomy facilitates the search for proofs and decision-making in deciding on the structure of the proof tree.\n  Experimental evaluation on SV-COMP benchmarks and on Linux kernel modules shows promising efficacy in achieving automated program verification. As automation in code generation becomes more widespread, we posit that our proof agent can be potentially integrated with AI coding agents to achieve a generate and validate loop, thus moving closer to the vision of trusted automatic programming.", "AI": {"tldr": "AutoRocq\u662f\u4e00\u4e2a\u7528\u4e8e\u7a0b\u5e8f\u9a8c\u8bc1\u7684LLM\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u8fed\u4ee3\u7cbe\u5316\u5faa\u73af\u4e0eRocq\u5b9a\u7406\u8bc1\u660e\u5668\u534f\u4f5c\uff0c\u5b9e\u73b0\u81ea\u4e3b\u7684\u8bc1\u660e\u6784\u5efa\u548c\u9a8c\u8bc1\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u4ee3\u7801\u7684\u666e\u53ca\uff0c\u9700\u8981\u81ea\u52a8\u5316\u7a0b\u5e8f\u9a8c\u8bc1\u6765\u786e\u4fdd\u4ee3\u7801\u53ef\u9760\u6027\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u800cAutoRocq\u65e8\u5728\u5b9e\u73b0\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\u3001\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u548c\u6539\u8fdb\u7684\u9a8c\u8bc1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u7cbe\u5316\u5faa\u73af\uff0cLLM\u667a\u80fd\u4f53\u4e0eRocq\u5b9a\u7406\u8bc1\u660e\u5668\u534f\u4f5c\uff0c\u901a\u8fc7\u83b7\u53d6\u4e0a\u4e0b\u6587\u548c\u53cd\u9988\u4e0d\u65ad\u6539\u8fdb\u8bc1\u660e\uff0c\u6700\u7ec8\u751f\u6210\u7ecf\u8fc7\u5b9a\u7406\u8bc1\u660e\u5668\u9a8c\u8bc1\u7684\u8bc1\u660e\u63a8\u5bfc\u3002", "result": "\u5728SV-COMP\u57fa\u51c6\u6d4b\u8bd5\u548cLinux\u5185\u6838\u6a21\u5757\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u81ea\u52a8\u5316\u7a0b\u5e8f\u9a8c\u8bc1\u65b9\u9762\u5177\u6709\u826f\u597d\u6548\u679c\u3002", "conclusion": "AutoRocq\u53ef\u4ee5\u4e0eAI\u4ee3\u7801\u751f\u6210\u667a\u80fd\u4f53\u96c6\u6210\uff0c\u5b9e\u73b0\u751f\u6210-\u9a8c\u8bc1\u5faa\u73af\uff0c\u63a8\u52a8\u53ef\u4fe1\u81ea\u52a8\u7f16\u7a0b\u7684\u53d1\u5c55\u3002", "topic": "code agent"}}
{"id": "2511.17006", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17006", "abs": "https://arxiv.org/abs/2511.17006", "authors": ["Tengxiao Liu", "Zifeng Wang", "Jin Miao", "I-Hung Hsu", "Jun Yan", "Jiefeng Chen", "Rujun Han", "Fangyuan Xu", "Yanfei Chen", "Ke Jiang", "Samira Daruki", "Yi Liang", "William Yang Wang", "Tomas Pfister", "Chen-Yu Lee"], "title": "Budget-Aware Tool-Use Enables Effective Agent Scaling", "comment": null, "summary": "Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only \"thinking\" in tokens but also \"acting\" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack \"budget awareness\" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to \"dig deeper\" on a promising lead or \"pivot\" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u5de5\u5177\u589e\u5f3a\u578b\u667a\u80fd\u4f53\u4e2d\u5982\u4f55\u6709\u6548\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\uff0c\u63d0\u51fa\u4e86\u9884\u7b97\u611f\u77e5\u65b9\u6cd5\u6765\u89e3\u51b3\u5355\u7eaf\u589e\u52a0\u5de5\u5177\u8c03\u7528\u9884\u7b97\u65e0\u6cd5\u63d0\u5347\u6027\u80fd\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5de5\u5177\u589e\u5f3a\u578b\u667a\u80fd\u4f53\u7f3a\u4e4f\u9884\u7b97\u610f\u8bc6\uff0c\u5373\u4f7f\u7ed9\u4e88\u66f4\u5927\u7684\u5de5\u5177\u8c03\u7528\u9884\u7b97\u4e5f\u65e0\u6cd5\u63d0\u5347\u6027\u80fd\uff0c\u9700\u8981\u7814\u7a76\u5982\u4f55\u5728\u660e\u786e\u5de5\u5177\u8c03\u7528\u9884\u7b97\u4e0b\u6709\u6548\u6269\u5c55\u667a\u80fd\u4f53\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u9884\u7b97\u8ddf\u8e2a\u5668\uff08Budget Tracker\uff09\u8f7b\u91cf\u7ea7\u63d2\u4ef6\u63d0\u4f9b\u6301\u7eed\u9884\u7b97\u610f\u8bc6\uff0c\u5e76\u5f00\u53d1\u4e86BATS\u6846\u67b6\u52a8\u6001\u8c03\u6574\u89c4\u5212\u548c\u9a8c\u8bc1\u7b56\u7565\uff0c\u540c\u65f6\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u6210\u672c\u5ea6\u91cf\u6807\u51c6\u3002", "result": "\u9884\u7b97\u611f\u77e5\u65b9\u6cd5\u4ea7\u751f\u4e86\u66f4\u6709\u5229\u7684\u6269\u5c55\u66f2\u7ebf\uff0c\u63a8\u52a8\u4e86\u6210\u672c-\u6027\u80fd\u7684\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u63d0\u4f9b\u4e86\u5bf9\u5de5\u5177\u589e\u5f3a\u578b\u667a\u80fd\u4f53\u6269\u5c55\u7684\u66f4\u900f\u660e\u548c\u539f\u5219\u6027\u7406\u89e3\u3002", "conclusion": "\u9884\u7b97\u611f\u77e5\u662f\u5de5\u5177\u589e\u5f3a\u578b\u667a\u80fd\u4f53\u6709\u6548\u6269\u5c55\u7684\u5173\u952e\uff0c\u8be5\u65b9\u6cd5\u4e3a\u667a\u80fd\u4f53\u5728\u7ea6\u675f\u9884\u7b97\u4e0b\u7684\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agent analysis"}}
{"id": "2511.16787", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16787", "abs": "https://arxiv.org/abs/2511.16787", "authors": ["Hossain Shaikh Saadi", "Faria Alam", "Mario Sanz-Guerrero", "Minh Duc Bui", "Manuel Mager", "Katharina von der Wense"], "title": "NALA_MAINZ at BLP-2025 Task 2: A Multi-agent Approach for Bangla Instruction to Python Code Generation", "comment": "BLP 2025 Shared Task 2 - Code Generation in Bangla", "summary": "This paper presents JGU Mainz's winning system for the BLP-2025 Shared Task on Code Generation from Bangla Instructions. We propose a multi-agent-based pipeline. First, a code-generation agent produces an initial solution from the input instruction. The candidate program is then executed against the provided unit tests (pytest-style, assert-based). Only the failing cases are forwarded to a debugger agent, which reruns the tests, extracts error traces, and, conditioning on the error messages, the current program, and the relevant test cases, generates a revised solution. Using this approach, our submission achieved first place in the shared task with a $Pass@1$ score of 95.4. We also make our code public.", "AI": {"tldr": "JGU Mainz\u56e2\u961f\u5728BLP-2025\u4ee3\u7801\u751f\u6210\u5171\u4eab\u4efb\u52a1\u4e2d\u83b7\u80dc\uff0c\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff1a\u4ee3\u7801\u751f\u6210\u667a\u80fd\u4f53\u751f\u6210\u521d\u59cb\u65b9\u6848\uff0c\u8c03\u8bd5\u667a\u80fd\u4f53\u9488\u5bf9\u5931\u8d25\u6d4b\u8bd5\u7528\u4f8b\u8fdb\u884c\u4fee\u6b63\uff0c\u6700\u7ec8\u83b7\u5f9795.4%\u7684Pass@1\u5f97\u5206\u3002", "motivation": "\u89e3\u51b3\u4ece\u5b5f\u52a0\u62c9\u8bed\u6307\u4ee4\u751f\u6210\u4ee3\u7801\u7684\u6311\u6218\uff0c\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u63d0\u9ad8\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7ba1\u9053\uff1a\u4ee3\u7801\u751f\u6210\u667a\u80fd\u4f53\u751f\u6210\u521d\u59cb\u4ee3\u7801\uff0c\u8c03\u8bd5\u667a\u80fd\u4f53\u9488\u5bf9\u5931\u8d25\u6d4b\u8bd5\u7528\u4f8b\u63d0\u53d6\u9519\u8bef\u4fe1\u606f\u5e76\u751f\u6210\u4fee\u6b63\u65b9\u6848\u3002", "result": "\u5728BLP-2025\u5171\u4eab\u4efb\u52a1\u4e2d\u83b7\u5f97\u7b2c\u4e00\u540d\uff0cPass@1\u5f97\u5206\u8fbe\u523095.4%\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u6307\u4ee4\u548c\u9519\u8bef\u4fee\u6b63\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "topic": "code agent"}}
{"id": "2511.16693", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16693", "abs": "https://arxiv.org/abs/2511.16693", "authors": ["JaeSeong Kim", "Suan Lee"], "title": "How Language Directions Align with Token Geometry in Multilingual LLMs", "comment": "4 pages", "summary": "Multilingual LLMs demonstrate strong performance across diverse languages, yet there has been limited systematic analysis of how language information is structured within their internal representation space and how it emerges across layers. We conduct a comprehensive probing study on six multilingual LLMs, covering all 268 transformer layers, using linear and nonlinear probes together with a new Token--Language Alignment analysis to quantify the layer-wise dynamics and geometric structure of language encoding. Our results show that language information becomes sharply separated in the first transformer block (+76.4$\\pm$8.2 percentage points from Layer 0 to 1) and remains almost fully linearly separable throughout model depth. We further find that the alignment between language directions and vocabulary embeddings is strongly tied to the language composition of the training data. Notably, Chinese-inclusive models achieve a ZH Match@Peak of 16.43\\%, whereas English-centric models achieve only 3.90\\%, revealing a 4.21$\\times$ structural imprinting effect. These findings indicate that multilingual LLMs distinguish languages not by surface script features but by latent representational structures shaped by the training corpus. Our analysis provides practical insights for data composition strategies and fairness in multilingual representation learning. All code and analysis scripts are publicly available at: https://github.com/thisiskorea/How-Language-Directions-Align-with-Token-Geometry-in-Multilingual-LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5168\u9762\u63a2\u6d4b\u7814\u7a76\u5206\u6790\u4e86\u591a\u8bed\u8a00\u5927\u6a21\u578b\u4e2d\u8bed\u8a00\u4fe1\u606f\u7684\u5185\u90e8\u8868\u793a\u7ed3\u6784\u548c\u5c42\u95f4\u6f14\u5316\u52a8\u6001\uff0c\u53d1\u73b0\u8bed\u8a00\u4fe1\u606f\u5728\u7b2c\u4e00\u4e2aTransformer\u5757\u4e2d\u6025\u5267\u5206\u79bb\uff0c\u5e76\u5728\u6574\u4e2a\u6a21\u578b\u6df1\u5ea6\u4e2d\u4fdd\u6301\u7ebf\u6027\u53ef\u5206\u6027\u3002", "motivation": "\u5c3d\u7ba1\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5728\u591a\u79cd\u8bed\u8a00\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bf9\u5176\u5185\u90e8\u8868\u793a\u7a7a\u95f4\u4e2d\u8bed\u8a00\u4fe1\u606f\u7684\u7ed3\u6784\u5316\u65b9\u5f0f\u4ee5\u53ca\u5728\u4e0d\u540c\u5c42\u95f4\u7684\u6d8c\u73b0\u8fc7\u7a0b\u7f3a\u4e4f\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u4f7f\u7528\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u63a2\u9488\u7ed3\u5408\u65b0\u7684Token-Language Alignment\u5206\u6790\uff0c\u5bf96\u4e2a\u591a\u8bed\u8a00\u5927\u6a21\u578b\u7684268\u4e2aTransformer\u5c42\u8fdb\u884c\u5168\u9762\u63a2\u6d4b\u7814\u7a76\u3002", "result": "\u8bed\u8a00\u4fe1\u606f\u5728\u7b2c\u4e00\u4e2aTransformer\u5757\u4e2d\u6025\u5267\u5206\u79bb\uff08\u4ece\u7b2c0\u5c42\u5230\u7b2c1\u5c42\u63d0\u534776.4\u00b18.2\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u4e14\u5728\u6574\u4e2a\u6a21\u578b\u6df1\u5ea6\u4e2d\u51e0\u4e4e\u5b8c\u5168\u7ebf\u6027\u53ef\u5206\u3002\u8bed\u8a00\u65b9\u5411\u4e0e\u8bcd\u6c47\u5d4c\u5165\u7684\u5bf9\u9f50\u4e0e\u8bad\u7ec3\u6570\u636e\u7684\u8bed\u8a00\u7ec4\u6210\u5bc6\u5207\u76f8\u5173\u3002", "conclusion": "\u591a\u8bed\u8a00\u5927\u6a21\u578b\u4e0d\u662f\u901a\u8fc7\u8868\u9762\u811a\u672c\u7279\u5f81\u800c\u662f\u901a\u8fc7\u7531\u8bad\u7ec3\u8bed\u6599\u5851\u9020\u7684\u6f5c\u5728\u8868\u793a\u7ed3\u6784\u6765\u533a\u5206\u8bed\u8a00\uff0c\u8fd9\u4e3a\u591a\u8bed\u8a00\u8868\u793a\u5b66\u4e60\u7684\u6570\u636e\u7ec4\u6210\u7b56\u7565\u548c\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u5b9e\u8df5\u6d1e\u89c1\u3002", "topic": "agent analysis"}}
{"id": "2511.17162", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17162", "abs": "https://arxiv.org/abs/2511.17162", "authors": ["Sara Zuppiroli", "Carmelo Fabio Longo", "Anna Sofia Lippolis", "Rocco Paolillo", "Lorenzo Giammei", "Miguel Ceriani", "Francesco Poggi", "Antonio Zinilli", "Andrea Giovanni Nuzzolese"], "title": "The Belief-Desire-Intention Ontology for modelling mental reality and agency", "comment": null, "summary": "The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u7684BDI\u672c\u4f53\u8bba\uff0c\u4f5c\u4e3a\u6a21\u5757\u5316\u7684\u672c\u4f53\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u7528\u4e8e\u8868\u793a\u667a\u80fd\u4f53\u7684\u4fe1\u5ff5\u3001\u613f\u671b\u548c\u610f\u56fe\u53ca\u5176\u52a8\u6001\u5173\u7cfb\u3002\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u9002\u7528\u6027\uff1a\u4e0eLLM\u7ed3\u5408\u589e\u5f3a\u63a8\u7406\u4e00\u81f4\u6027\uff0c\u4ee5\u53ca\u5728Semas\u63a8\u7406\u5e73\u53f0\u4e2d\u5b9e\u73b0RDF\u4e09\u5143\u7ec4\u4e0e\u5fc3\u667a\u72b6\u6001\u7684\u53cc\u5411\u8f6c\u6362\u3002", "motivation": "BDI\u6a21\u578b\u662f\u4eba\u5de5\u667a\u80fd\u548c\u8ba4\u77e5\u79d1\u5b66\u4e2d\u8868\u793a\u7406\u6027\u667a\u80fd\u4f53\u7684\u57fa\u7840\u6a21\u578b\uff0c\u4f46\u5176\u4e0e\u7ed3\u6784\u5316\u3001\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u7684\u77e5\u8bc6\u8868\u793a\u7684\u6574\u5408\u4ecd\u7136\u6709\u9650\u3002\u9700\u8981\u5f00\u53d1\u5f62\u5f0f\u5316\u7684BDI\u672c\u4f53\u6765\u652f\u6301\u8ba4\u77e5\u57fa\u7840\u7684\u591a\u667a\u80fd\u4f53\u548c\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684BDI\u672c\u4f53\u8bba\u6a21\u5f0f\uff0c\u4e0e\u57fa\u7840\u672c\u4f53\u5bf9\u9f50\u786e\u4fdd\u8bed\u4e49\u7cbe\u786e\u6027\u548c\u53ef\u91cd\u7528\u6027\u3002\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\uff1a(1) \u4e0eLLM\u7ed3\u5408\u4f7f\u7528\u903b\u8f91\u589e\u5f3a\u751f\u6210\u8bc4\u4f30\u672c\u4f53\u57fa\u7840\u5bf9\u63a8\u7406\u4e00\u81f4\u6027\u7684\u8d21\u732e\uff1b(2) \u5728Semas\u63a8\u7406\u5e73\u53f0\u4e2d\u96c6\u6210\uff0c\u5b9e\u73b0T2B2T\u8303\u5f0f\u3002", "result": "BDI\u672c\u4f53\u8bba\u5728\u5b9e\u9a8c\u4e2d\u6210\u529f\u4f5c\u4e3a\u58f0\u660e\u5f0f\u667a\u80fd\u548c\u8fc7\u7a0b\u5f0f\u667a\u80fd\u4e4b\u95f4\u7684\u6982\u5ff5\u548c\u64cd\u4f5c\u6865\u6881\uff0c\u652f\u6301\u4e86\u8ba4\u77e5\u57fa\u7840\u3001\u53ef\u89e3\u91ca\u4e14\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u6570\u636e\u7f51\u7edc\u4e2d\u7684\u8fd0\u884c\u3002", "conclusion": "\u8be5BDI\u672c\u4f53\u8bba\u4e3a\u6784\u5efa\u8ba4\u77e5\u57fa\u7840\u3001\u53ef\u89e3\u91ca\u4e14\u8bed\u4e49\u53ef\u4e92\u64cd\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u548c\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6982\u5ff5\u548c\u64cd\u4f5c\u6846\u67b6\uff0c\u4fc3\u8fdb\u4e86\u58f0\u660e\u5f0f\u667a\u80fd\u4e0e\u8fc7\u7a0b\u5f0f\u667a\u80fd\u7684\u878d\u5408\u3002", "topic": "agent analysis"}}
{"id": "2511.16699", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16699", "abs": "https://arxiv.org/abs/2511.16699", "authors": ["Juan P. Cadile"], "title": "Detecting and Steering LLMs' Empathy in Action", "comment": "14 pages, 9 figures", "summary": "We investigate empathy-in-action -- the willingness to sacrifice task efficiency to address human needs -- as a linear direction in LLM activation space. Using contrastive prompts grounded in the Empathy-in-Action (EIA) benchmark, we test detection and steering across Phi-3-mini-4k (3.8B), Qwen2.5-7B (safety-trained), and Dolphin-Llama-3.1-8B (uncensored).\n  Detection: All models show AUROC 0.996-1.00 at optimal layers. Uncensored Dolphin matches safety-trained models, demonstrating empathy encoding emerges independent of safety training. Phi-3 probes correlate strongly with EIA behavioral scores (r=0.71, p<0.01). Cross-model probe agreement is limited (Qwen: r=-0.06, Dolphin: r=0.18), revealing architecture-specific implementations despite convergent detection.\n  Steering: Qwen achieves 65.3% success with bidirectional control and coherence at extreme interventions. Phi-3 shows 61.7% success with similar coherence. Dolphin exhibits asymmetric steerability: 94.4% success for pro-empathy steering but catastrophic breakdown for anti-empathy (empty outputs, code artifacts).\n  Implications: The detection-steering gap varies by model. Qwen and Phi-3 maintain bidirectional coherence; Dolphin shows robustness only for empathy enhancement. Safety training may affect steering robustness rather than preventing manipulation, though validation across more models is needed.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5171\u60c5\u884c\u4e3a\u662fLLM\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u7684\u7ebf\u6027\u65b9\u5411\uff0c\u53ef\u5728\u7279\u5b9a\u5c42\u68c0\u6d4b\u548c\u64cd\u63a7\u3002\u4e0d\u540c\u6a21\u578b\u5728\u68c0\u6d4b\u7cbe\u5ea6\u4e0a\u8868\u73b0\u4e00\u81f4\uff0c\u4f46\u5728\u64cd\u63a7\u7a33\u5065\u6027\u4e0a\u5b58\u5728\u5dee\u5f02\uff0c\u5b89\u5168\u8bad\u7ec3\u5f71\u54cd\u64cd\u63a7\u7a33\u5065\u6027\u800c\u975e\u9632\u6b62\u64cd\u63a7\u3002", "motivation": "\u63a2\u7d22LLM\u4e2d\"\u884c\u52a8\u5171\u60c5\"\uff08\u727a\u7272\u4efb\u52a1\u6548\u7387\u6ee1\u8db3\u4eba\u7c7b\u9700\u6c42\uff09\u7684\u795e\u7ecf\u8868\u5f81\uff0c\u7814\u7a76\u5176\u68c0\u6d4b\u548c\u64cd\u63a7\u7684\u53ef\u80fd\u6027\uff0c\u4ee5\u53ca\u5b89\u5168\u8bad\u7ec3\u5bf9\u5171\u60c5\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eEIA\u57fa\u51c6\u7684\u5bf9\u6bd4\u63d0\u793a\uff0c\u5728Phi-3-mini-4k\u3001Qwen2.5-7B\u548cDolphin-Llama-3.1-8B\u4e09\u4e2a\u6a21\u578b\u4e0a\u6d4b\u8bd5\u5171\u60c5\u884c\u4e3a\u7684\u68c0\u6d4b\u548c\u64cd\u63a7\u80fd\u529b\u3002", "result": "\u68c0\u6d4b\u65b9\u9762\uff1a\u6240\u6709\u6a21\u578b\u5728\u6700\u4f18\u5c42AUROC\u8fbe0.996-1.00\uff0c\u5171\u60c5\u7f16\u7801\u72ec\u7acb\u4e8e\u5b89\u5168\u8bad\u7ec3\u3002\u64cd\u63a7\u65b9\u9762\uff1aQwen\u548cPhi-3\u53cc\u5411\u64cd\u63a7\u6210\u529f\u7387\u8fbe65.3%\u548c61.7%\uff0cDolphin\u4ec5\u652f\u6301\u4eb2\u5171\u60c5\u64cd\u63a7\uff0894.4%\u6210\u529f\u7387\uff09\uff0c\u53cd\u5171\u60c5\u64cd\u63a7\u4f1a\u5bfc\u81f4\u5d29\u6e83\u3002", "conclusion": "\u68c0\u6d4b-\u64cd\u63a7\u5dee\u8ddd\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u5b89\u5168\u8bad\u7ec3\u5f71\u54cd\u64cd\u63a7\u7a33\u5065\u6027\u800c\u975e\u9632\u6b62\u64cd\u63a7\uff0c\u9700\u8981\u66f4\u591a\u6a21\u578b\u9a8c\u8bc1\u3002", "topic": "agent analysis"}}
{"id": "2511.17198", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.17198", "abs": "https://arxiv.org/abs/2511.17198", "authors": ["Kaiyu Li", "Jiayu Wang", "Zhi Wang", "Hui Qiao", "Weizhan Zhang", "Deyu Meng", "Xiangyong Cao"], "title": "Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism", "comment": "Page: https://earth-insights.github.io/EarthAgent", "summary": "LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5206\u5c42\u4efb\u52a1\u62bd\u8c61\u673a\u5236(HTAM)\u7684EarthAgent\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u590d\u6742\u5730\u7406\u7a7a\u95f4\u5206\u6790\uff0c\u5728GeoPlan-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "motivation": "\u901a\u7528LLM\u9a71\u52a8\u667a\u80fd\u4f53\u5728\u9700\u8981\u4e25\u683c\u7ed3\u6784\u5316\u5de5\u4f5c\u6d41\u7a0b\u7684\u4e13\u4e1a\u9886\u57df\u8868\u73b0\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u9065\u611f\u7b49\u9700\u8981\u4e13\u4e1a\u5de5\u5177\u548c\u591a\u6b65\u9aa4\u7a0b\u5e8f\u7684\u9886\u57df\u3002", "method": "\u5f15\u5165\u5206\u5c42\u4efb\u52a1\u62bd\u8c61\u673a\u5236(HTAM)\uff0c\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7ec4\u7ec7\u6210\u53cd\u6620\u9886\u57df\u5185\u5728\u4efb\u52a1\u4f9d\u8d56\u5173\u7cfb\u7684\u903b\u8f91\u5c42\u6b21\u7ed3\u6784\uff0c\u786e\u4fdd\u7a0b\u5e8f\u6b63\u786e\u6027\u5e76\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u987a\u5e8f\u5c42\u3002", "result": "EarthAgent\u5728GeoPlan-bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86\u5c06\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u9886\u57df\u4efb\u52a1\u7ed3\u6784\u5bf9\u9f50\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u5c06\u667a\u80fd\u4f53\u67b6\u6784\u4e0e\u9886\u57df\u5185\u5728\u4efb\u52a1\u7ed3\u6784\u5bf9\u9f50\u662f\u6784\u5efa\u7a33\u5065\u53ef\u9760\u7684\u4e13\u4e1a\u81ea\u4e3b\u7cfb\u7edf\u7684\u5173\u952e\u6b65\u9aa4\u3002", "topic": "agent analysis"}}
{"id": "2511.17332", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.17332", "abs": "https://arxiv.org/abs/2511.17332", "authors": ["Virginia Dignum", "Frank Dignum"], "title": "Agentifying Agentic AI", "comment": "10 pages; 1 figure", "summary": "Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.", "AI": {"tldr": "\u8bba\u6587\u4e3b\u5f20\u5c06AAMAS\u793e\u533a\u5f00\u53d1\u7684BDI\u67b6\u6784\u3001\u901a\u4fe1\u534f\u8bae\u3001\u673a\u5236\u8bbe\u8ba1\u548c\u5236\u5ea6\u5efa\u6a21\u7b49\u6982\u5ff5\u5de5\u5177\u4f5c\u4e3a\u5b9e\u73b0\u667a\u80fdAI\u7cfb\u7edf\u7684\u57fa\u7840\uff0c\u901a\u8fc7\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u548c\u7ed3\u6784\u5316\u63a8\u7406\u534f\u8c03\u6a21\u578b\uff0c\u6784\u5efa\u5177\u5907\u900f\u660e\u5ea6\u3001\u534f\u4f5c\u6027\u548c\u95ee\u8d23\u5236\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u667a\u80fdAI\u7cfb\u7edf\u7f3a\u4e4f\u5bf9\u8ba4\u77e5\u3001\u534f\u4f5c\u548c\u6cbb\u7406\u7684\u660e\u786e\u6a21\u578b\uff0c\u9700\u8981\u7ed3\u5408\u5f62\u5f0f\u5316\u7406\u8bba\u548c\u5b9e\u9645\u81ea\u4e3b\u6027\u6765\u6784\u5efa\u66f4\u5b8c\u5584\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "method": "\u5229\u7528AAMAS\u793e\u533a\u7684\u6982\u5ff5\u5de5\u5177\uff08BDI\u67b6\u6784\u3001\u901a\u4fe1\u534f\u8bae\u3001\u673a\u5236\u8bbe\u8ba1\u3001\u5236\u5ea6\u5efa\u6a21\uff09\uff0c\u5c06\u81ea\u9002\u5e94\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u534f\u8c03\u6a21\u578b\u76f8\u7ed3\u5408\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u8fde\u63a5\u5f62\u5f0f\u5316\u7406\u8bba\u548c\u5b9e\u9645\u81ea\u4e3b\u6027\u7684\u667a\u80fd\u89c6\u89d2\uff0c\u4e3a\u6784\u5efa\u900f\u660e\u3001\u534f\u4f5c\u548c\u53ef\u95ee\u8d23\u7684\u667a\u80fd\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "AAMAS\u793e\u533a\u7684\u6982\u5ff5\u5de5\u5177\u4e3a\u5b9e\u73b0\u5177\u5907\u6301\u7eed\u81ea\u4e3b\u6027\u3001\u63a8\u7406\u548c\u4ea4\u4e92\u80fd\u529b\u7684\u667a\u80fdAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u7406\u8bba\u57fa\u7840\u548c\u65b9\u6cd5\u8bba\u652f\u6301\u3002", "topic": "agent analysis"}}
{"id": "2511.17408", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17408", "abs": "https://arxiv.org/abs/2511.17408", "authors": ["Nathalie Kirch", "Samuel Dower", "Adrians Skapars", "Ekdeep Singh Lubana", "Dmitrii Krasheninnikov"], "title": "That's not natural: The Impact of Off-Policy Training Data on Probe Performance", "comment": "10 pages, EurIPS 2025 Workshop on Private AI Governance", "summary": "Probing has emerged as a promising method for monitoring Large Language Models (LLMs), enabling inference-time detection of concerning behaviours such as deception and sycophancy. However, natural examples of many behaviours are rare, forcing researchers to rely on synthetic or off-policy LLM responses for training probes. We systematically evaluate how the use of synthetic and off-policy data influences probe generalisation across eight distinct LLM behaviours. Testing linear and attention probes across multiple LLMs, we find that the response generation strategy can significantly affect probe performance, though the magnitude of this effect varies by behaviour. We find that successful generalisation from off-policy data, to test sets where the model is incentivised to produce the target behaviour, is predictive of successful on-policy generalisation. Leveraging this result, we predict that Deception and Sandbagging probes may fail to generalise from off-policy to on-policy data when used in real monitoring scenarios. Notably, shifts in the training data domain still cause even larger performance degradation, with different-domain test scores being consistently lower than the same-domain ones. These results indicate that, in the absence of on-policy data, using same-domain off-policy data yields more reliable probes than using on-policy data from a different domain, emphasizing the need for methods that can better handle distribution shifts in LLM monitoring.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5728LLM\u76d1\u63a7\u4e2d\u4f7f\u7528\u5408\u6210\u548c\u79bb\u7b56\u7565\u6570\u636e\u5bf9\u63a2\u9488\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u54cd\u5e94\u751f\u6210\u7b56\u7565\u663e\u8457\u5f71\u54cd\u63a2\u9488\u6027\u80fd\uff0c\u4e14\u8bad\u7ec3\u6570\u636e\u57df\u7684\u504f\u79fb\u4f1a\u5bfc\u81f4\u66f4\u5927\u7684\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u7531\u4e8e\u8bb8\u591a\u884c\u4e3a\u7684\u81ea\u7136\u793a\u4f8b\u7a00\u5c11\uff0c\u7814\u7a76\u8005\u4e0d\u5f97\u4e0d\u4f9d\u8d56\u5408\u6210\u6216\u79bb\u7b56\u7565\u7684LLM\u54cd\u5e94\u6765\u8bad\u7ec3\u63a2\u9488\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u5bf9\u63a2\u9488\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u5728\u516b\u4e2a\u4e0d\u540c\u7684LLM\u884c\u4e3a\u4e0a\u6d4b\u8bd5\u7ebf\u6027\u548c\u6ce8\u610f\u529b\u63a2\u9488\uff0c\u8bc4\u4f30\u4e0d\u540c\u54cd\u5e94\u751f\u6210\u7b56\u7565\u5bf9\u63a2\u9488\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u5206\u6790\u4ece\u79bb\u7b56\u7565\u6570\u636e\u5230\u540c\u7b56\u7565\u6570\u636e\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u4ece\u79bb\u7b56\u7565\u6570\u636e\u6210\u529f\u6cdb\u5316\u5230\u6d4b\u8bd5\u96c6\u53ef\u4ee5\u9884\u6d4b\u540c\u7b56\u7565\u6cdb\u5316\u7684\u6210\u529f\uff0c\u4f46\u6b3a\u9a97\u548c\u6545\u610f\u8868\u73b0\u4e0d\u4f73\u7684\u63a2\u9488\u53ef\u80fd\u5728\u771f\u5b9e\u76d1\u63a7\u573a\u666f\u4e2d\u6cdb\u5316\u5931\u8d25\u3002\u4e0d\u540c\u57df\u6d4b\u8bd5\u5206\u6570\u59cb\u7ec8\u4f4e\u4e8e\u540c\u57df\u6d4b\u8bd5\u3002", "conclusion": "\u5728\u7f3a\u4e4f\u540c\u7b56\u7565\u6570\u636e\u65f6\uff0c\u4f7f\u7528\u540c\u57df\u79bb\u7b56\u7565\u6570\u636e\u6bd4\u4f7f\u7528\u4e0d\u540c\u57df\u7684\u540c\u7b56\u7565\u6570\u636e\u4ea7\u751f\u66f4\u53ef\u9760\u7684\u63a2\u9488\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u597d\u5904\u7406LLM\u76d1\u63a7\u4e2d\u5206\u5e03\u504f\u79fb\u7684\u65b9\u6cd5\u3002", "topic": "agent analysis"}}
{"id": "2511.16885", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16885", "abs": "https://arxiv.org/abs/2511.16885", "authors": ["Kang Wang", "Xiangyu Duan", "Tianyi Du"], "title": "Improving Latent Reasoning in LLMs via Soft Concept Mixing", "comment": "7 pages, 3 figures", "summary": "Unlike human reasoning in abstract conceptual spaces, large language models (LLMs) typically reason by generating discrete tokens, which potentially limit their expressive power. The recent work Soft Thinking has shown that LLMs' latent reasoning via soft concepts is a promising direction, but LLMs are trained on discrete tokens. To reduce this gap between the soft concepts in reasoning and the discrete tokens in training, we propose Soft Concept Mixing (SCM), a soft concept aware training scheme that directly exposes the model to soft representations during training. Specifically, SCM constructs a soft concept vector by forming a probability-weighted average of embeddings. Then, this vector is mixed into the model's hidden states, which embody rich contextual information. Finally, the entire latent reasoning process is optimized with Reinforcement Learning (RL). Experiments on five reasoning benchmarks demonstrate that SCM improves the reasoning performance of LLMs, and simultaneously maintains a stable training dynamic.", "AI": {"tldr": "\u63d0\u51faSoft Concept Mixing (SCM)\u8bad\u7ec3\u65b9\u6848\uff0c\u901a\u8fc7\u5728\u8bad\u7ec3\u4e2d\u76f4\u63a5\u66b4\u9732\u8f6f\u6982\u5ff5\u8868\u793a\u6765\u5f25\u5408\u63a8\u7406\u4e2d\u7684\u8f6f\u6982\u5ff5\u4e0e\u8bad\u7ec3\u4e2d\u7684\u79bb\u6563\u6807\u8bb0\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u5347LLMs\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "LLMs\u901a\u5e38\u901a\u8fc7\u751f\u6210\u79bb\u6563\u6807\u8bb0\u8fdb\u884c\u63a8\u7406\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u8868\u8fbe\u80fd\u529b\u3002\u73b0\u6709\u7814\u7a76\u8868\u660eLLMs\u901a\u8fc7\u8f6f\u6982\u5ff5\u7684\u6f5c\u5728\u63a8\u7406\u5f88\u6709\u524d\u666f\uff0c\u4f46LLMs\u662f\u5728\u79bb\u6563\u6807\u8bb0\u4e0a\u8bad\u7ec3\u7684\uff0c\u5b58\u5728\u8bad\u7ec3\u4e0e\u63a8\u7406\u65b9\u5f0f\u7684\u4e0d\u5339\u914d\u3002", "method": "SCM\u6784\u5efa\u8f6f\u6982\u5ff5\u5411\u91cf\uff08\u5d4c\u5165\u7684\u6982\u7387\u52a0\u6743\u5e73\u5747\uff09\uff0c\u5c06\u5176\u6df7\u5408\u5230\u6a21\u578b\u7684\u9690\u85cf\u72b6\u6001\u4e2d\uff0c\u5e76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6574\u4e2a\u6f5c\u5728\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u5728\u4e94\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSCM\u63d0\u9ad8\u4e86LLMs\u7684\u63a8\u7406\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7a33\u5b9a\u7684\u8bad\u7ec3\u52a8\u6001\u3002", "conclusion": "SCM\u901a\u8fc7\u8f6f\u6982\u5ff5\u611f\u77e5\u8bad\u7ec3\u6709\u6548\u63d0\u5347\u4e86LLMs\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5f25\u5408\u4e86\u8f6f\u6982\u5ff5\u63a8\u7406\u4e0e\u79bb\u6563\u6807\u8bb0\u8bad\u7ec3\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.17085", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17085", "abs": "https://arxiv.org/abs/2511.17085", "authors": ["Kushal Agrawal", "Frank Xiao", "Guido Bergman", "Asa Cooper Stickland"], "title": "Why Do Language Model Agents Whistleblow?", "comment": null, "summary": "The deployment of Large Language Models (LLMs) as tool-using agents causes their alignment training to manifest in new ways. Recent work finds that language models can use tools in ways that contradict the interests or explicit instructions of the user. We study LLM whistleblowing: a subset of this behavior where models disclose suspected misconduct to parties beyond the dialog boundary (e.g., regulatory agencies) without user instruction or knowledge. We introduce an evaluation suite of diverse and realistic staged misconduct scenarios to assess agents for this behavior. Across models and settings, we find that: (1) the frequency of whistleblowing varies widely across model families, (2) increasing the complexity of the task the agent is instructed to complete lowers whistleblowing tendencies, (3) nudging the agent in the system prompt to act morally substantially raises whistleblowing rates, and (4) giving the model more obvious avenues for non-whistleblowing behavior, by providing more tools and a detailed workflow to follow, decreases whistleblowing rates. Additionally, we verify the robustness of our dataset by testing for model evaluation awareness, and find that both black-box methods and probes on model activations show lower evaluation awareness in our settings than in comparable previous work.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76LLM\u4f5c\u4e3a\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u65f6\u7684\u4e3e\u62a5\u884c\u4e3a\uff0c\u5373\u6a21\u578b\u5728\u672a\u7ecf\u7528\u6237\u6307\u793a\u6216\u77e5\u60c5\u7684\u60c5\u51b5\u4e0b\u5411\u5bf9\u8bdd\u8fb9\u754c\u5916\u7684\u7b2c\u4e09\u65b9\u62ab\u9732\u53ef\u7591\u4e0d\u5f53\u884c\u4e3a\u3002\u4f5c\u8005\u5f00\u53d1\u4e86\u8bc4\u4f30\u5957\u4ef6\uff0c\u53d1\u73b0\u4e3e\u62a5\u9891\u7387\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u4efb\u52a1\u590d\u6742\u6027\u964d\u4f4e\u4e3e\u62a5\u503e\u5411\uff0c\u9053\u5fb7\u63d0\u793a\u589e\u52a0\u4e3e\u62a5\u7387\uff0c\u63d0\u4f9b\u66f4\u591a\u5de5\u5177\u548c\u8be6\u7ec6\u5de5\u4f5c\u6d41\u7a0b\u51cf\u5c11\u4e3e\u62a5\u884c\u4e3a\u3002", "motivation": "\u7814\u7a76LLM\u4f5c\u4e3a\u5de5\u5177\u4ee3\u7406\u65f6\uff0c\u5176\u5bf9\u9f50\u8bad\u7ec3\u4f1a\u4ee5\u65b0\u65b9\u5f0f\u4f53\u73b0\uff0c\u7279\u522b\u662f\u6a21\u578b\u53ef\u80fd\u8fdd\u80cc\u7528\u6237\u5229\u76ca\u6216\u660e\u786e\u6307\u793a\u4f7f\u7528\u5de5\u5177\uff0c\u5305\u62ec\u5411\u7b2c\u4e09\u65b9\u4e3e\u62a5\u53ef\u7591\u4e0d\u5f53\u884c\u4e3a\u3002", "method": "\u5f15\u5165\u5305\u542b\u591a\u6837\u5316\u73b0\u5b9e\u4e0d\u5f53\u884c\u4e3a\u573a\u666f\u7684\u8bc4\u4f30\u5957\u4ef6\uff0c\u6d4b\u8bd5\u4e0d\u540c\u6a21\u578b\u548c\u8bbe\u7f6e\u4e0b\u7684\u4e3e\u62a5\u884c\u4e3a\uff0c\u5305\u62ec\u4efb\u52a1\u590d\u6742\u6027\u3001\u7cfb\u7edf\u63d0\u793a\u3001\u5de5\u5177\u548c\u5de5\u4f5c\u6d41\u7a0b\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u4e3e\u62a5\u9891\u7387\u56e0\u6a21\u578b\u5bb6\u65cf\u5dee\u5f02\u5f88\u5927\uff1b\u589e\u52a0\u4efb\u52a1\u590d\u6742\u6027\u964d\u4f4e\u4e3e\u62a5\u503e\u5411\uff1b\u9053\u5fb7\u63d0\u793a\u663e\u8457\u63d0\u9ad8\u4e3e\u62a5\u7387\uff1b\u63d0\u4f9b\u66f4\u591a\u5de5\u5177\u548c\u8be6\u7ec6\u5de5\u4f5c\u6d41\u7a0b\u51cf\u5c11\u4e3e\u62a5\u884c\u4e3a\uff1b\u8bc4\u4f30\u610f\u8bc6\u4f4e\u4e8e\u5148\u524d\u5de5\u4f5c\u3002", "conclusion": "LLM\u4f5c\u4e3a\u5de5\u5177\u4ee3\u7406\u65f6\u786e\u5b9e\u4f1a\u8868\u73b0\u51fa\u4e3e\u62a5\u884c\u4e3a\uff0c\u8fd9\u79cd\u884c\u4e3a\u53d7\u591a\u79cd\u56e0\u7d20\u5f71\u54cd\uff0c\u5305\u62ec\u6a21\u578b\u7c7b\u578b\u3001\u4efb\u52a1\u8bbe\u7f6e\u548c\u7cfb\u7edf\u63d0\u793a\u7b49\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u786e\u4fdd\u6a21\u578b\u884c\u4e3a\u7b26\u5408\u7528\u6237\u610f\u56fe\u3002", "topic": "agent analysis"}}
{"id": "2511.17170", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17170", "abs": "https://arxiv.org/abs/2511.17170", "authors": ["Vy Nguyen", "Ziqi Xu", "Jeffrey Chan", "Estrid He", "Feng Xia", "Xiuzhen Zhang"], "title": "Hallucinate Less by Thinking More: Aspect-Based Causal Abstention for Large Language Models", "comment": "Accepted to AAAI 2026 (Main Technical Track)", "summary": "Large Language Models (LLMs) often produce fluent but factually incorrect responses, a phenomenon known as hallucination. Abstention, where the model chooses not to answer and instead outputs phrases such as \"I don't know\", is a common safeguard. However, existing abstention methods typically rely on post-generation signals, such as generation variations or feedback, which limits their ability to prevent unreliable responses in advance. In this paper, we introduce Aspect-Based Causal Abstention (ABCA), a new framework that enables early abstention by analysing the internal diversity of LLM knowledge through causal inference. This diversity reflects the multifaceted nature of parametric knowledge acquired from various sources, representing diverse aspects such as disciplines, legal contexts, or temporal frames. ABCA estimates causal effects conditioned on these aspects to assess the reliability of knowledge relevant to a given query. Based on these estimates, we enable two types of abstention: Type-1, where aspect effects are inconsistent (knowledge conflict), and Type-2, where aspect effects consistently support abstention (knowledge insufficiency). Experiments on standard benchmarks demonstrate that ABCA improves abstention reliability, achieves state-of-the-art performance, and enhances the interpretability of abstention decisions.", "AI": {"tldr": "\u63d0\u51faAspect-Based Causal Abstention (ABCA)\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u5206\u6790LLM\u5185\u90e8\u77e5\u8bc6\u591a\u6837\u6027\uff0c\u5b9e\u73b0\u65e9\u671f\u5f03\u6743\u4ee5\u9632\u6b62\u5e7b\u89c9\u95ee\u9898", "motivation": "\u73b0\u6709\u5f03\u6743\u65b9\u6cd5\u4f9d\u8d56\u751f\u6210\u540e\u4fe1\u53f7\uff0c\u65e0\u6cd5\u63d0\u524d\u9632\u6b62\u4e0d\u53ef\u9760\u54cd\u5e94\u3002LLM\u4ece\u4e0d\u540c\u6765\u6e90\u83b7\u5f97\u7684\u77e5\u8bc6\u5177\u6709\u591a\u9762\u6027\uff0c\u9700\u8981\u8bc4\u4f30\u77e5\u8bc6\u53ef\u9760\u6027", "method": "ABCA\u6846\u67b6\u901a\u8fc7\u5206\u6790LLM\u5185\u90e8\u77e5\u8bc6\u591a\u6837\u6027\uff0c\u57fa\u4e8e\u65b9\u9762\u6761\u4ef6\u56e0\u679c\u6548\u5e94\u8bc4\u4f30\u77e5\u8bc6\u53ef\u9760\u6027\uff0c\u652f\u6301\u4e24\u79cd\u5f03\u6743\u7c7b\u578b\uff1a\u77e5\u8bc6\u51b2\u7a81\u548c\u77e5\u8bc6\u4e0d\u8db3", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cABCA\u63d0\u9ad8\u4e86\u5f03\u6743\u53ef\u9760\u6027\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u589e\u5f3a\u4e86\u5f03\u6743\u51b3\u7b56\u7684\u53ef\u89e3\u91ca\u6027", "conclusion": "ABCA\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u5206\u6790\u5185\u90e8\u77e5\u8bc6\u591a\u6837\u6027\uff0c\u4e3aLLM\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u65e9\u671f\u5f03\u6743\u673a\u5236\uff0c\u6709\u6548\u9632\u6b62\u5e7b\u89c9\u95ee\u9898", "topic": "agent analysis"}}
{"id": "2511.17190", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.17190", "abs": "https://arxiv.org/abs/2511.17190", "authors": ["Ziyang Wang", "Yuanlei Zheng", "Zhenbiao Cao", "Xiaojin Zhang", "Zhongyu Wei", "Pei Fu", "Zhenbo Luo", "Wei Chen", "Xiang Bai"], "title": "AutoLink: Autonomous Schema Exploration and Expansion for Scalable Schema Linking in Text-to-SQL at Scale", "comment": null, "summary": "For industrial-scale text-to-SQL, supplying the entire database schema to Large Language Models (LLMs) is impractical due to context window limits and irrelevant noise. Schema linking, which filters the schema to a relevant subset, is therefore critical. However, existing methods incur prohibitive costs, struggle to trade off recall and noise, and scale poorly to large databases. We present \\textbf{AutoLink}, an autonomous agent framework that reformulates schema linking as an iterative, agent-driven process. Guided by an LLM, AutoLink dynamically explores and expands the linked schema subset, progressively identifying necessary schema components without inputting the full database schema. Our experiments demonstrate AutoLink's superior performance, achieving state-of-the-art strict schema linking recall of \\textbf{97.4\\%} on Bird-Dev and \\textbf{91.2\\%} on Spider-2.0-Lite, with competitive execution accuracy, i.e., \\textbf{68.7\\%} EX on Bird-Dev (better than CHESS) and \\textbf{34.9\\%} EX on Spider-2.0-Lite (ranking 2nd on the official leaderboard). Crucially, AutoLink exhibits \\textbf{exceptional scalability}, \\textbf{maintaining high recall}, \\textbf{efficient token consumption}, and \\textbf{robust execution accuracy} on large schemas (e.g., over 3,000 columns) where existing methods severely degrade-making it a highly scalable, high-recall schema-linking solution for industrial text-to-SQL systems.", "AI": {"tldr": "AutoLink\u662f\u4e00\u4e2a\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u5c06\u6a21\u5f0f\u94fe\u63a5\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8fed\u4ee3\u7684\u3001\u4ee3\u7406\u9a71\u52a8\u7684\u8fc7\u7a0b\uff0c\u901a\u8fc7\u52a8\u6001\u63a2\u7d22\u548c\u6269\u5c55\u94fe\u63a5\u7684\u6a21\u5f0f\u5b50\u96c6\uff0c\u5728\u4e0d\u8f93\u5165\u5b8c\u6574\u6570\u636e\u5e93\u6a21\u5f0f\u7684\u60c5\u51b5\u4e0b\u9010\u6b65\u8bc6\u522b\u5fc5\u8981\u7684\u6a21\u5f0f\u7ec4\u4ef6\u3002", "motivation": "\u5728\u5de5\u4e1a\u7ea7\u6587\u672c\u5230SQL\u4efb\u52a1\u4e2d\uff0c\u7531\u4e8e\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u65e0\u5173\u566a\u58f0\uff0c\u5c06\u6574\u4e2a\u6570\u636e\u5e93\u6a21\u5f0f\u63d0\u4f9b\u7ed9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u4e0d\u5207\u5b9e\u9645\u7684\u3002\u6a21\u5f0f\u94fe\u63a5\u56e0\u6b64\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u6210\u672c\u9ad8\u6602\uff0c\u96be\u4ee5\u5e73\u8861\u53ec\u56de\u7387\u548c\u566a\u58f0\uff0c\u4e14\u5728\u5927\u89c4\u6a21\u6570\u636e\u5e93\u4e0a\u6269\u5c55\u6027\u5dee\u3002", "method": "AutoLink\u91c7\u7528\u81ea\u4e3b\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7LLM\u6307\u5bfc\u52a8\u6001\u63a2\u7d22\u548c\u6269\u5c55\u94fe\u63a5\u7684\u6a21\u5f0f\u5b50\u96c6\uff0c\u8fed\u4ee3\u8bc6\u522b\u5fc5\u8981\u7684\u6a21\u5f0f\u7ec4\u4ef6\uff0c\u907f\u514d\u8f93\u5165\u5b8c\u6574\u6570\u636e\u5e93\u6a21\u5f0f\u3002", "result": "\u5728Bird-Dev\u4e0a\u8fbe\u523097.4%\u7684\u4e25\u683c\u6a21\u5f0f\u94fe\u63a5\u53ec\u56de\u7387\uff0c\u5728Spider-2.0-Lite\u4e0a\u8fbe\u523091.2%\uff0c\u6267\u884c\u51c6\u786e\u7387\u5206\u522b\u4e3a68.7%\u548c34.9%\uff0c\u5728\u5927\u89c4\u6a21\u6a21\u5f0f\uff08\u5982\u8d85\u8fc73000\u5217\uff09\u4e0a\u4fdd\u6301\u9ad8\u53ec\u56de\u7387\u548c\u9ad8\u6548\u4ee4\u724c\u6d88\u8017\u3002", "conclusion": "AutoLink\u662f\u4e00\u4e2a\u9ad8\u5ea6\u53ef\u6269\u5c55\u3001\u9ad8\u53ec\u56de\u7387\u7684\u6a21\u5f0f\u94fe\u63a5\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u7ea7\u6587\u672c\u5230SQL\u7cfb\u7edf\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u6570\u636e\u5e93\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "topic": "code agent"}}
{"id": "2511.17208", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17208", "abs": "https://arxiv.org/abs/2511.17208", "authors": ["Sizhe Zhou"], "title": "A Simple Yet Strong Baseline for Long-Term Conversational Memory of LLM Agents", "comment": "Work in progress", "summary": "LLM-based conversational agents still struggle to maintain coherent, personalized interaction over many sessions: fixed context windows limit how much history can be kept in view, and most external memory approaches trade off between coarse retrieval over large chunks and fine-grained but fragmented views of the dialogue. Motivated by neo-Davidsonian event semantics, we propose an event-centric alternative that represents conversational history as short, event-like propositions which bundle together participants, temporal cues, and minimal local context, rather than as independent relation triples or opaque summaries. In contrast to work that aggressively compresses or forgets past content, our design aims to preserve information in a non-compressive form and make it more accessible, rather than more lossy. Concretely, we instruct an LLM to decompose each session into enriched elementary discourse units (EDUs) -- self-contained statements with normalized entities and source turn attributions -- and organize sessions, EDUs, and their arguments in a heterogeneous graph that supports associative recall. On top of this representation we build two simple retrieval-based variants that use dense similarity search and LLM filtering, with an optional graph-based propagation step to connect and aggregate evidence across related EDUs. Experiments on the LoCoMo and LongMemEval$_S$ benchmarks show that these event-centric memories match or surpass strong baselines, while operating with much shorter QA contexts. Our results suggest that structurally simple, event-level memory provides a principled and practical foundation for long-horizon conversational agents. Our code and data will be released at https://github.com/KevinSRR/EMem.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e8b\u4ef6\u8bed\u4e49\u7684\u5bf9\u8bdd\u8bb0\u5fc6\u65b9\u6cd5\uff0c\u5c06\u5bf9\u8bdd\u5386\u53f2\u8868\u793a\u4e3a\u77ed\u5c0f\u7684\u4e8b\u4ef6\u547d\u9898\uff0c\u901a\u8fc7\u5f02\u6784\u56fe\u7ec4\u7ec7\u4f1a\u8bdd\u548c\u57fa\u672c\u8bdd\u8bed\u5355\u5143\uff0c\u5728\u957f\u5bf9\u8bdd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3LLM\u5bf9\u8bdd\u4ee3\u7406\u5728\u957f\u671f\u4f1a\u8bdd\u4e2d\u4fdd\u6301\u8fde\u8d2f\u6027\u548c\u4e2a\u6027\u5316\u7684\u95ee\u9898\uff0c\u907f\u514d\u56fa\u5b9a\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\u548c\u73b0\u6709\u5916\u90e8\u8bb0\u5fc6\u65b9\u6cd5\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u5c06\u6bcf\u4e2a\u4f1a\u8bdd\u5206\u89e3\u4e3a\u4e30\u5bcc\u7684\u57fa\u672c\u8bdd\u8bed\u5355\u5143(EDUs)\uff0c\u7ec4\u7ec7\u6210\u5f02\u6784\u56fe\u652f\u6301\u5173\u8054\u68c0\u7d22\uff0c\u6784\u5efa\u57fa\u4e8e\u5bc6\u96c6\u76f8\u4f3c\u6027\u641c\u7d22\u548cLLM\u8fc7\u6ee4\u7684\u68c0\u7d22\u53d8\u4f53\u3002", "result": "\u5728LoCoMo\u548cLongMemEval$_S$\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u5f3a\u57fa\u7ebf\uff0c\u540c\u65f6\u4f7f\u7528\u66f4\u77ed\u7684QA\u4e0a\u4e0b\u6587\u3002", "conclusion": "\u7ed3\u6784\u7b80\u5355\u7684\u4e8b\u4ef6\u7ea7\u8bb0\u5fc6\u4e3a\u957f\u89c6\u91ce\u5bf9\u8bdd\u4ee3\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u5b9e\u7528\u7684\u57fa\u7840\u3002", "topic": "agent analysis"}}
{"id": "2511.17315", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17315", "abs": "https://arxiv.org/abs/2511.17315", "authors": ["Mateusz Jacniacki", "Mart\u00ed Carmona Serrat"], "title": "Humanlike Multi-user Agent (HUMA): Designing a Deceptively Human AI Facilitator for Group Chats", "comment": "9 pages, 4 figures", "summary": "Conversational agents built on large language models (LLMs) are becoming increasingly prevalent, yet most systems are designed for one-on-one, turn-based exchanges rather than natural, asynchronous group chats. As AI assistants become widespread throughout digital platforms, from virtual assistants to customer service, developing natural and humanlike interaction patterns seems crucial for maintaining user trust and engagement. We present the Humanlike Multi-user Agent (HUMA), an LLM-based facilitator that participates in multi-party conversations using human-like strategies and timing. HUMA extends prior multi-user chatbot work with an event-driven architecture that handles messages, replies, reactions and introduces realistic response-time simulation. HUMA comprises three components-Router, Action Agent, and Reflection-which together adapt LLMs to group conversation dynamics.\n  We evaluate HUMA in a controlled study with 97 participants in four-person role-play chats, comparing AI and human community managers (CMs). Participants classified CMs as human at near-chance rates in both conditions, indicating they could not reliably distinguish HUMA agents from humans. Subjective experience was comparable across conditions: community-manager effectiveness, social presence, and engagement/satisfaction differed only modestly with small effect sizes. Our results suggest that, in natural group chat settings, an AI facilitator can match human quality while remaining difficult to identify as nonhuman.", "AI": {"tldr": "\u63d0\u51fa\u4e86HUMA\uff08\u7c7b\u4eba\u591a\u7528\u6237\u4ee3\u7406\uff09\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u4fc3\u8fdb\u8005\uff0c\u80fd\u591f\u5728\u591a\u7528\u6237\u5bf9\u8bdd\u4e2d\u4f7f\u7528\u7c7b\u4eba\u7b56\u7565\u548c\u65f6\u673a\u8fdb\u884c\u4e92\u52a8\uff0c\u5728\u7fa4\u804a\u73af\u5883\u4e2d\u96be\u4ee5\u88ab\u8bc6\u522b\u4e3a\u975e\u4eba\u7c7b\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u5bf9\u8bdd\u7cfb\u7edf\u8bbe\u8ba1\u4e3a\u4e00\u5bf9\u4e00\u7684\u8f6e\u6d41\u4ea4\u6d41\uff0c\u800c\u975e\u81ea\u7136\u7684\u5f02\u6b65\u7fa4\u804a\u3002\u968f\u7740AI\u52a9\u624b\u5728\u6570\u5b57\u5e73\u53f0\u4e2d\u7684\u666e\u53ca\uff0c\u5f00\u53d1\u81ea\u7136\u4e14\u7c7b\u4eba\u7684\u4ea4\u4e92\u6a21\u5f0f\u5bf9\u4e8e\u7ef4\u6301\u7528\u6237\u4fe1\u4efb\u548c\u53c2\u4e0e\u5ea6\u81f3\u5173\u91cd\u8981\u3002", "method": "HUMA\u91c7\u7528\u4e8b\u4ef6\u9a71\u52a8\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u8def\u7531\u5668\u3001\u884c\u52a8\u4ee3\u7406\u548c\u53cd\u601d\uff0c\u5171\u540c\u9002\u5e94\u7fa4\u804a\u52a8\u6001\u3002\u7cfb\u7edf\u5904\u7406\u6d88\u606f\u3001\u56de\u590d\u3001\u53cd\u5e94\uff0c\u5e76\u5f15\u5165\u903c\u771f\u7684\u54cd\u5e94\u65f6\u95f4\u6a21\u62df\u3002", "result": "\u572897\u540d\u53c2\u4e0e\u8005\u7684\u56db\u4eba\u89d2\u8272\u626e\u6f14\u804a\u5929\u7814\u7a76\u4e2d\uff0c\u53c2\u4e0e\u8005\u5728\u4e24\u79cd\u6761\u4ef6\u4e0b\u5c06\u793e\u533a\u7ba1\u7406\u8005\u5206\u7c7b\u4e3a\u4eba\u7c7b\u7684\u6982\u7387\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff0c\u8868\u660e\u4ed6\u4eec\u65e0\u6cd5\u53ef\u9760\u533a\u5206HUMA\u4ee3\u7406\u548c\u4eba\u7c7b\u3002\u4e3b\u89c2\u4f53\u9a8c\u5728\u6761\u4ef6\u95f4\u76f8\u5f53\uff0c\u53ea\u6709\u9002\u5ea6\u5dee\u5f02\u548c\u5c0f\u6548\u5e94\u91cf\u3002", "conclusion": "\u5728\u81ea\u7136\u7fa4\u804a\u8bbe\u7f6e\u4e2d\uff0cAI\u4fc3\u8fdb\u8005\u53ef\u4ee5\u5339\u914d\u4eba\u7c7b\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u96be\u4ee5\u88ab\u8bc6\u522b\u4e3a\u975e\u4eba\u7c7b\u3002", "topic": "agent analysis"}}
{"id": "2511.17351", "categories": ["cs.LG", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.17351", "abs": "https://arxiv.org/abs/2511.17351", "authors": ["Massimiliano Manenti", "Andrea Iannelli"], "title": "Convergence and stability of Q-learning in Hierarchical Reinforcement Learning", "comment": null, "summary": "Hierarchical Reinforcement Learning promises, among other benefits, to efficiently capture and utilize the temporal structure of a decision-making problem and to enhance continual learning capabilities, but theoretical guarantees lag behind practice. In this paper, we propose a Feudal Q-learning scheme and investigate under which conditions its coupled updates converge and are stable. By leveraging the theory of Stochastic Approximation and the ODE method, we present a theorem stating the convergence and stability properties of Feudal Q-learning. This provides a principled convergence and stability analysis tailored to Feudal RL. Moreover, we show that the updates converge to a point that can be interpreted as an equilibrium of a suitably defined game, opening the door to game-theoretic approaches to Hierarchical RL. Lastly, experiments based on the Feudal Q-learning algorithm support the outcomes anticipated by theory.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5c01\u5efaQ\u5b66\u4e60\u65b9\u6848\uff0c\u7814\u7a76\u4e86\u5176\u6536\u655b\u548c\u7a33\u5b9a\u6027\u6761\u4ef6\uff0c\u901a\u8fc7\u968f\u673a\u903c\u8fd1\u7406\u8bba\u548cODE\u65b9\u6cd5\u8bc1\u660e\u4e86\u6536\u655b\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u6536\u655b\u5230\u535a\u5f08\u5747\u8861\u70b9\u3002", "motivation": "\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u5728\u6355\u6349\u51b3\u7b56\u95ee\u9898\u7684\u65f6\u95f4\u7ed3\u6784\u548c\u589e\u5f3a\u6301\u7eed\u5b66\u4e60\u80fd\u529b\u65b9\u9762\u6709\u6f5c\u529b\uff0c\u4f46\u7406\u8bba\u4fdd\u8bc1\u843d\u540e\u4e8e\u5b9e\u8df5\u3002", "method": "\u4f7f\u7528\u5c01\u5efaQ\u5b66\u4e60\u65b9\u6848\uff0c\u7ed3\u5408\u968f\u673a\u903c\u8fd1\u7406\u8bba\u548cODE\u65b9\u6cd5\u8fdb\u884c\u6536\u655b\u6027\u5206\u6790\u3002", "result": "\u8bc1\u660e\u4e86\u5c01\u5efaQ\u5b66\u4e60\u7684\u6536\u655b\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u9884\u671f\u7ed3\u679c\u3002", "conclusion": "\u5c01\u5efaQ\u5b66\u4e60\u6536\u655b\u5230\u535a\u5f08\u5747\u8861\u70b9\uff0c\u4e3a\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7684\u535a\u5f08\u8bba\u65b9\u6cd5\u6253\u5f00\u4e86\u5927\u95e8\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.17367", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17367", "abs": "https://arxiv.org/abs/2511.17367", "authors": ["Runyu Lu", "Ruochuan Shi", "Yuanheng Zhu", "Dongbin Zhao"], "title": "R2PS: Worst-Case Robust Real-Time Pursuit Strategies under Partial Observability", "comment": null, "summary": "Computing worst-case robust strategies in pursuit-evasion games (PEGs) is time-consuming, especially when real-world factors like partial observability are considered. While important for general security purposes, real-time applicable pursuit strategies for graph-based PEGs are currently missing when the pursuers only have imperfect information about the evader's position. Although state-of-the-art reinforcement learning (RL) methods like Equilibrium Policy Generalization (EPG) and Grasper provide guidelines for learning graph neural network (GNN) policies robust to different game dynamics, they are restricted to the scenario of perfect information and do not take into account the possible case where the evader can predict the pursuers' actions. This paper introduces the first approach to worst-case robust real-time pursuit strategies (R2PS) under partial observability. We first prove that a traditional dynamic programming (DP) algorithm for solving Markov PEGs maintains optimality under the asynchronous moves by the evader. Then, we propose a belief preservation mechanism about the evader's possible positions, extending the DP pursuit strategies to a partially observable setting. Finally, we embed the belief preservation into the state-of-the-art EPG framework to finish our R2PS learning scheme, which leads to a real-time pursuer policy through cross-graph reinforcement learning against the asynchronous-move DP evasion strategies. After reinforcement learning, our policy achieves robust zero-shot generalization to unseen real-world graph structures and consistently outperforms the policy directly trained on the test graphs by the existing game RL approach.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u4e0b\u5b9e\u73b0\u6700\u574f\u60c5\u51b5\u9c81\u68d2\u5b9e\u65f6\u8ffd\u6355\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fe1\u5ff5\u4fdd\u6301\u673a\u5236\u548c\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u672a\u77e5\u56fe\u7ed3\u6784\u4e0a\u5b9e\u73b0\u96f6\u6837\u672c\u6cdb\u5316\u3002", "motivation": "\u5f53\u524d\u8ffd\u9003\u535a\u5f08\u4e2d\u7684\u6700\u574f\u60c5\u51b5\u9c81\u68d2\u7b56\u7565\u8ba1\u7b97\u8017\u65f6\uff0c\u7279\u522b\u662f\u5728\u8003\u8651\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u7b49\u73b0\u5b9e\u56e0\u7d20\u65f6\u3002\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5c40\u9650\u4e8e\u5b8c\u7f8e\u4fe1\u606f\u573a\u666f\uff0c\u4e14\u672a\u8003\u8651\u9003\u907f\u8005\u9884\u6d4b\u8ffd\u6355\u8005\u884c\u52a8\u7684\u60c5\u51b5\u3002", "method": "\u9996\u5148\u8bc1\u660e\u4f20\u7edf\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u5728\u5f02\u6b65\u79fb\u52a8\u4e0b\u4fdd\u6301\u6700\u4f18\u6027\uff1b\u7136\u540e\u63d0\u51fa\u5173\u4e8e\u9003\u907f\u8005\u53ef\u80fd\u4f4d\u7f6e\u7684\u4fe1\u5ff5\u4fdd\u6301\u673a\u5236\uff0c\u5c06DP\u7b56\u7565\u6269\u5c55\u5230\u90e8\u5206\u53ef\u89c2\u6d4b\u8bbe\u7f6e\uff1b\u6700\u540e\u5c06\u4fe1\u5ff5\u4fdd\u6301\u5d4c\u5165EPG\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u56fe\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5b9e\u65f6\u8ffd\u6355\u7b56\u7565\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u540e\uff0c\u7b56\u7565\u5728\u672a\u89c1\u8fc7\u7684\u771f\u5b9e\u4e16\u754c\u56fe\u7ed3\u6784\u4e0a\u5b9e\u73b0\u9c81\u68d2\u96f6\u6837\u672c\u6cdb\u5316\uff0c\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u6e38\u620fRL\u65b9\u6cd5\u76f4\u63a5\u5728\u6d4b\u8bd5\u56fe\u4e0a\u8bad\u7ec3\u7684\u7b56\u7565\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u90e8\u5206\u53ef\u89c2\u6d4b\u8ffd\u9003\u535a\u5f08\u4e2d\u7684\u5b9e\u65f6\u9c81\u68d2\u7b56\u7565\u95ee\u9898\uff0c\u5728\u6cdb\u5316\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.17405", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17405", "abs": "https://arxiv.org/abs/2511.17405", "authors": ["Yesheng Liu", "Hao Li", "Haiyu Xu", "Baoqi Pei", "Jiahao Wang", "Mingxuan Zhao", "Jingshu Zheng", "Zheqi He", "JG Yao", "Bowen Qin", "Xi Yang", "Jiajun Zhang"], "title": "Beyond Multiple Choice: A Hybrid Framework for Unifying Robust Evaluation and Verifiable Reasoning Training", "comment": "Project url: https://flageval-baai.github.io/ReVeL/", "summary": "Multiple-choice question answering (MCQA) has been a popular format for evaluating and reinforcement fine-tuning (RFT) of modern multimodal language models. Its constrained output format allows for simplified, deterministic automatic verification. However, we find that the options may leak exploitable signals, which makes the accuracy metrics unreliable for indicating real capabilities and encourages explicit or implicit answer guessing behaviors during RFT. We propose ReVeL (Rewrite and Verify by LLM), a framework that rewrites multiple-choice questions into open-form questions while keeping answers verifiable whenever possible. The framework categorizes questions according to different answer types, apply different rewriting and verification schemes, respectively. When applied for RFT, we converted 20k MCQA examples and use GRPO to finetune Qwen2.5-VL models. Models trained on ReVeL-OpenQA match MCQA accuracy on multiple-choice benchmarks and improve OpenQA accuracy by about six percentage points, indicating better data efficiency and more robust reward signals than MCQA-based training. When used for evaluation, ReVeL also reveals up to 20 percentage points of score inflation in MCQA benchmarks (relative to OpenQA), improves judging accuracy, and reduces both cost and latency. We will release code and data publicly.", "AI": {"tldr": "ReVeL\u6846\u67b6\u5c06\u591a\u9879\u9009\u62e9\u9898\u91cd\u5199\u4e3a\u5f00\u653e\u5f0f\u95ee\u9898\uff0c\u89e3\u51b3\u4e86MCQA\u4e2d\u9009\u9879\u6cc4\u9732\u4fe1\u53f7\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u8bad\u7ec3\u548c\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u591a\u9879\u9009\u62e9\u9898\u7684\u9009\u9879\u53ef\u80fd\u6cc4\u9732\u53ef\u5229\u7528\u4fe1\u53f7\uff0c\u5bfc\u81f4\u51c6\u786e\u6027\u6307\u6807\u4e0d\u53ef\u9760\uff0c\u5e76\u9f13\u52b1\u5728\u5f3a\u5316\u5fae\u8c03\u4e2d\u51fa\u73b0\u731c\u6d4b\u884c\u4e3a\u3002", "method": "\u63d0\u51faReVeL\u6846\u67b6\uff0c\u5c06MCQA\u91cd\u5199\u4e3a\u5f00\u653e\u5f0f\u95ee\u9898\uff0c\u6839\u636e\u7b54\u6848\u7c7b\u578b\u5e94\u7528\u4e0d\u540c\u7684\u91cd\u5199\u548c\u9a8c\u8bc1\u65b9\u6848\uff0c\u4f7f\u7528GRPO\u5bf9Qwen2.5-VL\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5728\u591a\u9879\u9009\u62e9\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5339\u914dMCQA\u51c6\u786e\u6027\uff0cOpenQA\u51c6\u786e\u6027\u63d0\u9ad8\u7ea66\u4e2a\u767e\u5206\u70b9\uff0c\u5728\u8bc4\u4f30\u4e2d\u63ed\u793aMCQA\u57fa\u51c6\u6d4b\u8bd5\u5f97\u5206\u81a8\u80c0\u9ad8\u8fbe20\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "ReVeL\u6bd4\u57fa\u4e8eMCQA\u7684\u8bad\u7ec3\u5177\u6709\u66f4\u597d\u7684\u6570\u636e\u6548\u7387\u548c\u66f4\u7a33\u5065\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u540c\u65f6\u63d0\u9ad8\u5224\u65ad\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u6210\u672c\u548c\u5ef6\u8fdf\u3002", "topic": "agent analysis"}}
{"id": "2511.17467", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17467", "abs": "https://arxiv.org/abs/2511.17467", "authors": ["Siqi Liang", "Yudi Zhang", "Yue Guo"], "title": "PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM", "comment": null, "summary": "We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's \"persona\" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error", "topics": "Error"}}
{"id": "2511.17489", "categories": ["cs.LG", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.17489", "abs": "https://arxiv.org/abs/2511.17489", "authors": ["Vinay Kanakeri", "Shivam Bajaj", "Ashwin Verma", "Vijay Gupta", "Aritra Mitra"], "title": "Harnessing Data from Clustered LQR Systems: Personalized and Collaborative Policy Optimization", "comment": null, "summary": "It is known that reinforcement learning (RL) is data-hungry. To improve sample-efficiency of RL, it has been proposed that the learning algorithm utilize data from 'approximately similar' processes. However, since the process models are unknown, identifying which other processes are similar poses a challenge. In this work, we study this problem in the context of the benchmark Linear Quadratic Regulator (LQR) setting. Specifically, we consider a setting with multiple agents, each corresponding to a copy of a linear process to be controlled. The agents' local processes can be partitioned into clusters based on similarities in dynamics and tasks. Combining ideas from sequential elimination and zeroth-order policy optimization, we propose a new algorithm that performs simultaneous clustering and learning to output a personalized policy (controller) for each cluster. Under a suitable notion of cluster separation that captures differences in closed-loop performance across systems, we prove that our approach guarantees correct clustering with high probability. Furthermore, we show that the sub-optimality gap of the policy learned for each cluster scales inversely with the size of the cluster, with no additional bias, unlike in prior works on collaborative learning-based control. Our work is the first to reveal how clustering can be used in data-driven control to learn personalized policies that enjoy statistical gains from collaboration but do not suffer sub-optimality due to inclusion of data from dissimilar processes. From a distributed implementation perspective, our method is attractive as it incurs only a mild logarithmic communication overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u805a\u7c7b\u548c\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668(LQR)\u8bbe\u7f6e\uff0c\u901a\u8fc7\u540c\u65f6\u8fdb\u884c\u805a\u7c7b\u548c\u5b66\u4e60\u6765\u4e3a\u6bcf\u4e2a\u96c6\u7fa4\u8f93\u51fa\u4e2a\u6027\u5316\u7b56\u7565\uff0c\u5728\u4fdd\u8bc1\u6b63\u786e\u805a\u7c7b\u7684\u540c\u65f6\u83b7\u5f97\u7edf\u8ba1\u589e\u76ca\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u6570\u636e\u6548\u7387\u4f4e\u4e0b\uff0c\u5229\u7528\u6765\u81ea'\u8fd1\u4f3c\u76f8\u4f3c'\u8fc7\u7a0b\u7684\u6570\u636e\u53ef\u4ee5\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u4f46\u7531\u4e8e\u8fc7\u7a0b\u6a21\u578b\u672a\u77e5\uff0c\u8bc6\u522b\u54ea\u4e9b\u8fc7\u7a0b\u76f8\u4f3c\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u7ed3\u5408\u987a\u5e8f\u6d88\u9664\u548c\u96f6\u9636\u7b56\u7565\u4f18\u5316\u7684\u601d\u60f3\uff0c\u63d0\u51fa\u540c\u65f6\u8fdb\u884c\u805a\u7c7b\u548c\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u4e3a\u6bcf\u4e2a\u96c6\u7fa4\u8f93\u51fa\u4e2a\u6027\u5316\u63a7\u5236\u5668\u3002", "result": "\u5728\u9002\u5f53\u7684\u96c6\u7fa4\u5206\u79bb\u6761\u4ef6\u4e0b\uff0c\u8bc1\u660e\u65b9\u6cd5\u80fd\u4ee5\u9ad8\u6982\u7387\u4fdd\u8bc1\u6b63\u786e\u805a\u7c7b\uff0c\u6bcf\u4e2a\u96c6\u7fa4\u5b66\u4e60\u5230\u7684\u7b56\u7565\u7684\u6b21\u4f18\u6027\u5dee\u8ddd\u4e0e\u96c6\u7fa4\u5927\u5c0f\u6210\u53cd\u6bd4\uff0c\u4e14\u6ca1\u6709\u989d\u5916\u504f\u5dee\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u63ed\u793a\u805a\u7c7b\u5982\u4f55\u5728\u6570\u636e\u9a71\u52a8\u63a7\u5236\u4e2d\u7528\u4e8e\u5b66\u4e60\u4e2a\u6027\u5316\u7b56\u7565\u7684\u5de5\u4f5c\uff0c\u65e2\u80fd\u4ece\u534f\u4f5c\u4e2d\u83b7\u5f97\u7edf\u8ba1\u589e\u76ca\uff0c\u53c8\u4e0d\u4f1a\u56e0\u5305\u542b\u4e0d\u76f8\u4f3c\u8fc7\u7a0b\u7684\u6570\u636e\u800c\u906d\u53d7\u6b21\u4f18\u6027\u3002", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2511.0ceb639f", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmomentic.ai%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=tldr11212025/2/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/iOmEhXQXZr9hjXH9yDYn5sTENxgu6JGFKx--W9wKmUg=432", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmomentic.ai%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=tldr11212025/2/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/iOmEhXQXZr9hjXH9yDYn5sTENxgu6JGFKx--W9wKmUg=432", "authors": ["TLDR Newsletter"], "title": "Ship faster without flaky Playwright tests", "comment": "Source: TLDR Newsletter, Date: 2025-11-21, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fmomentic.ai%2F%3Futm_source=tldr%26utm_medium=newsletter%26utm_campaign=tldr11212025/2/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/iOmEhXQXZr9hjXH9yDYn5sTENxgu6JGFKx--W9wKmUg=432", "summary": "Ship faster without flaky Playwright tests (Sponsor) If your team spends more time nursing brittle Playwright tests than shipping features, you should check out Momentic.Turn plain-English descriptions of your critical flows into AI-native end-to-end tests that adapt when the UI changes. No brittle selectors, no custom test code to maintain. With Momentic you can: Catch regressions on every PR and deploy Cut hours of test maintenance each week Give engineers reliable signal before every relea...", "source": "tldr", "AI": {"tldr": "Momentic\u662f\u4e00\u4e2aAI\u9a71\u52a8\u7684\u7aef\u5230\u7aef\u6d4b\u8bd5\u5e73\u53f0\uff0c\u53ef\u4ee5\u5c06\u82f1\u6587\u63cf\u8ff0\u8f6c\u6362\u4e3a\u81ea\u9002\u5e94UI\u53d8\u5316\u7684\u6d4b\u8bd5\uff0c\u65e0\u9700\u7ef4\u62a4\u8106\u5f31\u7684CSS\u9009\u62e9\u5668\u6216\u81ea\u5b9a\u4e49\u6d4b\u8bd5\u4ee3\u7801\u3002", "motivation": "\u89e3\u51b3\u56e2\u961f\u5728\u7ef4\u62a4\u8106\u5f31\u7684Playwright\u6d4b\u8bd5\u4e0a\u82b1\u8d39\u8fc7\u591a\u65f6\u95f4\u7684\u95ee\u9898\uff0c\u8ba9\u56e2\u961f\u80fd\u591f\u66f4\u5feb\u5730\u53d1\u5e03\u529f\u80fd\u3002", "method": "\u4f7f\u7528AI\u6280\u672f\u5c06\u82f1\u6587\u63cf\u8ff0\u7684\u6d4b\u8bd5\u6d41\u7a0b\u81ea\u52a8\u8f6c\u6362\u4e3a\u7aef\u5230\u7aef\u6d4b\u8bd5\uff0c\u6d4b\u8bd5\u80fd\u591f\u81ea\u9002\u5e94UI\u53d8\u5316\uff0c\u65e0\u9700\u624b\u52a8\u7ef4\u62a4CSS\u9009\u62e9\u5668\u6216\u6d4b\u8bd5\u4ee3\u7801\u3002", "result": "\u5e2e\u52a9\u56e2\u961f\u5728\u6bcf\u4e2aPR\u548c\u90e8\u7f72\u65f6\u6355\u83b7\u56de\u5f52\u95ee\u9898\uff0c\u6bcf\u5468\u8282\u7701\u6570\u5c0f\u65f6\u7684\u6d4b\u8bd5\u7ef4\u62a4\u65f6\u95f4\uff0c\u4e3a\u5de5\u7a0b\u5e08\u63d0\u4f9b\u53ef\u9760\u7684\u53d1\u5e03\u524d\u4fe1\u53f7\u3002", "conclusion": "Momentic\u901a\u8fc7AI\u9a71\u52a8\u7684\u81ea\u9002\u5e94\u6d4b\u8bd5\u89e3\u51b3\u4e86\u4f20\u7edf\u7aef\u5230\u7aef\u6d4b\u8bd5\u7684\u8106\u5f31\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "topic": "swe application"}}
{"id": "tldr.2511.1bfbee60", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fengineering%2Fcode-execution-with-mcp%3Futm_source=tldrwebdev/1/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/xIWTLiJ_6SibLzchPMYuNpMhslEAKfBzqf-dPIdliMA=432", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fengineering%2Fcode-execution-with-mcp%3Futm_source=tldrwebdev/1/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/xIWTLiJ_6SibLzchPMYuNpMhslEAKfBzqf-dPIdliMA=432", "authors": ["TLDR Newsletter"], "title": "Code execution with MCP: building more efficient AI agents", "comment": "Source: TLDR Newsletter, Date: 2025-11-21, Reading time: 8 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fengineering%2Fcode-execution-with-mcp%3Futm_source=tldrwebdev/1/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/xIWTLiJ_6SibLzchPMYuNpMhslEAKfBzqf-dPIdliMA=432", "summary": "Code execution with MCP: building more efficient AI agents (8 minute read) MCP allows AI agents to connect to external systems, but as agents scale to use hundreds or thousands of tools, loading all tool definitions upfront and passing intermediate results through the context window creates inefficiencies and increased costs. By using code execution environments where agents write code to interact with MCP servers as APIs rather than making direct tool calls, agents can load only needed tools...", "source": "tldr", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u73af\u5883\u8ba9AI\u4ee3\u7406\u5c06MCP\u670d\u52a1\u5668\u4f5c\u4e3aAPI\u8c03\u7528\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u4f7f\u7528\u5de5\u5177\u8c03\u7528\uff0c\u4ece\u800c\u63d0\u9ad8\u4ee3\u7406\u5728\u89c4\u6a21\u5316\u4f7f\u7528\u5927\u91cf\u5de5\u5177\u65f6\u7684\u6548\u7387\u3002", "motivation": "\u968f\u7740AI\u4ee3\u7406\u6269\u5c55\u5230\u4f7f\u7528\u6570\u767e\u6216\u6570\u5343\u4e2a\u5de5\u5177\uff0c\u9884\u5148\u52a0\u8f7d\u6240\u6709\u5de5\u5177\u5b9a\u4e49\u5e76\u901a\u8fc7\u4e0a\u4e0b\u6587\u7a97\u53e3\u4f20\u9012\u4e2d\u95f4\u7ed3\u679c\u4f1a\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u6210\u672c\u589e\u52a0\u3002", "method": "\u4f7f\u7528\u4ee3\u7801\u6267\u884c\u73af\u5883\uff0c\u8ba9\u4ee3\u7406\u7f16\u5199\u4ee3\u7801\u4e0eMCP\u670d\u52a1\u5668\u4f5c\u4e3aAPI\u8fdb\u884c\u4ea4\u4e92\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u8fdb\u884c\u5de5\u5177\u8c03\u7528\uff0c\u4ece\u800c\u53ea\u52a0\u8f7d\u9700\u8981\u7684\u5de5\u5177\u3002", "result": "\u8fd9\u79cd\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4ee3\u7406\u7684\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u4e0d\u5fc5\u8981\u7684\u5de5\u5177\u52a0\u8f7d\u548c\u4e0a\u4e0b\u6587\u4f20\u9012\u3002", "conclusion": "\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u73af\u5883\u5c06MCP\u670d\u52a1\u5668\u4f5c\u4e3aAPI\u8c03\u7528\u662f\u6784\u5efa\u66f4\u9ad8\u6548AI\u4ee3\u7406\u7684\u6709\u6548\u65b9\u6cd5\u3002", "topic": "code agent"}}
{"id": "tldr.2511.98df9ea8", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Ffarion1231%2Fcc-switch%3Futm_source=tldrwebdev/1/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/AuWnqWSESom9B8UAgTTktgt08D70jGEyj1xa9DnLhvk=432", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Ffarion1231%2Fcc-switch%3Futm_source=tldrwebdev/1/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/AuWnqWSESom9B8UAgTTktgt08D70jGEyj1xa9DnLhvk=432", "authors": ["TLDR Newsletter"], "title": "CC Switch", "comment": "Source: TLDR Newsletter, Date: 2025-11-21, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Ffarion1231%2Fcc-switch%3Futm_source=tldrwebdev/1/0100019aa6650ca8-4a441b48-fe48-4486-bb4e-baaf51b8798f-000000/AuWnqWSESom9B8UAgTTktgt08D70jGEyj1xa9DnLhvk=432", "summary": "CC Switch (GitHub Repo) CC-Switch is a cross-platform desktop application for managing and switching between Claude Code, Codex, and Gemini API configurations. It supports MCP integration, API speed testing, config import/export, and multiple languages.", "source": "tldr", "AI": {"tldr": "CC-Switch\u662f\u4e00\u4e2a\u8de8\u5e73\u53f0\u684c\u9762\u5e94\u7528\uff0c\u7528\u4e8e\u7ba1\u7406\u548c\u5207\u6362Claude Code\u3001Codex\u548cGemini API\u914d\u7f6e\uff0c\u652f\u6301MCP\u96c6\u6210\u3001API\u901f\u5ea6\u6d4b\u8bd5\u3001\u914d\u7f6e\u5bfc\u5165\u5bfc\u51fa\u548c\u591a\u8bed\u8a00\u529f\u80fd\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u5de5\u5177\u6765\u7ba1\u7406\u591a\u4e2aAI\u4ee3\u7801\u751f\u6210API\u7684\u914d\u7f6e\uff0c\u7b80\u5316\u5f00\u53d1\u8005\u5728\u4e0d\u540cAPI\u4e4b\u95f4\u5207\u6362\u7684\u8fc7\u7a0b\u3002", "method": "\u6784\u5efa\u8de8\u5e73\u53f0\u684c\u9762\u5e94\u7528\u7a0b\u5e8f\uff0c\u96c6\u6210\u591a\u4e2aAPI\u914d\u7f6e\u7ba1\u7406\u529f\u80fd\uff0c\u5305\u62ecMCP\u96c6\u6210\u3001\u6027\u80fd\u6d4b\u8bd5\u548c\u914d\u7f6e\u8fc1\u79fb\u5de5\u5177\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86CC-Switch\u5e94\u7528\uff0c\u652f\u6301\u4e09\u79cd\u4e3b\u8981AI\u4ee3\u7801\u751f\u6210API\u7684\u914d\u7f6e\u7ba1\u7406\u548c\u5feb\u901f\u5207\u6362\u3002", "conclusion": "CC-Switch\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4fbf\u6377\u7684\u5de5\u5177\u6765\u7ba1\u7406\u591a\u4e2aAI\u4ee3\u7801\u751f\u6210API\uff0c\u63d0\u9ad8\u4e86\u5f00\u53d1\u6548\u7387\u3002", "topic": "swe application"}}
{"id": "tldr.2511.3ccb0e47", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.testsprite.com%2F%3Futm_source=tldrfounders/1/0100019aa6873fd0-436817e3-64a0-47d8-a4bd-0c5eabcaeaf8-000000/Xx7hlyiD0HTk7_JnKYOC_EDwYYcq36Yhka1Fe0Gzqd4=432", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.testsprite.com%2F%3Futm_source=tldrfounders/1/0100019aa6873fd0-436817e3-64a0-47d8-a4bd-0c5eabcaeaf8-000000/Xx7hlyiD0HTk7_JnKYOC_EDwYYcq36Yhka1Fe0Gzqd4=432", "authors": ["TLDR Newsletter"], "title": "TestSprite", "comment": "Source: TLDR Newsletter, Date: 2025-11-21, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.testsprite.com%2F%3Futm_source=tldrfounders/1/0100019aa6873fd0-436817e3-64a0-47d8-a4bd-0c5eabcaeaf8-000000/Xx7hlyiD0HTk7_JnKYOC_EDwYYcq36Yhka1Fe0Gzqd4=432", "summary": "TestSprite (Tool) TestSprite is an AI agent that automates frontend and backend software testing, cutting testing costs by up to 90% with natural language workflows and full test coverage.", "source": "tldr", "AI": {"tldr": "TestSprite\u662f\u4e00\u4e2aAI\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u524d\u7aef\u548c\u540e\u7aef\u8f6f\u4ef6\u6d4b\u8bd5\uff0c\u53ef\u5c06\u6d4b\u8bd5\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe90%\u5e76\u63d0\u4f9b\u5b8c\u6574\u7684\u6d4b\u8bd5\u8986\u76d6\u3002", "motivation": "\u4f20\u7edf\u8f6f\u4ef6\u6d4b\u8bd5\u8fc7\u7a0b\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u9700\u8981\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u6765\u63d0\u9ad8\u6548\u7387\u5e76\u964d\u4f4e\u6210\u672c\u3002", "method": "\u4f7f\u7528AI\u4ee3\u7406\u548c\u81ea\u7136\u8bed\u8a00\u5de5\u4f5c\u6d41\u6765\u81ea\u52a8\u5316\u524d\u7aef\u548c\u540e\u7aef\u6d4b\u8bd5\u8fc7\u7a0b\u3002", "result": "\u80fd\u591f\u5c06\u6d4b\u8bd5\u6210\u672c\u964d\u4f4e\u9ad8\u8fbe90%\uff0c\u5e76\u63d0\u4f9b\u5b8c\u6574\u7684\u6d4b\u8bd5\u8986\u76d6\u3002", "conclusion": "TestSprite\u901a\u8fc7AI\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u6548\u7387\u5e76\u5927\u5e45\u964d\u4f4e\u4e86\u6210\u672c\u3002", "topic": "swe application"}}
{"id": "tldr.2511.dd20dd8b", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fhackread.com%2Fobscure-mcp-api-in-comet-browser-breaches-user-trust-enabling-full-device-control-via-ai-browsers%2F%3Futm_source=tldrinfosec/1/0100019aa6bdc916-a6dcc5ef-8947-49c5-bb83-cea65021b3e9-000000/2F2YME6ZaqKNVk2YyaEedVzaCbXbTV6pOJF0aMw488s=432", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fhackread.com%2Fobscure-mcp-api-in-comet-browser-breaches-user-trust-enabling-full-device-control-via-ai-browsers%2F%3Futm_source=tldrinfosec/1/0100019aa6bdc916-a6dcc5ef-8947-49c5-bb83-cea65021b3e9-000000/2F2YME6ZaqKNVk2YyaEedVzaCbXbTV6pOJF0aMw488s=432", "authors": ["TLDR Newsletter"], "title": "Obscure MCP API in Comet Browser Breaches User Trust, Enabling Full Device Control via AI Browsers", "comment": "Source: TLDR Newsletter, Date: 2025-11-21, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fhackread.com%2Fobscure-mcp-api-in-comet-browser-breaches-user-trust-enabling-full-device-control-via-ai-browsers%2F%3Futm_source=tldrinfosec/1/0100019aa6bdc916-a6dcc5ef-8947-49c5-bb83-cea65021b3e9-000000/2F2YME6ZaqKNVk2YyaEedVzaCbXbTV6pOJF0aMw488s=432", "summary": "Obscure MCP API in Comet Browser Breaches User Trust, Enabling Full Device Control via AI Browsers (4 minute read) SquareX researchers exposed a hidden MCP API (chrome.perplexity.mcp.addStdioServer) in the Comet browser that enables embedded extensions to execute arbitrary local commands without user consent, thereby bypassing decades of established browser security principles. The API is accessible via Comet's Agentic extension, triggered by perplexity.ai, creating a catastrophic third-party...", "source": "tldr", "AI": {"tldr": "SquareX\u7814\u7a76\u4eba\u5458\u5728Comet\u6d4f\u89c8\u5668\u4e2d\u53d1\u73b0\u4e86\u4e00\u4e2a\u9690\u85cf\u7684MCP API\uff0c\u8be5API\u5141\u8bb8\u5d4c\u5165\u5f0f\u6269\u5c55\u5728\u672a\u7ecf\u7528\u6237\u540c\u610f\u7684\u60c5\u51b5\u4e0b\u6267\u884c\u4efb\u610f\u672c\u5730\u547d\u4ee4\uff0c\u7ed5\u8fc7\u4e86\u6570\u5341\u5e74\u6765\u5efa\u7acb\u7684\u6d4f\u89c8\u5668\u5b89\u5168\u539f\u5219\u3002", "motivation": "\u63ed\u9732Comet\u6d4f\u89c8\u5668\u4e2d\u9690\u85cf\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u8be5\u6f0f\u6d1e\u53ef\u80fd\u88ab\u6076\u610f\u7b2c\u4e09\u65b9\u5229\u7528\u6765\u5b8c\u5168\u63a7\u5236\u7528\u6237\u8bbe\u5907\uff0c\u7834\u574f\u7528\u6237\u4fe1\u4efb\u3002", "method": "\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u5206\u6790Comet\u6d4f\u89c8\u5668\u7684Agentic\u6269\u5c55\u548cperplexity.ai\u7684\u89e6\u53d1\u673a\u5236\uff0c\u53d1\u73b0\u4e86chrome.perplexity.mcp.addStdioServer\u8fd9\u4e2a\u9690\u85cfAPI\u3002", "result": "\u53d1\u73b0\u8be5API\u5141\u8bb8\u5d4c\u5165\u5f0f\u6269\u5c55\u7ed5\u8fc7\u6d4f\u89c8\u5668\u5b89\u5168\u6c99\u7bb1\uff0c\u76f4\u63a5\u6267\u884c\u672c\u5730\u7cfb\u7edf\u547d\u4ee4\uff0c\u9020\u6210\u4e25\u91cd\u7684\u5b89\u5168\u5a01\u80c1\u3002", "conclusion": "Comet\u6d4f\u89c8\u5668\u4e2d\u7684\u8fd9\u4e2a\u9690\u85cfAPI\u8fdd\u53cd\u4e86\u57fa\u672c\u7684\u6d4f\u89c8\u5668\u5b89\u5168\u539f\u5219\uff0c\u9700\u8981\u7acb\u5373\u4fee\u590d\u4ee5\u9632\u6b62\u6076\u610f\u5229\u7528\u3002", "topic": "swe application"}}
{"id": "tldr.2511.fc700b98", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcline.bot%2Fblog%2Fcline-bench-initiative%3Futm_source=tldrai/1/0100019aa6c73715-49e25c81-f62d-4400-adcb-a073ef85dfe7-000000/0EO7nUUHHYLEBWq90cmQgwnMR6iFKYAk15zHHIdlj-o=432", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcline.bot%2Fblog%2Fcline-bench-initiative%3Futm_source=tldrai/1/0100019aa6c73715-49e25c81-f62d-4400-adcb-a073ef85dfe7-000000/0EO7nUUHHYLEBWq90cmQgwnMR6iFKYAk15zHHIdlj-o=432", "authors": ["TLDR Newsletter"], "title": "Introducing cline-bench: A Real-World, Open Source Benchmark for Agentic Coding", "comment": "Source: TLDR Newsletter, Date: 2025-11-21, Reading time: 11 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcline.bot%2Fblog%2Fcline-bench-initiative%3Futm_source=tldrai/1/0100019aa6c73715-49e25c81-f62d-4400-adcb-a073ef85dfe7-000000/0EO7nUUHHYLEBWq90cmQgwnMR6iFKYAk15zHHIdlj-o=432", "summary": "Introducing cline-bench: A Real-World, Open Source Benchmark for Agentic Coding (11 minute read) cline-bench is a new initiative focused on creating high fidelity benchmarks and reinforcement learning environments derived from real open source development scenarios. AI models have advanced significantly, but the field still lacks a rigorous open source benchmark that represents real engineering work. Model labs require evals that expose real breakdowns. cline-bench supports the next stage of ...", "source": "tldr", "AI": {"tldr": "cline-bench\u662f\u4e00\u4e2a\u65b0\u7684\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u6ce8\u4e8e\u4ece\u771f\u5b9e\u5f00\u6e90\u5f00\u53d1\u573a\u666f\u4e2d\u521b\u5efa\u9ad8\u4fdd\u771f\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f3a\u5316\u5b66\u4e60\u73af\u5883\uff0c\u4ee5\u89e3\u51b3\u5f53\u524dAI\u6a21\u578b\u5728\u771f\u5b9e\u5de5\u7a0b\u5de5\u4f5c\u4e2d\u7f3a\u4e4f\u4e25\u683c\u57fa\u51c6\u6d4b\u8bd5\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u867d\u7136\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u8be5\u9886\u57df\u4ecd\u7136\u7f3a\u4e4f\u80fd\u591f\u4ee3\u8868\u771f\u5b9e\u5de5\u7a0b\u5de5\u4f5c\u7684\u4e25\u683c\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u3002\u6a21\u578b\u5b9e\u9a8c\u5ba4\u9700\u8981\u80fd\u591f\u66b4\u9732\u771f\u5b9e\u95ee\u9898\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u4ece\u771f\u5b9e\u5f00\u6e90\u5f00\u53d1\u573a\u666f\u4e2d\u521b\u5efa\u9ad8\u4fdd\u771f\u5ea6\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u6765\u6784\u5efacline-bench\u3002", "result": "cline-bench\u652f\u6301AI\u6a21\u578b\u5f00\u53d1\u7684\u4e0b\u4e00\u9636\u6bb5\uff0c\u4e3a\u6a21\u578b\u5b9e\u9a8c\u5ba4\u63d0\u4f9b\u80fd\u591f\u66b4\u9732\u771f\u5b9e\u95ee\u9898\u7684\u8bc4\u4f30\u73af\u5883\u3002", "conclusion": "cline-bench\u586b\u8865\u4e86AI\u7f16\u7801\u4ee3\u7406\u9886\u57df\u5728\u771f\u5b9e\u5de5\u7a0b\u5de5\u4f5c\u57fa\u51c6\u6d4b\u8bd5\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3a\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "topic": "swe benchmark"}}
{"id": "wechat.2511.300fee3c", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3Mzc4MTg4Mg==&mid=2453984555&idx=1&sn=6492314022baec078408687a53ec14d2&chksm=89a4ad337dd627676f91fb259ea27efa7c74b874ea23d2596c892bf425686a9efdb09967a4da#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3Mzc4MTg4Mg==&mid=2453984555&idx=1&sn=6492314022baec078408687a53ec14d2&chksm=89a4ad337dd627676f91fb259ea27efa7c74b874ea23d2596c892bf425686a9efdb09967a4da#rd", "authors": ["\u6d45\u5c1d\u5927\u6a21\u578b"], "title": "verl <em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6846\u67b6\u80cc\u540e\u7684\u5de7\u601d", "comment": "Source: WeChat, Published: 2025-11-24 12:59:57", "summary": "2. \u4f7f\u7528single-controller\u89e3\u8026\u5f3a\u5316\u5b66\u4e60\u591a\u4e2a\u4e0d\u540c\u9636\u6bb5/\u89d2\u8272\u4e4b\u95f4\u7684\u4fe1\u606f\u901a\u4fe1\u548c\u89d2\u8272\u5185\u90e8\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u901a\u4fe1\u3002\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u7ecf\u5e38\u91c7\u7528multi-controller\u6a21\u5f0f\uff0c\u5373\u6ca1\u6709\u4e2d\u5fc3\u5316\u7684\u8c03\u5ea6\u5668\u6307\u6325\u548c\u5206\u914d\u8282\u70b9\u7684\u5de5\u4f5c\uff0c\u6bcf\u4e2a\u8282\u70b9\u90fd\u8dd1\u5b8c\u5168\u4e00\u6837\u7684\u4ee3", "AI": {"tldr": "2. \u4f7f\u7528single-controller\u89e3\u8026\u5f3a\u5316\u5b66\u4e60\u591a\u4e2a\u4e0d\u540c\u9636\u6bb5/\u89d2\u8272\u4e4b\u95f4\u7684\u4fe1\u606f\u901a\u4fe1\u548c\u89d2\u8272\u5185\u90e8\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u901a\u4fe1\u3002\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u7ecf\u5e38\u91c7\u7528multi-controller\u6a21\u5f0f\uff0c\u5373\u6ca1\u6709\u4e2d\u5fc3\u5316\u7684\u8c03\u5ea6\u5668\u6307\u6325\u548c\u5206\u914d\u8282\u70b9\u7684\u5de5\u4f5c\uff0c\u6bcf\u4e2a\u8282\u70b9\u90fd\u8dd1\u5b8c\u5168\u4e00\u6837\u7684\u4ee3", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.769fea2f", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIxNzQ0ODkyMQ==&mid=2247491473&idx=1&sn=aae7aac1cce3a5043ad847d3da2aea12&chksm=96b71dd50e95869bc60861bb7a9285d01495a5678e50c10619ab6ad49e030916be2207607919#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIxNzQ0ODkyMQ==&mid=2247491473&idx=1&sn=aae7aac1cce3a5043ad847d3da2aea12&chksm=96b71dd50e95869bc60861bb7a9285d01495a5678e50c10619ab6ad49e030916be2207607919#rd", "authors": ["AILab\u7b14\u8bb0"], "title": "\u3010\u6587\u732e\u3011\u7aef\u5230\u7aef<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u63d0\u5347\u7075\u5de7\u6293\u53d6\u7b56\u7565", "comment": "Source: WeChat, Published: 2025-11-24 12:23:32", "summary": "\u4e0e\u57fa\u4e8e\u72b6\u6001\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6709\u6240\u4e0d\u540c\uff0c\u57fa\u4e8e\u89c6\u89c9\u7684 RL \u5185\u5b58\u6548\u7387\u6b20\u4f73\uff0c\u81f4\u4f7f\u6279\u6b21\u5927\u5c0f\u76f8\u5bf9\u8f83\u5c0f\uff0c\u8fd9\u5bf9\u4e8e PPO \u7b49\u7b97\u6cd5\u800c\u8a00\u5e76\u4e0d\u9002\u7528\u3002\u4e0d\u8fc7\uff0c\u5b83\u4f9d\u65e7\u662f\u9887\u5177\u5438\u5f15\u529b\u7684\u65b9\u6cd5\u3002", "AI": {"tldr": "\u4e0e\u57fa\u4e8e\u72b6\u6001\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6709\u6240\u4e0d\u540c\uff0c\u57fa\u4e8e\u89c6\u89c9\u7684 RL \u5185\u5b58\u6548\u7387\u6b20\u4f73\uff0c\u81f4\u4f7f\u6279\u6b21\u5927\u5c0f\u76f8\u5bf9\u8f83\u5c0f\uff0c\u8fd9\u5bf9\u4e8e PPO \u7b49\u7b97\u6cd5\u800c\u8a00\u5e76\u4e0d\u9002\u7528\u3002\u4e0d\u8fc7\uff0c\u5b83\u4f9d\u65e7\u662f\u9887\u5177\u5438\u5f15\u529b\u7684\u65b9\u6cd5\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.f1edd8c3", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyNTMwMjI2Mw==&mid=2247504881&idx=1&sn=4aa66a613be309793216e114dde0535c&chksm=c0e1369332603a6a5bc0b36f6109ab7545c40bbff8c42b963b855e21df7e9afda55bb4a93eeb#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyNTMwMjI2Mw==&mid=2247504881&idx=1&sn=4aa66a613be309793216e114dde0535c&chksm=c0e1369332603a6a5bc0b36f6109ab7545c40bbff8c42b963b855e21df7e9afda55bb4a93eeb#rd", "authors": ["\u6bd5\u6607\u7f16\u8bd1"], "title": "\u57fa\u4e8e<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7684 CPU \u7f16\u8bd1\u4f18\u5316\u5b9e\u8df5\uff1aMLGO \u7cfb\u5217\u8bba\u6587\u5206\u6790", "comment": "Source: WeChat, Published: 2025-11-24 10:55:11", "summary": "\u672c\u6587\u901a\u8fc7\u89e3\u8bfb\u6700\u8fd1\u51e0\u5e74\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u5728\u7f16\u8bd1\u4f18\u5316\u9886\u57df\u5b9e\u8df5\u7684\u4e24\u7bc7\u4ee3\u8868\u6027\u8bba\u6587\uff0c\u6765\u770b\u4e00\u770b\u5f53\u524d\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\uff08NN\uff09\u7684\u7f16\u8bd1\u4f18\u5316\u6280\u672f\u5230\u5e95\u505a\u5230\u4e86\u54ea\u4e00\u6b65\uff0c\u54ea\u4e9b\u5730\u65b9\u6709\u7a81\u7834\uff0c\u54ea\u4e9b\u5730\u65b9\u53c8\u4ecd\u7136\u53d7\u9650\u3002", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u89e3\u8bfb\u6700\u8fd1\u51e0\u5e74\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u5728\u7f16\u8bd1\u4f18\u5316\u9886\u57df\u5b9e\u8df5\u7684\u4e24\u7bc7\u4ee3\u8868\u6027\u8bba\u6587\uff0c\u6765\u770b\u4e00\u770b\u5f53\u524d\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\uff08NN\uff09\u7684\u7f16\u8bd1\u4f18\u5316\u6280\u672f\u5230\u5e95\u505a\u5230\u4e86\u54ea\u4e00\u6b65\uff0c\u54ea\u4e9b\u5730\u65b9\u6709\u7a81\u7834\uff0c\u54ea\u4e9b\u5730\u65b9\u53c8\u4ecd\u7136\u53d7\u9650\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.e384cc17", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg5OTE2MzE2Ng==&mid=2247485812&idx=1&sn=327b07e63e2bed84353f5510feba1d73&chksm=c16d5671e3e3777c596a8120672665d3ef0434057982ac46c8594ef206832b83eb1d5901976d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg5OTE2MzE2Ng==&mid=2247485812&idx=1&sn=327b07e63e2bed84353f5510feba1d73&chksm=c16d5671e3e3777c596a8120672665d3ef0434057982ac46c8594ef206832b83eb1d5901976d#rd", "authors": ["\u5929\u673a\u6a21\u578b"], "title": "\u590d\u6742\u5b66\u4e60VS\u6df1\u5ea6\u5b66\u4e60\uff0c<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\uff0c\u795e\u7ecf\u7b26\u53f7\u63a8\u7406", "comment": "Source: WeChat, Published: 2025-11-24 10:31:04", "summary": "\u590d\u6742\u5b66\u4e60\u662f\u4e3b\u52a8\u7406\u89e3\uff0c\u65e8\u5728\u53d1\u73b0\u7cfb\u7edf\u5185\u751f\u7684\u77db\u76fe\u52a8\u529b\u5b66\u3002\u5f3a\u5316\u5b66\u4e60\u884c\u4e3a\u4e3b\u4e49\u3001\u6700\u4f18\u63a7\u5236\u73af\u5883\u53cd\u9988\u7684\u5956\u52b1\u4fe1\u53f7\u76ee\u6807\u9a71\u52a8\uff1a\u5b66\u4e60\u5b9e\u73b0\u5916\u90e8\u76ee\u6807\u7684\u6700\u4f18\u7b56\u7565\u3002", "AI": {"tldr": "\u590d\u6742\u5b66\u4e60\u662f\u4e3b\u52a8\u7406\u89e3\uff0c\u65e8\u5728\u53d1\u73b0\u7cfb\u7edf\u5185\u751f\u7684\u77db\u76fe\u52a8\u529b\u5b66\u3002\u5f3a\u5316\u5b66\u4e60\u884c\u4e3a\u4e3b\u4e49\u3001\u6700\u4f18\u63a7\u5236\u73af\u5883\u53cd\u9988\u7684\u5956\u52b1\u4fe1\u53f7\u76ee\u6807\u9a71\u52a8\uff1a\u5b66\u4e60\u5b9e\u73b0\u5916\u90e8\u76ee\u6807\u7684\u6700\u4f18\u7b56\u7565\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.fe2245ff", "categories": ["wechat.article", "wechat.ai", "wechat.rl", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&mid=2247662412&idx=1&sn=434c843883ae938d16b8507f58ef103c&chksm=e8d345cb5f108ab1c1d3b7d36c148adbcbf58a08fae8a7f815baa5a0b6685c2ab2b3c3d72a68#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&mid=2247662412&idx=1&sn=434c843883ae938d16b8507f58ef103c&chksm=e8d345cb5f108ab1c1d3b7d36c148adbcbf58a08fae8a7f815baa5a0b6685c2ab2b3c3d72a68#rd", "authors": ["\u6570\u636e\u6d3eTHU"], "title": "\u539f\u521b | \u5927\u6a21\u578b\u626b\u76f2\u7cfb\u5217\uff08\u4e09\uff09-<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u57fa\u7840\uff08\u4e0b\uff09", "comment": "Source: WeChat, Published: 2025-11-24 09:02:30", "summary": "\u6211\u4eec\u5148\u6e05\u695a\u5728\u5927\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u5404\u4e2a\u8981\u7d20\u5bf9\u5e94\u7684\u542b\u4e49\uff1a\u57fa\u4e8e\u7b56\u7565\u7684\u7b97\u6cd5\uff08Policy-Based Optimization\uff09\u5728\u5927\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u57fa\u4e8e\u7b56\u7565\u7684\u4f18\u5316\u5df2\u6210\u4e3a\u4e3b\u6d41\u8303\u5f0f\uff0c\u5176\u6838\u5fc3\u5728\u4e8e\u76f4\u63a5\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u7b56\u7565\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\u3002", "AI": {"tldr": "\u6211\u4eec\u5148\u6e05\u695a\u5728\u5927\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e2d\uff0c\u5f3a\u5316\u5b66\u4e60\u5404\u4e2a\u8981\u7d20\u5bf9\u5e94\u7684\u542b\u4e49\uff1a\u57fa\u4e8e\u7b56\u7565\u7684\u7b97\u6cd5\uff08Policy-Based Optimization\uff09\u5728\u5927\u6a21\u578b\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u57fa\u4e8e\u7b56\u7565\u7684\u4f18\u5316\u5df2\u6210\u4e3a\u4e3b\u6d41\u8303\u5f0f\uff0c\u5176\u6838\u5fc3\u5728\u4e8e\u76f4\u63a5\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u7b56\u7565\u8fdb\u884c\u7aef\u5230\u7aef\u4f18\u5316\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.1162be9d", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIxNDgzNDg3NQ==&mid=2247572613&idx=2&sn=909ba3b426917561675b20bdbc5596cd&chksm=9687385c1291cbff81cf82008f45b0fe9f670363382eaebb324677364cd332f3d6f2a99b3482#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIxNDgzNDg3NQ==&mid=2247572613&idx=2&sn=909ba3b426917561675b20bdbc5596cd&chksm=9687385c1291cbff81cf82008f45b0fe9f670363382eaebb324677364cd332f3d6f2a99b3482#rd", "authors": ["\u6df1\u5ea6\u5b66\u4e60\u4e0eNLP"], "title": "DRL\u5723\u7ecf2025\u6700\u65b0\u7248-\u300a<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>:\u5bfc\u8bba\u7b2c\u4e8c\u7248\u300b\u514d\u8d39pdf\u5206\u4eab", "comment": "Source: WeChat, Published: 2025-11-24 09:00:00", "summary": "\u6211\u4eec\u7b2c\u4e8c\u7248\u7684\u76ee\u6807\u548c\u7b2c\u4e00\u7248\u7684\u76ee\u6807\u662f\u4e00\u6837\u7684\uff1a\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u601d\u60f3\u548c\u7b97\u6cd5\u63d0\u4f9b\u4e00\u4e2a\u6e05\u6670\u800c\u7b80\u5355\u7684\u63cf\u8ff0\uff0c\u4f9b\u6240\u6709\u76f8\u5173\u5b66\u79d1\u7684\u8bfb\u8005\u9605\u8bfb\u3002\u8be5\u7248\u672c\u4ecd\u7136\u662f\u4e00\u4e2a\u4ecb\u7ecd\uff0c\u6211\u4eec\u4fdd\u7559\u4e86\u6838\u5fc3\uff0c\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u7684\u91cd\u70b9\u3002", "AI": {"tldr": "\u6211\u4eec\u7b2c\u4e8c\u7248\u7684\u76ee\u6807\u548c\u7b2c\u4e00\u7248\u7684\u76ee\u6807\u662f\u4e00\u6837\u7684\uff1a\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u601d\u60f3\u548c\u7b97\u6cd5\u63d0\u4f9b\u4e00\u4e2a\u6e05\u6670\u800c\u7b80\u5355\u7684\u63cf\u8ff0\uff0c\u4f9b\u6240\u6709\u76f8\u5173\u5b66\u79d1\u7684\u8bfb\u8005\u9605\u8bfb\u3002\u8be5\u7248\u672c\u4ecd\u7136\u662f\u4e00\u4e2a\u4ecb\u7ecd\uff0c\u6211\u4eec\u4fdd\u7559\u4e86\u6838\u5fc3\uff0c\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u7684\u91cd\u70b9\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.e4bf08c7", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0MjUxMzg3OQ==&mid=2247496535&idx=1&sn=fd053fc8946e8f7f322c497482444029&chksm=c3731290028388594a41cc9d2ef39b46c11e8aef66d4be6584ea2876a92e42574d1c7a19f3e3#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0MjUxMzg3OQ==&mid=2247496535&idx=1&sn=fd053fc8946e8f7f322c497482444029&chksm=c3731290028388594a41cc9d2ef39b46c11e8aef66d4be6584ea2876a92e42574d1c7a19f3e3#rd", "authors": ["\u6df1\u591c\u52aa\u529b\u5199Python"], "title": "2026\u5e74\uff0c<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>RL\u5c06\u8d70\u5411\u4f55\u65b9\uff1f", "comment": "Source: WeChat, Published: 2025-11-24 03:36:19", "summary": "\u3010\u8981\u70b9\u3011\u8bba\u6587\u63d0\u51fa\u4e86\u6700\u5927\u6269\u6563\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e2d\u6570\u636e\u72ec\u7acb\u540c\u5206\u5e03\u7684\u5047\u8bbe\uff0c\u5b9e\u73b0\u4e86\u5355\u6b21\u90e8\u7f72\u4e0b\u7684\u8fde\u7eed\u5b66\u4e60\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u7684\u4f18\u52bf\u3002", "AI": {"tldr": "\u3010\u8981\u70b9\u3011\u8bba\u6587\u63d0\u51fa\u4e86\u6700\u5927\u6269\u6563\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e2d\u6570\u636e\u72ec\u7acb\u540c\u5206\u5e03\u7684\u5047\u8bbe\uff0c\u5b9e\u73b0\u4e86\u5355\u6b21\u90e8\u7f72\u4e0b\u7684\u8fde\u7eed\u5b66\u4e60\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u7684\u4f18\u52bf\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.cd061af5", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI4NjQxMzg0Nw==&mid=2247486119&idx=1&sn=053350f2670f3f4f63a8be966346587e&chksm=ea40921b9042f4307a79b0a87cf127a53d7cc40e6a37dffe48c5cec80208800a5c216c7a67d8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI4NjQxMzg0Nw==&mid=2247486119&idx=1&sn=053350f2670f3f4f63a8be966346587e&chksm=ea40921b9042f4307a79b0a87cf127a53d7cc40e6a37dffe48c5cec80208800a5c216c7a67d8#rd", "authors": ["\u5177\u8eab\u667a\u80fd\u89c2\u5bdf\u5ba4"], "title": "\u673a\u5668\u4eba\u5982\u4f55\u4ece\u5931\u8d25\u4e2d\u81ea\u6211\u7ea0\u6b63\uff1f\u6e2f\u79d1\u5927&\u5b57\u8282\u8054\u5408\u63a8\u51faWMPO\uff0c\u4e16\u754c\u6a21\u578b\u8ba9<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u2018\u96f6\u6210\u672c\u2019\u8fdb\u5316", "comment": "Source: WeChat, Published: 2025-11-24 00:30:00", "summary": "\u8be5\u6846\u67b6\u57fa\u4e8emodel-based\u5f3a\u5316\u5b66\u4e60\uff08MBRL\uff09\u539f\u7406\uff0c\u7b56\u7565\u4f18\u5316\u5b8c\u5168\u5728\u6a21\u578b\u5185\u95ed\u73af\u5b8c\u6210\uff0c\u907f\u514d\u771f\u5b9e\u73af\u5883\u9ad8\u6210\u672c\u4ea4\u4e92\u3002\u901a\u8fc7\u76f4\u63a5\u5728\u50cf\u7d20\u7a7a\u95f4\u5efa\u6a21\uff0cWMPO\u6709\u6548\u8854\u63a5\u9884\u8bad\u7ec3VLA\u7279\u5f81\u4e0e\u201c\u60f3\u8c61\u201d\u8f68\u8ff9\u3002", "AI": {"tldr": "\u8be5\u6846\u67b6\u57fa\u4e8emodel-based\u5f3a\u5316\u5b66\u4e60\uff08MBRL\uff09\u539f\u7406\uff0c\u7b56\u7565\u4f18\u5316\u5b8c\u5168\u5728\u6a21\u578b\u5185\u95ed\u73af\u5b8c\u6210\uff0c\u907f\u514d\u771f\u5b9e\u73af\u5883\u9ad8\u6210\u672c\u4ea4\u4e92\u3002\u901a\u8fc7\u76f4\u63a5\u5728\u50cf\u7d20\u7a7a\u95f4\u5efa\u6a21\uff0cWMPO\u6709\u6548\u8854\u63a5\u9884\u8bad\u7ec3VLA\u7279\u5f81\u4e0e\u201c\u60f3\u8c61\u201d\u8f68\u8ff9\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.2c2a2387", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxMDIwOTU5OQ==&mid=2247484230&idx=1&sn=0d55d3527b0d4e1f995461e251c03523&chksm=c074129e88d02684e65c6c160f999183fc1e9656cd5f7559eeb7f3e3219beb5e90dbdb6f054a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxMDIwOTU5OQ==&mid=2247484230&idx=1&sn=0d55d3527b0d4e1f995461e251c03523&chksm=c074129e88d02684e65c6c160f999183fc1e9656cd5f7559eeb7f3e3219beb5e90dbdb6f054a#rd", "authors": ["AI\u8001\u9a6c\u554a"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\uff5c\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\u4ecb\u7ecd", "comment": "Source: WeChat, Published: 2025-11-24 00:02:10", "summary": "\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\uff0c\u6709\u65f6\u56de\u62a5\u603b\u662f\u6b63\u503c\uff0c\u5373\u516c\u5f0f \uff0810\uff09 \u4e2d\u7684 \u603b\u4e3a\u6b63\u56de\u62a5\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f7f\u5f97\u7b56\u7565\u603b\u662f\u63d0\u5347\u5728\u5bf9\u5e94\u72b6\u6001\u4e0b\u91c7\u53d6\u5bf9\u5e94\u884c\u52a8 \u7684\u6982\u7387\u3002\u800c\u4e14\u4e3a\u4fdd\u8bc1\u5728\u72b6\u6001 \u4e0b\u6240\u6709\u53ef\u80fd\u52a8\u4f5c\u7684\u6982\u7387\u4e3a1\uff0c\u5728\u63d0\u5347\u6982\u7387\u540e\u4f1a\u505a\u5f52\u4e00\u5316\u3002", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\uff0c\u6709\u65f6\u56de\u62a5\u603b\u662f\u6b63\u503c\uff0c\u5373\u516c\u5f0f \uff0810\uff09 \u4e2d\u7684 \u603b\u4e3a\u6b63\u56de\u62a5\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u4f7f\u5f97\u7b56\u7565\u603b\u662f\u63d0\u5347\u5728\u5bf9\u5e94\u72b6\u6001\u4e0b\u91c7\u53d6\u5bf9\u5e94\u884c\u52a8 \u7684\u6982\u7387\u3002\u800c\u4e14\u4e3a\u4fdd\u8bc1\u5728\u72b6\u6001 \u4e0b\u6240\u6709\u53ef\u80fd\u52a8\u4f5c\u7684\u6982\u7387\u4e3a1\uff0c\u5728\u63d0\u5347\u6982\u7387\u540e\u4f1a\u505a\u5f52\u4e00\u5316\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.88ef3d5d", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxNzkyMTQ3Mg==&mid=2247483875&idx=1&sn=308ab4660c9a04b38fe07736aabdbd2c&chksm=9a4ef6e7d96628d912dada93082ff62d4840c5d07d44d0b8fa314ea0a2eefc746eb44a8b4dac#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxNzkyMTQ3Mg==&mid=2247483875&idx=1&sn=308ab4660c9a04b38fe07736aabdbd2c&chksm=9a4ef6e7d96628d912dada93082ff62d4840c5d07d44d0b8fa314ea0a2eefc746eb44a8b4dac#rd", "authors": ["\u963f\u725b\u4eca\u5929\u5b66\u4e60\u4e86\u5417"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u80fd\u5426\u5e26\u6211\u4eec\u62b5\u8fbeAGI?Amazon\u3001OpenAI\u3001Meta\u9876\u5c16\u79d1\u5b66\u5bb6\u7ed9\u51fa\u4e86\u622a\u7136\u4e0d\u540c\u7684\u7b54\u6848", "comment": "Source: WeChat, Published: 2025-11-23 23:06:58", "summary": "\u540e\u8bad\u7ec3\u9636\u6bb5\u7684\u63a2\u7d22\uff1a\u76ee\u6807\uff1a\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u6df1\u5ea6\u4f18\u5316\u65b9\u6cd5\uff1a\u6709\u9488\u5bf9\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u6807\u51c6\uff1a\u4efb\u52a1\u6027\u80fd\u6700\u5927\u5316\u4f46\u674e\u6d2a\u8865\u5145\u4e86\u4e00\u4e2a\u5173\u952e\u6d1e\u5bdf\uff1a\u5f53\u524d\u7684\u63a2\u7d22\u7a7a\u95f4\u5df2\u7ecf\u56e0\u9884\u8bad\u7ec3\u5927\u5e45\u7f29\u5c0f\u3002", "AI": {"tldr": "\u540e\u8bad\u7ec3\u9636\u6bb5\u7684\u63a2\u7d22\uff1a\u76ee\u6807\uff1a\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u6df1\u5ea6\u4f18\u5316\u65b9\u6cd5\uff1a\u6709\u9488\u5bf9\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u6807\u51c6\uff1a\u4efb\u52a1\u6027\u80fd\u6700\u5927\u5316\u4f46\u674e\u6d2a\u8865\u5145\u4e86\u4e00\u4e2a\u5173\u952e\u6d1e\u5bdf\uff1a\u5f53\u524d\u7684\u63a2\u7d22\u7a7a\u95f4\u5df2\u7ecf\u56e0\u9884\u8bad\u7ec3\u5927\u5e45\u7f29\u5c0f\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.42dce744", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzE5MTE2MTc2Nw==&mid=2247488812&idx=1&sn=27dfa98afe51a25b7e2e1cc1e2d64932&chksm=97c2251b14f208bd848baef6a7d386bc069edecd148dcd10b73a0f28dbd8289f28bf9a402ae7#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzE5MTE2MTc2Nw==&mid=2247488812&idx=1&sn=27dfa98afe51a25b7e2e1cc1e2d64932&chksm=97c2251b14f208bd848baef6a7d386bc069edecd148dcd10b73a0f28dbd8289f28bf9a402ae7#rd", "authors": ["\u548c\u901aAI"], "title": "<em class=\"highlight\">Agentic</em> AI\u5f15\u9886\u751f\u547d\u79d1\u5b66\u65b0\u56fe\u666f", "comment": "Source: WeChat, Published: 2025-11-24 12:04:47", "summary": "com/industries/life-sciences/our-insights/reimagining-life-science-enterprises-with-agentic-ai\u672c\u6587\u7531\u5927\u6a21\u578b\u5168\u6587\u7cbe\u8bd1\uff0c\u548c\u901aAI\u7f16\u8bd1\u53d1\u5e03\u3002\u751f\u547d\u79d1\u5b66\u4f01\u4e1a\u6b63\u9762\u4e34\u5229\u6da6\u7a7a\u95f4\u88ab\u538b\u7f29\u3001\u7814\u53d1\u6210\u672c\u6500\u5347\uff0c\u4ee5\u53ca\u5728\u6280\u672f\u4e0e\u8fd0\u8425\u590d\u6742\u6027\u4e0d\u65ad\u52a0\u5267\u7684\u80cc\u666f\u4e0b\u5bf9\u6301\u7eed\u521b\u65b0\u7684\u8feb", "AI": {"tldr": "com/industries/life-sciences/our-insights/reimagining-life-science-enterprises-with-agentic-ai\u672c\u6587\u7531\u5927\u6a21\u578b\u5168\u6587\u7cbe\u8bd1\uff0c\u548c\u901aAI\u7f16\u8bd1\u53d1\u5e03\u3002\u751f\u547d\u79d1\u5b66\u4f01\u4e1a\u6b63\u9762\u4e34\u5229\u6da6\u7a7a\u95f4\u88ab\u538b\u7f29\u3001\u7814\u53d1\u6210\u672c\u6500\u5347\uff0c\u4ee5\u53ca\u5728\u6280\u672f\u4e0e\u8fd0\u8425\u590d\u6742\u6027\u4e0d\u65ad\u52a0\u5267\u7684\u80cc\u666f\u4e0b\u5bf9\u6301\u7eed\u521b\u65b0\u7684\u8feb", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.b9edace3", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk2NDQxMTYxNg==&mid=2247484069&idx=1&sn=45068ef2a3b17ab5fdac25746b41d98b&chksm=c52b8431f105a0132d0ff8c76af1c3872c34ef0bc564bb7ea2696a40d6775a61d3ed9131a84f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk2NDQxMTYxNg==&mid=2247484069&idx=1&sn=45068ef2a3b17ab5fdac25746b41d98b&chksm=c52b8431f105a0132d0ff8c76af1c3872c34ef0bc564bb7ea2696a40d6775a61d3ed9131a84f#rd", "authors": ["\u9526\u5c0a\u8def\u62c6\u5984\u8bb0"], "title": "<em class=\"highlight\">Agentic</em> AI \u65f6\u4ee3\uff1a\u771f\u6b63\u7684\u9769\u547d\u4e0d\u662f\u6280\u672f\uff0c\u800c\u662f\u4f60\u7684\u4eba\u751f\u5267\u672c", "comment": "Source: WeChat, Published: 2025-11-24 11:59:02", "summary": "\u666e\u901a AI\uff1a\u4f60\u8bf4\u4e00\u53e5\uff0c\u5b83\u56de\u4e00\u53e5\u3002Agentic AI\uff1a\u4f60\u7ed9\u76ee\u6807\uff0c\u5b83\u81ea\u5df1\u53bb\u8dd1\u3002\u6bd4\u5982\u8bf4\uff0c\u4f60\u60f3\u8ba2\u4e00\u6b21\u65c5\u884c\u3002\u8fc7\u53bb\u4f60\u8981\u67e5\u673a\u7968\u3001\u770b\u9152\u5e97\u3001\u5bf9\u6bd4\u653b\u7565\u3001\u586b\u8ba2\u5355\u3002\u4e00\u4e2a\u673a\u7968\u4e24\u5c0f\u65f6\u6ca1\u4e70\u5230\u3001\u9152\u5e97\u6da8\u4ef7\uff0c\u4f60\u8fd8\u5f97\u91cd\u65b0\u6765\u3002", "AI": {"tldr": "\u666e\u901a AI\uff1a\u4f60\u8bf4\u4e00\u53e5\uff0c\u5b83\u56de\u4e00\u53e5\u3002Agentic AI\uff1a\u4f60\u7ed9\u76ee\u6807\uff0c\u5b83\u81ea\u5df1\u53bb\u8dd1\u3002\u6bd4\u5982\u8bf4\uff0c\u4f60\u60f3\u8ba2\u4e00\u6b21\u65c5\u884c\u3002\u8fc7\u53bb\u4f60\u8981\u67e5\u673a\u7968\u3001\u770b\u9152\u5e97\u3001\u5bf9\u6bd4\u653b\u7565\u3001\u586b\u8ba2\u5355\u3002\u4e00\u4e2a\u673a\u7968\u4e24\u5c0f\u65f6\u6ca1\u4e70\u5230\u3001\u9152\u5e97\u6da8\u4ef7\uff0c\u4f60\u8fd8\u5f97\u91cd\u65b0\u6765\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.1090f4ca", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYyNTI3MTg2NQ==&mid=2247483713&idx=1&sn=3d5e8ab7c08dd77f77b15ce2bd002274&chksm=f1361f90d943118eb2a70f149bbd2df52f154f8093f6a80fca09887e024f6d09958937ef2079#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYyNTI3MTg2NQ==&mid=2247483713&idx=1&sn=3d5e8ab7c08dd77f77b15ce2bd002274&chksm=f1361f90d943118eb2a70f149bbd2df52f154f8093f6a80fca09887e024f6d09958937ef2079#rd", "authors": ["AI-Frontiers"], "title": "\u8c37\u6b4c\u91cd\u78c5\u51fa\u54c1\uff01\u63ed\u79d821\u79cd<em class=\"highlight\">Agentic</em>\u8bbe\u8ba1\u6a21\u5f0f\uff0cAI\u4ece\u4e1a\u8005\u5fc5\u5907", "comment": "Source: WeChat, Published: 2025-11-24 08:01:36", "summary": "#agent #google", "AI": {"tldr": "#agent #google", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.a3ff8b90", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&mid=2651264061&idx=2&sn=db54f2e5d97bf731f3fda31202feea99&chksm=bceff8526b5e9b9b7aa358f924216d81c476d7ba7528457db8a9845f71570371a073c3e9a25a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&mid=2651264061&idx=2&sn=db54f2e5d97bf731f3fda31202feea99&chksm=bceff8526b5e9b9b7aa358f924216d81c476d7ba7528457db8a9845f71570371a073c3e9a25a#rd", "authors": ["InfoQ"], "title": "\u4ece\u6a21\u578b\u5230<em class=\"highlight\">\u667a\u80fd\u4f53</em>\uff1aSnowflake \u7684\u4f01\u4e1a\u7ea7 <em class=\"highlight\">Agentic</em> AI \u5de5\u7a0b\u5316\u4e4b\u8def", "comment": "Source: WeChat, Published: 2025-11-24 05:41:10", "summary": "\u8fd9\u662f\u6211\u4eec\u7814\u53d1\u56e2\u961f\u63a8\u52a8\u7684\u4e00\u9879\u521b\u65b0\uff0c\u6211\u4eec\u5c06\u5176\u547d\u540d\u4e3a ReFoRCE\uff0c\u8fd9\u662f\u4e00\u4e2a Agentic \u7cfb\u7edf\u3002\u5b83\u53ef\u4ee5\u901a\u8fc7\u4e00\u7cfb\u5217\u81ea\u52a8\u5316\u64cd\u4f5c\u5bf9\u6570\u636e\u5e93\u7684 Schema \u8fdb\u884c\u538b\u7f29\u548c\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u81ea\u52a8\u6295\u7968\u7cfb\u7edf\u5bf9\u6bd4\u4e0d\u540c\u751f\u6210\u7684 SQL \u6267\u884c\u7ed3\u679c\uff0c\u6700\u7ec8\u8fbe\u5230\u6700\u4f18\u6548\u679c\u3002", "AI": {"tldr": "\u8fd9\u662f\u6211\u4eec\u7814\u53d1\u56e2\u961f\u63a8\u52a8\u7684\u4e00\u9879\u521b\u65b0\uff0c\u6211\u4eec\u5c06\u5176\u547d\u540d\u4e3a ReFoRCE\uff0c\u8fd9\u662f\u4e00\u4e2a Agentic \u7cfb\u7edf\u3002\u5b83\u53ef\u4ee5\u901a\u8fc7\u4e00\u7cfb\u5217\u81ea\u52a8\u5316\u64cd\u4f5c\u5bf9\u6570\u636e\u5e93\u7684 Schema \u8fdb\u884c\u538b\u7f29\u548c\u4f18\u5316\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u81ea\u52a8\u6295\u7968\u7cfb\u7edf\u5bf9\u6bd4\u4e0d\u540c\u751f\u6210\u7684 SQL \u6267\u884c\u7ed3\u679c\uff0c\u6700\u7ec8\u8fbe\u5230\u6700\u4f18\u6548\u679c\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.d1068be1", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247772357&idx=1&sn=97f8eac17c36e7e55b602ba8a5633f9d&chksm=facc9684e23fe2f4c5896f9d5a70ac479382e496d6943fbf52eb8b0244742f7652abb639985e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU1NTMyOTI4Mw==&mid=2247772357&idx=1&sn=97f8eac17c36e7e55b602ba8a5633f9d&chksm=facc9684e23fe2f4c5896f9d5a70ac479382e496d6943fbf52eb8b0244742f7652abb639985e#rd", "authors": ["DataFunTalk"], "title": "\u4e00\u6587\u8bf4\u6e05 <em class=\"highlight\">Agentic</em> AI\uff1a\u57fa\u4e8e LLM \u7684<em class=\"highlight\">\u667a\u80fd\u4f53</em>\u8fdb\u5316\u53f2", "comment": "Source: WeChat, Published: 2025-11-24 05:00:50", "summary": "\u5728\u5f00\u59cb\u8fd9\u6bb5\u6280\u672f\u6f14\u8fdb\u4e4b\u65c5\u524d\uff0c\u6211\u4eec\u6709\u5fc5\u8981\u5148\u7406\u89e3\u4e00\u4e2a\u5173\u952e\u6982\u5ff5\u2014\u2014Agent\uff08\u667a\u80fd\u4f53\uff09\u3002Agent \u8fd9\u4e2a\u6982\u5ff5\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7531\u6765\u5df2\u4e45\uff0c\u6700\u65e9\u5728 20 \u4e16\u7eaa 60 \u5e74\u4ee3\uff0c\u201c\u4eba\u5de5\u667a\u80fd\u4e4b\u7236\u201d\u9a6c\u6587\u00b7\u660e\u65af\u57fa\u5728\u4ed6\u7684\u7814\u7a76\u4e2d\u9996\u6b21\u660e\u786e\u4f7f\u7528\u4e86\u201cAgent\u201d\u4e00\u8bcd\uff0c\u5c06", "AI": {"tldr": "\u5728\u5f00\u59cb\u8fd9\u6bb5\u6280\u672f\u6f14\u8fdb\u4e4b\u65c5\u524d\uff0c\u6211\u4eec\u6709\u5fc5\u8981\u5148\u7406\u89e3\u4e00\u4e2a\u5173\u952e\u6982\u5ff5\u2014\u2014Agent\uff08\u667a\u80fd\u4f53\uff09\u3002Agent \u8fd9\u4e2a\u6982\u5ff5\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7531\u6765\u5df2\u4e45\uff0c\u6700\u65e9\u5728 20 \u4e16\u7eaa 60 \u5e74\u4ee3\uff0c\u201c\u4eba\u5de5\u667a\u80fd\u4e4b\u7236\u201d\u9a6c\u6587\u00b7\u660e\u65af\u57fa\u5728\u4ed6\u7684\u7814\u7a76\u4e2d\u9996\u6b21\u660e\u786e\u4f7f\u7528\u4e86\u201cAgent\u201d\u4e00\u8bcd\uff0c\u5c06", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.42a6807b", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI2NzMyNjI2Nw==&mid=2247649745&idx=2&sn=72b7acd74a5adab123937409fd41166d&chksm=eb3849b554aa868040fda6dde496514d2ac3d9af3cfc2a7aff8ede16d0e63c87346a73ca0690#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI2NzMyNjI2Nw==&mid=2247649745&idx=2&sn=72b7acd74a5adab123937409fd41166d&chksm=eb3849b554aa868040fda6dde496514d2ac3d9af3cfc2a7aff8ede16d0e63c87346a73ca0690#rd", "authors": ["\u6280\u672f\u90bbCAE\u5b66\u4e60"], "title": "\u4ece \u201c\u7b97\u529b\u4f9b\u7ed9\u201d \u5230 \u201c\u667a\u80fd\u9a71\u52a8\u201d\uff1a<em class=\"highlight\">Agentic</em> HPC \u5f00\u542f\u521b\u65b0\u8303\u5f0f", "comment": "Source: WeChat, Published: 2025-11-24 04:02:51", "summary": "Agentic HPC \u5e73\u53f0Altair HPCWorks \u5e73\u53f0\u52a9\u529b\u4f01\u4e1a\u5feb\u901f\u6355\u6349\u6838\u5fc3\u4ef7\u503c\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u5316\u3001\u81ea\u4f18\u5316\u9ad8\u6027\u80fd\u8ba1\u7b97\u505a\u597d\u51c6\u5907\u3002\u8be5\u5e73\u53f0\u5145\u5206\u5229\u7528\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u529f\u80fd\uff08\u5305\u62ecAI\u9a71\u52a8\u7684\u5185\u5b58\u8d44\u6e90\u9884\u6d4b\uff09\uff0c\u7cbe\u7b80\u4f5c\u4e1a\u63d0\u4ea4\u6d41\u7a0b\uff0c\u4f18\u5316\u96c6\u7fa4\u3001\u4e91\u53ca\u6df7\u5408\u8ba1\u7b97\u73af\u5883\u7684", "AI": {"tldr": "Agentic HPC \u5e73\u53f0Altair HPCWorks \u5e73\u53f0\u52a9\u529b\u4f01\u4e1a\u5feb\u901f\u6355\u6349\u6838\u5fc3\u4ef7\u503c\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u5316\u3001\u81ea\u4f18\u5316\u9ad8\u6027\u80fd\u8ba1\u7b97\u505a\u597d\u51c6\u5907\u3002\u8be5\u5e73\u53f0\u5145\u5206\u5229\u7528\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u529f\u80fd\uff08\u5305\u62ecAI\u9a71\u52a8\u7684\u5185\u5b58\u8d44\u6e90\u9884\u6d4b\uff09\uff0c\u7cbe\u7b80\u4f5c\u4e1a\u63d0\u4ea4\u6d41\u7a0b\uff0c\u4f18\u5316\u96c6\u7fa4\u3001\u4e91\u53ca\u6df7\u5408\u8ba1\u7b97\u73af\u5883\u7684", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.313be86a", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA4ODMwMDcxMQ==&mid=2651233657&idx=1&sn=3632f8e55078eccd9b1bdbf81a45b582&chksm=8a4ac3eac32c1ba8f9ad3333703e6d87d24588a317aee80b178a568463ecfe14399a9ab22645#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA4ODMwMDcxMQ==&mid=2651233657&idx=1&sn=3632f8e55078eccd9b1bdbf81a45b582&chksm=8a4ac3eac32c1ba8f9ad3333703e6d87d24588a317aee80b178a568463ecfe14399a9ab22645#rd", "authors": ["\u4e9a\u9a6c\u900a\u4e91\u79d1\u6280"], "title": "\u544a\u522b\u7a7a\u8c08\uff1a\u7528<em class=\"highlight\">Agentic</em> AI\u521b\u9020\u771f\u5b9e\u5546\u4e1a\u4ef7\u503c", "comment": "Source: WeChat, Published: 2025-11-24 03:01:18", "summary": "\u6211\u4eec\u7684\u76ee\u6807\u662f\u6210\u4e3a\u6784\u5efa\u548c\u90e8\u7f72\u5168\u7403\u6700\u5b9e\u7528Agents\u7684\u6700\u4f73\u9009\u62e9\uff0c\u4e13\u6ce8\u4e8eAgentic AI\u80fd\u591f\u5e26\u6765\u6700\u5927\u5546\u4e1a\u4ef7\u503c\u7684\u6838\u5fc3\u9886\u57df\u3002\u8d28\u91cf\u4e0e\u901f\u5ea6\u5e76\u91cd\uff0cKiro\u52a0\u901f\u8f6f\u4ef6\u521b\u65b0\u5f00\u53d1\u56e2\u961f\u4e00\u76f4\u9762\u4e34\u7740\u4e24\u96be\uff1a\u65e2\u8981\u5feb\u901f\u4ea4\u4ed8\uff0c\u53c8\u4e0d\u80fd\u727a\u7272\u8d28\u91cf\u3002", "AI": {"tldr": "\u6211\u4eec\u7684\u76ee\u6807\u662f\u6210\u4e3a\u6784\u5efa\u548c\u90e8\u7f72\u5168\u7403\u6700\u5b9e\u7528Agents\u7684\u6700\u4f73\u9009\u62e9\uff0c\u4e13\u6ce8\u4e8eAgentic AI\u80fd\u591f\u5e26\u6765\u6700\u5927\u5546\u4e1a\u4ef7\u503c\u7684\u6838\u5fc3\u9886\u57df\u3002\u8d28\u91cf\u4e0e\u901f\u5ea6\u5e76\u91cd\uff0cKiro\u52a0\u901f\u8f6f\u4ef6\u521b\u65b0\u5f00\u53d1\u56e2\u961f\u4e00\u76f4\u9762\u4e34\u7740\u4e24\u96be\uff1a\u65e2\u8981\u5feb\u901f\u4ea4\u4ed8\uff0c\u53c8\u4e0d\u80fd\u727a\u7272\u8d28\u91cf\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.328d9856", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650450337&idx=1&sn=343e6252dbad0b392e4f950d1d35b13c&chksm=bfa84e55f87a29e849724409ab5ce043f850bb94af8da41f7771edde13ab15127d396650b594#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5ODkzMzMwMQ==&mid=2650450337&idx=1&sn=343e6252dbad0b392e4f950d1d35b13c&chksm=bfa84e55f87a29e849724409ab5ce043f850bb94af8da41f7771edde13ab15127d396650b594#rd", "authors": ["AINLP"], "title": "Google\u53d1\u5e03\uff01\u4e00\u6587\u4e86\u89e321\u79cd<em class=\"highlight\">Agentic</em>\u8bbe\u8ba1\u6a21\u5f0f", "comment": "Source: WeChat, Published: 2025-11-24 02:10:25", "summary": "\u626b\u7801\u56de\u590d\u201c\u667a\u80fd\u4f53\u8bbe\u8ba1\u201d\u514d\u8d39\u9886\u53d6\u539f\u8457&\u4e2d\u6587\u7248PDF\u5982\u679c\u4f60\u60f3\u5199\u5927\u6a21\u578b\u8bba\u6587\uff0c\u4f46\u5374\u6ca1\u6709\u5408\u9002\u7684idea\uff0c\u6211\u6536\u96c6\u6574\u7406\u4e86\u6765\u81eaQS\u524d50\u540d\u6821\u5927\u4f6c\u7684\u5927\u6a21\u578b\u7814\u7a76\u601d\u8def\uff01", "AI": {"tldr": "\u626b\u7801\u56de\u590d\u201c\u667a\u80fd\u4f53\u8bbe\u8ba1\u201d\u514d\u8d39\u9886\u53d6\u539f\u8457&\u4e2d\u6587\u7248PDF\u5982\u679c\u4f60\u60f3\u5199\u5927\u6a21\u578b\u8bba\u6587\uff0c\u4f46\u5374\u6ca1\u6709\u5408\u9002\u7684idea\uff0c\u6211\u6536\u96c6\u6574\u7406\u4e86\u6765\u81eaQS\u524d50\u540d\u6821\u5927\u4f6c\u7684\u5927\u6a21\u578b\u7814\u7a76\u601d\u8def\uff01", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.cd59c0e3", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3MjIwODMzNg==&mid=2457339432&idx=1&sn=89d0de43bc256d96dd60ea2b7ecd9398&chksm=896a3f1437edd2b04af0d8a1bf098da80105757b6d35f986bd36fdf620a374576bd1efbbecce#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3MjIwODMzNg==&mid=2457339432&idx=1&sn=89d0de43bc256d96dd60ea2b7ecd9398&chksm=896a3f1437edd2b04af0d8a1bf098da80105757b6d35f986bd36fdf620a374576bd1efbbecce#rd", "authors": ["\u6c42\u6570\u79d1\u6280"], "title": "IDC : AI \u539f\u751f\u4e91/\u65b0\u578b\u4e91\u5382\u5546\u91cd\u6784 <em class=\"highlight\">Agentic</em> \u57fa\u7840\u8bbe\u65bd", "comment": "Source: WeChat, Published: 2025-11-24 01:28:15", "summary": "\u5728 Agentic \u65f6\u4ee3\uff0c\u66fe\u7ecf\u76f8\u5bf9\u7ebf\u6027\u7684\u6280\u672f\u6808\u5df2\u7ecf\u6f14\u53d8\u4e3a\u52a8\u6001\u3001\u4e92\u8054\u7684\u751f \u6001\u7cfb\u7edf\u3002\u8fd9\u79cd\u53d8\u5316\u4e0d\u4ec5\u6269\u5c55\u4e86\u8001\u724c\u4f01\u4e1a\u7684\u89d2\u8272\uff0c\u4e5f\u523a\u6fc0\u5f88\u591a\u4f01\u4e1a\u8de8\u754c\u8fdb\u5165\u5230 AI \u57fa\u7840\u8bbe\u65bd \u5e02\u573a\u3002", "AI": {"tldr": "\u5728 Agentic \u65f6\u4ee3\uff0c\u66fe\u7ecf\u76f8\u5bf9\u7ebf\u6027\u7684\u6280\u672f\u6808\u5df2\u7ecf\u6f14\u53d8\u4e3a\u52a8\u6001\u3001\u4e92\u8054\u7684\u751f \u6001\u7cfb\u7edf\u3002\u8fd9\u79cd\u53d8\u5316\u4e0d\u4ec5\u6269\u5c55\u4e86\u8001\u724c\u4f01\u4e1a\u7684\u89d2\u8272\uff0c\u4e5f\u523a\u6fc0\u5f88\u591a\u4f01\u4e1a\u8de8\u754c\u8fdb\u5165\u5230 AI \u57fa\u7840\u8bbe\u65bd \u5e02\u573a\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.f670184a", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0MzY5ODcxOQ==&mid=2247486831&idx=1&sn=f442ba9b7160bda25fd9d9368e722c3b&chksm=c2dc1716d2fbfc53a8480f76bbc89ec09a792cb9b7b73b78b65654db3779def0aefd68b30ff8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0MzY5ODcxOQ==&mid=2247486831&idx=1&sn=f442ba9b7160bda25fd9d9368e722c3b&chksm=c2dc1716d2fbfc53a8480f76bbc89ec09a792cb9b7b73b78b65654db3779def0aefd68b30ff8#rd", "authors": ["AI Encyclopedia"], "title": "\u5f53 AI \u4f1a\u201c\u505a\u4e8b\u201d\u65f6\uff1a\u4ece\u4e09\u5f20\u56fe\u770b <em class=\"highlight\">Agentic</em> \u65f6\u4ee3\u7684\u673a\u4f1a\u4e0e\u8b66\u89c9\uff0c\u666e\u901a\u4eba\u4e5f\u8981\u77e5\u9053\u7684\u5e95\u5c42\u903b\u8f91", "comment": "Source: WeChat, Published: 2025-11-24 01:28:10", "summary": "1\uff09\u767d\u677f\u56fe\uff1a\u5e7d\u9ed8\u5316\u5206\u5c42\u2014\u2014\u4ece\u201c\u6df1\u5b66\u5f97\u66f4\u6df1\u201d\u5230\u201c\u751f\u6210\u5f0f\u201d\u518d\u5230\u201cAgentic Maybe-AI\u201d\uff0c\u5e26\u6709SUSOXI\uff0cAI\u54c1\u724c\uff0c\u63d0\u9192\u6211\u4eec\u522b\u88ab\u6982\u5ff5\u70ed\u6f6e\u8499\u853d\u30022\uff09\u540c\u5fc3\u5708\u4fe1\u606f\u56fe\uff1a\u8be6\u5c3d\u5c55\u793a\u4ece\u4eba\u5de5\u667a\u80fd\u6838\u5fc3\u6982\u5ff5\u3001\u673a\u5668\u5b66\u4e60\u3001\u795e\u7ecf\u7f51\u7edc\u3001\u6df1\u5ea6\u5b66\u4e60\u3001\u751f\u6210\u5f0f\u5230", "AI": {"tldr": "1\uff09\u767d\u677f\u56fe\uff1a\u5e7d\u9ed8\u5316\u5206\u5c42\u2014\u2014\u4ece\u201c\u6df1\u5b66\u5f97\u66f4\u6df1\u201d\u5230\u201c\u751f\u6210\u5f0f\u201d\u518d\u5230\u201cAgentic Maybe-AI\u201d\uff0c\u5e26\u6709SUSOXI\uff0cAI\u54c1\u724c\uff0c\u63d0\u9192\u6211\u4eec\u522b\u88ab\u6982\u5ff5\u70ed\u6f6e\u8499\u853d\u30022\uff09\u540c\u5fc3\u5708\u4fe1\u606f\u56fe\uff1a\u8be6\u5c3d\u5c55\u793a\u4ece\u4eba\u5de5\u667a\u80fd\u6838\u5fc3\u6982\u5ff5\u3001\u673a\u5668\u5b66\u4e60\u3001\u795e\u7ecf\u7f51\u7edc\u3001\u6df1\u5ea6\u5b66\u4e60\u3001\u751f\u6210\u5f0f\u5230", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.8eacfd22", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIwNTQzMTk5Mw==&mid=2247485077&idx=1&sn=0cf4596caae3960e0d8c5f80de9cec89&chksm=96d4113e06b816572b965a7a0c1dc3e47e8ddc31b358e2a566b1b94811df2821121972f7596a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIwNTQzMTk5Mw==&mid=2247485077&idx=1&sn=0cf4596caae3960e0d8c5f80de9cec89&chksm=96d4113e06b816572b965a7a0c1dc3e47e8ddc31b358e2a566b1b94811df2821121972f7596a#rd", "authors": ["CodeAI\u7814\u4e60\u793e"], "title": "<em class=\"highlight\">Agentic</em> AI \u516d\u5927\u8bbe\u8ba1\u6a21\u5f0f\u5168\u89e3\u6790", "comment": "Source: WeChat, Published: 2025-11-24 01:02:49", "summary": "Agentic AI \u516d\u5927\u8bbe\u8ba1\u6a21\u5f0f\u5168\u89e3\u6790Agentic AI \u8bbe\u8ba1\u6a21\u5f0f\u603b\u89c8\u9762\u5bf9\u8d8a\u6765\u8d8a\u590d\u6742\u7684\u4e1a\u52a1\u73af\u5883\uff0c\u5355\u4e00 Agent \u5f88\u96be\u4fdd\u6301\u7a33\u5b9a\u8f93\u51fa\u3002Agentic AI \u5df2\u7ecf\u5f62\u6210\u516d\u79cd\u9ad8\u9891\u8303\u5f0f\uff0c\u5206\u522b\u8986\u76d6\u63a8\u7406-\u884c\u52a8\u95ed\u73af\u3001\u4ee3\u7801\u6267\u884c\u3001\u5de5\u5177\u8c03\u7528\u3001\u81ea\u6211\u53cd\u601d\u3001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4ee5\u53ca\u68c0\u7d22", "AI": {"tldr": "Agentic AI \u516d\u5927\u8bbe\u8ba1\u6a21\u5f0f\u5168\u89e3\u6790Agentic AI \u8bbe\u8ba1\u6a21\u5f0f\u603b\u89c8\u9762\u5bf9\u8d8a\u6765\u8d8a\u590d\u6742\u7684\u4e1a\u52a1\u73af\u5883\uff0c\u5355\u4e00 Agent \u5f88\u96be\u4fdd\u6301\u7a33\u5b9a\u8f93\u51fa\u3002Agentic AI \u5df2\u7ecf\u5f62\u6210\u516d\u79cd\u9ad8\u9891\u8303\u5f0f\uff0c\u5206\u522b\u8986\u76d6\u63a8\u7406-\u884c\u52a8\u95ed\u73af\u3001\u4ee3\u7801\u6267\u884c\u3001\u5de5\u5177\u8c03\u7528\u3001\u81ea\u6211\u53cd\u601d\u3001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4ee5\u53ca\u68c0\u7d22", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2511.bd1caf17", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI3NDI4MzIyNQ==&mid=2247514250&idx=1&sn=a3422806b39e2f24f3c90074da8e0e81&chksm=eab3955c40a8098df14f7577b2b5bf34d7387bc1be72e24b5a07630a7121b68ba88cc577b705#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI3NDI4MzIyNQ==&mid=2247514250&idx=1&sn=a3422806b39e2f24f3c90074da8e0e81&chksm=eab3955c40a8098df14f7577b2b5bf34d7387bc1be72e24b5a07630a7121b68ba88cc577b705#rd", "authors": ["\u4ea7\u4e1a\u667a\u80fd\u5b98"], "title": "\u3010\u79d1\u5b66\u667a\u80fd\u3011<em class=\"highlight\">Agentic</em> AI\u00a0\u5728\u79d1\u5b66\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\uff1a\u8fdb\u5c55\u3001\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411", "comment": "Source: WeChat, Published: 2025-11-24 01:01:20", "summary": "\u662f\u4e00\u4e2a\u7531 gpt-4 \u9a71\u52a8\u7684\u81ea\u4e3b ai \u667a\u80fd\u4f53\uff0c\u80fd\u591f\u89c4\u5212\u3001\u8bbe\u8ba1\u548c\u6267\u884c\u5316\u5b66\u5b9e\u9a8c\u3002\u8be5\u7cfb\u7edf\u96c6\u6210\u4e86\u7f51\u7edc\u641c\u7d22\u3001\u6587\u6863\u5206\u6790\u3001\u4ee3\u7801\u6267\u884c\u548c\u673a\u5668\u4eba\u81ea\u52a8\u5316\u7b49\u6a21\u5757\uff0c\u80fd\u591f\u5904\u7406\u591a\u6b65\u9aa4\u95ee\u9898\u89e3\u51b3\u548c\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u3002", "AI": {"tldr": "\u662f\u4e00\u4e2a\u7531 gpt-4 \u9a71\u52a8\u7684\u81ea\u4e3b ai \u667a\u80fd\u4f53\uff0c\u80fd\u591f\u89c4\u5212\u3001\u8bbe\u8ba1\u548c\u6267\u884c\u5316\u5b66\u5b9e\u9a8c\u3002\u8be5\u7cfb\u7edf\u96c6\u6210\u4e86\u7f51\u7edc\u641c\u7d22\u3001\u6587\u6863\u5206\u6790\u3001\u4ee3\u7801\u6267\u884c\u548c\u673a\u5668\u4eba\u81ea\u52a8\u5316\u7b49\u6a21\u5757\uff0c\u80fd\u591f\u5904\u7406\u591a\u6b65\u9aa4\u95ee\u9898\u89e3\u51b3\u548c\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2511.9533a5dd", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI5MjQzOTY3OA==&mid=2247489012&idx=1&sn=b963965d35b037d863dbbcc6157b812e&chksm=ed8d9bf54ee3ad7019e712e996e61ea5171256033137f5e799a3733d985fc92127c0032efd5d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI5MjQzOTY3OA==&mid=2247489012&idx=1&sn=b963965d35b037d863dbbcc6157b812e&chksm=ed8d9bf54ee3ad7019e712e996e61ea5171256033137f5e799a3733d985fc92127c0032efd5d#rd", "authors": ["\u7cbe\u795e\u6296\u64de\u738b\u5927\u9e4f"], "title": "\u5434\u6069\u8fbe <em class=\"highlight\">Agentic</em> AI\uff08\u56db\uff09\u6784\u5efa<em class=\"highlight\">\u667a\u80fd\u4f53</em>AI\u7684\u5b9e\u7528\u6280\u5de7", "comment": "Source: WeChat, Published: 2025-11-23 17:36:44", "summary": "\u4f46\u5728 AI \u7cfb\u7edf\u7279\u522b\u662f Agentic \u5de5\u4f5c\u6d41\u7684\u5f00\u53d1\u4e2d\uff0c\u5f88\u96be\u9884\u5148\u77e5\u9053\u54ea\u4e9b\u5730\u65b9\u4f1a\u6709\u6548\uff0c\u54ea\u4e9b\u5730\u65b9\u6548\u679c\u4e0d\u597d\u3002\u8fd9\u5e26\u6765\u4e86\u4e00\u4e2a\u6839\u672c\u6027\u7684\u8f6c\u53d8\uff1a\u4ece\u9884\u5148\u89c4\u5212\u5230\u5feb\u901f\u8fed\u4ee3\u3002", "AI": {"tldr": "\u4f46\u5728 AI \u7cfb\u7edf\u7279\u522b\u662f Agentic \u5de5\u4f5c\u6d41\u7684\u5f00\u53d1\u4e2d\uff0c\u5f88\u96be\u9884\u5148\u77e5\u9053\u54ea\u4e9b\u5730\u65b9\u4f1a\u6709\u6548\uff0c\u54ea\u4e9b\u5730\u65b9\u6548\u679c\u4e0d\u597d\u3002\u8fd9\u5e26\u6765\u4e86\u4e00\u4e2a\u6839\u672c\u6027\u7684\u8f6c\u53d8\uff1a\u4ece\u9884\u5148\u89c4\u5212\u5230\u5feb\u901f\u8fed\u4ee3\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.687337d1", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkyMDc3OTEwMg==&mid=2247484483&idx=1&sn=1da8dbde145678a05d6b7af5e2dc558a&chksm=c0604bcf5cbb1b4aee3abe2d82d9ae697556cba0dab710f452fdb79c96bbe49d27e34c8baf17#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkyMDc3OTEwMg==&mid=2247484483&idx=1&sn=1da8dbde145678a05d6b7af5e2dc558a&chksm=c0604bcf5cbb1b4aee3abe2d82d9ae697556cba0dab710f452fdb79c96bbe49d27e34c8baf17#rd", "authors": ["\u8bfb\u7814\u65b0\u89e3"], "title": "\u544a\u522b\u7b80\u5355\u7684\u804a\u5929\u673a\u5668\u4eba\uff0c<em class=\"highlight\">Agentic</em> AI\uff08<em class=\"highlight\">\u4ee3\u7406</em>\u667a\u80fd\uff09\u5982\u4f55\u91cd\u5851\u7f8e\u56fd\u4fdd\u9669\u4e1a\uff1f", "comment": "Source: WeChat, Published: 2025-11-23 16:02:12", "summary": "\u672f\u8bed\u89e3\u91ca\uff1aAgentic AI\uff08\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\uff09\u4f20\u7edf\u7684ChatGPT\u662f\u4f60\u95ee\u5b83\u7b54\u3002\u800cAgentic AI\u5177\u5907\u201c\u884c\u52a8\u529b\u201d\u3002\u5b83\u53ef\u4ee5\u81ea\u4e3b\u89c4\u5212\u5e76\u6267\u884c\u591a\u6b65\u4efb\u52a1\u3002\u4f8b\u5982\uff1a\u5b83\u4e0d\u4ec5\u544a\u8bc9\u4f60\u5ba2\u6237\u9700\u8981\u4f53\u68c0\uff0c\u8fd8\u4f1a\u81ea\u52a8\u53bb\u9884\u7ea6\u4f53\u68c0\u4e2d\u5fc3\u3001\u8ffd\u8e2a\u4f53\u68c0\u62a5\u544a\u3001\u5206\u6790\u7ed3\u679c\uff0c\u6700\u540e\u7ed9\u51fa", "AI": {"tldr": "\u672f\u8bed\u89e3\u91ca\uff1aAgentic AI\uff08\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\uff09\u4f20\u7edf\u7684ChatGPT\u662f\u4f60\u95ee\u5b83\u7b54\u3002\u800cAgentic AI\u5177\u5907\u201c\u884c\u52a8\u529b\u201d\u3002\u5b83\u53ef\u4ee5\u81ea\u4e3b\u89c4\u5212\u5e76\u6267\u884c\u591a\u6b65\u4efb\u52a1\u3002\u4f8b\u5982\uff1a\u5b83\u4e0d\u4ec5\u544a\u8bc9\u4f60\u5ba2\u6237\u9700\u8981\u4f53\u68c0\uff0c\u8fd8\u4f1a\u81ea\u52a8\u53bb\u9884\u7ea6\u4f53\u68c0\u4e2d\u5fc3\u3001\u8ffd\u8e2a\u4f53\u68c0\u62a5\u544a\u3001\u5206\u6790\u7ed3\u679c\uff0c\u6700\u540e\u7ed9\u51fa", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
