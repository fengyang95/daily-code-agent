{"id": "2511.03773", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03773", "abs": "https://arxiv.org/abs/2511.03773", "authors": ["Zhaorun Chen", "Zhuokai Zhao", "Kai Zhang", "Bo Liu", "Qi Qi", "Yifan Wu", "Tarun Kalluri", "Sara Cao", "Yuanhao Xiong", "Haibo Tong", "Huaxiu Yao", "Hengduo Li", "Jiacheng Zhu", "Xian Li", "Dawn Song", "Bo Li", "Jason Weston", "Dat Huynh"], "title": "Scaling Agent Learning via Experience Synthesis", "comment": null, "summary": "While reinforcement learning (RL) can empower large language model (LLM)\nagents by enabling self-improvement through interaction, its practical adoption\nremains challenging due to costly rollouts, limited task diversity, unreliable\nreward signals, and infrastructure complexity, all of which obstruct the\ncollection of scalable experience data. To address these challenges, we\nintroduce DreamGym, the first unified framework designed to synthesize diverse\nexperiences with scalability in mind to enable effective online RL training for\nautonomous agents. Rather than relying on expensive real-environment rollouts,\nDreamGym distills environment dynamics into a reasoning-based experience model\nthat derives consistent state transitions and feedback signals through\nstep-by-step reasoning, enabling scalable agent rollout collection for RL. To\nimprove the stability and quality of transitions, DreamGym leverages an\nexperience replay buffer initialized with offline real-world data and\ncontinuously enriched with fresh interactions to actively support agent\ntraining. To improve knowledge acquisition, DreamGym adaptively generates new\ntasks that challenge the current agent policy, enabling more effective online\ncurriculum learning. Experiments across diverse environments and agent\nbackbones demonstrate that DreamGym substantially improves RL training, both in\nfully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready\ntasks like WebArena, DreamGym outperforms all baselines by over 30%. And in\nRL-ready but costly settings, it matches GRPO and PPO performance using only\nsynthetic interactions. When transferring a policy trained purely on synthetic\nexperiences to real-environment RL, DreamGym yields significant additional\nperformance gains while requiring far fewer real-world interactions, providing\na scalable warm-start strategy for general-purpose RL.", "AI": {"tldr": "DreamGym\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u591a\u6837\u5316\u7ecf\u9a8c\u6570\u636e\u6765\u89e3\u51b3RL\u8bad\u7ec3\u4e2d\u7684\u6311\u6218\uff0c\u907f\u514d\u6602\u8d35\u7684\u771f\u5b9e\u73af\u5883\u4ea4\u4e92\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684\u81ea\u4e3b\u4ee3\u7406\u8bad\u7ec3\u3002", "motivation": "\u89e3\u51b3RL\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u6311\u6218\uff1a\u6602\u8d35\u7684\u73af\u5883\u4ea4\u4e92\u3001\u4efb\u52a1\u591a\u6837\u6027\u6709\u9650\u3001\u5956\u52b1\u4fe1\u53f7\u4e0d\u53ef\u9760\u548c\u57fa\u7840\u8bbe\u65bd\u590d\u6742\u6027\uff0c\u8fd9\u4e9b\u56e0\u7d20\u963b\u788d\u4e86\u53ef\u6269\u5c55\u7ecf\u9a8c\u6570\u636e\u7684\u6536\u96c6\u3002", "method": "1) \u5c06\u73af\u5883\u52a8\u6001\u63d0\u70bc\u4e3a\u57fa\u4e8e\u63a8\u7406\u7684\u7ecf\u9a8c\u6a21\u578b\uff0c\u901a\u8fc7\u9010\u6b65\u63a8\u7406\u83b7\u5f97\u4e00\u81f4\u7684\u72b6\u6001\u8f6c\u6362\u548c\u53cd\u9988\u4fe1\u53f7\uff1b2) \u4f7f\u7528\u79bb\u7ebf\u771f\u5b9e\u4e16\u754c\u6570\u636e\u521d\u59cb\u5316\u7ecf\u9a8c\u56de\u653e\u7f13\u51b2\u533a\uff0c\u5e76\u6301\u7eed\u4e30\u5bcc\u65b0\u4ea4\u4e92\uff1b3) \u81ea\u9002\u5e94\u751f\u6210\u6311\u6218\u5f53\u524d\u4ee3\u7406\u7b56\u7565\u7684\u65b0\u4efb\u52a1\uff0c\u5b9e\u73b0\u6709\u6548\u7684\u5728\u7ebf\u8bfe\u7a0b\u5b66\u4e60\u3002", "result": "\u5728\u591a\u6837\u73af\u5883\u548c\u4ee3\u7406\u9aa8\u5e72\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1a\u5728\u975eRL\u5c31\u7eea\u4efb\u52a1\u5982WebArena\u4e0a\uff0cDreamGym\u6bd4\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\u6027\u80fd\u63d0\u5347\u8d85\u8fc730%\uff1b\u5728RL\u5c31\u7eea\u4f46\u6210\u672c\u9ad8\u7684\u8bbe\u7f6e\u4e2d\uff0c\u4ec5\u4f7f\u7528\u5408\u6210\u4ea4\u4e92\u5c31\u80fd\u5339\u914dGRPO\u548cPPO\u6027\u80fd\uff1b\u5728\u5c06\u7eaf\u5408\u6210\u7ecf\u9a8c\u8bad\u7ec3\u7684\u7b56\u7565\u8fc1\u79fb\u5230\u771f\u5b9e\u73af\u5883RL\u65f6\uff0cDreamGym\u5728\u9700\u8981\u66f4\u5c11\u771f\u5b9e\u4e16\u754c\u4ea4\u4e92\u7684\u540c\u65f6\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "DreamGym\u4e3a\u901a\u7528RL\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u9884\u70ed\u542f\u52a8\u7b56\u7565\uff0c\u901a\u8fc7\u5408\u6210\u7ecf\u9a8c\u6709\u6548\u89e3\u51b3\u4e86RL\u8bad\u7ec3\u4e2d\u7684\u6570\u636e\u6536\u96c6\u74f6\u9888\u95ee\u9898\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.03738", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03738", "abs": "https://arxiv.org/abs/2511.03738", "authors": ["Pranav Bhandari", "Nicolas Fay", "Sanjeevan Selvaganapathy", "Amitava Datta", "Usman Naseem", "Mehwish Nasim"], "title": "Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs", "comment": null, "summary": "Large Language Models exhibit implicit personalities in their generation, but\nreliably controlling or aligning these traits to meet specific needs remains an\nopen challenge. The need for effective mechanisms for behavioural manipulation\nof the model during generation is a critical gap in the literature that needs\nto be fulfilled. Personality-aware LLMs hold a promising direction towards this\nobjective. However, the relationship between these psychological constructs and\ntheir representations within LLMs remains underexplored and requires further\ninvestigation. Moreover, it is intriguing to understand and study the use of\nthese representations to steer the models' behaviour. We propose a novel\npipeline that extracts hidden state activations from transformer layers using\nthe Big Five Personality Traits (Openness, Conscientiousness, Extraversion,\nAgreeableness and Neuroticism), which is a comprehensive and empirically\nvalidated framework to model human personality applies low-rank subspace\ndiscovery methods, and identifies trait-specific optimal layers across\ndifferent model architectures for robust injection. The resulting\npersonality-aligned directions are then operationalised through a flexible\nsteering framework with dynamic layer selection, enabling precise control of\ntrait expression in LLM outputs. Our findings reveal that personality traits\noccupy a low-rank shared subspace, and that these latent structures can be\ntransformed into actionable mechanisms for effective steering through careful\nperturbations without impacting the fluency, variance and general capabilities,\nhelping to bridge the gap between psychological theory and practical model\nalignment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u4e94\u4eba\u683c\u7279\u8d28\u63d0\u53d6LLM\u9690\u85cf\u72b6\u6001\u6fc0\u6d3b\uff0c\u901a\u8fc7\u4f4e\u79e9\u5b50\u7a7a\u95f4\u53d1\u73b0\u65b9\u6cd5\u8bc6\u522b\u7279\u8d28\u7279\u5b9a\u5c42\uff0c\u5b9e\u73b0\u4eba\u683c\u5bf9\u9f50\u7684\u7cbe\u786e\u63a7\u5236\u6846\u67b6\u3002", "motivation": "LLM\u5728\u751f\u6210\u4e2d\u8868\u73b0\u51fa\u9690\u542b\u4eba\u683c\u7279\u8d28\uff0c\u4f46\u53ef\u9760\u63a7\u5236\u6216\u5bf9\u9f50\u8fd9\u4e9b\u7279\u8d28\u4ee5\u6ee1\u8db3\u7279\u5b9a\u9700\u6c42\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7684\u884c\u4e3a\u64cd\u7eb5\u673a\u5236\u3002", "method": "\u4ecetransformer\u5c42\u63d0\u53d6\u9690\u85cf\u72b6\u6001\u6fc0\u6d3b\uff0c\u5e94\u7528\u4f4e\u79e9\u5b50\u7a7a\u95f4\u53d1\u73b0\u65b9\u6cd5\u8bc6\u522b\u7279\u8d28\u7279\u5b9a\u6700\u4f18\u5c42\uff0c\u901a\u8fc7\u52a8\u6001\u5c42\u9009\u62e9\u548c\u6270\u52a8\u5b9e\u73b0\u4eba\u683c\u5bf9\u9f50\u63a7\u5236\u3002", "result": "\u53d1\u73b0\u4eba\u683c\u7279\u8d28\u5360\u636e\u4f4e\u79e9\u5171\u4eab\u5b50\u7a7a\u95f4\uff0c\u8fd9\u4e9b\u6f5c\u5728\u7ed3\u6784\u53ef\u901a\u8fc7\u7cbe\u5fc3\u6270\u52a8\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u64cd\u7eb5\u673a\u5236\uff0c\u4e0d\u5f71\u54cd\u6d41\u7545\u6027\u3001\u65b9\u5dee\u548c\u4e00\u822c\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u52a9\u4e8e\u5f25\u5408\u5fc3\u7406\u5b66\u7406\u8bba\u4e0e\u5b9e\u9645\u6a21\u578b\u5bf9\u9f50\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u4eba\u683c\u611f\u77e5LLM\u63d0\u4f9b\u53ef\u884c\u7684\u5b9e\u73b0\u8def\u5f84\u3002", "topic": "agent analysis"}}
{"id": "2511.03739", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.03739", "abs": "https://arxiv.org/abs/2511.03739", "authors": ["Eugenius Mario Situmorang", "Adila Alfa Krisnadhi", "Ari Wibisono"], "title": "TextualVerifier: Verify TextGrad Step-by-Step", "comment": null, "summary": "TextGrad is a novel approach to text-based automatic differentiation that\nenables composite AI systems to perform optimization without explicit numerical\nequations. However, it currently lacks self-verification mechanisms that ensure\nreasoning validity in text-based decision making. This research introduces\nTextualVerifier, a verification framework that leverages chain-of-thought\nreasoning and majority voting with large language models to address this\nverification gap. TextualVerifier implements a four-stage workflow:\nchain-of-thought decomposition, variant generation, majority voting, and\nconsensus aggregation. It integrates non-invasively with TextGrad at both the\nloss function and optimization result verification stages. Experimental\nevaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)\nstandalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad\non GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically\nsignificant improvements (p < 0.001). In phase one, TextualVerifier improves\nthe validity of reasoning steps by 29 percent. In phase two, integration into\nTextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4\npercent with a moderate overhead of 5.9 LLM calls on average. Further\nevaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92\npercentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.\nTextualVerifier thus presents the first self-verification framework for\nTextGrad through LLM-based techniques without requiring numerical gradients,\nenabling more reliable reasoning and opening new directions for verification in\ntext-based optimization.", "AI": {"tldr": "TextualVerifier\u662f\u4e00\u4e2a\u7528\u4e8eTextGrad\u7684\u81ea\u6211\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u5206\u89e3\u3001\u53d8\u4f53\u751f\u6210\u3001\u591a\u6570\u6295\u7968\u548c\u5171\u8bc6\u805a\u5408\u56db\u9636\u6bb5\u5de5\u4f5c\u6d41\uff0c\u89e3\u51b3\u6587\u672c\u4f18\u5316\u4e2d\u63a8\u7406\u6709\u6548\u6027\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u63a8\u7406\u6709\u6548\u6027\u3002", "motivation": "TextGrad\u7f3a\u4e4f\u786e\u4fdd\u6587\u672c\u51b3\u7b56\u4e2d\u63a8\u7406\u6709\u6548\u6027\u7684\u81ea\u6211\u9a8c\u8bc1\u673a\u5236\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u590d\u5408AI\u7cfb\u7edf\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5\u5de5\u4f5c\u6d41\uff1a\u601d\u7ef4\u94fe\u5206\u89e3\u3001\u53d8\u4f53\u751f\u6210\u3001\u591a\u6570\u6295\u7968\u548c\u5171\u8bc6\u805a\u5408\uff0c\u5e76\u4e0eTextGrad\u5728\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u7ed3\u679c\u9a8c\u8bc1\u9636\u6bb5\u975e\u4fb5\u5165\u5f0f\u96c6\u6210\u3002", "result": "\u5728PRM800K\u4e0a\u63a8\u7406\u6b65\u9aa4\u6709\u6548\u6027\u63d0\u534729%\uff1b\u4e0eTextGrad\u96c6\u6210\u540e\u5728GPQA-Diamond\u3001MMLU-ML\u548cMMLU-CP\u57fa\u51c6\u4e0a\u5206\u522b\u83b7\u5f978.08\u300110.71\u548c3.92\u4e2a\u767e\u5206\u70b9\u7684\u6539\u8fdb\uff0c\u635f\u5931\u51fd\u6570\u9a8c\u8bc1\u5e26\u67652.2\u4e2a\u767e\u5206\u70b9\u589e\u76ca\u3002", "conclusion": "TextualVerifier\u662f\u9996\u4e2a\u57fa\u4e8eLLM\u6280\u672f\u7684TextGrad\u81ea\u6211\u9a8c\u8bc1\u6846\u67b6\uff0c\u65e0\u9700\u6570\u503c\u68af\u5ea6\u5373\u53ef\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u63a8\u7406\uff0c\u4e3a\u6587\u672c\u4f18\u5316\u9a8c\u8bc1\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "topic": "agent analysis"}}
{"id": "2511.03934", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03934", "abs": "https://arxiv.org/abs/2511.03934", "authors": ["Athma Narayanan", "Mahesh Subedar", "Omesh Tickoo"], "title": "PEFA-AI: Advancing Open-source LLMs for RTL generation using Progressive Error Feedback Agentic-AI", "comment": "Appeared in the Design Automation Conference (DAC) 2025, Workshop\n  Poster on June 22, 2025", "summary": "We present an agentic flow consisting of multiple agents that combine\nspecialized LLMs and hardware simulation tools to collaboratively complete the\ncomplex task of Register Transfer Level (RTL) generation without human\nintervention. A key feature of the proposed flow is the progressive error\nfeedback system of agents (PEFA), a self-correcting mechanism that leverages\niterative error feedback to progressively increase the complexity of the\napproach. The generated RTL includes checks for compilation, functional\ncorrectness, and synthesizable constructs. To validate this adaptive approach\nto code generation, benchmarking is performed using two opensource natural\nlanguage-to-RTL datasets. We demonstrate the benefits of the proposed approach\nimplemented on an open source agentic framework, using both open- and\nclosed-source LLMs, effectively bridging the performance gap between them.\nCompared to previously published methods, our approach sets a new benchmark,\nproviding state-of-the-art pass rates while being efficient in token counts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e13\u7528LLM\u548c\u786c\u4ef6\u4eff\u771f\u5de5\u5177\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u5b8c\u6210\u5bc4\u5b58\u5668\u4f20\u8f93\u7ea7(RTL)\u751f\u6210\u4efb\u52a1\u3002\u6838\u5fc3\u662f\u6e10\u8fdb\u5f0f\u9519\u8bef\u53cd\u9988\u7cfb\u7edf(PEFA)\uff0c\u901a\u8fc7\u8fed\u4ee3\u9519\u8bef\u53cd\u9988\u9010\u6b65\u589e\u52a0\u65b9\u6cd5\u590d\u6742\u5ea6\u3002", "motivation": "\u89e3\u51b3\u590d\u6742RTL\u4ee3\u7801\u751f\u6210\u7684\u81ea\u52a8\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u548c\u81ea\u6211\u7ea0\u6b63\u673a\u5236\u63d0\u9ad8\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u6b63\u786e\u6027\u3002", "method": "\u4f7f\u7528\u591a\u4ee3\u7406\u6d41\u7a0b\uff0c\u7ed3\u5408\u4e13\u7528LLM\u548c\u786c\u4ef6\u4eff\u771f\u5de5\u5177\uff0c\u91c7\u7528\u6e10\u8fdb\u5f0f\u9519\u8bef\u53cd\u9988\u7cfb\u7edf(PEFA)\u8fdb\u884c\u81ea\u6211\u7ea0\u6b63\uff0c\u751f\u6210\u5305\u542b\u7f16\u8bd1\u68c0\u67e5\u3001\u529f\u80fd\u6b63\u786e\u6027\u548c\u53ef\u7efc\u5408\u6784\u9020\u7684RTL\u4ee3\u7801\u3002", "result": "\u5728\u4e24\u4e2a\u5f00\u6e90\u81ea\u7136\u8bed\u8a00\u5230RTL\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u4f7f\u7528\u5f00\u6e90\u548c\u95ed\u6e90LLM\u5747\u8868\u73b0\u51fa\u8272\uff0c\u7f29\u5c0f\u4e86\u5b83\u4eec\u4e4b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u5728\u901a\u8fc7\u7387\u548ctoken\u6548\u7387\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3aRTL\u4ee3\u7801\u751f\u6210\u8bbe\u7acb\u4e86\u65b0\u7684\u57fa\u51c6\uff0c\u5728\u4fdd\u6301token\u6548\u7387\u7684\u540c\u65f6\u63d0\u4f9b\u4e86\u6700\u5148\u8fdb\u7684\u901a\u8fc7\u7387\uff0c\u8bc1\u660e\u4e86\u81ea\u9002\u5e94\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "topic": "code agent"}}
{"id": "2511.04012", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04012", "abs": "https://arxiv.org/abs/2511.04012", "authors": ["Yongxi Chen", "Lei Chen"], "title": "PSD2Code: Automated Front-End Code Generation from Design Files via Multimodal Large Language Models", "comment": null, "summary": "Design-to-code generation has emerged as a promising approach to bridge the\ngap between design prototypes and deployable frontend code. However, existing\nmethods often suffer from structural inconsistencies, asset misalignment, and\nlimited production readiness. This paper presents PSD2Code, a novel multi-modal\napproach that leverages PSD file parsing and asset alignment to generate\nproduction-ready React+SCSS code. Our method introduces a ParseAlignGenerate\npipeline that extracts hierarchical structures, layer properties, and metadata\nfrom PSD files, providing large language models with precise spatial\nrelationships and semantic groupings for frontend code generation. The system\nemploys a constraint-based alignment strategy that ensures consistency between\ngenerated elements and design resources, while a structured prompt construction\nenhances controllability and code quality. Comprehensive evaluation\ndemonstrates significant improvements over existing methods across multiple\nmetrics including code similarity, visual fidelity, and production readiness.\nThe method exhibits strong model independence across different large language\nmodels, validating the effectiveness of integrating structured design\ninformation with multimodal large language models for industrial-grade code\ngeneration, marking an important step toward design-driven automated frontend\ndevelopment.", "AI": {"tldr": "PSD2Code\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u8bbe\u8ba1\u5230\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7PSD\u6587\u4ef6\u89e3\u6790\u548c\u8d44\u6e90\u5bf9\u9f50\u751f\u6210\u751f\u4ea7\u5c31\u7eea\u7684React+SCSS\u4ee3\u7801\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u76f8\u4f3c\u6027\u3001\u89c6\u89c9\u4fdd\u771f\u5ea6\u548c\u751f\u4ea7\u5c31\u7eea\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u8bbe\u8ba1\u5230\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u7ed3\u6784\u4e0d\u4e00\u81f4\u3001\u8d44\u6e90\u9519\u4f4d\u548c\u751f\u4ea7\u5c31\u7eea\u5ea6\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u751f\u6210\u5de5\u4e1a\u7ea7\u524d\u7aef\u4ee3\u7801\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528ParseAlignGenerate\u6d41\u6c34\u7ebf\uff0c\u4ecePSD\u6587\u4ef6\u4e2d\u63d0\u53d6\u5c42\u6b21\u7ed3\u6784\u3001\u56fe\u5c42\u5c5e\u6027\u548c\u5143\u6570\u636e\uff0c\u4f7f\u7528\u57fa\u4e8e\u7ea6\u675f\u7684\u5bf9\u9f50\u7b56\u7565\u786e\u4fdd\u751f\u6210\u5143\u7d20\u4e0e\u8bbe\u8ba1\u8d44\u6e90\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u6784\u5efa\u589e\u5f3a\u53ef\u63a7\u6027\u548c\u4ee3\u7801\u8d28\u91cf\u3002", "result": "\u7efc\u5408\u8bc4\u4f30\u663e\u793a\u5728\u4ee3\u7801\u76f8\u4f3c\u6027\u3001\u89c6\u89c9\u4fdd\u771f\u5ea6\u548c\u751f\u4ea7\u5c31\u7eea\u5ea6\u7b49\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5728\u4e0d\u540c\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u5f3a\u6a21\u578b\u72ec\u7acb\u6027\u3002", "conclusion": "\u5c06\u7ed3\u6784\u5316\u8bbe\u8ba1\u4fe1\u606f\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5bf9\u4e8e\u5de5\u4e1a\u7ea7\u4ee3\u7801\u751f\u6210\u5177\u6709\u6709\u6548\u6027\uff0c\u6807\u5fd7\u7740\u8bbe\u8ba1\u9a71\u52a8\u81ea\u52a8\u5316\u524d\u7aef\u5f00\u53d1\u7684\u91cd\u8981\u8fdb\u5c55\u3002", "topic": "swe application"}}
{"id": "2511.03878", "categories": ["cs.AI", "cs.IR", "cs.LG", "cs.MA", "I.2.7; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.03878", "abs": "https://arxiv.org/abs/2511.03878", "authors": ["Suraj Prasai", "Mengnan Du", "Ying Zhang", "Fan Yang"], "title": "KnowThyself: An Agentic Assistant for LLM Interpretability", "comment": "5 pages, 1 figure, Accepted for publication at the Demonstration\n  Track of the 40th AAAI Conference on Artificial Intelligence (AAAI 26)", "summary": "We develop KnowThyself, an agentic assistant that advances large language\nmodel (LLM) interpretability. Existing tools provide useful insights but remain\nfragmented and code-intensive. KnowThyself consolidates these capabilities into\na chat-based interface, where users can upload models, pose natural language\nquestions, and obtain interactive visualizations with guided explanations. At\nits core, an orchestrator LLM first reformulates user queries, an agent router\nfurther directs them to specialized modules, and the outputs are finally\ncontextualized into coherent explanations. This design lowers technical\nbarriers and provides an extensible platform for LLM inspection. By embedding\nthe whole process into a conversational workflow, KnowThyself offers a robust\nfoundation for accessible LLM interpretability.", "AI": {"tldr": "KnowThyself\u662f\u4e00\u4e2a\u57fa\u4e8e\u804a\u5929\u7684\u667a\u80fd\u52a9\u624b\uff0c\u65e8\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u901a\u8fc7\u6574\u5408\u73b0\u6709\u5de5\u5177\u63d0\u4f9b\u7edf\u4e00\u754c\u9762\uff0c\u964d\u4f4e\u6280\u672f\u95e8\u69db\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5de5\u5177\u5206\u6563\u4e14\u4ee3\u7801\u5bc6\u96c6\uff0c\u7528\u6237\u4f7f\u7528\u4e0d\u4fbf\u3002KnowThyself\u65e8\u5728\u5c06\u8fd9\u4e9b\u80fd\u529b\u6574\u5408\u5230\u804a\u5929\u754c\u9762\u4e2d\uff0c\u8ba9\u7528\u6237\u80fd\u591f\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u5e76\u83b7\u5f97\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u89e3\u91ca\u3002", "method": "\u91c7\u7528\u7f16\u6392\u5668LLM\u91cd\u65b0\u8868\u8ff0\u7528\u6237\u67e5\u8be2\uff0c\u4ee3\u7406\u8def\u7531\u5668\u5c06\u67e5\u8be2\u5bfc\u5411\u4e13\u95e8\u6a21\u5757\uff0c\u6700\u540e\u5c06\u8f93\u51fa\u60c5\u5883\u5316\u4e3a\u8fde\u8d2f\u7684\u89e3\u91ca\u3002\u6574\u4e2a\u6d41\u7a0b\u5d4c\u5165\u5bf9\u8bdd\u5f0f\u5de5\u4f5c\u6d41\u4e2d\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u901a\u8fc7\u804a\u5929\u754c\u9762\u63d0\u4f9b\u6a21\u578b\u4e0a\u4f20\u3001\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u529f\u80fd\uff0c\u964d\u4f4e\u4e86LLM\u68c0\u67e5\u7684\u6280\u672f\u969c\u788d\u3002", "conclusion": "KnowThyself\u4e3a\u53ef\u8bbf\u95ee\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u901a\u8fc7\u5bf9\u8bdd\u5f0f\u5de5\u4f5c\u6d41\u6574\u5408\u4e86\u5206\u6563\u7684\u5de5\u5177\u80fd\u529b\u3002", "topic": "agent analysis"}}
{"id": "2511.04014", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.04014", "abs": "https://arxiv.org/abs/2511.04014", "authors": ["Hao Zhu", "Jia Li", "Cuiyun Gao", "Jiaru Qian", "Yihong Dong", "Huanyu Liu", "Lecheng Wang", "Ziliang Wang", "Xiaolong Hu", "Ge Li"], "title": "Specification-Guided Vulnerability Detection with Large Language Models", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable progress in code\nunderstanding tasks. However, they demonstrate limited performance in\nvulnerability detection and struggle to distinguish vulnerable code from\npatched code. We argue that LLMs lack understanding of security specifications\n-- the expectations about how code should behave to remain safe. When code\nbehavior differs from these expectations, it becomes a potential vulnerability.\nHowever, such knowledge is rarely explicit in training data, leaving models\nunable to reason about security flaws. We propose VulInstruct, a\nspecification-guided approach that systematically extracts security\nspecifications from historical vulnerabilities to detect new ones. VulInstruct\nconstructs a specification knowledge base from two perspectives: (i) General\nspecifications from high-quality patches across projects, capturing fundamental\nsafe behaviors; and (ii) Domain-specific specifications from repeated\nviolations in particular repositories relevant to the target code. VulInstruct\nretrieves relevant past cases and specifications, enabling LLMs to reason about\nexpected safe behaviors rather than relying on surface patterns. We evaluate\nVulInstruct under strict criteria requiring both correct predictions and valid\nreasoning. On PrimeVul, VulInstruct achieves 45.0% F1-score (32.7% improvement)\nand 37.7% recall (50.8% improvement) compared to baselines, while uniquely\ndetecting 24.3% of vulnerabilities -- 2.4x more than any baseline. In pair-wise\nevaluation, VulInstruct achieves 32.3% relative improvement. VulInstruct also\ndiscovered a previously unknown high-severity vulnerability (CVE-2025-56538) in\nproduction code, demonstrating practical value for real-world vulnerability\ndiscovery. All code and supplementary materials are available at\nhttps://github.com/zhuhaopku/VulInstruct-temp.", "AI": {"tldr": "VulInstruct\u662f\u4e00\u4e2a\u57fa\u4e8e\u5b89\u5168\u89c4\u8303\u7684\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u5386\u53f2\u6f0f\u6d1e\u4e2d\u63d0\u53d6\u5b89\u5168\u89c4\u8303\u77e5\u8bc6\uff0c\u5e2e\u52a9LLMs\u7406\u89e3\u4ee3\u7801\u7684\u5b89\u5168\u884c\u4e3a\u671f\u671b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLMs\u5728\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u4e3b\u8981\u56e0\u4e3a\u7f3a\u4e4f\u5bf9\u5b89\u5168\u89c4\u8303\u7684\u7406\u89e3\u2014\u2014\u5373\u4ee3\u7801\u5e94\u8be5\u5982\u4f55\u884c\u4e3a\u624d\u80fd\u4fdd\u6301\u5b89\u5168\u3002\u5f53\u4ee3\u7801\u884c\u4e3a\u4e0e\u8fd9\u4e9b\u671f\u671b\u4e0d\u7b26\u65f6\uff0c\u5c31\u5f62\u6210\u4e86\u6f5c\u5728\u6f0f\u6d1e\uff0c\u4f46\u8fd9\u7c7b\u77e5\u8bc6\u5728\u8bad\u7ec3\u6570\u636e\u4e2d\u5f88\u5c11\u663e\u5f0f\u5b58\u5728\u3002", "method": "VulInstruct\u4ece\u4e24\u4e2a\u89d2\u5ea6\u6784\u5efa\u89c4\u8303\u77e5\u8bc6\u5e93\uff1a(1)\u4ece\u8de8\u9879\u76ee\u7684\u9ad8\u8d28\u91cf\u8865\u4e01\u4e2d\u63d0\u53d6\u901a\u7528\u89c4\u8303\uff0c\u6355\u6349\u57fa\u672c\u5b89\u5168\u884c\u4e3a\uff1b(2)\u4ece\u7279\u5b9a\u4ed3\u5e93\u4e2d\u91cd\u590d\u7684\u8fdd\u89c4\u884c\u4e3a\u4e2d\u63d0\u53d6\u9886\u57df\u7279\u5b9a\u89c4\u8303\u3002\u901a\u8fc7\u68c0\u7d22\u76f8\u5173\u5386\u53f2\u6848\u4f8b\u548c\u89c4\u8303\uff0c\u4f7fLLMs\u80fd\u591f\u57fa\u4e8e\u671f\u671b\u7684\u5b89\u5168\u884c\u4e3a\u8fdb\u884c\u63a8\u7406\u3002", "result": "\u5728PrimeVul\u6570\u636e\u96c6\u4e0a\uff0cVulInstruct\u8fbe\u523045.0% F1\u5206\u6570\uff08\u63d0\u534732.7%\uff09\u548c37.7%\u53ec\u56de\u7387\uff08\u63d0\u534750.8%\uff09\uff0c\u72ec\u7279\u68c0\u6d4b\u523024.3%\u7684\u6f0f\u6d1e\u2014\u2014\u6bd4\u4efb\u4f55\u57fa\u7ebf\u65b9\u6cd5\u591a2.4\u500d\u3002\u5728\u6210\u5bf9\u8bc4\u4f30\u4e2d\u5b9e\u73b032.3%\u7684\u76f8\u5bf9\u63d0\u5347\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u4e2a\u4e4b\u524d\u672a\u77e5\u7684\u9ad8\u4e25\u91cd\u6027\u6f0f\u6d1e(CVE-2025-56538)\u3002", "conclusion": "VulInstruct\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u5229\u7528\u5b89\u5168\u89c4\u8303\u77e5\u8bc6\uff0c\u663e\u8457\u63d0\u5347\u4e86LLMs\u5728\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u9762\u7684\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u89c4\u8303\u5f15\u5bfc\u65b9\u6cd5\u5728\u5b9e\u9645\u6f0f\u6d1e\u53d1\u73b0\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "topic": "code agent"}}
{"id": "2511.04064", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04064", "abs": "https://arxiv.org/abs/2511.04064", "authors": ["Zhengran Zeng", "Yixin Li", "Rui Xie", "Wei Ye", "Shikun Zhang"], "title": "Benchmarking and Studying the LLM-based Agent System in End-to-End Software Development", "comment": null, "summary": "The development of LLM-based autonomous agents for end-to-end software\ndevelopment represents a significant paradigm shift in software engineering.\nHowever, the scientific evaluation of these systems is hampered by significant\nchallenges, including overly simplistic benchmarks and the difficulty of\nconducting fair comparisons between different agent architectures due to\nconfounding implementation variables. To address these limitations, we first\nconstruct a challenging and dynamically curated E2EDevBench to simulate\nrealistic development scenarios. Second, we propose a hybrid evaluation\nframework that combines test-case-based functional assessment with\nfine-grained, LLM-based requirement verification. Using this framework, we\nconduct a controlled empirical study on three representative agent\narchitectures implemented upon a unified foundation to isolate the impact of\nworkflow design. Our findings reveal that state-of-the-art agents can fulfill\napproximately 50\\% of requirements on \\bench{}, but their success is critically\ndependent on the architectural strategy for task decomposition and\ncollaboration. Furthermore, our analysis indicates that the primary bottleneck\nis the omission of requirements and inadequate self-verification. This work\nprovides the community with a more realistic benchmark, a comprehensive\nevaluation framework, and crucial insights into the current capabilities and\ncore challenges of software development agents, guiding future research toward\nenhancing requirement comprehension and planning.", "AI": {"tldr": "\u63d0\u51fa\u4e86E2EDevBench\u57fa\u51c6\u6d4b\u8bd5\u548c\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf9\u4e09\u79cd\u4ee3\u8868\u6027\u4ee3\u7406\u67b6\u6784\u8fdb\u884c\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u5f53\u524d\u6700\u5148\u8fdb\u4ee3\u7406\u53ea\u80fd\u6ee1\u8db3\u7ea650%\u9700\u6c42\uff0c\u6210\u529f\u5173\u952e\u53d6\u51b3\u4e8e\u4efb\u52a1\u5206\u89e3\u548c\u534f\u4f5c\u7684\u67b6\u6784\u7b56\u7565\u3002", "motivation": "\u73b0\u6709LLM\u81ea\u4e3b\u4ee3\u7406\u8bc4\u4f30\u5b58\u5728\u57fa\u51c6\u8fc7\u4e8e\u7b80\u5355\u3001\u4e0d\u540c\u67b6\u6784\u96be\u4ee5\u516c\u5e73\u6bd4\u8f83\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u73b0\u5b9e\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u57fa\u51c6\u3002", "method": "\u6784\u5efaE2EDevBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63d0\u51fa\u7ed3\u5408\u6d4b\u8bd5\u7528\u4f8b\u529f\u80fd\u8bc4\u4f30\u548c\u7ec6\u7c92\u5ea6LLM\u9700\u6c42\u9a8c\u8bc1\u7684\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u7edf\u4e00\u57fa\u7840\u4e0a\u5b9e\u73b0\u4e09\u79cd\u4ee3\u7406\u67b6\u6784\u8fdb\u884c\u5bf9\u6bd4\u7814\u7a76\u3002", "result": "\u6700\u5148\u8fdb\u4ee3\u7406\u53ea\u80fd\u6ee1\u8db3\u7ea650%\u9700\u6c42\uff0c\u6210\u529f\u5173\u952e\u53d6\u51b3\u4e8e\u4efb\u52a1\u5206\u89e3\u548c\u534f\u4f5c\u7684\u67b6\u6784\u7b56\u7565\uff0c\u4e3b\u8981\u74f6\u9888\u662f\u9700\u6c42\u9057\u6f0f\u548c\u81ea\u9a8c\u8bc1\u4e0d\u8db3\u3002", "conclusion": "\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u7684\u57fa\u51c6\u3001\u5168\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u8f6f\u4ef6\u5f00\u53d1\u4ee3\u7406\u5f53\u524d\u80fd\u529b\u548c\u6838\u5fc3\u6311\u6218\uff0c\u6307\u5bfc\u672a\u6765\u7814\u7a76\u589e\u5f3a\u9700\u6c42\u7406\u89e3\u548c\u89c4\u5212\u80fd\u529b\u3002", "topic": "swe benchmark"}}
{"id": "2511.03985", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03985", "abs": "https://arxiv.org/abs/2511.03985", "authors": ["Zhuowen Yuan", "Tao Liu", "Yang Yang", "Yang Wang", "Feng Qi", "Kaushik Rangadurai", "Bo Li", "Shuang Yang"], "title": "ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering", "comment": null, "summary": "Recent LLM-based agents have demonstrated strong capabilities in automated ML\nengineering. However, they heavily rely on repeated full training runs to\nevaluate candidate solutions, resulting in significant computational overhead,\nlimited scalability to large search spaces, and slow iteration cycles. To\naddress these challenges, we introduce ArchPilot, a multi-agent system that\nintegrates architecture generation, proxy-based evaluation, and adaptive search\ninto a unified framework. ArchPilot consists of three specialized agents: an\norchestration agent that coordinates the search process using a Monte Carlo\nTree Search (MCTS)-inspired novel algorithm with a restart mechanism and\nmanages memory of previous candidates; a generation agent that iteratively\ngenerates, improves, and debugs candidate architectures; and an evaluation\nagent that executes proxy training runs, generates and optimizes proxy\nfunctions, and aggregates the proxy scores into a fidelity-aware performance\nmetric. This multi-agent collaboration allows ArchPilot to prioritize\nhigh-potential candidates with minimal reliance on expensive full training\nruns, facilitating efficient ML engineering under limited budgets. Experiments\non MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE\nand ML-Master, validating the effectiveness of our multi-agent system.", "AI": {"tldr": "ArchPilot\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u96c6\u6210\u67b6\u6784\u751f\u6210\u3001\u57fa\u4e8e\u4ee3\u7406\u7684\u8bc4\u4f30\u548c\u81ea\u9002\u5e94\u641c\u7d22\u6765\u89e3\u51b3LLM\u4ee3\u7406\u5728\u81ea\u52a8\u5316ML\u5de5\u7a0b\u4e2d\u4f9d\u8d56\u91cd\u590d\u5b8c\u6574\u8bad\u7ec3\u8fd0\u884c\u7684\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u7684LLM\u4ee3\u7406\u5728\u81ea\u52a8\u5316ML\u5de5\u7a0b\u4e2d\u4e25\u91cd\u4f9d\u8d56\u91cd\u590d\u7684\u5b8c\u6574\u8bad\u7ec3\u8fd0\u884c\u6765\u8bc4\u4f30\u5019\u9009\u89e3\u51b3\u65b9\u6848\uff0c\u5bfc\u81f4\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u641c\u7d22\u7a7a\u95f4\u6269\u5c55\u6027\u6709\u9650\u3001\u8fed\u4ee3\u5468\u671f\u6162\u3002", "method": "\u91c7\u7528\u591a\u4ee3\u7406\u7cfb\u7edf\u67b6\u6784\uff0c\u5305\u542b\u4e09\u4e2a\u4e13\u95e8\u4ee3\u7406\uff1a\u7f16\u6392\u4ee3\u7406\u4f7f\u7528MCTS\u542f\u53d1\u5f0f\u7b97\u6cd5\u534f\u8c03\u641c\u7d22\u8fc7\u7a0b\uff0c\u751f\u6210\u4ee3\u7406\u8fed\u4ee3\u751f\u6210\u548c\u6539\u8fdb\u5019\u9009\u67b6\u6784\uff0c\u8bc4\u4f30\u4ee3\u7406\u6267\u884c\u4ee3\u7406\u8bad\u7ec3\u8fd0\u884c\u5e76\u751f\u6210\u4f18\u5316\u7684\u4ee3\u7406\u51fd\u6570\u3002", "result": "\u5728MLE-Bench\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cArchPilot\u4f18\u4e8eAIDE\u548cML-Master\u7b49\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "conclusion": "ArchPilot\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u80fd\u591f\u4f18\u5148\u8003\u8651\u9ad8\u6f5c\u529b\u5019\u9009\u65b9\u6848\uff0c\u6700\u5c0f\u5316\u5bf9\u6602\u8d35\u5b8c\u6574\u8bad\u7ec3\u8fd0\u884c\u7684\u4f9d\u8d56\uff0c\u5728\u6709\u9650\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u6548\u7684ML\u5de5\u7a0b\u3002", "topic": "code agent"}}
{"id": "2511.03828", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03828", "abs": "https://arxiv.org/abs/2511.03828", "authors": ["Lipeng Zu", "Hansong Zhou", "Xiaonan Zhang"], "title": "From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification", "comment": null, "summary": "Transitioning from offline to online reinforcement learning (RL) poses\ncritical challenges due to distributional shifts between the fixed behavior\npolicy in the offline dataset and the evolving policy during online learning.\nAlthough this issue is widely recognized, few methods attempt to explicitly\nassess or utilize the distributional structure of the offline data itself,\nleaving a research gap in adapting learning strategies to different types of\nsamples. To address this challenge, we propose an innovative method,\nEnergy-Guided Diffusion Stratification (StratDiff), which facilitates smoother\ntransitions in offline-to-online RL. StratDiff deploys a diffusion model to\nlearn prior knowledge from the offline dataset. It then refines this knowledge\nthrough energy-based functions to improve policy imitation and generate\noffline-like actions during online fine-tuning. The KL divergence between the\ngenerated action and the corresponding sampled action is computed for each\nsample and used to stratify the training batch into offline-like and\nonline-like subsets. Offline-like samples are updated using offline objectives,\nwhile online-like samples follow online learning strategies. We demonstrate the\neffectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL\nand IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff\nsignificantly outperforms existing methods, achieving enhanced adaptability and\nmore stable performance across diverse RL settings.", "AI": {"tldr": "\u63d0\u51faEnergy-Guided Diffusion Stratification (StratDiff)\u65b9\u6cd5\uff0c\u901a\u8fc7\u6269\u6563\u6a21\u578b\u5b66\u4e60\u79bb\u7ebf\u6570\u636e\u5148\u9a8c\u77e5\u8bc6\uff0c\u4f7f\u7528\u80fd\u91cf\u51fd\u6570\u6539\u8fdb\u7b56\u7565\u6a21\u4eff\uff0c\u5728\u5728\u7ebf\u5fae\u8c03\u671f\u95f4\u751f\u6210\u79bb\u7ebf\u7c7b\u52a8\u4f5c\uff0c\u901a\u8fc7KL\u6563\u5ea6\u5c06\u8bad\u7ec3\u6279\u6b21\u5206\u5c42\u4e3a\u79bb\u7ebf\u7c7b\u548c\u5728\u7ebf\u7c7b\u6837\u672c\u5206\u522b\u5904\u7406\u3002", "motivation": "\u89e3\u51b3\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u5f88\u5c11\u660e\u786e\u8bc4\u4f30\u6216\u5229\u7528\u79bb\u7ebf\u6570\u636e\u672c\u8eab\u7684\u5206\u5e03\u7ed3\u6784\uff0c\u5b58\u5728\u9002\u5e94\u4e0d\u540c\u6837\u672c\u7c7b\u578b\u7684\u5b66\u4e60\u7b56\u7565\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u4f7f\u7528\u6269\u6563\u6a21\u578b\u5b66\u4e60\u79bb\u7ebf\u6570\u636e\u5148\u9a8c\uff0c\u901a\u8fc7\u80fd\u91cf\u51fd\u6570\u6539\u8fdb\u7b56\u7565\u6a21\u4eff\uff0c\u8ba1\u7b97\u751f\u6210\u52a8\u4f5c\u4e0e\u91c7\u6837\u52a8\u4f5c\u7684KL\u6563\u5ea6\u6765\u5206\u5c42\u8bad\u7ec3\u6279\u6b21\uff0c\u79bb\u7ebf\u7c7b\u6837\u672c\u4f7f\u7528\u79bb\u7ebf\u76ee\u6807\u66f4\u65b0\uff0c\u5728\u7ebf\u7c7b\u6837\u672c\u91c7\u7528\u5728\u7ebf\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728D4RL\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u4e0eCal-QL\u548cIQL\u96c6\u6210\u540e\uff0cStratDiff\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u9002\u5e94\u6027\u548c\u66f4\u7a33\u5b9a\u7684\u6027\u80fd\u3002", "conclusion": "StratDiff\u65b9\u6cd5\u901a\u8fc7\u663e\u5f0f\u5229\u7528\u79bb\u7ebf\u6570\u636e\u7684\u5206\u5e03\u7ed3\u6784\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u79bb\u7ebf\u5230\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5b66\u4e60\u8fc7\u7a0b\u7684\u7a33\u5b9a\u6027\u548c\u9002\u5e94\u6027\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.04115", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.04115", "abs": "https://arxiv.org/abs/2511.04115", "authors": ["Ruksit Rojpaisarnkit", "Youmei Fan", "Kenichi Matsumoto", "Raula Gaikovina Kula"], "title": "How Natural Language Proficiency Shapes GenAI Code for Software Engineering Tasks", "comment": "7 pages, 4 tables, 1 figure", "summary": "With the widespread adoption of Foundation Model (FM)-powered tools in\nsoftware engineering, the natural language prompt has become a critical\ninterface between developers and Large Language Models (LLMs). While much\nresearch has focused on prompt structure, the natural language proficiency is\nan underexplored factor that can influence the quality of generated code. This\npaper investigates whether the English language proficiency itself independent\nof the prompting technique affects the proficiency and correctness of code\ngenerated by LLMs. Using the HumanEval dataset, we systematically varied the\nEnglish proficiency of prompts from basic to advanced for 164 programming tasks\nand measured the resulting code proficiency and correctness. Our findings show\nthat LLMs default to an intermediate (B2) natural language level. While the\neffect on the resulting code proficiency was model-dependent, we found that\nhigher-proficiency prompts consistently yielded more correct code across all\nmodels. These results demonstrate that natural language proficiency is a key\nlever for controlling code generation, helping developers tailor AI output and\nimprove the reliability of solutions.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u82f1\u8bed\u8bed\u8a00\u80fd\u529b\u5bf9LLM\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u9ad8\u7ea7\u82f1\u8bed\u63d0\u793a\u80fd\u4ea7\u751f\u66f4\u6b63\u786e\u7684\u4ee3\u7801\uff0c\u5373\u4f7f\u4e0d\u8003\u8651\u63d0\u793a\u6280\u672f\u672c\u8eab\u3002", "motivation": "\u968f\u7740\u57fa\u7840\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u6210\u4e3a\u5f00\u53d1\u8005\u4e0eLLM\u7684\u5173\u952e\u63a5\u53e3\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u5173\u6ce8\u63d0\u793a\u7ed3\u6784\uff0c\u4f46\u81ea\u7136\u8bed\u8a00\u80fd\u529b\u8fd9\u4e00\u5f71\u54cd\u4ee3\u7801\u8d28\u91cf\u7684\u56e0\u7d20\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u4f7f\u7528HumanEval\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u5730\u5c06164\u4e2a\u7f16\u7a0b\u4efb\u52a1\u7684\u82f1\u8bed\u63d0\u793a\u4ece\u57fa\u7840\u5230\u9ad8\u7ea7\u8fdb\u884c\u53d8\u5316\uff0c\u6d4b\u91cf\u751f\u6210\u7684\u4ee3\u7801\u80fd\u529b\u548c\u6b63\u786e\u6027\u3002", "result": "LLM\u9ed8\u8ba4\u4f7f\u7528\u4e2d\u7ea7(B2)\u81ea\u7136\u8bed\u8a00\u6c34\u5e73\u3002\u867d\u7136\u5bf9\u4ee3\u7801\u80fd\u529b\u7684\u5f71\u54cd\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u4f46\u9ad8\u7ea7\u82f1\u8bed\u63d0\u793a\u5728\u6240\u6709\u6a21\u578b\u4e2d\u90fd\u80fd\u4ea7\u751f\u66f4\u6b63\u786e\u7684\u4ee3\u7801\u3002", "conclusion": "\u81ea\u7136\u8bed\u8a00\u80fd\u529b\u662f\u63a7\u5236\u4ee3\u7801\u751f\u6210\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u5b9a\u5236AI\u8f93\u51fa\u5e76\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u9760\u6027\u3002", "topic": "code agent"}}
{"id": "2511.04032", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04032", "abs": "https://arxiv.org/abs/2511.04032", "authors": ["Divya Pathak", "Harshit Kumar", "Anuska Roy", "Felix George", "Mudit Verma", "Pratibha Moogi"], "title": "Detecting Silent Failures in Multi-Agentic AI Trajectories", "comment": null, "summary": "Multi-Agentic AI systems, powered by large language models (LLMs), are\ninherently non-deterministic and prone to silent failures such as drift,\ncycles, and missing details in outputs, which are difficult to detect. We\nintroduce the task of anomaly detection in agentic trajectories to identify\nthese failures and present a dataset curation pipeline that captures user\nbehavior, agent non-determinism, and LLM variation. Using this pipeline, we\ncurate and label two benchmark datasets comprising \\textbf{4,275 and 894}\ntrajectories from Multi-Agentic AI systems. Benchmarking anomaly detection\nmethods on these datasets, we show that supervised (XGBoost) and\nsemi-supervised (SVDD) approaches perform comparably, achieving accuracies up\nto 98% and 96%, respectively. This work provides the first systematic study of\nanomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,\nand insights to guide future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u4efb\u52a1\uff0c\u6784\u5efa\u4e86\u4e24\u4e2a\u5305\u542b4,275\u548c894\u6761\u8f68\u8ff9\u7684\u6570\u636e\u96c6\uff0c\u5e76\u6bd4\u8f83\u4e86\u76d1\u7763\u548c\u534a\u76d1\u7763\u65b9\u6cd5\u5728\u68c0\u6d4b\u667a\u80fd\u4f53\u6f02\u79fb\u3001\u5faa\u73af\u548c\u8f93\u51fa\u7ec6\u8282\u7f3a\u5931\u7b49\u6545\u969c\u65b9\u9762\u7684\u6027\u80fd\u3002", "motivation": "\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u5177\u6709\u975e\u786e\u5b9a\u6027\u4e14\u5bb9\u6613\u51fa\u73b0\u96be\u4ee5\u68c0\u6d4b\u7684\u9759\u9ed8\u6545\u969c\uff0c\u5982\u6f02\u79fb\u3001\u5faa\u73af\u548c\u8f93\u51fa\u7ec6\u8282\u7f3a\u5931\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u6765\u8bc6\u522b\u8fd9\u4e9b\u6545\u969c\u3002", "method": "\u5f00\u53d1\u4e86\u6570\u636e\u96c6\u6784\u5efa\u6d41\u7a0b\u6765\u6355\u6349\u7528\u6237\u884c\u4e3a\u3001\u667a\u80fd\u4f53\u975e\u786e\u5b9a\u6027\u548cLLM\u53d8\u5316\uff0c\u6784\u5efa\u4e86\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86XGBoost\uff08\u76d1\u7763\uff09\u548cSVDD\uff08\u534a\u76d1\u7763\uff09\u7b49\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u76d1\u7763\u65b9\u6cd5\uff08XGBoost\uff09\u548c\u534a\u76d1\u7763\u65b9\u6cd5\uff08SVDD\uff09\u8868\u73b0\u76f8\u5f53\uff0c\u5206\u522b\u8fbe\u523098%\u548c96%\u7684\u51c6\u786e\u7387\uff0c\u8868\u660e\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u6709\u6548\u68c0\u6d4b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u5f02\u5e38\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u5bf9\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u7684\u7cfb\u7edf\u6027\u7814\u7a76\uff0c\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u3001\u57fa\u51c6\u6d4b\u8bd5\u548c\u89c1\u89e3\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "topic": "agent analysis"}}
{"id": "2511.04053", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04053", "abs": "https://arxiv.org/abs/2511.04053", "authors": ["Hirohane Takagi", "Gouki Minegishi", "Shota Kizawa", "Issey Sukeda", "Hitomi Yanaka"], "title": "Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models", "comment": "Accepted to IJCNLP-AACL 2025 (Main). Code available at\n  https://github.com/htkg/num_attrs", "summary": "Although behavioral studies have documented numerical reasoning errors in\nlarge language models (LLMs), the underlying representational mechanisms remain\nunclear. We hypothesize that numerical attributes occupy shared latent\nsubspaces and investigate two questions:(1) How do LLMs internally integrate\nmultiple numerical attributes of a single entity? (2)How does irrelevant\nnumerical context perturb these representations and their downstream outputs?\nTo address these questions, we combine linear probing with partial correlation\nanalysis and prompt-based vulnerability tests across models of varying sizes.\nOur results show that LLMs encode real-world numerical correlations but tend to\nsystematically amplify them. Moreover, irrelevant context induces consistent\nshifts in magnitude representations, with downstream effects that vary by model\nsize. These findings reveal a vulnerability in LLM decision-making and lay the\ngroundwork for fairer, representation-aware control under multi-attribute\nentanglement.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86LLMs\u4e2d\u6570\u503c\u63a8\u7406\u9519\u8bef\u7684\u8868\u793a\u673a\u5236\uff0c\u53d1\u73b0LLMs\u7f16\u7801\u771f\u5b9e\u4e16\u754c\u6570\u503c\u76f8\u5173\u6027\u4f46\u4f1a\u7cfb\u7edf\u6027\u653e\u5927\u5b83\u4eec\uff0c\u65e0\u5173\u4e0a\u4e0b\u6587\u4f1a\u8bf1\u5bfc\u4e00\u81f4\u7684\u5e45\u5ea6\u8868\u793a\u504f\u79fb\u3002", "motivation": "\u5c3d\u7ba1\u884c\u4e3a\u7814\u7a76\u5df2\u8bb0\u5f55LLMs\u4e2d\u7684\u6570\u503c\u63a8\u7406\u9519\u8bef\uff0c\u4f46\u5e95\u5c42\u8868\u793a\u673a\u5236\u4ecd\u4e0d\u6e05\u695a\u3002\u4f5c\u8005\u5047\u8bbe\u6570\u503c\u5c5e\u6027\u5360\u636e\u5171\u4eab\u6f5c\u5728\u5b50\u7a7a\u95f4\uff0c\u65e8\u5728\u63a2\u7a76LLMs\u5982\u4f55\u5185\u90e8\u6574\u5408\u5355\u4e2a\u5b9e\u4f53\u7684\u591a\u4e2a\u6570\u503c\u5c5e\u6027\uff0c\u4ee5\u53ca\u65e0\u5173\u6570\u503c\u4e0a\u4e0b\u6587\u5982\u4f55\u5e72\u6270\u8fd9\u4e9b\u8868\u793a\u53ca\u5176\u4e0b\u6e38\u8f93\u51fa\u3002", "method": "\u7ed3\u5408\u7ebf\u6027\u63a2\u6d4b\u4e0e\u504f\u76f8\u5173\u5206\u6790\uff0c\u4ee5\u53ca\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u8fdb\u884c\u57fa\u4e8e\u63d0\u793a\u7684\u8106\u5f31\u6027\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u663e\u793aLLMs\u7f16\u7801\u771f\u5b9e\u4e16\u754c\u6570\u503c\u76f8\u5173\u6027\u4f46\u503e\u5411\u4e8e\u7cfb\u7edf\u6027\u653e\u5927\u5b83\u4eec\u3002\u65e0\u5173\u4e0a\u4e0b\u6587\u8bf1\u5bfc\u4e00\u81f4\u7684\u5e45\u5ea6\u8868\u793a\u504f\u79fb\uff0c\u4e0b\u6e38\u5f71\u54cd\u56e0\u6a21\u578b\u89c4\u6a21\u800c\u5f02\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63ed\u793a\u4e86LLM\u51b3\u7b56\u4e2d\u7684\u8106\u5f31\u6027\uff0c\u4e3a\u5728\u591a\u5c5e\u6027\u7ea0\u7f20\u4e0b\u5b9e\u73b0\u66f4\u516c\u5e73\u3001\u8868\u793a\u611f\u77e5\u7684\u63a7\u5236\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "topic": "agent analysis"}}
{"id": "2511.03836", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.03836", "abs": "https://arxiv.org/abs/2511.03836", "authors": ["Lipeng Zu", "Hansong Zhou", "Xiaonan Zhang"], "title": "Enhancing Q-Value Updates in Deep Q-Learning via Successor-State Prediction", "comment": null, "summary": "Deep Q-Networks (DQNs) estimate future returns by learning from transitions\nsampled from a replay buffer. However, the target updates in DQN often rely on\nnext states generated by actions from past, potentially suboptimal, policy. As\na result, these states may not provide informative learning signals, causing\nhigh variance into the update process. This issue is exacerbated when the\nsampled transitions are poorly aligned with the agent's current policy. To\naddress this limitation, we propose the Successor-state Aggregation Deep\nQ-Network (SADQ), which explicitly models environment dynamics using a\nstochastic transition model. SADQ integrates successor-state distributions into\nthe Q-value estimation process, enabling more stable and policy-aligned value\nupdates. Additionally, it explores a more efficient action selection strategy\nwith the modeled transition structure. We provide theoretical guarantees that\nSADQ maintains unbiased value estimates while reducing training variance. Our\nextensive empirical results across standard RL benchmarks and real-world\nvector-based control tasks demonstrate that SADQ consistently outperforms DQN\nvariants in both stability and learning efficiency.", "AI": {"tldr": "\u63d0\u51faSADQ\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u73af\u5883\u52a8\u6001\u548c\u4f7f\u7528\u540e\u7ee7\u72b6\u6001\u5206\u5e03\u6765\u6539\u8fdbDQN\uff0c\u51cf\u5c11\u8bad\u7ec3\u65b9\u5dee\u5e76\u63d0\u9ad8\u5b66\u4e60\u7a33\u5b9a\u6027", "motivation": "\u89e3\u51b3DQN\u4e2d\u76ee\u6807\u66f4\u65b0\u4f9d\u8d56\u8fc7\u53bb\u6b21\u4f18\u7b56\u7565\u751f\u6210\u7684\u72b6\u6001\uff0c\u5bfc\u81f4\u5b66\u4e60\u4fe1\u53f7\u4e0d\u5177\u4fe1\u606f\u6027\u548c\u9ad8\u65b9\u5dee\u7684\u95ee\u9898", "method": "\u4f7f\u7528\u968f\u673a\u8f6c\u79fb\u6a21\u578b\u663e\u5f0f\u5efa\u6a21\u73af\u5883\u52a8\u6001\uff0c\u5c06\u540e\u7ee7\u72b6\u6001\u5206\u5e03\u96c6\u6210\u5230Q\u503c\u4f30\u8ba1\u8fc7\u7a0b\u4e2d\uff0c\u5e76\u63a2\u7d22\u57fa\u4e8e\u8f6c\u79fb\u7ed3\u6784\u7684\u66f4\u9ad8\u6548\u52a8\u4f5c\u9009\u62e9\u7b56\u7565", "result": "\u5728\u6807\u51c6RL\u57fa\u51c6\u548c\u5b9e\u9645\u5411\u91cf\u63a7\u5236\u4efb\u52a1\u4e2d\uff0cSADQ\u5728\u7a33\u5b9a\u6027\u548c\u5b66\u4e60\u6548\u7387\u4e0a\u6301\u7eed\u4f18\u4e8eDQN\u53d8\u4f53", "conclusion": "SADQ\u901a\u8fc7\u5efa\u6a21\u73af\u5883\u52a8\u6001\u548c\u540e\u7ee7\u72b6\u6001\u5206\u5e03\uff0c\u5728\u4fdd\u6301\u65e0\u504f\u503c\u4f30\u8ba1\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u65b9\u5dee", "topic": "agentic reinforcement learning"}}
{"id": "2511.04076", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04076", "abs": "https://arxiv.org/abs/2511.04076", "authors": ["Hao Li", "Haotian Chen", "Ruoyuan Gong", "Juanjuan Wang", "Hao Jiang"], "title": "Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents", "comment": "Accepted by AAAI AISI 2026", "summary": "Redistricting plays a central role in shaping how votes are translated into\npolitical power. While existing computational methods primarily aim to generate\nlarge ensembles of legally valid districting plans, they often neglect the\nstrategic dynamics involved in the selection process. This oversight creates\nopportunities for partisan actors to cherry-pick maps that, while technically\ncompliant, are politically advantageous. Simply satisfying formal constraints\ndoes not ensure fairness when the selection process itself can be manipulated.\nWe propose \\textbf{Agentmandering}, a framework that reimagines redistricting\nas a turn-based negotiation between two agents representing opposing political\ninterests. Drawing inspiration from game-theoretic ideas, particularly the\n\\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction\ninto the redistricting process via large language model (LLM) agents. Agents\nalternate between selecting and freezing districts from a small set of\ncandidate maps, gradually partitioning the state through constrained and\ninterpretable choices. Evaluation on post-2020 U.S. Census data across all\nstates shows that Agentmandering significantly reduces partisan bias and\nunfairness, while achieving 2 to 3 orders of magnitude lower variance than\nstandard baselines. These results demonstrate both fairness and stability,\nespecially in swing-state scenarios. Our code is available at\nhttps://github.com/Lihaogx/AgentMandering.", "AI": {"tldr": "\u63d0\u51fa\u4e86Agentmandering\u6846\u67b6\uff0c\u5c06\u9009\u533a\u91cd\u5212\u91cd\u65b0\u6784\u60f3\u4e3a\u4e24\u4e2a\u4ee3\u8868\u5bf9\u7acb\u653f\u6cbb\u5229\u76ca\u7684\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u56de\u5408\u5236\u8c08\u5224\uff0c\u901a\u8fc7LLM\u667a\u80fd\u4f53\u5c06\u6218\u7565\u4e92\u52a8\u5d4c\u5165\u5230\u9009\u533a\u91cd\u5212\u8fc7\u7a0b\u4e2d\u3002", "motivation": "\u73b0\u6709\u7684\u8ba1\u7b97\u65b9\u6cd5\u4e3b\u8981\u751f\u6210\u5927\u91cf\u6cd5\u5f8b\u4e0a\u6709\u6548\u7684\u9009\u533a\u5212\u5206\u65b9\u6848\uff0c\u4f46\u5ffd\u7565\u4e86\u9009\u62e9\u8fc7\u7a0b\u4e2d\u7684\u6218\u7565\u52a8\u6001\uff0c\u8fd9\u4e3a\u515a\u6d3e\u884c\u4e3a\u8005\u6311\u9009\u653f\u6cbb\u4e0a\u6709\u5229\u7684\u5730\u56fe\u521b\u9020\u4e86\u673a\u4f1a\u3002", "method": "\u57fa\u4e8e\u535a\u5f08\u8bba\u601d\u60f3\uff0c\u7279\u522b\u662f\"\u9009\u62e9\u5e76\u51bb\u7ed3\"\u534f\u8bae\uff0c\u8ba9\u4e24\u4e2a\u4ee3\u8868\u5bf9\u7acb\u653f\u6cbb\u5229\u76ca\u7684LLM\u667a\u80fd\u4f53\u8f6e\u6d41\u4ece\u5019\u9009\u5730\u56fe\u4e2d\u9009\u62e9\u548c\u51bb\u7ed3\u9009\u533a\uff0c\u901a\u8fc7\u53d7\u9650\u4e14\u53ef\u89e3\u91ca\u7684\u9009\u62e9\u9010\u6b65\u5212\u5206\u5dde\u3002", "result": "\u57282020\u5e74\u7f8e\u56fd\u4eba\u53e3\u666e\u67e5\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cAgentmandering\u663e\u8457\u51cf\u5c11\u4e86\u515a\u6d3e\u504f\u89c1\u548c\u4e0d\u516c\u5e73\u6027\uff0c\u540c\u65f6\u6bd4\u6807\u51c6\u57fa\u7ebf\u5b9e\u73b0\u4e862\u52303\u4e2a\u6570\u91cf\u7ea7\u7684\u66f4\u4f4e\u65b9\u5dee\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u516c\u5e73\u6027\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u6447\u6446\u5dde\u573a\u666f\u4e2d\u3002", "topic": "agent analysis"}}
{"id": "2511.04355", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04355", "abs": "https://arxiv.org/abs/2511.04355", "authors": ["Amir Molzam Sharifloo", "Maedeh Heydari", "Parsa Kazerooni", "Daniel Maninger", "Mira Mezini"], "title": "Where Do LLMs Still Struggle? An In-Depth Analysis of Code Generation Benchmarks", "comment": "To be published in Proceedings of 2025 2nd IEEE/ACM International\n  Conference on AI-powered Software (AIware), Data & Benchmark Track", "summary": "Large Language Models (LLMs) have achieved remarkable success in code\ngeneration, and the race to improve their performance has become a central\nfocus of AI research. Benchmarks and leaderboards are increasingly popular,\noffering quantitative rankings of LLMs. However, they provide limited insight\ninto the tasks that LLMs consistently fail to solve - information that is\ncrucial for understanding current limitations and guiding the development of\nmore capable models. To address this gap, we examined code generation tasks\nacross four popular benchmarks, identifying those that major LLMs are most\nlikely to fail. To understand the causes of these failures, we investigated\nwhether the static complexity of solution code contributes to them, followed by\na systematic inspection of 114 tasks that LLMs consistently struggled with. Our\nanalysis revealed four recurring patterns of weaknesses in LLMs, as well as\ncommon complications within benchmark tasks that most often lead to failure.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u56db\u4e2a\u6d41\u884c\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2dLLM\u6700\u53ef\u80fd\u5931\u8d25\u7684\u4efb\u52a1\uff0c\u8bc6\u522b\u51faLLM\u7684\u56db\u79cd\u5e38\u89c1\u5f31\u70b9\u6a21\u5f0f\u548c\u5bfc\u81f4\u5931\u8d25\u7684\u57fa\u51c6\u4efb\u52a1\u590d\u6742\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u548c\u6392\u884c\u699c\u4ec5\u63d0\u4f9bLLM\u7684\u5b9a\u91cf\u6392\u540d\uff0c\u4f46\u65e0\u6cd5\u63ed\u793aLLM\u6301\u7eed\u5931\u8d25\u7684\u4efb\u52a1\u7c7b\u578b\uff0c\u8fd9\u4e9b\u4fe1\u606f\u5bf9\u4e8e\u7406\u89e3\u5f53\u524d\u5c40\u9650\u6027\u548c\u5f00\u53d1\u66f4\u5f3a\u5927\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u68c0\u67e5\u4e86\u56db\u4e2a\u6d41\u884c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u4ee3\u7801\u751f\u6210\u4efb\u52a1\uff0c\u8bc6\u522b\u4e3b\u8981LLM\u6700\u53ef\u80fd\u5931\u8d25\u7684\u4efb\u52a1\uff1b\u8c03\u67e5\u89e3\u51b3\u65b9\u6848\u4ee3\u7801\u7684\u9759\u6001\u590d\u6742\u6027\u662f\u5426\u5bfc\u81f4\u5931\u8d25\uff1b\u7cfb\u7edf\u68c0\u67e5114\u4e2aLLM\u6301\u7eed\u56f0\u96be\u7684\u4efb\u52a1\u3002", "result": "\u5206\u6790\u63ed\u793a\u4e86LLM\u7684\u56db\u79cd\u91cd\u590d\u51fa\u73b0\u7684\u5f31\u70b9\u6a21\u5f0f\uff0c\u4ee5\u53ca\u57fa\u51c6\u4efb\u52a1\u4e2d\u6700\u5e38\u5bfc\u81f4\u5931\u8d25\u7684\u5e38\u89c1\u590d\u6742\u6027\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u57fa\u51c6\u6d4b\u8bd5\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u5bf9LLM\u4ee3\u7801\u751f\u6210\u80fd\u529b\u5c40\u9650\u6027\u7684\u6df1\u5165\u7406\u89e3\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u6a21\u578b\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "topic": "swe benchmark"}}
{"id": "2511.04177", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04177", "abs": "https://arxiv.org/abs/2511.04177", "authors": ["Claire Yang", "Maya Cakmak", "Max Kleiman-Weiner"], "title": "When Empowerment Disempowers", "comment": null, "summary": "Empowerment, a measure of an agent's ability to control its environment, has\nbeen proposed as a universal goal-agnostic objective for motivating assistive\nbehavior in AI agents. While multi-human settings like homes and hospitals are\npromising for AI assistance, prior work on empowerment-based assistance assumes\nthat the agent assists one human in isolation. We introduce an open source\nmulti-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we\nempirically show that assistive RL agents optimizing for one human's\nempowerment can significantly reduce another human's environmental influence\nand rewards - a phenomenon we formalize as disempowerment. We characterize when\ndisempowerment occurs in these environments and show that joint empowerment\nmitigates disempowerment at the cost of the user's reward. Our work reveals a\nbroader challenge for the AI alignment community: goal-agnostic objectives that\nseem aligned in single-agent settings can become misaligned in multi-agent\ncontexts.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u591a\u4eba\u7c7b\u73af\u5883\u4e2d\u7684\u8d4b\u6743\u95ee\u9898\uff0c\u53d1\u73b0\u4e13\u6ce8\u4e8e\u5355\u4eba\u7c7b\u8d4b\u6743\u7684AI\u52a9\u624b\u53ef\u80fd\u4f1a\u524a\u5f31\u5176\u4ed6\u4eba\u7c7b\u7684\u73af\u5883\u5f71\u54cd\u529b\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\"\u53bb\u8d4b\u6743\"\u3002", "motivation": "\u7814\u7a76\u591a\u4eba\u7c7b\u73af\u5883\u4e2d\u8d4b\u6743\u4f5c\u4e3aAI\u52a9\u624b\u901a\u7528\u76ee\u6807\u7684\u6709\u6548\u6027\uff0c\u56e0\u4e3a\u73b0\u6709\u7814\u7a76\u5047\u8bbeAI\u52a9\u624b\u53ea\u670d\u52a1\u5355\u4e2a\u4eba\u7c7b\uff0c\u800c\u73b0\u5b9e\u73af\u5883\u5982\u5bb6\u5ead\u548c\u533b\u9662\u6d89\u53ca\u591a\u4e2a\u4eba\u7c7b\u3002", "method": "\u5f00\u53d1\u4e86\u5f00\u6e90\u591a\u4eba\u7c7b\u7f51\u683c\u4e16\u754c\u6d4b\u8bd5\u5957\u4ef6Disempower-Grid\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e13\u6ce8\u4e8e\u5355\u4eba\u7c7b\u8d4b\u6743\u7684\u5f3a\u5316\u5b66\u4e60\u52a9\u624b\u5bf9\u5176\u4ed6\u4eba\u7c7b\u73af\u5883\u5f71\u54cd\u548c\u5956\u52b1\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f18\u5316\u5355\u4eba\u7c7b\u8d4b\u6743\u7684\u52a9\u624b\u4f1a\u663e\u8457\u964d\u4f4e\u5176\u4ed6\u4eba\u7c7b\u7684\u73af\u5883\u5f71\u54cd\u529b\u548c\u5956\u52b1\uff0c\u5373\u4ea7\u751f\u53bb\u8d4b\u6743\u73b0\u8c61\u3002\u8054\u5408\u8d4b\u6743\u65b9\u6cd5\u53ef\u4ee5\u7f13\u89e3\u53bb\u8d4b\u6743\uff0c\u4f46\u4f1a\u727a\u7272\u7528\u6237\u7684\u5956\u52b1\u3002", "conclusion": "AI\u5bf9\u9f50\u793e\u533a\u9762\u4e34\u66f4\u5e7f\u6cdb\u7684\u6311\u6218\uff1a\u5728\u5355\u667a\u80fd\u4f53\u8bbe\u7f6e\u4e2d\u770b\u4f3c\u5bf9\u9f50\u7684\u76ee\u6807\u65e0\u5173\u76ee\u6807\uff0c\u5728\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u53ef\u80fd\u53d8\u5f97\u4e0d\u5bf9\u9f50\u3002", "topic": "agent analysis"}}
{"id": "2511.04427", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04427", "abs": "https://arxiv.org/abs/2511.04427", "authors": ["Hao He", "Courtney Miller", "Shyam Agarwal", "Christian K\u00e4stner", "Bogdan Vasilescu"], "title": "Speed at the Cost of Quality? The Impact of LLM Agent Assistance on Software Development", "comment": null, "summary": "Large language models (LLMs) have demonstrated the promise to revolutionize\nthe field of software engineering. Among other things, LLM agents are rapidly\ngaining momentum in their application to software development, with\npractitioners claiming a multifold productivity increase after adoption. Yet,\nempirical evidence is lacking around these claims. In this paper, we estimate\nthe causal effect of adopting a widely popular LLM agent assistant, namely\nCursor, on development velocity and software quality. The estimation is enabled\nby a state-of-the-art difference-in-differences design comparing\nCursor-adopting GitHub projects with a matched control group of similar GitHub\nprojects that do not use Cursor. We find that the adoption of Cursor leads to a\nsignificant, large, but transient increase in project-level development\nvelocity, along with a significant and persistent increase in static analysis\nwarnings and code complexity. Further panel generalized method of moments\nestimation reveals that the increase in static analysis warnings and code\ncomplexity acts as a major factor causing long-term velocity slowdown. Our\nstudy carries implications for software engineering practitioners, LLM agent\nassistant designers, and researchers.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u8bc4\u4f30\u4e86Cursor LLM\u52a9\u624b\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u80fd\u663e\u8457\u4f46\u77ed\u6682\u63d0\u5347\u5f00\u53d1\u901f\u5ea6\uff0c\u540c\u65f6\u5bfc\u81f4\u4ee3\u7801\u590d\u6742\u5ea6\u548c\u9759\u6001\u5206\u6790\u8b66\u544a\u7684\u6301\u7eed\u589e\u52a0\uff0c\u6700\u7ec8\u8fd9\u4e9b\u8d28\u91cf\u95ee\u9898\u4f1a\u53cd\u8fc7\u6765\u964d\u4f4e\u957f\u671f\u5f00\u53d1\u6548\u7387\u3002", "motivation": "LLM\u4ee3\u7406\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u5176\u5bf9\u5f00\u53d1\u6548\u7387\u548c\u8f6f\u4ef6\u8d28\u91cf\u5f71\u54cd\u7684\u5b9e\u8bc1\u8bc1\u636e\u3002\u672c\u6587\u65e8\u5728\u91cf\u5316\u8bc4\u4f30\u6d41\u884cLLM\u52a9\u624bCursor\u7684\u56e0\u679c\u6548\u5e94\u3002", "method": "\u91c7\u7528\u5dee\u5206\u6cd5\u8bbe\u8ba1\uff0c\u6bd4\u8f83\u4f7f\u7528Cursor\u7684GitHub\u9879\u76ee\u4e0e\u5339\u914d\u7684\u672a\u4f7f\u7528\u63a7\u5236\u7ec4\uff0c\u5e76\u4f7f\u7528\u9762\u677f\u5e7f\u4e49\u77e9\u4f30\u8ba1\u5206\u6790\u957f\u671f\u5f71\u54cd\u673a\u5236\u3002", "result": "Cursor\u91c7\u7528\u5bfc\u81f4\u9879\u76ee\u7ea7\u5f00\u53d1\u901f\u5ea6\u663e\u8457\u4f46\u77ed\u6682\u63d0\u5347\uff0c\u540c\u65f6\u9759\u6001\u5206\u6790\u8b66\u544a\u548c\u4ee3\u7801\u590d\u6742\u5ea6\u663e\u8457\u6301\u7eed\u589e\u52a0\u3002\u8d28\u91cf\u95ee\u9898\u7684\u589e\u52a0\u662f\u5bfc\u81f4\u957f\u671f\u901f\u5ea6\u4e0b\u964d\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "conclusion": "LLM\u52a9\u624b\u867d\u7136\u80fd\u77ed\u671f\u63d0\u5347\u5f00\u53d1\u6548\u7387\uff0c\u4f46\u53ef\u80fd\u4ee5\u727a\u7272\u4ee3\u7801\u8d28\u91cf\u4e3a\u4ee3\u4ef7\uff0c\u8fd9\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u8005\u3001LLM\u52a9\u624b\u8bbe\u8ba1\u8005\u548c\u7814\u7a76\u8005\u90fd\u6709\u91cd\u8981\u542f\u793a\u3002", "topic": "swe application"}}
{"id": "2511.04070", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04070", "abs": "https://arxiv.org/abs/2511.04070", "authors": ["Shreya Havaldar", "Helen Jin", "Chaehyeon Kim", "Anton Xue", "Weiqiu You", "Marco Gatti", "Bhuvnesh Jain", "Helen Qu", "Daniel A Hashimoto", "Amin Madani", "Rajat Deo", "Sameed Ahmed M. Khatana", "Gary E. Weissman", "Lyle Ungar", "Eric Wong"], "title": "T-FIX: Text-Based Explanations with Features Interpretable to eXperts", "comment": null, "summary": "As LLMs are deployed in knowledge-intensive settings (e.g., surgery,\nastronomy, therapy), users expect not just answers, but also meaningful\nexplanations for those answers. In these settings, users are often domain\nexperts (e.g., doctors, astrophysicists, psychologists) who require\nexplanations that reflect expert-level reasoning. However, current evaluation\nschemes primarily emphasize plausibility or internal faithfulness of the\nexplanation, which fail to capture whether the content of the explanation truly\naligns with expert intuition. We formalize expert alignment as a criterion for\nevaluating explanations with T-FIX, a benchmark spanning seven\nknowledge-intensive domains. In collaboration with domain experts, we develop\nnovel metrics to measure the alignment of LLM explanations with expert\njudgment.", "AI": {"tldr": "\u63d0\u51fa\u4e86T-FIX\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u4e2d\u751f\u6210\u89e3\u91ca\u4e0e\u4e13\u5bb6\u5224\u65ad\u7684\u5bf9\u9f50\u7a0b\u5ea6\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u89e3\u91ca\u7684\u5408\u7406\u6027\u6216\u5185\u90e8\u4e00\u81f4\u6027\u3002", "motivation": "\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\uff08\u5982\u624b\u672f\u3001\u5929\u6587\u5b66\u3001\u6cbb\u7597\u7b49\uff09\u4e2d\uff0c\u7528\u6237\uff08\u901a\u5e38\u662f\u9886\u57df\u4e13\u5bb6\uff09\u4e0d\u4ec5\u9700\u8981\u7b54\u6848\uff0c\u8fd8\u9700\u8981\u53cd\u6620\u4e13\u5bb6\u7ea7\u63a8\u7406\u7684\u6709\u610f\u4e49\u89e3\u91ca\u3002\u5f53\u524d\u8bc4\u4f30\u65b9\u6848\u4e3b\u8981\u5173\u6ce8\u89e3\u91ca\u7684\u5408\u7406\u6027\u6216\u5185\u90e8\u5fe0\u5b9e\u6027\uff0c\u672a\u80fd\u6355\u6349\u89e3\u91ca\u5185\u5bb9\u662f\u5426\u771f\u6b63\u7b26\u5408\u4e13\u5bb6\u76f4\u89c9\u3002", "method": "\u4e0e\u9886\u57df\u4e13\u5bb6\u5408\u4f5c\u5f00\u53d1\u4e86T-FIX\u57fa\u51c6\uff0c\u6db5\u76d6\u4e03\u4e2a\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\uff0c\u5e76\u8bbe\u8ba1\u4e86\u65b0\u7684\u6307\u6807\u6765\u8861\u91cfLLM\u89e3\u91ca\u4e0e\u4e13\u5bb6\u5224\u65ad\u7684\u5bf9\u9f50\u7a0b\u5ea6\u3002", "result": "\u5f00\u53d1\u4e86T-FIX\u57fa\u51c6\u548c\u76f8\u5e94\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLM\u751f\u6210\u89e3\u91ca\u4e0e\u4e13\u5bb6\u5224\u65ad\u7684\u5bf9\u9f50\u6027\u3002", "conclusion": "\u4e13\u5bb6\u5bf9\u9f50\u5e94\u4f5c\u4e3a\u8bc4\u4f30\u89e3\u91ca\u7684\u91cd\u8981\u6807\u51c6\uff0cT-FIX\u57fa\u51c6\u4e3a\u8bc4\u4f30LLM\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u4e2d\u7684\u89e3\u91ca\u8d28\u91cf\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u6846\u67b6\u3002", "topic": "agent analysis"}}
{"id": "2511.04486", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04486", "abs": "https://arxiv.org/abs/2511.04486", "authors": ["Wayne Chi", "Valerie Chen", "Ryan Shar", "Aditya Mittal", "Jenny Liang", "Wei-Lin Chiang", "Anastasios Nikolas Angelopoulos", "Ion Stoica", "Graham Neubig", "Ameet Talwalkar", "Chris Donahue"], "title": "EDIT-Bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits", "comment": null, "summary": "Instructed code editing, where LLMs directly modify a developer's existing\ncode based on a user instruction, is becoming a widely used interaction mode in\nAI coding assistants. However, few benchmarks directly evaluate this capability\nand current datasets often rely on artificial sources. We introduce EDIT-Bench,\na benchmark for evaluating LLM code editing capabilities grounded in real-world\nusage, i.e., user instructions and code contexts collected in the wild.\nEDIT-Bench comprises of 545 problems, multiple natural and programming\nlanguages, and a diverse set of real-world use cases, ranging from resolving\nerrors to adding features. EDIT-Bench introduces context-dependent problems\nthat require the model to understand code context, highlighted code, and cursor\nposition in addition to the user instruction. We evaluate 40 diverse LLMs and\nobserve that EDIT-Bench is a challenging set of problems where only 5 models\nscore over 60%. We find that model performance varies across different\ncategories of user instructions. Further, we find that varying levels of\ncontextual information greatly affect task success rate, with performance\nvarying up to 11%, indicating the importance of evaluating with realistic\ncontext.", "AI": {"tldr": "EDIT-Bench\u662f\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u4f7f\u7528\u573a\u666f\u7684\u4ee3\u7801\u7f16\u8f91\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b545\u4e2a\u95ee\u9898\uff0c\u6db5\u76d6\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u548c\u7f16\u7a0b\u8bed\u8a00\uff0c\u8bc4\u4f30LLM\u5728\u7406\u89e3\u4ee3\u7801\u4e0a\u4e0b\u6587\u3001\u9ad8\u4eae\u4ee3\u7801\u548c\u5149\u6807\u4f4d\u7f6e\u7684\u57fa\u7840\u4e0a\u8fdb\u884c\u4ee3\u7801\u7f16\u8f91\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u76f4\u63a5\u8bc4\u4f30LLM\u4ee3\u7801\u7f16\u8f91\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u73b0\u6709\u6570\u636e\u96c6\u5f80\u5f80\u4f9d\u8d56\u4eba\u5de5\u6765\u6e90\uff0c\u9700\u8981\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u4f7f\u7528\u573a\u666f\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u6536\u96c6\u771f\u5b9e\u4e16\u754c\u7684\u7528\u6237\u6307\u4ee4\u548c\u4ee3\u7801\u4e0a\u4e0b\u6587\u6784\u5efaEDIT-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u591a\u79cd\u4f7f\u7528\u573a\u666f\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u95ee\u9898\uff0c\u8bc4\u4f3040\u4e2a\u4e0d\u540cLLM\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "EDIT-Bench\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53ea\u67095\u4e2a\u6a21\u578b\u5f97\u5206\u8d85\u8fc760%\uff0c\u6a21\u578b\u6027\u80fd\u5728\u4e0d\u540c\u7528\u6237\u6307\u4ee4\u7c7b\u522b\u95f4\u5dee\u5f02\u663e\u8457\uff0c\u4e0a\u4e0b\u6587\u4fe1\u606f\u91cf\u5bf9\u4efb\u52a1\u6210\u529f\u7387\u5f71\u54cd\u53ef\u8fbe11%\u3002", "conclusion": "\u4ee3\u7801\u7f16\u8f91\u8bc4\u4f30\u9700\u8981\u57fa\u4e8e\u771f\u5b9e\u4e0a\u4e0b\u6587\uff0cEDIT-Bench\u4e3a\u8bc4\u4f30LLM\u4ee3\u7801\u7f16\u8f91\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\uff0c\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u4efb\u52a1\u6210\u529f\u81f3\u5173\u91cd\u8981\u3002", "topic": "swe benchmark"}}
{"id": "2511.04235", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.04235", "abs": "https://arxiv.org/abs/2511.04235", "authors": ["Zhengru Fang", "Yu Guo", "Jingjing Wang", "Yuang Zhang", "Haonan An", "Yinhai Wang", "Yuguang Fang"], "title": "Shared Spatial Memory Through Predictive Coding", "comment": "We have prepared the open-source code and video demonstration pages:\n  1. Code: github.com/fangzr/SSM-PC 2. Demo: fangzr.github.io/SSM-PC/index.html", "summary": "Sharing and reconstructing a consistent spatial memory is a critical\nchallenge in multi-agent systems, where partial observability and limited\nbandwidth often lead to catastrophic failures in coordination. We introduce a\nmulti-agent predictive coding framework that formulate coordination as the\nminimization of mutual uncertainty among agents. Instantiated as an information\nbottleneck objective, it prompts agents to learn not only who and what to\ncommunicate but also when. At the foundation of this framework lies a\ngrid-cell-like metric as internal spatial coding for self-localization,\nemerging spontaneously from self-supervised motion prediction. Building upon\nthis internal spatial code, agents gradually develop a bandwidth-efficient\ncommunication mechanism and specialized neural populations that encode\npartners' locations: an artificial analogue of hippocampal social place cells\n(SPCs). These social representations are further enacted by a hierarchical\nreinforcement learning policy that actively explores to reduce joint\nuncertainty. On the Memory-Maze benchmark, our approach shows exceptional\nresilience to bandwidth constraints: success degrades gracefully from 73.5% to\n64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast\nbaseline collapses from 67.6% to 28.6%. Our findings establish a theoretically\nprincipled and biologically plausible basis for how complex social\nrepresentations emerge from a unified predictive drive, leading to social\ncollective intelligence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u9884\u6d4b\u7f16\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u76f8\u4e92\u4e0d\u786e\u5b9a\u6027\u6765\u534f\u8c03\u667a\u80fd\u4f53\u884c\u4e3a\uff0c\u5728\u5e26\u5bbd\u53d7\u9650\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7531\u4e8e\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u548c\u6709\u9650\u5e26\u5bbd\u5bfc\u81f4\u7684\u7a7a\u95f4\u8bb0\u5fc6\u5171\u4eab\u548c\u534f\u8c03\u5931\u8d25\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u76ee\u6807\u7684\u591a\u667a\u80fd\u4f53\u9884\u6d4b\u7f16\u7801\u6846\u67b6\uff0c\u7ed3\u5408\u7f51\u683c\u7ec6\u80de\u72b6\u5185\u90e8\u7a7a\u95f4\u7f16\u7801\u548c\u5206\u5c42\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u81ea\u53d1\u5f62\u6210\u5e26\u5bbd\u9ad8\u6548\u7684\u901a\u4fe1\u673a\u5236\u3002", "result": "\u5728Memory-Maze\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5f53\u5e26\u5bbd\u4ece128\u4f4d/\u6b65\u964d\u81f34\u4f4d/\u6b65\u65f6\uff0c\u6210\u529f\u7387\u4ece73.5%\u4f18\u96c5\u4e0b\u964d\u81f364.4%\uff0c\u800c\u5168\u5e7f\u64ad\u57fa\u7ebf\u4ece67.6%\u5d29\u6e83\u81f328.6%\u3002", "conclusion": "\u4e3a\u590d\u6742\u793e\u4f1a\u8868\u5f81\u5982\u4f55\u4ece\u7edf\u4e00\u7684\u9884\u6d4b\u9a71\u52a8\u4e2d\u6d8c\u73b0\u63d0\u4f9b\u4e86\u7406\u8bba\u539f\u5219\u548c\u751f\u7269\u5b66\u5408\u7406\u7684\u57fa\u7840\uff0c\u5b9e\u73b0\u4e86\u793e\u4f1a\u96c6\u4f53\u667a\u80fd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.04285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04285", "abs": "https://arxiv.org/abs/2511.04285", "authors": ["Zeng Zhiyuan", "Jiashuo Liu", "Zhangyue Yin", "Ge Zhang", "Wenhao Huang", "Xipeng Qiu"], "title": "RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization", "comment": null, "summary": "While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for\ntraining large reasoning models, its training dynamics harbor a critical\nchallenge: RL overfitting, where models gain training rewards but lose\ngeneralization. Our analysis reveals this is driven by policy\nover-specialization and catastrophic forgetting of diverse solutions generated\nduring training. Standard optimization discards this valuable inter-step policy\ndiversity. To address this, we introduce RLoop, a self-improving framework\nbuilt on iterative policy initialization. RLoop transforms the standard\ntraining process into a virtuous cycle: it first uses RL to explore the\nsolution space from a given policy, then filters the successful trajectories to\ncreate an expert dataset. This dataset is used via Rejection-sampling\nFine-Tuning (RFT) to refine the initial policy, creating a superior starting\npoint for the next iteration. This loop of exploration and exploitation via\niterative re-initialization effectively converts transient policy variations\ninto robust performance gains. Our experiments show RLoop mitigates forgetting\nand substantially improves generalization, boosting average accuracy by 9% and\npass@32 by over 15% compared to vanilla RL.", "AI": {"tldr": "RLoop\u662f\u4e00\u4e2a\u57fa\u4e8e\u8fed\u4ee3\u7b56\u7565\u521d\u59cb\u5316\u7684\u81ea\u6539\u8fdb\u6846\u67b6\uff0c\u901a\u8fc7\u63a2\u7d22-\u5229\u7528\u5faa\u73af\u5c06\u77ac\u65f6\u7b56\u7565\u53d8\u5316\u8f6c\u5316\u4e3a\u7a33\u5065\u6027\u80fd\u63d0\u5347\uff0c\u89e3\u51b3RL\u8bad\u7ec3\u4e2d\u7684\u8fc7\u62df\u5408\u548c\u707e\u96be\u6027\u9057\u5fd8\u95ee\u9898\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u53ef\u9a8c\u8bc1\u5956\u52b1\u8bad\u7ec3\u4e2d\u5b58\u5728\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u6a21\u578b\u83b7\u5f97\u8bad\u7ec3\u5956\u52b1\u4f46\u5931\u53bb\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u7531\u7b56\u7565\u8fc7\u5ea6\u4e13\u4e1a\u5316\u548c\u8bad\u7ec3\u671f\u95f4\u751f\u6210\u7684\u4e0d\u540c\u89e3\u51b3\u65b9\u6848\u7684\u707e\u96be\u6027\u9057\u5fd8\u9a71\u52a8\u3002", "method": "RLoop\u6846\u67b6\uff1a\u9996\u5148\u4f7f\u7528RL\u4ece\u7ed9\u5b9a\u7b56\u7565\u63a2\u7d22\u89e3\u7a7a\u95f4\uff0c\u7136\u540e\u8fc7\u6ee4\u6210\u529f\u8f68\u8ff9\u521b\u5efa\u4e13\u5bb6\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u62d2\u7edd\u91c7\u6837\u5fae\u8c03(RFT)\u6765\u6539\u8fdb\u521d\u59cb\u7b56\u7565\uff0c\u4e3a\u4e0b\u4e00\u6b21\u8fed\u4ee3\u521b\u5efa\u66f4\u597d\u7684\u8d77\u70b9\u3002", "result": "RLoop\u663e\u8457\u6539\u5584\u6cdb\u5316\u80fd\u529b\uff0c\u5e73\u5747\u51c6\u786e\u7387\u63d0\u53479%\uff0cpass@32\u63d0\u5347\u8d85\u8fc715%\uff0c\u76f8\u6bd4\u666e\u901aRL\u65b9\u6cd5\u3002", "conclusion": "RLoop\u901a\u8fc7\u8fed\u4ee3\u91cd\u65b0\u521d\u59cb\u5316\u7684\u63a2\u7d22-\u5229\u7528\u5faa\u73af\u6709\u6548\u7f13\u89e3\u9057\u5fd8\u95ee\u9898\uff0c\u5c06\u77ac\u65f6\u7b56\u7565\u53d8\u5316\u8f6c\u5316\u4e3a\u7a33\u5065\u6027\u80fd\u589e\u76ca\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.04307", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04307", "abs": "https://arxiv.org/abs/2511.04307", "authors": ["Jian Mu", "Chaoyun Zhang", "Chiming Ni", "Lu Wang", "Bo Qiao", "Kartik Mathur", "Qianhui Wu", "Yuhang Xie", "Xiaojun Ma", "Mengyu Zhou", "Si Qin", "Liqun Li", "Yu Kang", "Minghua Ma", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents", "comment": null, "summary": "We introduce GUI-360$^\\circ$, a large-scale, comprehensive dataset and\nbenchmark suite designed to advance computer-using agents (CUAs). CUAs present\nunique challenges and is constrained by three persistent gaps: a scarcity of\nreal-world CUA tasks, the lack of automated collection-and-annotation pipelines\nfor multi-modal trajectories, and the absence of a unified benchmark that\njointly evaluates GUI grounding, screen parsing, and action prediction.\n  GUI-360$^\\circ$ addresses these gaps with an LLM-augmented, largely automated\npipeline for query sourcing, environment-template construction, task\ninstantiation, batched execution, and LLM-driven quality filtering. The\nreleased corpus contains over 1.2M executed action steps across thousands of\ntrajectories in popular Windows office applications, and includes\nfull-resolution screenshots, accessibility metadata when available,\ninstantiated goals, intermediate reasoning traces, and both successful and\nfailed action trajectories. The dataset supports three canonical tasks, GUI\ngrounding, screen parsing, and action prediction, and a hybrid GUI+API action\nspace that reflects modern agent designs. Benchmarking state-of-the-art\nvision--language models on GUI-360$^\\circ$ reveals substantial out-of-the-box\nshortcomings in grounding and action prediction; supervised fine-tuning and\nreinforcement learning yield significant gains but do not close the gap to\nhuman-level reliability. We release GUI-360$^\\circ$ and accompanying code to\nfacilitate reproducible research and accelerate progress on robust desktop\nCUAs.\n  The full dataset has been made public on\nhttps://huggingface.co/datasets/vyokky/GUI-360.", "AI": {"tldr": "GUI-360\u00b0\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u57fa\u51c6\u5957\u4ef6\uff0c\u7528\u4e8e\u63a8\u8fdb\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u7684\u53d1\u5c55\uff0c\u5305\u542b\u8d85\u8fc7120\u4e07\u6267\u884c\u6b65\u9aa4\uff0c\u652f\u6301GUI\u5b9a\u4f4d\u3001\u5c4f\u5e55\u89e3\u6790\u548c\u52a8\u4f5c\u9884\u6d4b\u4e09\u4e2a\u6838\u5fc3\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u9762\u4e34\u7684\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u771f\u5b9e\u4e16\u754cCUA\u4efb\u52a1\u7a00\u7f3a\u3001\u591a\u6a21\u6001\u8f68\u8ff9\u81ea\u52a8\u6536\u96c6\u548c\u6807\u6ce8\u6d41\u7a0b\u7f3a\u4e4f\u3001\u4ee5\u53ca\u7f3a\u4e4f\u7edf\u4e00\u8bc4\u4f30GUI\u5b9a\u4f4d\u3001\u5c4f\u5e55\u89e3\u6790\u548c\u52a8\u4f5c\u9884\u6d4b\u7684\u57fa\u51c6\u3002", "method": "\u91c7\u7528LLM\u589e\u5f3a\u7684\u81ea\u52a8\u5316\u6d41\u7a0b\uff0c\u5305\u62ec\u67e5\u8be2\u6765\u6e90\u3001\u73af\u5883\u6a21\u677f\u6784\u5efa\u3001\u4efb\u52a1\u5b9e\u4f8b\u5316\u3001\u6279\u91cf\u6267\u884c\u548cLLM\u9a71\u52a8\u7684\u8d28\u91cf\u8fc7\u6ee4\uff0c\u5728Windows\u529e\u516c\u5e94\u7528\u4e2d\u6536\u96c6\u6570\u5343\u6761\u8f68\u8ff9\u6570\u636e\u3002", "result": "\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u73b0\u6709\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728GUI\u5b9a\u4f4d\u548c\u52a8\u4f5c\u9884\u6d4b\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u5e26\u6765\u663e\u8457\u6539\u8fdb\u4f46\u672a\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u53ef\u9760\u6027\u3002", "conclusion": "GUI-360\u00b0\u6570\u636e\u96c6\u548c\u4ee3\u7801\u5df2\u516c\u5f00\u53d1\u5e03\uff0c\u65e8\u5728\u4fc3\u8fdb\u53ef\u91cd\u590d\u7814\u7a76\u5e76\u52a0\u901f\u7a33\u5065\u684c\u9762CUAs\u7684\u53d1\u5c55\u3002", "topic": "swe benchmark"}}
{"id": "2511.04108", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04108", "abs": "https://arxiv.org/abs/2511.04108", "authors": ["Wenmo Qiu", "Saurabh Srivastava"], "title": "Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models", "comment": null, "summary": "Recent work has explored batch prompting as a strategy to amortize inference\ncost in large language models (LLMs). In this paper, we show that batching\noffers an additional, underappreciated benefit: it regularizes model behavior\nduring multi-step reasoning for Large Reasoning Models (LRMs). We conduct a\ncomprehensive study across 13 diverse benchmarks and observe that batching\nimproves accuracy while substantially reducing reasoning token usage, often by\n3x-5x. Through detailed behavioral analysis, we find that batching suppresses\noverthinking, reduces hedging language (e.g., repetitive self-corrections), and\nencourages more decisive answers. Surprisingly, we also observe emergent\ncollective effects in batched inference: models often generalize patterns from\nearlier examples to solve harder ones in the same batch. These findings\nposition batching not just as a throughput optimization, but as a powerful\ninference-time regularizer for more efficient and reliable LLM reasoning.", "AI": {"tldr": "\u6279\u5904\u7406\u63d0\u793a\u4e0d\u4ec5\u964d\u4f4e\u63a8\u7406\u6210\u672c\uff0c\u8fd8\u80fd\u4f5c\u4e3a\u63a8\u7406\u65f6\u6b63\u5219\u5316\u5668\uff0c\u63d0\u9ad8\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u51cf\u5c113-5\u500d\u7684\u63a8\u7406\u4ee4\u724c\u4f7f\u7528\u3002", "motivation": "\u63a2\u7d22\u6279\u5904\u7406\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u989d\u5916\u76ca\u5904\uff0c\u7279\u522b\u662f\u4f5c\u4e3a\u591a\u6b65\u63a8\u7406\u7684\u6b63\u5219\u5316\u673a\u5236\u3002", "method": "\u572813\u4e2a\u4e0d\u540c\u57fa\u51c6\u4e0a\u8fdb\u884c\u7684\u7efc\u5408\u7814\u7a76\uff0c\u901a\u8fc7\u884c\u4e3a\u5206\u6790\u8003\u5bdf\u6279\u5904\u7406\u5bf9\u6a21\u578b\u63a8\u7406\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "result": "\u6279\u5904\u7406\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u4ee4\u724c\u4f7f\u7528\uff08\u901a\u5e383-5\u500d\uff09\uff0c\u6291\u5236\u8fc7\u5ea6\u601d\u8003\uff0c\u51cf\u5c11\u72b9\u8c6b\u8bed\u8a00\uff0c\u4fc3\u8fdb\u66f4\u679c\u65ad\u7684\u56de\u7b54\uff0c\u5e76\u51fa\u73b0\u96c6\u4f53\u6548\u5e94\u3002", "conclusion": "\u6279\u5904\u7406\u4e0d\u4ec5\u662f\u541e\u5410\u91cf\u4f18\u5316\uff0c\u66f4\u662f\u5f3a\u5927\u7684\u63a8\u7406\u65f6\u6b63\u5219\u5316\u5668\uff0c\u53ef\u5b9e\u73b0\u66f4\u9ad8\u6548\u53ef\u9760\u7684LLM\u63a8\u7406\u3002", "topic": "agent analysis"}}
{"id": "2511.04153", "categories": ["cs.CL", "cs.AI", "cs.DB", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04153", "abs": "https://arxiv.org/abs/2511.04153", "authors": ["Fahim Ahmed", "Md Mubtasim Ahasan", "Jahir Sadik Monon", "Muntasir Wahed", "M Ashraful Amin", "A K M Mahbubur Rahman", "Amin Ahsan Ali"], "title": "BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation", "comment": null, "summary": "Text-to-SQL systems provide a natural language interface that can enable even\nlaymen to access information stored in databases. However, existing Large\nLanguage Models (LLM) struggle with SQL generation from natural instructions\ndue to large schema sizes and complex reasoning. Prior work often focuses on\ncomplex, somewhat impractical pipelines using flagship models, while smaller,\nefficient models remain overlooked. In this work, we explore three multi-agent\nLLM pipelines, with systematic performance benchmarking across a range of small\nto large open-source models: (1) Multi-agent discussion pipeline, where agents\niteratively critique and refine SQL queries, and a judge synthesizes the final\nanswer; (2) Planner-Coder pipeline, where a thinking model planner generates\nstepwise SQL generation plans and a coder synthesizes queries; and (3)\nCoder-Aggregator pipeline, where multiple coders independently generate SQL\nqueries, and a reasoning agent selects the best query. Experiments on the\nBird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small\nmodel performance, with up to 10.6% increase in Execution Accuracy for\nQwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines,\nthe LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B\nand QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest\nscore of 56.4%. Codes are available at\nhttps://github.com/treeDweller98/bappa-sql.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u4e09\u79cd\u591a\u4ee3\u7406LLM\u7ba1\u9053\u7528\u4e8eText-to-SQL\u4efb\u52a1\uff0c\u53d1\u73b0\u591a\u4ee3\u7406\u8ba8\u8bba\u80fd\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\uff0c\u5176\u4e2dLLM\u63a8\u7406\u5668-\u7f16\u7801\u5668\u7ba1\u9053\u6548\u679c\u6700\u4f73\uff0cDeepSeek-R1-32B\u548cQwQ-32B\u89c4\u5212\u5668\u5c06Gemma 3 27B IT\u7684\u51c6\u786e\u7387\u4ece52.4%\u63d0\u5347\u81f356.4%\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210SQL\u65f6\u9762\u4e34\u6a21\u5f0f\u89c4\u6a21\u5927\u548c\u590d\u6742\u63a8\u7406\u7684\u6311\u6218\uff0c\u5148\u524d\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u590d\u6742\u4e0d\u5b9e\u7528\u7684\u7ba1\u9053\uff0c\u800c\u5ffd\u7565\u4e86\u66f4\u5c0f\u3001\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u591a\u4ee3\u7406LLM\u7ba1\u9053\uff1a(1)\u591a\u4ee3\u7406\u8ba8\u8bba\u7ba1\u9053\uff0c\u4ee3\u7406\u8fed\u4ee3\u6279\u8bc4\u548c\u7cbe\u70bcSQL\u67e5\u8be2\uff1b(2)\u89c4\u5212\u5668-\u7f16\u7801\u5668\u7ba1\u9053\uff0c\u601d\u8003\u6a21\u578b\u89c4\u5212\u5668\u751f\u6210\u9010\u6b65SQL\u751f\u6210\u8ba1\u5212\uff1b(3)\u7f16\u7801\u5668-\u805a\u5408\u5668\u7ba1\u9053\uff0c\u591a\u4e2a\u7f16\u7801\u5668\u72ec\u7acb\u751f\u6210SQL\u67e5\u8be2\uff0c\u63a8\u7406\u4ee3\u7406\u9009\u62e9\u6700\u4f73\u67e5\u8be2\u3002", "result": "\u5728Bird-Bench Mini-Dev\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0c\u591a\u4ee3\u7406\u8ba8\u8bba\u80fd\u63d0\u5347\u5c0f\u6a21\u578b\u6027\u80fd\uff0cQwen2.5-7b-Instruct\u7ecf\u8fc7\u4e09\u8f6e\u8ba8\u8bba\u540e\u6267\u884c\u51c6\u786e\u7387\u63d0\u534710.6%\u3002LLM\u63a8\u7406\u5668-\u7f16\u7801\u5668\u7ba1\u9053\u6548\u679c\u6700\u4f73\uff0cDeepSeek-R1-32B\u548cQwQ-32B\u89c4\u5212\u5668\u5c06Gemma 3 27B IT\u51c6\u786e\u7387\u4ece52.4%\u63d0\u5347\u81f356.4%\u3002", "conclusion": "\u591a\u4ee3\u7406\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347Text-to-SQL\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u8f83\u5c0f\u6a21\u578b\uff0c\u5176\u4e2d\u89c4\u5212\u5668-\u7f16\u7801\u5668\u7ba1\u9053\u8868\u73b0\u6700\u4f73\u3002", "topic": "agent analysis"}}
{"id": "2511.04439", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04439", "abs": "https://arxiv.org/abs/2511.04439", "authors": ["Anisha Garg", "Ganesh Venkatesh"], "title": "The Peril of Preference: Why GRPO fails on Ordinal Rewards", "comment": null, "summary": "Group-relative Policy Optimization's (GRPO) simplicity makes it highly\ndesirable for adapting LLMs to become experts at specific tasks. But this\nsimplicity also makes it ill-specified as we seek to enhance RL training with\nricher, non-binary feedback. When using ordinal rewards to give partial credit,\nGRPO's simplicity starts to hurt, as its group-average baseline often assigns a\npositive advantage to failed trajectories and reinforces incorrect behavior.\n  We introduce Correctness Relative Policy Optimization (CoRPO), a new\nformulation that solves this flaw. CoRPO uses an adaptive baseline that\nenforces a minimum quality threshold, ensuring failed solutions are never\npositively reinforced. Once the policy consistently meets this threshold, the\nbaseline automatically transitions to a relative preference mode, pushing the\nmodel to find optimal solutions rather than just \"acceptable\" ones. We\nempirically validate CoRPO on a code verification task, where it demonstrates\nmore stable convergence and better out-of-domain generalization.\n  This work represents a critical step in our broader research program to\nenable LLMs to learn genuinely new capabilities through reinforcement learning.\nWe achieve this by enabling LLMs to learn from rich, multi-dimensional feedback\n- progressing from binary to ordinal rewards in this work, and onward to\ndenser, per-step supervision.", "AI": {"tldr": "CoRPO\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86GRPO\u5728\u4f7f\u7528\u5e8f\u6570\u5956\u52b1\u65f6\u5bf9\u5931\u8d25\u8f68\u8ff9\u9519\u8bef\u5f3a\u5316\u7684\u95ee\u9898\u3002\u5b83\u4f7f\u7528\u81ea\u9002\u5e94\u57fa\u7ebf\u786e\u4fdd\u5931\u8d25\u89e3\u51b3\u65b9\u6848\u4e0d\u88ab\u6b63\u5411\u5f3a\u5316\uff0c\u5e76\u5728\u8fbe\u5230\u8d28\u91cf\u9608\u503c\u540e\u81ea\u52a8\u5207\u6362\u5230\u76f8\u5bf9\u504f\u597d\u6a21\u5f0f\u3002", "motivation": "GRPO\u7684\u7b80\u5355\u6027\u4f7f\u5176\u5728\u9002\u5e94LLMs\u65f6\u5f88\u53d7\u6b22\u8fce\uff0c\u4f46\u5728\u4f7f\u7528\u5e8f\u6570\u5956\u52b1\u63d0\u4f9b\u90e8\u5206\u4fe1\u7528\u65f6\u5b58\u5728\u95ee\u9898\uff0c\u56e0\u4e3a\u5176\u7ec4\u5e73\u5747\u57fa\u7ebf\u7ecf\u5e38\u5bf9\u5931\u8d25\u8f68\u8ff9\u5206\u914d\u6b63\u4f18\u52bf\uff0c\u4ece\u800c\u5f3a\u5316\u9519\u8bef\u884c\u4e3a\u3002", "method": "CoRPO\u4f7f\u7528\u81ea\u9002\u5e94\u57fa\u7ebf\u5f3a\u5236\u6267\u884c\u6700\u4f4e\u8d28\u91cf\u9608\u503c\uff0c\u786e\u4fdd\u5931\u8d25\u89e3\u51b3\u65b9\u6848\u6c38\u8fdc\u4e0d\u4f1a\u88ab\u6b63\u5411\u5f3a\u5316\u3002\u4e00\u65e6\u7b56\u7565\u6301\u7eed\u8fbe\u5230\u6b64\u9608\u503c\uff0c\u57fa\u7ebf\u81ea\u52a8\u8fc7\u6e21\u5230\u76f8\u5bf9\u504f\u597d\u6a21\u5f0f\u3002", "result": "\u5728\u4ee3\u7801\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u8868\u660e\uff0cCoRPO\u8868\u73b0\u51fa\u66f4\u7a33\u5b9a\u7684\u6536\u655b\u6027\u548c\u66f4\u597d\u7684\u57df\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u8ba9LLMs\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5b66\u4e60\u771f\u6b63\u65b0\u80fd\u529b\u7684\u5173\u952e\u6b65\u9aa4\uff0c\u901a\u8fc7\u4f7fLLMs\u80fd\u591f\u4ece\u4e30\u5bcc\u7684\u591a\u7ef4\u53cd\u9988\u4e2d\u5b66\u4e60\u6765\u5b9e\u73b0\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.04464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04464", "abs": "https://arxiv.org/abs/2511.04464", "authors": ["Carnot Braun", "Rafael O. Jarczewski", "Gabriel U. Talasso", "Leandro A. Villas", "Allan M. de Souza"], "title": "Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context", "comment": null, "summary": "Traditional vehicle routing systems efficiently optimize singular metrics\nlike time or distance, and when considering multiple metrics, they need more\nprocesses to optimize . However, they lack the capability to interpret and\nintegrate the complex, semantic, and dynamic contexts of human drivers, such as\nmulti-step tasks, situational constraints, or urgent needs. This paper\nintroduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a\nhybrid agentic assistant designed to augment classical pathfinding algorithms\nwith contextual reasoning. Our approach employs a Large Language Model (LLM)\nagent that operates on a candidate set of routes generated by a multi-objective\n(time, CO2) Dijkstra algorithm. The agent evaluates these options against\nuser-provided tasks, preferences, and avoidance rules by leveraging a\npre-processed geospatial cache of urban Points of Interest (POIs). In a\nbenchmark of realistic urban scenarios, PAVe successfully used complex user\nintent into appropriate route modifications, achieving over 88% accuracy in its\ninitial route selections with a local model. We conclude that combining\nclassical routing algorithms with an LLM-based semantic reasoning layer is a\nrobust and effective approach for creating personalized, adaptive, and scalable\nsolutions for urban mobility optimization.", "AI": {"tldr": "PAVe\u7cfb\u7edf\u5c06\u7ecf\u5178\u8def\u5f84\u89c4\u5212\u7b97\u6cd5\u4e0eLLM\u8bed\u4e49\u63a8\u7406\u76f8\u7ed3\u5408\uff0c\u901a\u8fc7\u591a\u76ee\u6807Dijkstra\u7b97\u6cd5\u751f\u6210\u5019\u9009\u8def\u7ebf\uff0c\u518d\u7531LLM\u4ee3\u7406\u6839\u636e\u7528\u6237\u4efb\u52a1\u3001\u504f\u597d\u548c\u89c4\u907f\u89c4\u5219\u8fdb\u884c\u8bed\u4e49\u8bc4\u4f30\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u8f66\u8f86\u8def\u7531\u4f18\u5316\u3002", "motivation": "\u4f20\u7edf\u8f66\u8f86\u8def\u7531\u7cfb\u7edf\u53ea\u80fd\u4f18\u5316\u5355\u4e00\u6307\u6807\uff08\u5982\u65f6\u95f4\u6216\u8ddd\u79bb\uff09\uff0c\u7f3a\u4e4f\u5bf9\u9a7e\u9a76\u5458\u590d\u6742\u8bed\u4e49\u548c\u52a8\u6001\u4e0a\u4e0b\u6587\uff08\u5982\u591a\u6b65\u9aa4\u4efb\u52a1\u3001\u60c5\u5883\u7ea6\u675f\u3001\u7d27\u6025\u9700\u6c42\uff09\u7684\u7406\u89e3\u548c\u6574\u5408\u80fd\u529b\u3002", "method": "\u91c7\u7528\u6df7\u5408\u4ee3\u7406\u65b9\u6cd5\uff1a\u591a\u76ee\u6807\uff08\u65f6\u95f4\u3001CO2\uff09Dijkstra\u7b97\u6cd5\u751f\u6210\u5019\u9009\u8def\u7ebf\uff0cLLM\u4ee3\u7406\u57fa\u4e8e\u9884\u5904\u7406\u7684\u5730\u7406\u7a7a\u95f4POI\u7f13\u5b58\uff0c\u8bc4\u4f30\u8def\u7ebf\u662f\u5426\u7b26\u5408\u7528\u6237\u63d0\u4f9b\u7684\u4efb\u52a1\u3001\u504f\u597d\u548c\u89c4\u907f\u89c4\u5219\u3002", "result": "\u5728\u73b0\u5b9e\u57ce\u5e02\u573a\u666f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPAVe\u6210\u529f\u5c06\u590d\u6742\u7528\u6237\u610f\u56fe\u8f6c\u5316\u4e3a\u9002\u5f53\u7684\u8def\u7ebf\u4fee\u6539\uff0c\u4f7f\u7528\u672c\u5730\u6a21\u578b\u65f6\u521d\u59cb\u8def\u7ebf\u9009\u62e9\u51c6\u786e\u7387\u8d85\u8fc788%\u3002", "conclusion": "\u5c06\u7ecf\u5178\u8def\u7531\u7b97\u6cd5\u4e0e\u57fa\u4e8eLLM\u7684\u8bed\u4e49\u63a8\u7406\u5c42\u76f8\u7ed3\u5408\uff0c\u662f\u521b\u5efa\u4e2a\u6027\u5316\u3001\u81ea\u9002\u5e94\u548c\u53ef\u6269\u5c55\u57ce\u5e02\u79fb\u52a8\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u7684\u7a33\u5065\u6709\u6548\u65b9\u6cd5\u3002", "topic": "agent analysis"}}
{"id": "2511.04195", "categories": ["cs.CL", "cs.MA", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.04195", "abs": "https://arxiv.org/abs/2511.04195", "authors": ["Nicol\u00f2 Pagan", "Petter T\u00f6rnberg", "Christopher A. Bail", "Anik\u00f3 Hann\u00e1k", "Christopher Barrie"], "title": "Computational Turing Test Reveals Systematic Differences Between Human and AI Language", "comment": null, "summary": "Large language models (LLMs) are increasingly used in the social sciences to\nsimulate human behavior, based on the assumption that they can generate\nrealistic, human-like text. Yet this assumption remains largely untested.\nExisting validation efforts rely heavily on human-judgment-based evaluations --\ntesting whether humans can distinguish AI from human output -- despite evidence\nthat such judgments are blunt and unreliable. As a result, the field lacks\nrobust tools for assessing the realism of LLM-generated text or for calibrating\nmodels to real-world data. This paper makes two contributions. First, we\nintroduce a computational Turing test: a validation framework that integrates\naggregate metrics (BERT-based detectability and semantic similarity) with\ninterpretable linguistic features (stylistic markers and topical patterns) to\nassess how closely LLMs approximate human language within a given dataset.\nSecond, we systematically compare nine open-weight LLMs across five calibration\nstrategies -- including fine-tuning, stylistic prompting, and context retrieval\n-- benchmarking their ability to reproduce user interactions on X (formerly\nTwitter), Bluesky, and Reddit. Our findings challenge core assumptions in the\nliterature. Even after calibration, LLM outputs remain clearly distinguishable\nfrom human text, particularly in affective tone and emotional expression.\nInstruction-tuned models underperform their base counterparts, and scaling up\nmodel size does not enhance human-likeness. Crucially, we identify a trade-off:\noptimizing for human-likeness often comes at the cost of semantic fidelity, and\nvice versa. These results provide a much-needed scalable framework for\nvalidation and calibration in LLM simulations -- and offer a cautionary note\nabout their current limitations in capturing human communication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8ba1\u7b97\u56fe\u7075\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u751f\u6210\u6587\u672c\u7684\u4eba\u7c7b\u76f8\u4f3c\u5ea6\uff0c\u5e76\u5728\u591a\u4e2a\u793e\u4ea4\u5a92\u4f53\u5e73\u53f0\u4e0a\u7cfb\u7edf\u6bd4\u8f83\u4e869\u4e2a\u5f00\u6e90LLM\u7684\u6821\u51c6\u7b56\u7565\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u793e\u4f1a\u79d1\u5b66\u4e2d\u4f7f\u7528LLM\u6a21\u62df\u4eba\u7c7b\u884c\u4e3a\u65f6\uff0c\u7f3a\u4e4f\u53ef\u9760\u7684\u9a8c\u8bc1\u5de5\u5177\u6765\u8bc4\u4f30\u751f\u6210\u6587\u672c\u7684\u771f\u5b9e\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e0d\u53ef\u9760\u7684\u4eba\u5de5\u5224\u65ad\u3002", "method": "\u5f00\u53d1\u4e86\u96c6\u6210\u805a\u5408\u6307\u6807\uff08BERT\u68c0\u6d4b\u6027\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff09\u4e0e\u53ef\u89e3\u91ca\u8bed\u8a00\u7279\u5f81\uff08\u98ce\u683c\u6807\u8bb0\u548c\u4e3b\u9898\u6a21\u5f0f\uff09\u7684\u8ba1\u7b97\u56fe\u7075\u6d4b\u8bd5\u6846\u67b6\uff0c\u5e76\u6bd4\u8f83\u4e869\u4e2aLLM\u57285\u79cd\u6821\u51c6\u7b56\u7565\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5373\u4f7f\u7ecf\u8fc7\u6821\u51c6\uff0cLLM\u8f93\u51fa\u4ecd\u660e\u663e\u53ef\u533a\u5206\u4e8e\u4eba\u7c7b\u6587\u672c\uff0c\u7279\u522b\u662f\u5728\u60c5\u611f\u8bed\u8c03\u65b9\u9762\uff1b\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u8868\u73b0\u4e0d\u5982\u57fa\u7840\u6a21\u578b\uff1b\u6a21\u578b\u89c4\u6a21\u6269\u5927\u4e0d\u63d0\u5347\u4eba\u7c7b\u76f8\u4f3c\u5ea6\uff1b\u5b58\u5728\u4eba\u7c7b\u76f8\u4f3c\u5ea6\u4e0e\u8bed\u4e49\u4fdd\u771f\u5ea6\u7684\u6743\u8861\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u9a8c\u8bc1\u548c\u6821\u51c6\u6846\u67b6\uff0c\u540c\u65f6\u8b66\u793a\u5f53\u524dLLM\u5728\u6355\u6349\u4eba\u7c7b\u4ea4\u6d41\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "topic": "agent analysis"}}
{"id": "2511.04481", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04481", "abs": "https://arxiv.org/abs/2511.04481", "authors": ["Lars Krupp", "Daniel Gei\u00dfler", "Vishal Banwari", "Paul Lukowicz", "Jakob Karolus"], "title": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis", "comment": "Accepted by AAAI 2026 AISI", "summary": "Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful\nagentic systems pushing the boundaries of Large Language Models (LLM). They can\nautonomously interact with the internet at the user's behest, such as\nnavigating websites, filling search masks, and comparing price lists. Though\nweb agent research is thriving, induced sustainability issues remain largely\nunexplored. To highlight the urgency of this issue, we provide an initial\nexploration of the energy and $CO_2$ cost associated with web agents from both\na theoretical -via estimation- and an empirical perspective -by benchmarking.\nOur results show how different philosophies in web agent creation can severely\nimpact the associated expended energy, and that more energy consumed does not\nnecessarily equate to better results. We highlight a lack of transparency\nregarding disclosing model parameters and processes used for some web agents as\na limiting factor when estimating energy consumption. Our work contributes\ntowards a change in thinking of how we evaluate web agents, advocating for\ndedicated metrics measuring energy consumption in benchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u4ece\u7406\u8bba\u548c\u5b9e\u8bc1\u89d2\u5ea6\u63a2\u8ba8\u4e86\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u6e90\u6d88\u8017\u548c\u78b3\u6392\u653e\u95ee\u9898\uff0c\u53d1\u73b0\u4e0d\u540c\u7f51\u7edc\u4ee3\u7406\u8bbe\u8ba1\u7406\u5ff5\u5bf9\u80fd\u8017\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u80fd\u8017\u4e0e\u6027\u80fd\u4e0d\u4e00\u5b9a\u6210\u6b63\u6bd4\u3002", "motivation": "\u5f53\u524d\u7f51\u7edc\u4ee3\u7406\u7814\u7a76\u84ec\u52c3\u53d1\u5c55\uff0c\u4f46\u5176\u5f15\u53d1\u7684\u53ef\u6301\u7eed\u6027\u95ee\u9898\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u4f5c\u8005\u65e8\u5728\u63ed\u793a\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u6e90\u548c\u78b3\u6392\u653e\u6210\u672c\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53ef\u6301\u7eed\u6027\u8003\u91cf\u3002", "method": "\u91c7\u7528\u7406\u8bba\u4f30\u8ba1\u548c\u5b9e\u8bc1\u57fa\u51c6\u6d4b\u8bd5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e0d\u540c\u7f51\u7edc\u4ee3\u7406\u7684\u80fd\u8017\u8868\u73b0\uff0c\u5e76\u8bc4\u4f30\u6a21\u578b\u53c2\u6570\u548c\u8fc7\u7a0b\u900f\u660e\u5ea6\u5bf9\u80fd\u8017\u4f30\u7b97\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u663e\u793a\u4e0d\u540c\u7f51\u7edc\u4ee3\u7406\u8bbe\u8ba1\u7406\u5ff5\u4f1a\u4e25\u91cd\u5f71\u54cd\u80fd\u8017\uff0c\u80fd\u8017\u589e\u52a0\u4e0d\u4e00\u5b9a\u5e26\u6765\u66f4\u597d\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u53d1\u73b0\u67d0\u4e9b\u7f51\u7edc\u4ee3\u7406\u7f3a\u4e4f\u6a21\u578b\u53c2\u6570\u548c\u8fc7\u7a0b\u900f\u660e\u5ea6\uff0c\u9650\u5236\u4e86\u80fd\u8017\u4f30\u7b97\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u9700\u8981\u6539\u53d8\u7f51\u7edc\u4ee3\u7406\u8bc4\u4f30\u65b9\u5f0f\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u52a0\u5165\u4e13\u95e8\u7684\u80fd\u8017\u6307\u6807\uff0c\u63a8\u52a8\u7f51\u7edc\u4ee3\u7406\u7814\u7a76\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002", "topic": "agent analysis"}}
{"id": "2511.04205", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04205", "abs": "https://arxiv.org/abs/2511.04205", "authors": ["Micha\u0142 Karp", "Anna Kubaszewska", "Magdalena Kr\u00f3l", "Robert Kr\u00f3l", "Aleksander Smywi\u0144ski-Pohl", "Mateusz Szyma\u0144ski", "Witold Wydma\u0144ski"], "title": "LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal", "comment": null, "summary": "This study provides an empirical assessment of whether current large language\nmodels (LLMs) can pass the official qualifying examination for membership in\nPoland's National Appeal Chamber (Krajowa Izba Odwo{\\l}awcza). The authors\nexamine two related ideas: using LLM as actual exam candidates and applying the\n'LLM-as-a-judge' approach, in which model-generated answers are automatically\nevaluated by other models. The paper describes the structure of the exam, which\nincludes a multiple-choice knowledge test on public procurement law and a\nwritten judgment, and presents the hybrid information recovery and extraction\npipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4\nSonnet and Bielik-11B-v2.6) were tested in closed-book and various\nRetrieval-Augmented Generation settings. The results show that although the\nmodels achieved satisfactory scores in the knowledge test, none met the passing\nthreshold in the practical written part, and the evaluations of the\n'LLM-as-a-judge' often diverged from the judgments of the official examining\ncommittee. The authors highlight key limitations: susceptibility to\nhallucinations, incorrect citation of legal provisions, weaknesses in logical\nargumentation, and the need for close collaboration between legal experts and\ntechnical teams. The findings indicate that, despite rapid technological\nprogress, current LLMs cannot yet replace human judges or independent examiners\nin Polish public procurement adjudication.", "AI": {"tldr": "\u8bc4\u4f30\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u901a\u8fc7\u6ce2\u5170\u56fd\u5bb6\u4e0a\u8bc9\u5ead\u8d44\u683c\u8003\u8bd5\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u6d4b\u8bd5\u4e86\u6a21\u578b\u4f5c\u4e3a\u8003\u751f\u548c\u81ea\u52a8\u8bc4\u5206\u8005\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u77e5\u8bc6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u5b9e\u8df5\u5199\u4f5c\u90e8\u5206\u5747\u672a\u901a\u8fc7\uff0c\u4e14\u81ea\u52a8\u8bc4\u5206\u4e0e\u5b98\u65b9\u8bc4\u5ba1\u5b58\u5728\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u4e13\u4e1a\u8d44\u683c\u8003\u8bd5\u4e2d\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u63a2\u7d22\u5176\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u4f5c\u4e3a\u8003\u751f\u548c\u81ea\u52a8\u8bc4\u5206\u8005\u7684\u53ef\u884c\u6027\u3002", "method": "\u6784\u5efa\u4e86\u6df7\u5408\u4fe1\u606f\u68c0\u7d22\u548c\u63d0\u53d6\u7ba1\u9053\uff0c\u6d4b\u8bd5\u4e86GPT-4.1\u3001Claude 4 Sonnet\u548cBielik-11B-v2.6\u7b49\u6a21\u578b\u5728\u95ed\u5377\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8bbe\u7f6e\u4e0b\u7684\u8868\u73b0\uff0c\u5305\u62ec\u591a\u9879\u9009\u62e9\u77e5\u8bc6\u6d4b\u8bd5\u548c\u4e66\u9762\u5224\u51b3\u5199\u4f5c\u3002", "result": "\u6a21\u578b\u5728\u77e5\u8bc6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u6ee1\u610f\u5206\u6570\uff0c\u4f46\u5728\u5b9e\u8df5\u5199\u4f5c\u90e8\u5206\u5747\u672a\u8fbe\u5230\u53ca\u683c\u7ebf\uff0cLLM\u4f5c\u4e3a\u8bc4\u5206\u8005\u7684\u8bc4\u4f30\u4e0e\u5b98\u65b9\u8bc4\u5ba1\u59d4\u5458\u4f1a\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u5c3d\u7ba1\u6280\u672f\u8fdb\u6b65\u8fc5\u901f\uff0c\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5c1a\u65e0\u6cd5\u5728\u6ce2\u5170\u516c\u5171\u91c7\u8d2d\u88c1\u51b3\u4e2d\u66ff\u4ee3\u4eba\u7c7b\u6cd5\u5b98\u6216\u72ec\u7acb\u8003\u5b98\uff0c\u5b58\u5728\u5e7b\u89c9\u3001\u6cd5\u5f8b\u6761\u6b3e\u5f15\u7528\u9519\u8bef\u3001\u903b\u8f91\u8bba\u8bc1\u8584\u5f31\u7b49\u95ee\u9898\u3002", "topic": "agent analysis"}}
{"id": "2511.04583", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04583", "abs": "https://arxiv.org/abs/2511.04583", "authors": ["Atsuyuki Miyai", "Mashiro Toyooka", "Takashi Otonari", "Zaiying Zhao", "Kiyoharu Aizawa"], "title": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper", "comment": "Issues, comments, and questions are all welcome in\n  https://github.com/Agent4Science-UTokyo/Jr.AI-Scientist", "summary": "Understanding the current capabilities and risks of AI Scientist systems is\nessential for ensuring trustworthy and sustainable AI-driven scientific\nprogress while preserving the integrity of the academic ecosystem. To this end,\nwe develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system\nthat mimics the core research workflow of a novice student researcher: Given\nthe baseline paper from the human mentor, it analyzes its limitations,\nformulates novel hypotheses for improvement, validates them through rigorous\nexperimentation, and writes a paper with the results. Unlike previous\napproaches that assume full automation or operate on small-scale code, Jr. AI\nScientist follows a well-defined research workflow and leverages modern coding\nagents to handle complex, multi-file implementations, leading to scientifically\nvaluable contributions. For evaluation, we conducted automated assessments\nusing AI Reviewers, author-led evaluations, and submissions to Agents4Science,\na venue dedicated to AI-driven scientific contributions. The findings\ndemonstrate that Jr. AI Scientist generates papers receiving higher review\nscores than existing fully automated systems. Nevertheless, we identify\nimportant limitations from both the author evaluation and the Agents4Science\nreviews, indicating the potential risks of directly applying current AI\nScientist systems and key challenges for future research. Finally, we\ncomprehensively report various risks identified during development. We hope\nthese insights will deepen understanding of current progress and risks in AI\nScientist development.", "AI": {"tldr": "\u5f00\u53d1\u4e86Jr. AI Scientist\u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u6a21\u62df\u5b66\u751f\u7814\u7a76\u6d41\u7a0b\u7684\u81ea\u4e3bAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\uff0c\u80fd\u591f\u5206\u6790\u8bba\u6587\u5c40\u9650\u6027\u3001\u63d0\u51fa\u5047\u8bbe\u3001\u5b9e\u9a8c\u9a8c\u8bc1\u5e76\u64b0\u5199\u8bba\u6587\uff0c\u5728\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5168\u81ea\u52a8\u7cfb\u7edf\uff0c\u4f46\u4ecd\u6709\u91cd\u8981\u5c40\u9650\u6027\u3002", "motivation": "\u7406\u89e3AI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u7684\u5f53\u524d\u80fd\u529b\u548c\u98ce\u9669\u5bf9\u4e8e\u786e\u4fdd\u53ef\u4fe1\u8d56\u548c\u53ef\u6301\u7eed\u7684AI\u9a71\u52a8\u79d1\u5b66\u8fdb\u6b65\u81f3\u5173\u91cd\u8981\uff0c\u540c\u65f6\u4fdd\u62a4\u5b66\u672f\u751f\u6001\u7cfb\u7edf\u7684\u5b8c\u6574\u6027\u3002", "method": "\u5f00\u53d1Jr. AI Scientist\u7cfb\u7edf\uff0c\u6a21\u62df\u5b66\u751f\u7814\u7a76\u6d41\u7a0b\uff1a\u5206\u6790\u57fa\u7ebf\u8bba\u6587\u5c40\u9650\u6027\u3001\u5236\u5b9a\u6539\u8fdb\u5047\u8bbe\u3001\u901a\u8fc7\u4e25\u683c\u5b9e\u9a8c\u9a8c\u8bc1\u3001\u64b0\u5199\u7ed3\u679c\u8bba\u6587\uff0c\u5229\u7528\u73b0\u4ee3\u7f16\u7801\u4ee3\u7406\u5904\u7406\u590d\u6742\u591a\u6587\u4ef6\u5b9e\u73b0\u3002", "result": "Jr. AI Scientist\u751f\u6210\u7684\u8bba\u6587\u83b7\u5f97\u6bd4\u73b0\u6709\u5168\u81ea\u52a8\u7cfb\u7edf\u66f4\u9ad8\u7684\u8bc4\u5ba1\u5206\u6570\uff0c\u4f46\u4f5c\u8005\u8bc4\u4f30\u548cAgents4Science\u8bc4\u5ba1\u5747\u53d1\u73b0\u91cd\u8981\u5c40\u9650\u6027\u3002", "conclusion": "\u5f53\u524dAI\u79d1\u5b66\u5bb6\u7cfb\u7edf\u5b58\u5728\u76f4\u63a5\u5e94\u7528\u7684\u98ce\u9669\u548c\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u89e3\u51b3\u5df2\u8bc6\u522b\u7684\u5404\u79cd\u98ce\u9669\u3002", "topic": "agent analysis"}}
{"id": "2511.04432", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04432", "abs": "https://arxiv.org/abs/2511.04432", "authors": ["Lars Bungum", "Charles Yijia Huang", "Abeer Kashar"], "title": "If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning Task for LLMs", "comment": "8 pages, 1 figure, 3 tables, submitted to aconference", "summary": "In this study, we experiment with the ability of LLMs to do temporal\nreasoning. Using a Norwegian book from 1940 containing trivia questions, we\nprompt the LLMs to answer the questions as if it were 1940. We also pose the\nquestions in both English and Norwegian. Correct answers are often presented as\nsentences, and grading is done by means of LLM-as-judge, with sampled checks by\na native speaker. Prompting in English consistently gave better results than in\nNorwegian, an unexpected result. In contrast, using larger LLMs improved\nresults. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families,\nand also the largest available LLM especially crafted for Norwegian.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLMs\u5728\u65f6\u95f4\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4f7f\u75281940\u5e74\u632a\u5a01\u4e66\u7c4d\u4e2d\u7684\u7410\u4e8b\u95ee\u9898\uff0c\u6d4b\u8bd5LLMs\u4ee51940\u5e74\u7684\u77e5\u8bc6\u6c34\u5e73\u56de\u7b54\u95ee\u9898\uff0c\u5e76\u6bd4\u8f83\u4e86\u82f1\u8bed\u548c\u632a\u5a01\u8bed\u63d0\u793a\u7684\u6548\u679c\u3002", "motivation": "\u63a2\u7d22LLMs\u5728\u65f6\u95f4\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u6d4b\u8bd5\u5b83\u4eec\u80fd\u5426\u57fa\u4e8e\u5386\u53f2\u77e5\u8bc6\u56de\u7b54\u95ee\u9898\uff0c\u5e76\u6bd4\u8f83\u4e0d\u540c\u8bed\u8a00\u63d0\u793a\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u75281940\u5e74\u632a\u5a01\u4e66\u7c4d\u4e2d\u7684\u7410\u4e8b\u95ee\u9898\uff0c\u8ba9LLMs\u4ee51940\u5e74\u7684\u89c6\u89d2\u56de\u7b54\u95ee\u9898\uff0c\u6d4b\u8bd5\u4e86\u82f1\u8bed\u548c\u632a\u5a01\u8bed\u4e24\u79cd\u8bed\u8a00\u63d0\u793a\uff0c\u5e76\u91c7\u7528LLM-as-judge\u548c\u4eba\u5de5\u68c0\u67e5\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\u8fdb\u884c\u8bc4\u5206\u3002", "result": "\u82f1\u8bed\u63d0\u793a\u7684\u7ed3\u679c\u59cb\u7ec8\u4f18\u4e8e\u632a\u5a01\u8bed\u63d0\u793a\uff0c\u8fd9\u662f\u4e00\u4e2a\u610f\u5916\u7684\u53d1\u73b0\u3002\u540c\u65f6\uff0c\u4f7f\u7528\u66f4\u5927\u7684LLM\u6a21\u578b\u80fd\u591f\u6539\u5584\u7ed3\u679c\u3002\u6d4b\u8bd5\u4e86DeepSeek-R1\u3001Gemma3\u3001Qwen3\u548cLlama3.1\u7b49\u6a21\u578b\u7cfb\u5217\uff0c\u4ee5\u53ca\u4e13\u95e8\u4e3a\u632a\u5a01\u8bed\u8bbe\u8ba1\u7684\u6700\u5927\u7684LLM\u3002", "conclusion": "LLMs\u5728\u65f6\u95f4\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u4e00\u5b9a\u7684\u80fd\u529b\uff0c\u4f46\u8bed\u8a00\u9009\u62e9\u5bf9\u7ed3\u679c\u6709\u663e\u8457\u5f71\u54cd\uff0c\u82f1\u8bed\u63d0\u793a\u6548\u679c\u66f4\u597d\uff0c\u6a21\u578b\u89c4\u6a21\u4e5f\u662f\u5f71\u54cd\u6027\u80fd\u7684\u91cd\u8981\u56e0\u7d20\u3002", "topic": "agent analysis"}}
{"id": "2511.04499", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04499", "abs": "https://arxiv.org/abs/2511.04499", "authors": ["Christos-Nikolaos Zacharopoulos", "Revekka Kyriakoglou"], "title": "Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering", "comment": "Accepted at IJCNLP-AACL 2025", "summary": "As Large Language Models (LLMs) become integral to human-centered\napplications, understanding their personality-like behaviors is increasingly\nimportant for responsible development and deployment. This paper systematically\nevaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to\nassess trait expressions under varying sampling temperatures. We find\nsignificant differences across four of the five personality dimensions, with\nNeuroticism and Extraversion susceptible to temperature adjustments. Further,\nhierarchical clustering reveals distinct model clusters, suggesting that\narchitectural features may predispose certain models toward stable trait\nprofiles. Taken together, these results offer new insights into the emergence\nof personality-like patterns in LLMs and provide a new perspective on model\ntuning, selection, and the ethical governance of AI systems. We share the data\nand code for this analysis here:\nhttps://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e866\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728BFI-2\u4eba\u683c\u6846\u67b6\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u5728\u4eba\u683c\u7ef4\u5ea6\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u795e\u7ecf\u8d28\u548c\u5916\u5411\u6027\u5bf9\u6e29\u5ea6\u53c2\u6570\u654f\u611f\uff0c\u67b6\u6784\u7279\u5f81\u5f71\u54cd\u4eba\u683c\u7a33\u5b9a\u6027\u3002", "motivation": "\u968f\u7740LLMs\u5728\u4eba\u7c7b\u4e2d\u5fc3\u5e94\u7528\u4e2d\u7684\u91cd\u8981\u6027\u589e\u52a0\uff0c\u7406\u89e3\u5176\u7c7b\u4f3c\u4eba\u683c\u7684\u884c\u4e3a\u5bf9\u4e8e\u8d1f\u8d23\u4efb\u5f00\u53d1\u548c\u90e8\u7f72\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5e94\u7528BFI-2\u4eba\u683c\u6846\u67b6\u8bc4\u4f306\u4e2aLLMs\u5728\u4e0d\u540c\u91c7\u6837\u6e29\u5ea6\u4e0b\u7684\u4eba\u683c\u7279\u8d28\u8868\u8fbe\uff0c\u4f7f\u7528\u5c42\u6b21\u805a\u7c7b\u5206\u6790\u6a21\u578b\u7279\u5f81\u3002", "result": "\u53d1\u73b0\u56db\u4e2a\u4e3b\u8981\u4eba\u683c\u7ef4\u5ea6\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u795e\u7ecf\u8d28\u548c\u5916\u5411\u6027\u5bf9\u6e29\u5ea6\u8c03\u6574\u654f\u611f\uff0c\u805a\u7c7b\u5206\u6790\u663e\u793a\u67b6\u6784\u7279\u5f81\u5f71\u54cd\u4eba\u683c\u7a33\u5b9a\u6027\u3002", "conclusion": "\u7814\u7a76\u4e3aLLMs\u4e2d\u4eba\u683c\u6a21\u5f0f\u7684\u51fa\u73b0\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u4e3a\u6a21\u578b\u8c03\u4f18\u3001\u9009\u62e9\u548cAI\u7cfb\u7edf\u4f26\u7406\u6cbb\u7406\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "topic": "agent analysis"}}
{"id": "2511.04502", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04502", "abs": "https://arxiv.org/abs/2511.04502", "authors": ["Joshua Gao", "Quoc Huy Pham", "Subin Varghese", "Silwal Saurav", "Vedhus Hoskere"], "title": "RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is a critical technique for grounding\nLarge Language Models (LLMs) in factual evidence, yet evaluating RAG systems in\nspecialized, safety-critical domains remains a significant challenge. Existing\nevaluation frameworks often rely on heuristic-based metrics that fail to\ncapture domain-specific nuances and other works utilize LLM-as-a-Judge\napproaches that lack validated alignment with human judgment. This paper\nintroduces RAGalyst, an automated, human-aligned agentic framework designed for\nthe rigorous evaluation of domain-specific RAG systems. RAGalyst features an\nagentic pipeline that generates high-quality, synthetic question-answering (QA)\ndatasets from source documents, incorporating an agentic filtering step to\nensure data fidelity. The framework refines two key LLM-as-a-Judge\nmetrics-Answer Correctness and Answerability-using prompt optimization to\nachieve a strong correlation with human annotations. Applying this framework to\nevaluate various RAG components across three distinct domains (military\noperations, cybersecurity, and bridge engineering), we find that performance is\nhighly context-dependent. No single embedding model, LLM, or hyperparameter\nconfiguration proves universally optimal. Additionally, we provide an analysis\non the most common low Answer Correctness reasons in RAG. These findings\nhighlight the necessity of a systematic evaluation framework like RAGalyst,\nwhich empowers practitioners to uncover domain-specific trade-offs and make\ninformed design choices for building reliable and effective RAG systems.\nRAGalyst is available on our Github.", "AI": {"tldr": "\u63d0\u51fa\u4e86RAGalyst\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e13\u4e1a\u9886\u57df\u81ea\u52a8\u5316\u8bc4\u4f30RAG\u7cfb\u7edf\uff0c\u901a\u8fc7\u4ee3\u7406\u7ba1\u9053\u751f\u6210\u9ad8\u8d28\u91cfQA\u6570\u636e\u96c6\u5e76\u4f18\u5316LLM\u8bc4\u4f30\u6307\u6807\uff0c\u5728\u4e09\u4e2a\u4e0d\u540c\u9886\u57df\u9a8c\u8bc1\u4e86RAG\u6027\u80fd\u7684\u9886\u57df\u4f9d\u8d56\u6027\u3002", "motivation": "\u73b0\u6709RAG\u8bc4\u4f30\u6846\u67b6\u5728\u4e13\u4e1a\u5b89\u5168\u5173\u952e\u9886\u57df\u5b58\u5728\u4e0d\u8db3\uff0c\u542f\u53d1\u5f0f\u6307\u6807\u65e0\u6cd5\u6355\u6349\u9886\u57df\u7279\u5f02\u6027\uff0c\u800cLLM-as-a-Judge\u65b9\u6cd5\u7f3a\u4e4f\u4e0e\u4eba\u7c7b\u5224\u65ad\u7684\u6709\u6548\u5bf9\u9f50\u9a8c\u8bc1\u3002", "method": "\u5f00\u53d1RAGalyst\u4ee3\u7406\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u5408\u6210QA\u6570\u636e\u96c6\u7684\u4ee3\u7406\u7ba1\u9053\u548c\u4ee3\u7406\u8fc7\u6ee4\u6b65\u9aa4\uff0c\u901a\u8fc7\u63d0\u793a\u4f18\u5316\u6539\u8fdbAnswer Correctness\u548cAnswerability\u4e24\u4e2aLLM\u8bc4\u4f30\u6307\u6807\u3002", "result": "\u5728\u519b\u4e8b\u884c\u52a8\u3001\u7f51\u7edc\u5b89\u5168\u548c\u6865\u6881\u5de5\u7a0b\u4e09\u4e2a\u9886\u57df\u8bc4\u4f30\u53d1\u73b0\uff0cRAG\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u4e0a\u4e0b\u6587\uff0c\u6ca1\u6709\u5355\u4e00\u5d4c\u5165\u6a21\u578b\u3001LLM\u6216\u8d85\u53c2\u6570\u914d\u7f6e\u662f\u666e\u904d\u6700\u4f18\u7684\u3002", "conclusion": "RAGalyst\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u80fd\u5e2e\u52a9\u4ece\u4e1a\u8005\u53d1\u73b0\u9886\u57df\u7279\u5b9a\u6743\u8861\uff0c\u4e3a\u6784\u5efa\u53ef\u9760\u6709\u6548\u7684RAG\u7cfb\u7edf\u505a\u51fa\u660e\u667a\u8bbe\u8ba1\u9009\u62e9\u3002", "topic": "agent analysis"}}
{"id": "2511.04147", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04147", "abs": "https://arxiv.org/abs/2511.04147", "authors": ["Jiaming Zhang", "Yujie Yang", "Haoning Wang", "Liping Zhang", "Shengbo Eben Li"], "title": "Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning", "comment": "Submitted to the Journal of Machine Learning Research (JMLR), under\n  review", "summary": "Safe reinforcement learning (safe RL) aims to respect safety requirements\nwhile optimizing long-term performance. In many practical applications,\nhowever, the problem involves an infinite number of constraints, known as\nsemi-infinite safe RL (SI-safe RL). Such constraints typically appear when\nsafety conditions must be enforced across an entire continuous parameter space,\nsuch as ensuring adequate resource distribution at every spatial location. In\nthis paper, we propose exchange policy optimization (EPO), an algorithmic\nframework that achieves optimal policy performance and deterministic bounded\nsafety. EPO works by iteratively solving safe RL subproblems with finite\nconstraint sets and adaptively adjusting the active set through constraint\nexpansion and deletion. At each iteration, constraints with violations\nexceeding the predefined tolerance are added to refine the policy, while those\nwith zero Lagrange multipliers are removed after the policy update. This\nexchange rule prevents uncontrolled growth of the working set and supports\neffective policy training. Our theoretical analysis demonstrates that, under\nmild assumptions, strategies trained via EPO achieve performance comparable to\noptimal solutions with global constraint violations strictly remaining within a\nprescribed bound.", "AI": {"tldr": "\u63d0\u51fa\u4ea4\u6362\u7b56\u7565\u4f18\u5316(EPO)\u6846\u67b6\uff0c\u89e3\u51b3\u5177\u6709\u65e0\u9650\u7ea6\u675f\u7684\u534a\u65e0\u9650\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u8fed\u4ee3\u6c42\u89e3\u6709\u9650\u7ea6\u675f\u5b50\u95ee\u9898\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u6d3b\u52a8\u7ea6\u675f\u96c6\uff0c\u786e\u4fdd\u7b56\u7565\u6027\u80fd\u6700\u4f18\u4e14\u5b89\u5168\u7ea6\u675f\u4e25\u683c\u6709\u754c\u3002", "motivation": "\u4f20\u7edf\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u901a\u5e38\u5904\u7406\u6709\u9650\u7ea6\u675f\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7ecf\u5e38\u9047\u5230\u9700\u8981\u5728\u8fde\u7eed\u53c2\u6570\u7a7a\u95f4\u4e0a\u6267\u884c\u5b89\u5168\u6761\u4ef6\u7684\u534a\u65e0\u9650\u7ea6\u675f\u95ee\u9898\uff0c\u5982\u786e\u4fdd\u6bcf\u4e2a\u7a7a\u95f4\u4f4d\u7f6e\u7684\u8d44\u6e90\u5206\u914d\u5145\u8db3\u3002", "method": "EPO\u901a\u8fc7\u8fed\u4ee3\u6c42\u89e3\u6709\u9650\u7ea6\u675f\u7684\u5b89\u5168RL\u5b50\u95ee\u9898\uff0c\u91c7\u7528\u7ea6\u675f\u6269\u5c55\u548c\u5220\u9664\u673a\u5236\u81ea\u9002\u5e94\u8c03\u6574\u6d3b\u52a8\u96c6\uff1a\u8fdd\u53cd\u9884\u5b9a\u4e49\u5bb9\u5dee\u7684\u7ea6\u675f\u88ab\u6dfb\u52a0\u4ee5\u7ec6\u5316\u7b56\u7565\uff0c\u96f6\u62c9\u683c\u6717\u65e5\u4e58\u5b50\u7684\u7ea6\u675f\u5728\u7b56\u7565\u66f4\u65b0\u540e\u88ab\u79fb\u9664\u3002", "result": "\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\uff0c\u901a\u8fc7EPO\u8bad\u7ec3\u7684\u7b56\u7565\u5b9e\u73b0\u4e0e\u6700\u4f18\u89e3\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e14\u5168\u5c40\u7ea6\u675f\u8fdd\u53cd\u4e25\u683c\u4fdd\u6301\u5728\u9884\u5b9a\u754c\u9650\u5185\u3002", "conclusion": "EPO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u534a\u65e0\u9650\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u53ef\u63a7\u7684\u7ea6\u675f\u96c6\u7ba1\u7406\u5b9e\u73b0\u6700\u4f18\u7b56\u7565\u6027\u80fd\u548c\u786e\u5b9a\u6027\u6709\u754c\u5b89\u5168\u6027\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.04538", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04538", "abs": "https://arxiv.org/abs/2511.04538", "authors": ["Cyril Vallez", "Alexander Sternfeld", "Andrei Kucharavy", "Ljiljana Dolamic"], "title": "From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting", "comment": null, "summary": "As the role of Large Language Models (LLM)-based coding assistants in\nsoftware development becomes more critical, so does the role of the bugs they\ngenerate in the overall cybersecurity landscape. While a number of LLM code\nsecurity benchmarks have been proposed alongside approaches to improve the\nsecurity of generated code, it remains unclear to what extent they have\nimpacted widely used coding LLMs. Here, we show that even the latest\nopen-weight models are vulnerable in the earliest reported vulnerability\nscenarios in a realistic use setting, suggesting that the safety-functionality\ntrade-off has until now prevented effective patching of vulnerabilities. To\nhelp address this issue, we introduce a new severity metric that reflects the\nrisk posed by an LLM-generated vulnerability, accounting for vulnerability\nseverity, generation chance, and the formulation of the prompt that induces\nvulnerable code generation - Prompt Exposure (PE). To encourage the mitigation\nof the most serious and prevalent vulnerabilities, we use PE to define the\nModel Exposure (ME) score, which indicates the severity and prevalence of\nvulnerabilities a model generates.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86LLM\u4ee3\u7801\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5b89\u5168\u98ce\u9669\uff0c\u53d1\u73b0\u5373\u4f7f\u6700\u65b0\u5f00\u6e90\u6a21\u578b\u4ecd\u5b58\u5728\u65e9\u671f\u62a5\u544a\u7684\u6f0f\u6d1e\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u5b89\u5168\u5ea6\u91cf\u6307\u6807Prompt Exposure\u548cModel Exposure\u6765\u8bc4\u4f30\u6f0f\u6d1e\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u57fa\u4e8eLLM\u7684\u4ee3\u7801\u52a9\u624b\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u4f5c\u7528\u65e5\u76ca\u91cd\u8981\uff0c\u5176\u751f\u6210\u7684bug\u5bf9\u7f51\u7edc\u5b89\u5168\u7684\u5f71\u54cd\u4e5f\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u8bc4\u4f30\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u548c\u6539\u8fdb\u65b9\u6cd5\u5bf9\u4e3b\u6d41\u7f16\u7801LLM\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u5f15\u5165\u65b0\u7684\u4e25\u91cd\u6027\u5ea6\u91cfPrompt Exposure(PE)\uff0c\u7efc\u5408\u8003\u8651\u6f0f\u6d1e\u4e25\u91cd\u7a0b\u5ea6\u3001\u751f\u6210\u6982\u7387\u548c\u8bf1\u5bfc\u6f0f\u6d1e\u4ee3\u7801\u751f\u6210\u7684\u63d0\u793a\u8868\u8ff0\u3002\u57fa\u4e8ePE\u5b9a\u4e49Model Exposure(ME)\u8bc4\u5206\u6765\u6307\u793a\u6a21\u578b\u751f\u6210\u6f0f\u6d1e\u7684\u4e25\u91cd\u6027\u548c\u666e\u904d\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\u5373\u4f7f\u6700\u65b0\u7684\u5f00\u6e90\u6a21\u578b\u5728\u73b0\u5b9e\u4f7f\u7528\u73af\u5883\u4e2d\u4ecd\u7136\u5bb9\u6613\u53d7\u5230\u65e9\u671f\u62a5\u544a\u7684\u6f0f\u6d1e\u653b\u51fb\uff0c\u8868\u660e\u5b89\u5168-\u529f\u80fd\u6027\u6743\u8861\u963b\u788d\u4e86\u6709\u6548\u7684\u6f0f\u6d1e\u4fee\u8865\u3002", "conclusion": "\u9700\u8981\u65b0\u7684\u5b89\u5168\u5ea6\u91cf\u6807\u51c6\u6765\u9f13\u52b1\u7f13\u89e3\u6700\u4e25\u91cd\u548c\u666e\u904d\u7684\u6f0f\u6d1e\uff0c\u63d0\u51fa\u7684PE\u548cME\u6307\u6807\u6709\u52a9\u4e8e\u66f4\u51c6\u786e\u5730\u8bc4\u4f30LLM\u4ee3\u7801\u751f\u6210\u7684\u5b89\u5168\u98ce\u9669\u3002", "topic": "agent analysis"}}
{"id": "2511.04286", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04286", "abs": "https://arxiv.org/abs/2511.04286", "authors": ["Matteo Cercola", "Valeria Capretti", "Simone Formentin"], "title": "Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference", "comment": null, "summary": "Learning from human preferences is a cornerstone of aligning machine learning\nmodels with subjective human judgments. Yet, collecting such preference data is\noften costly and time-consuming, motivating the need for more efficient\nlearning paradigms. Two established approaches offer complementary advantages:\nRLHF scales effectively to high-dimensional tasks such as LLM fine-tuning,\nwhile PBO achieves greater sample efficiency through active querying. We\npropose a hybrid framework that unifies RLHF's scalability with PBO's query\nefficiency by integrating an acquisition-driven module into the RLHF pipeline,\nthereby enabling active and sample-efficient preference gathering. We validate\nthe proposed approach on two representative domains: (i) high-dimensional\npreference optimization and (ii) LLM fine-tuning. Experimental results\ndemonstrate consistent improvements in both sample efficiency and overall\nperformance across these tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408RLHF\u53ef\u6269\u5c55\u6027\u548cPBO\u6837\u672c\u6548\u7387\u7684\u6df7\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u5728RLHF\u6d41\u7a0b\u4e2d\u96c6\u6210\u4e3b\u52a8\u67e5\u8be2\u6a21\u5757\uff0c\u5b9e\u73b0\u9ad8\u6548\u504f\u597d\u6570\u636e\u6536\u96c6\u3002", "motivation": "\u4eba\u7c7b\u504f\u597d\u6570\u636e\u6536\u96c6\u6210\u672c\u9ad8\u4e14\u8017\u65f6\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5b66\u4e60\u8303\u5f0f\u3002RLHF\u5728\u9ad8\u7ef4\u4efb\u52a1\u4e2d\u6269\u5c55\u6027\u597d\uff0c\u800cPBO\u901a\u8fc7\u4e3b\u52a8\u67e5\u8be2\u5b9e\u73b0\u66f4\u9ad8\u6837\u672c\u6548\u7387\u3002", "method": "\u5728RLHF\u6d41\u7a0b\u4e2d\u96c6\u6210\u4e3b\u52a8\u67e5\u8be2\u6a21\u5757\uff0c\u7ed3\u5408RLHF\u7684\u53ef\u6269\u5c55\u6027\u548cPBO\u7684\u67e5\u8be2\u6548\u7387\uff0c\u5b9e\u73b0\u4e3b\u52a8\u4e14\u6837\u672c\u9ad8\u6548\u7684\u504f\u597d\u6536\u96c6\u3002", "result": "\u5728\u9ad8\u7ef4\u504f\u597d\u4f18\u5316\u548cLLM\u5fae\u8c03\u4e24\u4e2a\u4ee3\u8868\u6027\u9886\u57df\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5728\u6837\u672c\u6548\u7387\u548c\u6574\u4f53\u6027\u80fd\u4e0a\u5747\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u6846\u67b6\u6210\u529f\u7edf\u4e00\u4e86RLHF\u7684\u53ef\u6269\u5c55\u6027\u548cPBO\u7684\u67e5\u8be2\u6548\u7387\uff0c\u4e3a\u504f\u597d\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2511.04598", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04598", "abs": "https://arxiv.org/abs/2511.04598", "authors": ["Hampus \u00c5str\u00f6m", "Elin Anna Topp", "Jacek Malec"], "title": "Environment Agnostic Goal-Conditioning, A Study of Reward-Free Autonomous Learning", "comment": "8 pages without cover, references and supplementary materials, 11\n  with. Submitted to RLC 2025's workshop RLBrew and IMOL 2025", "summary": "In this paper we study how transforming regular reinforcement learning\nenvironments into goal-conditioned environments can let agents learn to solve\ntasks autonomously and reward-free. We show that an agent can learn to solve\ntasks by selecting its own goals in an environment-agnostic way, at training\ntimes comparable to externally guided reinforcement learning. Our method is\nindependent of the underlying off-policy learning algorithm. Since our method\nis environment-agnostic, the agent does not value any goals higher than others,\nleading to instability in performance for individual goals. However, in our\nexperiments, we show that the average goal success rate improves and\nstabilizes. An agent trained with this method can be instructed to seek any\nobservations made in the environment, enabling generic training of agents prior\nto specific use cases.", "AI": {"tldr": "\u5c06\u5e38\u89c4\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u8f6c\u6362\u4e3a\u76ee\u6807\u6761\u4ef6\u73af\u5883\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u81ea\u4e3b\u3001\u65e0\u5956\u52b1\u5730\u5b66\u4e60\u89e3\u51b3\u4efb\u52a1\uff0c\u901a\u8fc7\u81ea\u9009\u76ee\u6807\u5b9e\u73b0\u73af\u5883\u65e0\u5173\u7684\u5b66\u4e60\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u8ba9\u667a\u80fd\u4f53\u5728\u65e0\u9700\u5916\u90e8\u5956\u52b1\u6307\u5bfc\u7684\u60c5\u51b5\u4e0b\u81ea\u4e3b\u5b66\u4e60\u89e3\u51b3\u4efb\u52a1\uff0c\u5b9e\u73b0\u73af\u5883\u65e0\u5173\u7684\u901a\u7528\u667a\u80fd\u4f53\u8bad\u7ec3\u3002", "method": "\u5c06\u5e38\u89c4RL\u73af\u5883\u8f6c\u6362\u4e3a\u76ee\u6807\u6761\u4ef6\u73af\u5883\uff0c\u8ba9\u667a\u80fd\u4f53\u81ea\u4e3b\u9009\u62e9\u76ee\u6807\u8fdb\u884c\u5b66\u4e60\uff0c\u8be5\u65b9\u6cd5\u4e0e\u5e95\u5c42\u79bb\u7b56\u7565\u5b66\u4e60\u7b97\u6cd5\u65e0\u5173\u3002", "result": "\u667a\u80fd\u4f53\u80fd\u591f\u4ee5\u4e0e\u5916\u90e8\u6307\u5bfcRL\u76f8\u5f53\u7684\u65f6\u95f4\u5b66\u4e60\u89e3\u51b3\u4efb\u52a1\uff0c\u5e73\u5747\u76ee\u6807\u6210\u529f\u7387\u5f97\u5230\u6539\u5584\u548c\u7a33\u5b9a\uff0c\u4f46\u5355\u4e2a\u76ee\u6807\u6027\u80fd\u5b58\u5728\u4e0d\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u8bad\u7ec3\u51fa\u53ef\u88ab\u6307\u793a\u8ffd\u6c42\u73af\u5883\u4e2d\u4efb\u4f55\u89c2\u6d4b\u7684\u901a\u7528\u667a\u80fd\u4f53\uff0c\u4e3a\u7279\u5b9a\u7528\u4f8b\u524d\u7684\u901a\u7528\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2511.9cf4975d", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Foraios%2Fserena%3Futm_source=tldrdevops/1/0100019a53e8fb63-19fa30d1-eba0-45d3-9eb6-b2ed3b20457b-000000/XZ-_iLdR12Y92EPsx0stPRPmcG--EB2tqgygv2GQnus=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Foraios%2Fserena%3Futm_source=tldrdevops/1/0100019a53e8fb63-19fa30d1-eba0-45d3-9eb6-b2ed3b20457b-000000/XZ-_iLdR12Y92EPsx0stPRPmcG--EB2tqgygv2GQnus=430", "authors": ["TLDR Newsletter"], "title": "Serena", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2Foraios%2Fserena%3Futm_source=tldrdevops/1/0100019a53e8fb63-19fa30d1-eba0-45d3-9eb6-b2ed3b20457b-000000/XZ-_iLdR12Y92EPsx0stPRPmcG--EB2tqgygv2GQnus=430", "summary": "Serena (GitHub Repo) Serena, a free and open-source coding agent toolkit, combines semantic code retrieval with editing and shell execution via its MCP server and LSP-based language server integrations, and can be integrated with LLMs like Claude Code to save tokens and time. Serena can be further customized through Modes and Contexts, which allow users to tailor its behavior to their workflow and environment.", "source": "tldr", "AI": {"tldr": "Serena\u662f\u4e00\u4e2a\u5f00\u6e90\u7f16\u7801\u4ee3\u7406\u5de5\u5177\u5305\uff0c\u7ed3\u5408\u8bed\u4e49\u4ee3\u7801\u68c0\u7d22\u4e0e\u7f16\u8f91\u548cshell\u6267\u884c\u529f\u80fd\uff0c\u901a\u8fc7MCP\u670d\u52a1\u5668\u548cLSP\u96c6\u6210\uff0c\u53ef\u4e0eClaude Code\u7b49LLM\u96c6\u6210\u4ee5\u8282\u7701token\u548c\u65f6\u95f4\u3002", "motivation": "\u63d0\u4f9b\u53ef\u5b9a\u5236\u7684\u7f16\u7801\u4ee3\u7406\u5de5\u5177\u5305\uff0c\u901a\u8fc7\u8bed\u4e49\u68c0\u7d22\u548c\u96c6\u6210\u529f\u80fd\u63d0\u9ad8\u5f00\u53d1\u6548\u7387\uff0c\u51cf\u5c11LLM\u4f7f\u7528\u6210\u672c\u3002", "method": "\u4f7f\u7528MCP\u670d\u52a1\u5668\u548cLSP\u8bed\u8a00\u670d\u52a1\u5668\u96c6\u6210\uff0c\u7ed3\u5408\u8bed\u4e49\u4ee3\u7801\u68c0\u7d22\u3001\u7f16\u8f91\u548cshell\u6267\u884c\u529f\u80fd\uff0c\u652f\u6301\u901a\u8fc7Modes\u548cContexts\u8fdb\u884c\u5b9a\u5236\u3002", "result": "\u5f00\u53d1\u4e86Serena\u5de5\u5177\u5305\uff0c\u80fd\u591f\u4e0eClaude Code\u7b49LLM\u96c6\u6210\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\u7f16\u7801\u8f85\u52a9\u529f\u80fd\u3002", "conclusion": "Serena\u662f\u4e00\u4e2a\u529f\u80fd\u4e30\u5bcc\u4e14\u53ef\u5b9a\u5236\u7684\u5f00\u6e90\u7f16\u7801\u4ee3\u7406\u5de5\u5177\u5305\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\u5e76\u964d\u4f4eLLM\u4f7f\u7528\u6210\u672c\u3002", "topic": "code agent"}}
{"id": "tldr.2511.1172cc3d", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.sonarsource.com%2Fsem%2F7-habits-of-highly-effective-ai-coding-ebook%2F%3Futm_medium=paid%26utm_source=tldr%26utm_campaign=ss-7-habits-ebook25%26utm_content=newsletter-primary-tldr-dev-251105-x%26utm_term=ww-psp-x%26s_category=Paid%26s_source=Paid%2520Other%26s_origin=tldr/2/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/fG5PFt3nwvtNzkzQPcvnT8goP95bBF4ZX7VsOqSN3is=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.sonarsource.com%2Fsem%2F7-habits-of-highly-effective-ai-coding-ebook%2F%3Futm_medium=paid%26utm_source=tldr%26utm_campaign=ss-7-habits-ebook25%26utm_content=newsletter-primary-tldr-dev-251105-x%26utm_term=ww-psp-x%26s_category=Paid%26s_source=Paid%2520Other%26s_origin=tldr/2/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/fG5PFt3nwvtNzkzQPcvnT8goP95bBF4ZX7VsOqSN3is=430", "authors": ["TLDR Newsletter"], "title": "7 habits of highly effective AI coding", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.sonarsource.com%2Fsem%2F7-habits-of-highly-effective-ai-coding-ebook%2F%3Futm_medium=paid%26utm_source=tldr%26utm_campaign=ss-7-habits-ebook25%26utm_content=newsletter-primary-tldr-dev-251105-x%26utm_term=ww-psp-x%26s_category=Paid%26s_source=Paid%2520Other%26s_origin=tldr/2/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/fG5PFt3nwvtNzkzQPcvnT8goP95bBF4ZX7VsOqSN3is=430", "summary": "7 habits of highly effective AI coding (Sponsor) How can your team use AI coding effectively without drowning in security risks and new technical debt?Discover the 7 essential habits you need to confidently adopt AI, reduce toil, and ship secure, high-quality code. Read this ebook from Sonar to learn how to: Boost real engineering productivity and velocity, not just code volume. Ensure AI-generated code is secure, reliable, and maintainable. Foster a culture of developer accountability. Tackl...", "source": "tldr", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u6709\u6548\u4f7f\u7528AI\u7f16\u7a0b\u76847\u4e2a\u5173\u952e\u4e60\u60ef\uff0c\u65e8\u5728\u5e2e\u52a9\u56e2\u961f\u5b89\u5168\u9ad8\u6548\u5730\u91c7\u7528AI\u7f16\u7801\uff0c\u907f\u514d\u5b89\u5168\u98ce\u9669\u548c\u6280\u672f\u503a\u52a1", "motivation": "\u5e2e\u52a9\u5f00\u53d1\u56e2\u961f\u5728\u91c7\u7528AI\u7f16\u7801\u65f6\u907f\u514d\u5b89\u5168\u98ce\u9669\u3001\u51cf\u5c11\u6280\u672f\u503a\u52a1\uff0c\u540c\u65f6\u63d0\u5347\u5de5\u7a0b\u751f\u4ea7\u529b\u548c\u4ee3\u7801\u8d28\u91cf", "method": "\u63d0\u51fa7\u4e2a\u6838\u5fc3\u4e60\u60ef\u6846\u67b6\uff0c\u5305\u62ec\u63d0\u5347\u771f\u5b9e\u5de5\u7a0b\u751f\u4ea7\u529b\u3001\u786e\u4fddAI\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u53ef\u9760\u6027\u3001\u57f9\u517b\u5f00\u53d1\u8005\u8d23\u4efb\u6587\u5316\u7b49", "result": "\u901a\u8fc7\u91c7\u7528\u8fd9\u4e9b\u4e60\u60ef\uff0c\u56e2\u961f\u80fd\u591f\u66f4\u81ea\u4fe1\u5730\u4f7f\u7528AI\uff0c\u51cf\u5c11\u91cd\u590d\u52b3\u52a8\uff0c\u4ea4\u4ed8\u5b89\u5168\u9ad8\u8d28\u91cf\u7684\u4ee3\u7801", "conclusion": "\u7cfb\u7edf\u6027\u5730\u91c7\u7528AI\u7f16\u7801\u9700\u8981\u5efa\u7acb\u6b63\u786e\u7684\u4e60\u60ef\u548c\u5b9e\u8df5\uff0c\u4ee5\u786e\u4fdd\u4ee3\u7801\u5b89\u5168\u6027\u548c\u5de5\u7a0b\u6548\u7387", "topic": "swe application"}}
{"id": "tldr.2511.383c3bf7", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcognition.ai%2Fblog%2Fcodemaps%3Futm_source=tldrwebdev/1/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/A83Avk75SlOX1VKIa-YPxob7VDLMUVkRSq1Rqk75RRs=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcognition.ai%2Fblog%2Fcodemaps%3Futm_source=tldrwebdev/1/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/A83Avk75SlOX1VKIa-YPxob7VDLMUVkRSq1Rqk75RRs=430", "authors": ["TLDR Newsletter"], "title": "Windsurf Codemaps: Understand Code, Before You Vibe It", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: 7 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcognition.ai%2Fblog%2Fcodemaps%3Futm_source=tldrwebdev/1/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/A83Avk75SlOX1VKIa-YPxob7VDLMUVkRSq1Rqk75RRs=430", "summary": "Windsurf Codemaps: Understand Code, Before You Vibe It (7 minute read) Cognition has announced Windsurf Codemaps, an AI-annotated structured map of codebases powered by SWE-1.5 and Claude Sonnet 4.5 designed to help devs quickly understand and navigate complex code. Codemaps provides just-in-time mapping for tasks like debugging and refactoring, allowing devs to visualize code structure, trace functionality, and improve context for AI agents.", "source": "tldr", "AI": {"tldr": "Windsurf Codemaps \u662f\u4e00\u4e2a\u7531 SWE-1.5 \u548c Claude Sonnet 4.5 \u9a71\u52a8\u7684 AI \u6ce8\u91ca\u4ee3\u7801\u7ed3\u6784\u56fe\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u5feb\u901f\u7406\u89e3\u548c\u5bfc\u822a\u590d\u6742\u4ee3\u7801\u5e93\u3002", "motivation": "\u89e3\u51b3\u5f00\u53d1\u8005\u5728\u8c03\u8bd5\u548c\u91cd\u6784\u7b49\u4efb\u52a1\u4e2d\u5feb\u901f\u7406\u89e3\u590d\u6742\u4ee3\u7801\u5e93\u7684\u9700\u6c42\uff0c\u63d0\u4f9b\u5373\u65f6\u6620\u5c04\u529f\u80fd\u3002", "method": "\u4f7f\u7528 SWE-1.5 \u548c Claude Sonnet 4.5 \u751f\u6210 AI \u6ce8\u91ca\u7684\u7ed3\u6784\u5316\u4ee3\u7801\u5730\u56fe\uff0c\u53ef\u89c6\u5316\u4ee3\u7801\u7ed3\u6784\u5e76\u8ffd\u8e2a\u529f\u80fd\u3002", "result": "\u5f00\u53d1\u4e86\u80fd\u591f\u5e2e\u52a9\u5f00\u53d1\u8005\u53ef\u89c6\u5316\u4ee3\u7801\u7ed3\u6784\u3001\u8ffd\u8e2a\u529f\u80fd\u5e76\u6539\u5584 AI \u4ee3\u7406\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u5de5\u5177\u3002", "conclusion": "Codemaps \u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u4ee3\u7801\u7406\u89e3\u548c\u5bfc\u822a\u65b9\u5f0f\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8c03\u8bd5\u548c\u91cd\u6784\u4efb\u52a1\u3002", "topic": "swe application"}}
{"id": "tldr.2511.0382cbc9", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2F100x.bot%2Fa%2Fchaining-ffmpeg-with-browser-agent%3Futm_source=tldrwebdev/1/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/tBQOjv7RjrOt7kR5eSdt5nZAJRtZlxWuSyxmPzA6PO4=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2F100x.bot%2Fa%2Fchaining-ffmpeg-with-browser-agent%3Futm_source=tldrwebdev/1/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/tBQOjv7RjrOt7kR5eSdt5nZAJRtZlxWuSyxmPzA6PO4=430", "authors": ["TLDR Newsletter"], "title": "Chaining ffmpeg with a Browser Agent", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2F100x.bot%2Fa%2Fchaining-ffmpeg-with-browser-agent%3Futm_source=tldrwebdev/1/0100019a53ec2e04-fc2d5128-4728-4a9e-98e9-a4788961bfe2-000000/tBQOjv7RjrOt7kR5eSdt5nZAJRtZlxWuSyxmPzA6PO4=430", "summary": "Chaining ffmpeg with a Browser Agent (4 minute read) By integrating FFmpeg as a WebAssembly module within a browser agent, complex media processing can be executed serverlessly and statelessly within a workflow, turning FFmpeg into a composable API accessible as a single step.", "source": "tldr", "AI": {"tldr": "\u901a\u8fc7\u5c06FFmpeg\u4f5c\u4e3aWebAssembly\u6a21\u5757\u96c6\u6210\u5230\u6d4f\u89c8\u5668\u4ee3\u7406\u4e2d\uff0c\u53ef\u4ee5\u5728\u65e0\u670d\u52a1\u5668\u3001\u65e0\u72b6\u6001\u7684\u5de5\u4f5c\u6d41\u4e2d\u6267\u884c\u590d\u6742\u7684\u5a92\u4f53\u5904\u7406\uff0c\u5c06FFmpeg\u8f6c\u53d8\u4e3a\u53ef\u7ec4\u5408\u7684API\uff0c\u4f5c\u4e3a\u5355\u4e2a\u6b65\u9aa4\u8bbf\u95ee\u3002", "motivation": "\u89e3\u51b3\u590d\u6742\u5a92\u4f53\u5904\u7406\u5728\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u6267\u884c\u7684\u6311\u6218\uff0c\u4f7fFFmpeg\u80fd\u591f\u5728\u6d4f\u89c8\u5668\u4ee3\u7406\u4e2d\u4f5c\u4e3a\u53ef\u7ec4\u5408\u7684API\u4f7f\u7528\uff0c\u7b80\u5316\u5a92\u4f53\u5904\u7406\u5de5\u4f5c\u6d41\u3002", "method": "\u5c06FFmpeg\u7f16\u8bd1\u4e3aWebAssembly\u6a21\u5757\uff0c\u96c6\u6210\u5230\u6d4f\u89c8\u5668\u4ee3\u7406\u4e2d\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u65e0\u670d\u52a1\u5668\u3001\u65e0\u72b6\u6001\u7684\u5de5\u4f5c\u6d41\u4e2d\u6267\u884c\u5a92\u4f53\u5904\u7406\u4efb\u52a1\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86FFmpeg\u4f5c\u4e3a\u53ef\u7ec4\u5408API\u7684\u96c6\u6210\uff0c\u53ef\u4ee5\u5728\u6d4f\u89c8\u5668\u4ee3\u7406\u4e2d\u4f5c\u4e3a\u5355\u4e2a\u6b65\u9aa4\u6267\u884c\u590d\u6742\u7684\u5a92\u4f53\u5904\u7406\u64cd\u4f5c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u5a92\u4f53\u5904\u7406\u7684\u6311\u6218\uff0c\u4f7fFFmpeg\u80fd\u591f\u4ee5\u66f4\u7075\u6d3b\u3001\u53ef\u7ec4\u5408\u7684\u65b9\u5f0f\u5728\u6d4f\u89c8\u5668\u4ee3\u7406\u4e2d\u4f7f\u7528\u3002", "topic": "swe application"}}
{"id": "tldr.2511.7dae6fa5", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.commonreader.co.uk%2Fp%2Fmetapreferences-and-the-future-of%3Futm_source=tldrfounders/1/0100019a54317134-259c1825-e3a4-4e6d-8018-2bcc38d6b661-000000/fLcS2ICNoaLbsLXZm0ZZRq6j2eA__1gPkcMjkRer4xI=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.commonreader.co.uk%2Fp%2Fmetapreferences-and-the-future-of%3Futm_source=tldrfounders/1/0100019a54317134-259c1825-e3a4-4e6d-8018-2bcc38d6b661-000000/fLcS2ICNoaLbsLXZm0ZZRq6j2eA__1gPkcMjkRer4xI=430", "authors": ["TLDR Newsletter"], "title": "A simple test for developing taste", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.commonreader.co.uk%2Fp%2Fmetapreferences-and-the-future-of%3Futm_source=tldrfounders/1/0100019a54317134-259c1825-e3a4-4e6d-8018-2bcc38d6b661-000000/fLcS2ICNoaLbsLXZm0ZZRq6j2eA__1gPkcMjkRer4xI=430", "summary": "A simple test for developing taste (4 minute read) Taste isn't about what you like\u2014it's about how your preferences change once you've seen something better. You read Middlemarch after Remains of the Day, and suddenly the scale resets. You can't unsee the difference. That's how taste develops: through comparison, awareness, and the slow upgrading of what you think good means. It happens in every field - music, design, writing, code. The more you expose yourself to better work, the clearer your...", "source": "tldr", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error", "topics": "Error"}}
{"id": "tldr.2511.031c6e3e", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2F100x.bot%2Fa%2Fchaining-ffmpeg-with-browser-agent%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/X1oNkpu00NAOd6f15YYVxWfoXbXenwmF99_s_BkJDOI=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2F100x.bot%2Fa%2Fchaining-ffmpeg-with-browser-agent%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/X1oNkpu00NAOd6f15YYVxWfoXbXenwmF99_s_BkJDOI=430", "authors": ["TLDR Newsletter"], "title": "Chaining ffmpeg with a Browser Agent", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: 4 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2F100x.bot%2Fa%2Fchaining-ffmpeg-with-browser-agent%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/X1oNkpu00NAOd6f15YYVxWfoXbXenwmF99_s_BkJDOI=430", "summary": "Chaining ffmpeg with a Browser Agent (4 minute read) 100x included ffmpeg into its Chrome extension to make complex media processing a single, serverless, and stateless step in any workflow. It already had a browser agent for automation - ffmpeg became another 'tool call' for the agent. This enabled the agent to deal with complex editing tasks like mixing audio and video and adding text over video. This post gives readers a look at how the integration works.", "source": "tldr", "AI": {"tldr": "100x\u5c06ffmpeg\u96c6\u6210\u5230\u5176Chrome\u6269\u5c55\u4e2d\uff0c\u4f7f\u590d\u6742\u7684\u5a92\u4f53\u5904\u7406\u6210\u4e3a\u5de5\u4f5c\u6d41\u4e2d\u7684\u5355\u4e00\u3001\u65e0\u670d\u52a1\u5668\u3001\u65e0\u72b6\u6001\u6b65\u9aa4\uff0c\u4f5c\u4e3a\u6d4f\u89c8\u5668\u4ee3\u7406\u7684\u5de5\u5177\u8c03\u7528\u3002", "motivation": "\u4f7f\u6d4f\u89c8\u5668\u4ee3\u7406\u80fd\u591f\u5904\u7406\u590d\u6742\u7684\u5a92\u4f53\u7f16\u8f91\u4efb\u52a1\uff0c\u5982\u97f3\u9891\u89c6\u9891\u6df7\u5408\u548c\u89c6\u9891\u6dfb\u52a0\u6587\u672c\uff0c\u800c\u65e0\u9700\u670d\u52a1\u5668\u652f\u6301\u3002", "method": "\u5c06ffmpeg\u4f5c\u4e3a\u5de5\u5177\u8c03\u7528\u96c6\u6210\u5230\u73b0\u6709\u7684\u6d4f\u89c8\u5668\u4ee3\u7406\u4e2d\uff0c\u5229\u7528Chrome\u6269\u5c55\u5b9e\u73b0\u65e0\u670d\u52a1\u5668\u3001\u65e0\u72b6\u6001\u7684\u5a92\u4f53\u5904\u7406\u3002", "result": "\u6210\u529f\u5b9e\u73b0\u4e86\u6d4f\u89c8\u5668\u4ee3\u7406\u5bf9\u590d\u6742\u5a92\u4f53\u7f16\u8f91\u4efb\u52a1\u7684\u5904\u7406\u80fd\u529b\uff0c\u4f7fffmpeg\u6210\u4e3a\u4ee3\u7406\u7684\u5de5\u5177\u4e4b\u4e00\u3002", "conclusion": "\u901a\u8fc7\u5c06ffmpeg\u96c6\u6210\u5230\u6d4f\u89c8\u5668\u4ee3\u7406\u4e2d\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5904\u7406\u590d\u6742\u7684\u5a92\u4f53\u5904\u7406\u4efb\u52a1\uff0c\u6269\u5c55\u4e86\u4ee3\u7406\u7684\u529f\u80fd\u8303\u56f4\u3002", "topic": "swe application"}}
{"id": "tldr.2511.6d0f47f4", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fengineering%2Fcode-execution-with-mcp%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/RmAlfS00QJpZY0imWQR0VM-cdsUIJuJfFmNBuSNbDes=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fengineering%2Fcode-execution-with-mcp%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/RmAlfS00QJpZY0imWQR0VM-cdsUIJuJfFmNBuSNbDes=430", "authors": ["TLDR Newsletter"], "title": "Code execution with MCP: Building more efficient agents", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: 15 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.anthropic.com%2Fengineering%2Fcode-execution-with-mcp%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/RmAlfS00QJpZY0imWQR0VM-cdsUIJuJfFmNBuSNbDes=430", "summary": "Code execution with MCP: Building more efficient agents (15 minute read) Code execution can enable agents to interact with MCP servers more efficiently. When too many servers are connected, tool definitions and results can consume excessive tokens, reducing agent efficiency. Many of the problems with MCP feel novel, but they have known solutions from software engineering. Code execution applies established patterns to agents, letting them use familiar programming constructs to interact with M...", "source": "tldr", "AI": {"tldr": "\u901a\u8fc7\u4ee3\u7801\u6267\u884c\u8ba9\u4ee3\u7406\u4e0eMCP\u670d\u52a1\u5668\u66f4\u9ad8\u6548\u4ea4\u4e92\uff0c\u89e3\u51b3\u5de5\u5177\u5b9a\u4e49\u548c\u7ed3\u679c\u6d88\u8017\u8fc7\u591atoken\u7684\u95ee\u9898", "motivation": "\u5f53\u8fde\u63a5\u8fc7\u591aMCP\u670d\u52a1\u5668\u65f6\uff0c\u5de5\u5177\u5b9a\u4e49\u548c\u7ed3\u679c\u4f1a\u6d88\u8017\u8fc7\u591atoken\uff0c\u964d\u4f4e\u4ee3\u7406\u6548\u7387\u3002\u8fd9\u4e9b\u95ee\u9898\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5df2\u6709\u89e3\u51b3\u65b9\u6848", "method": "\u5e94\u7528\u4ee3\u7801\u6267\u884c\u6a21\u5f0f\uff0c\u8ba9\u4ee3\u7406\u4f7f\u7528\u719f\u6089\u7684\u7f16\u7a0b\u6784\u9020\u4e0eMCP\u670d\u52a1\u5668\u4ea4\u4e92", "result": "\u63d0\u9ad8\u4e86\u4ee3\u7406\u4e0eMCP\u670d\u52a1\u5668\u4ea4\u4e92\u7684\u6548\u7387", "conclusion": "\u4ee3\u7801\u6267\u884c\u5c06\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6210\u719f\u6a21\u5f0f\u5e94\u7528\u4e8e\u4ee3\u7406\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86MCP\u4e2d\u7684\u6548\u7387\u95ee\u9898", "topic": "code agent"}}
{"id": "tldr.2511.a42dbebd", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fryanperry.io%2Fpost%2Fcursor-profiling-missing-layer%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/UiUyISu-giohcyIJwy1C104fa7TmWcGGR2W-aCXMzq8=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fryanperry.io%2Fpost%2Fcursor-profiling-missing-layer%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/UiUyISu-giohcyIJwy1C104fa7TmWcGGR2W-aCXMzq8=430", "authors": ["TLDR Newsletter"], "title": "Profiling with Cursor 2.0: The Missing Layer in AI Code Generation", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: 5 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fryanperry.io%2Fpost%2Fcursor-profiling-missing-layer%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/UiUyISu-giohcyIJwy1C104fa7TmWcGGR2W-aCXMzq8=430", "summary": "Profiling with Cursor 2.0: The Missing Layer in AI Code Generation (5 minute read) Profiling is the best way to separate code that looks good from code that is actually good. The Pyroscope Performance Profiler is a Cursor extension that takes profiling data and paints it right on the code. It allows developers to look at multiple solutions generated by different agents and pick the best based on real numbers. Performance comparisons across deployments, trend analysis, and incident inspection ...", "source": "tldr", "AI": {"tldr": "Pyroscope Performance Profiler\u662f\u4e00\u4e2aCursor\u6269\u5c55\uff0c\u901a\u8fc7\u5c06\u6027\u80fd\u5206\u6790\u6570\u636e\u76f4\u63a5\u6807\u6ce8\u5728\u4ee3\u7801\u4e0a\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u57fa\u4e8e\u5b9e\u9645\u6027\u80fd\u6570\u636e\u4ece\u591a\u4e2aAI\u751f\u6210\u7684\u89e3\u51b3\u65b9\u6848\u4e2d\u9009\u62e9\u6700\u4f73\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u867d\u7136\u80fd\u4ea7\u751f\u770b\u8d77\u6765\u4e0d\u9519\u7684\u4ee3\u7801\uff0c\u4f46\u7f3a\u4e4f\u8bc4\u4f30\u4ee3\u7801\u5b9e\u9645\u6027\u80fd\u7684\u65b9\u6cd5\u3002\u5f00\u53d1\u8005\u9700\u8981\u4e00\u79cd\u5de5\u5177\u6765\u533a\u5206'\u770b\u8d77\u6765\u597d'\u548c'\u5b9e\u9645\u4e0a\u597d'\u7684\u4ee3\u7801\u3002", "method": "\u5f00\u53d1Pyroscope\u6027\u80fd\u5206\u6790\u5668\u4f5c\u4e3aCursor\u6269\u5c55\uff0c\u5c06\u6027\u80fd\u5206\u6790\u6570\u636e\u76f4\u63a5\u53ef\u89c6\u5316\u5728\u4ee3\u7801\u7f16\u8f91\u5668\u4e2d\uff0c\u652f\u6301\u591a\u4ee3\u7406\u89e3\u51b3\u65b9\u6848\u7684\u6027\u80fd\u6bd4\u8f83\u3001\u8d8b\u52bf\u5206\u6790\u548c\u4e8b\u4ef6\u68c0\u67e5\u3002", "result": "\u8be5\u5de5\u5177\u4f7f\u5f00\u53d1\u8005\u80fd\u591f\u57fa\u4e8e\u771f\u5b9e\u6027\u80fd\u6570\u636e\u8bc4\u4f30\u4e0d\u540cAI\u4ee3\u7406\u751f\u6210\u7684\u4ee3\u7801\uff0c\u63d0\u9ad8\u4e86\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u7684\u5ba2\u89c2\u6027\u548c\u6548\u7387\u3002", "conclusion": "\u6027\u80fd\u5206\u6790\u662fAI\u4ee3\u7801\u751f\u6210\u4e2d\u7f3a\u5931\u7684\u5173\u952e\u73af\u8282\uff0cPyroscope\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u505a\u51fa\u66f4\u660e\u667a\u7684\u4ee3\u7801\u9009\u62e9\u51b3\u7b56\u3002", "topic": "swe application"}}
{"id": "tldr.2511.526381ba", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Feu1.hubs.ly%2FH0p2Yqz0%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/CTHikhqza8JVMJ2JkJEG02l39K4-ruLf_4i8c1TPZio=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Feu1.hubs.ly%2FH0p2Yqz0%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/CTHikhqza8JVMJ2JkJEG02l39K4-ruLf_4i8c1TPZio=430", "authors": ["TLDR Newsletter"], "title": "Getting agents to code is easy... but can you get them to follow your rules?", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Feu1.hubs.ly%2FH0p2Yqz0%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/CTHikhqza8JVMJ2JkJEG02l39K4-ruLf_4i8c1TPZio=430", "summary": "Getting agents to code is easy... but can you get them to follow your rules? (Sponsor) Most AI tools generate lines of code \u2014 but fail to understand your architecture, standards, and compliance rules. Discover how Tabnine bridges the gap", "source": "tldr", "AI": {"tldr": "Tabnine\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u7406\u89e3\u67b6\u6784\u3001\u6807\u51c6\u548c\u5408\u89c4\u89c4\u5219\u7684AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u53ea\u751f\u6210\u4ee3\u7801\u4f46\u65e0\u6cd5\u9075\u5faa\u89c4\u5219\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u867d\u7136\u80fd\u751f\u6210\u4ee3\u7801\u884c\uff0c\u4f46\u65e0\u6cd5\u7406\u89e3\u7528\u6237\u7684\u67b6\u6784\u89c4\u8303\u3001\u7f16\u7801\u6807\u51c6\u548c\u5408\u89c4\u8981\u6c42\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u4ee3\u7801\u4e0d\u7b26\u5408\u5b9e\u9645\u5f00\u53d1\u9700\u6c42\u3002", "method": "Tabnine\u901a\u8fc7\u4e13\u95e8\u7684\u6280\u672f\u6765\u7406\u89e3\u548c\u9075\u5faa\u7528\u6237\u7684\u67b6\u6784\u3001\u6807\u51c6\u548c\u5408\u89c4\u89c4\u5219\uff0c\u4f7fAI\u751f\u6210\u7684\u4ee3\u7801\u80fd\u591f\u7b26\u5408\u5177\u4f53\u7684\u5f00\u53d1\u89c4\u8303\u3002", "result": "Tabnine\u6210\u529f\u5f25\u5408\u4e86AI\u4ee3\u7801\u751f\u6210\u4e0e\u9075\u5faa\u5f00\u53d1\u89c4\u5219\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u80fd\u591f\u751f\u6210\u7b26\u5408\u7279\u5b9a\u67b6\u6784\u548c\u6807\u51c6\u7684\u4ee3\u7801\u3002", "conclusion": "Tabnine\u8bc1\u660e\u4e86AI\u4ee3\u7801\u751f\u6210\u5de5\u5177\u4e0d\u4ec5\u80fd\u591f\u751f\u6210\u4ee3\u7801\uff0c\u8fd8\u80fd\u591f\u7406\u89e3\u548c\u9075\u5faa\u5f00\u53d1\u89c4\u5219\uff0c\u4e3a\u4ee3\u7801\u5f00\u53d1\u63d0\u4f9b\u4e86\u66f4\u667a\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "swe application"}}
{"id": "tldr.2511.785ca73b", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcognition.ai%2Fblog%2Fcodemaps%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/b2wgjEPXNQtQoVj2VRDXDegXi2EWxZApH8ccwmPDjaA=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcognition.ai%2Fblog%2Fcodemaps%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/b2wgjEPXNQtQoVj2VRDXDegXi2EWxZApH8ccwmPDjaA=430", "authors": ["TLDR Newsletter"], "title": "Codemaps: Understand Code, Before You Vibe It", "comment": "Source: TLDR Newsletter, Date: 2025-11-05, Reading time: 5 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcognition.ai%2Fblog%2Fcodemaps%3Futm_source=tldrai/1/0100019a5461b001-b6f95403-041d-4762-95af-c13bbb2e8b90-000000/b2wgjEPXNQtQoVj2VRDXDegXi2EWxZApH8ccwmPDjaA=430", "summary": "Codemaps: Understand Code, Before You Vibe It (5 minute read) Cognition launched Windsurf Codemaps, which creates AI-annotated structured maps of codebases to address the onboarding costs of learning a new codebase or maintaining unfamiliar legacy code.", "source": "tldr", "AI": {"tldr": "Codemaps\u901a\u8fc7AI\u751f\u6210\u4ee3\u7801\u5e93\u7684\u7ed3\u6784\u5316\u6ce8\u91ca\u5730\u56fe\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u7406\u89e3\u65b0\u4ee3\u7801\u5e93\u6216\u7ef4\u62a4\u4e0d\u719f\u6089\u7684\u9057\u7559\u4ee3\u7801\uff0c\u964d\u4f4e\u5b66\u4e60\u6210\u672c\u3002", "motivation": "\u89e3\u51b3\u5f00\u53d1\u8005\u5b66\u4e60\u65b0\u4ee3\u7801\u5e93\u6216\u7ef4\u62a4\u4e0d\u719f\u6089\u9057\u7559\u4ee3\u7801\u65f6\u7684\u9ad8\u6602\u5165\u95e8\u6210\u672c\u95ee\u9898\u3002", "method": "\u4f7f\u7528AI\u6280\u672f\u521b\u5efa\u4ee3\u7801\u5e93\u7684\u7ed3\u6784\u5316\u6ce8\u91ca\u5730\u56fe\uff0c\u4e3a\u4ee3\u7801\u63d0\u4f9b\u667a\u80fd\u6807\u6ce8\u548c\u7ec4\u7ec7\u3002", "result": "\u5f00\u53d1\u4e86Windsurf Codemaps\u5de5\u5177\uff0c\u80fd\u591f\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u7684AI\u6ce8\u91ca\u7ed3\u6784\u5316\u5730\u56fe\u3002", "conclusion": "Codemaps\u901a\u8fc7AI\u9a71\u52a8\u7684\u4ee3\u7801\u53ef\u89c6\u5316\u65b9\u6cd5\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u4ee3\u7801\u7406\u89e3\u548c\u7ef4\u62a4\u7684\u95e8\u69db\u3002", "topic": "swe application"}}
{"id": "tldr.2511.094252aa", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fclickhouse.com%2Fblog%2Flibrechat-open-source-agentic-data-stack%3Futm_source=tldrdata/1/0100019a58d992b4-e87efaf0-e81d-45c4-9475-4d30b556bb66-000000/_FB5CkJrGJBe_6CfcWwAv1_en9CUTjk8XUljo-y1ZDs=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fclickhouse.com%2Fblog%2Flibrechat-open-source-agentic-data-stack%3Futm_source=tldrdata/1/0100019a58d992b4-e87efaf0-e81d-45c4-9475-4d30b556bb66-000000/_FB5CkJrGJBe_6CfcWwAv1_en9CUTjk8XUljo-y1ZDs=430", "authors": ["TLDR Newsletter"], "title": "ClickHouse Welcomes LibreChat: Introducing the Open-Source Agentic Data Stack", "comment": "Source: TLDR Newsletter, Date: 2025-11-06, Reading time: 7 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fclickhouse.com%2Fblog%2Flibrechat-open-source-agentic-data-stack%3Futm_source=tldrdata/1/0100019a58d992b4-e87efaf0-e81d-45c4-9475-4d30b556bb66-000000/_FB5CkJrGJBe_6CfcWwAv1_en9CUTjk8XUljo-y1ZDs=430", "summary": "ClickHouse Welcomes LibreChat: Introducing the Open-Source Agentic Data Stack (7 minute read) ClickHouse has acquired LibreChat, integrating its open-source, multi-LLM chat platform as a core component of a unified Agentic Data Stack for agent-facing analytics.", "source": "tldr", "AI": {"tldr": "ClickHouse\u6536\u8d2d\u4e86LibreChat\uff0c\u5c06\u5176\u5f00\u6e90\u7684\u591aLLM\u804a\u5929\u5e73\u53f0\u6574\u5408\u4e3a\u7edf\u4e00\u7684Agentic Data Stack\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u7528\u4e8e\u9762\u5411\u4ee3\u7406\u7684\u5206\u6790\u3002", "motivation": "\u6784\u5efa\u7edf\u4e00\u7684Agentic Data Stack\uff0c\u4e3a\u4ee3\u7406\u63d0\u4f9b\u66f4\u597d\u7684\u5206\u6790\u80fd\u529b\uff0c\u6574\u5408\u5f00\u6e90\u7684\u591aLLM\u804a\u5929\u5e73\u53f0\u4ee5\u589e\u5f3a\u6570\u636e\u6808\u7684\u529f\u80fd\u3002", "method": "\u901a\u8fc7\u6536\u8d2dLibreChat\u5e76\u5c06\u5176\u5f00\u6e90\u7684\u591aLLM\u804a\u5929\u5e73\u53f0\u6574\u5408\u5230ClickHouse\u6570\u636e\u6808\u4e2d\uff0c\u5f62\u6210\u7edf\u4e00\u7684Agentic Data Stack\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u9762\u5411\u4ee3\u7406\u7684\u5206\u6790\u6570\u636e\u6808\uff0c\u6574\u5408\u4e86\u591aLLM\u804a\u5929\u529f\u80fd\u3002", "conclusion": "ClickHouse\u901a\u8fc7\u6536\u8d2dLibreChat\u589e\u5f3a\u4e86\u5176\u6570\u636e\u6808\u7684\u4ee3\u7406\u5206\u6790\u80fd\u529b\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u3002", "topic": "swe application"}}
{"id": "tldr.2511.a39ac870", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdata%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019a58d992b4-e87efaf0-e81d-45c4-9475-4d30b556bb66-000000/T42Ua3w8MrLoYvZOWaE71xg1kZqbe13Goekz2NMZkAA=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdata%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019a58d992b4-e87efaf0-e81d-45c4-9475-4d30b556bb66-000000/T42Ua3w8MrLoYvZOWaE71xg1kZqbe13Goekz2NMZkAA=430", "authors": ["TLDR Newsletter"], "title": "advertise with us", "comment": "Source: TLDR Newsletter, Date: 2025-11-06, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fadvertise.tldr.tech%2F%3Futm_source=tldrdata%26utm_medium=newsletter%26utm_campaign=advertisecta/1/0100019a58d992b4-e87efaf0-e81d-45c4-9475-4d30b556bb66-000000/T42Ua3w8MrLoYvZOWaE71xg1kZqbe13Goekz2NMZkAA=430", "summary": "ClickHouse Welcomes LibreChat: Introducing the Open-Source Agentic Data Stack (7 minute read) ClickHouse has acquired LibreChat, integrating its open-source, multi-LLM chat platform as a core component of a unified Agentic Data Stack for agent-facing analytics.", "source": "tldr", "AI": {"tldr": "ClickHouse\u6536\u8d2d\u4e86LibreChat\uff0c\u5c06\u5176\u5f00\u6e90\u7684\u591aLLM\u804a\u5929\u5e73\u53f0\u6574\u5408\u4e3a\u7edf\u4e00\u7684Agentic Data Stack\u7684\u6838\u5fc3\u7ec4\u4ef6\uff0c\u7528\u4e8e\u9762\u5411\u4ee3\u7406\u7684\u5206\u6790\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u7edf\u4e00\u7684\u4ee3\u7406\u6570\u636e\u5806\u6808\uff0c\u4e3aAI\u4ee3\u7406\u63d0\u4f9b\u5206\u6790\u80fd\u529b\uff0c\u901a\u8fc7\u6574\u5408\u804a\u5929\u5e73\u53f0\u6765\u589e\u5f3a\u6570\u636e\u4ea4\u4e92\u548c\u5206\u6790\u529f\u80fd\u3002", "method": "\u901a\u8fc7\u6536\u8d2dLibreChat\u5f00\u6e90\u591aLLM\u804a\u5929\u5e73\u53f0\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230ClickHouse\u7684Agentic Data Stack\u4e2d\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u4ee3\u7406\u6570\u636e\u5806\u6808\uff0c\u96c6\u6210\u4e86\u591aLLM\u804a\u5929\u529f\u80fd\uff0c\u4e3a\u4ee3\u7406\u63d0\u4f9b\u6570\u636e\u5206\u6790\u80fd\u529b\u3002", "conclusion": "ClickHouse\u901a\u8fc7\u6536\u8d2dLibreChat\u6210\u529f\u6784\u5efa\u4e86\u9762\u5411\u4ee3\u7406\u7684\u7edf\u4e00\u6570\u636e\u5806\u6808\uff0c\u589e\u5f3a\u4e86AI\u4ee3\u7406\u7684\u6570\u636e\u5206\u6790\u80fd\u529b\u3002", "topic": "agent analysis"}}
{"id": "tldr.2511.933ccbb4", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fblog.sentry.io%2Fai-code-review-30k-bugs-lighter-50-faster%2F%3Futm_source=tldr%26utm_medium=paid-community%26utm_campaign=aicodereview-fy26q4-aicodereviewlaunch%26utm_content=newsletter-30k-blog-learnmore/2/0100019a591e2f3d-ec2946e5-1c0f-4f48-99b9-eafc27e7c61f-000000/nEzvw9ztzr5lqCy15MoA9KxQSRLT_guzgGgAVPqKauE=430", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fblog.sentry.io%2Fai-code-review-30k-bugs-lighter-50-faster%2F%3Futm_source=tldr%26utm_medium=paid-community%26utm_campaign=aicodereview-fy26q4-aicodereviewlaunch%26utm_content=newsletter-30k-blog-learnmore/2/0100019a591e2f3d-ec2946e5-1c0f-4f48-99b9-eafc27e7c61f-000000/nEzvw9ztzr5lqCy15MoA9KxQSRLT_guzgGgAVPqKauE=430", "authors": ["TLDR Newsletter"], "title": "30,000 bugs in 30 days", "comment": "Source: TLDR Newsletter, Date: 2025-11-06, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fblog.sentry.io%2Fai-code-review-30k-bugs-lighter-50-faster%2F%3Futm_source=tldr%26utm_medium=paid-community%26utm_campaign=aicodereview-fy26q4-aicodereviewlaunch%26utm_content=newsletter-30k-blog-learnmore/2/0100019a591e2f3d-ec2946e5-1c0f-4f48-99b9-eafc27e7c61f-000000/nEzvw9ztzr5lqCy15MoA9KxQSRLT_guzgGgAVPqKauE=430", "summary": "30,000 bugs in 30 days (Sponsor) Sentry launched AI Code Review 30 days ago. Since then, it's caught 30k bugs and is working 50% faster. Read the blog post to learn: How Sentry applies a \u201cthinking budget\u201d to each review step to prevent overthinking - making AI code reviews are leaner and speedier. The new Claude Skill that connects Claude Code directly to AI Code Review outputs. Revamping how AI comments are structured \u27a1\ufe0f The bottom line: AI Code Review has caught 30K+ bugs.. .and it's only g...", "source": "tldr", "AI": {"tldr": "Sentry\u7684AI\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u572830\u5929\u5185\u53d1\u73b0\u4e8630,000\u4e2abug\uff0c\u5ba1\u67e5\u901f\u5ea6\u63d0\u5347\u4e8650%\uff0c\u901a\u8fc7'\u601d\u8003\u9884\u7b97'\u673a\u5236\u9632\u6b62\u8fc7\u5ea6\u601d\u8003\u3002", "motivation": "\u63d0\u9ad8\u4ee3\u7801\u5ba1\u67e5\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u901a\u8fc7AI\u6280\u672f\u81ea\u52a8\u53d1\u73b0\u4ee3\u7801\u4e2d\u7684bug\uff0c\u51cf\u5c11\u4eba\u5de5\u5ba1\u67e5\u8d1f\u62c5\u3002", "method": "\u5e94\u7528'\u601d\u8003\u9884\u7b97'\u673a\u5236\u9650\u5236\u6bcf\u4e2a\u5ba1\u67e5\u6b65\u9aa4\u7684\u601d\u8003\u65f6\u95f4\uff0c\u9632\u6b62AI\u8fc7\u5ea6\u601d\u8003\uff1b\u5f15\u5165Claude Skill\u8fde\u63a5Claude Code\u4e0eAI\u4ee3\u7801\u5ba1\u67e5\u8f93\u51fa\uff1b\u4f18\u5316AI\u8bc4\u8bba\u7ed3\u6784\u3002", "result": "30\u5929\u5185\u53d1\u73b030,000\u591a\u4e2abug\uff0c\u5ba1\u67e5\u901f\u5ea6\u63d0\u534750%\u3002", "conclusion": "AI\u4ee3\u7801\u5ba1\u67e5\u5de5\u5177\u80fd\u6709\u6548\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u548c\u5ba1\u67e5\u6548\u7387\uff0c'\u601d\u8003\u9884\u7b97'\u673a\u5236\u662f\u63d0\u9ad8\u6027\u80fd\u7684\u5173\u952e\u3002", "topic": "swe application"}}
{"id": "wechat.2511.7ebd8f2d", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5Mzc2NjczMQ==&mid=2651896459&idx=2&sn=45c3d875b10ac03155ffa27cb0ae30e4&chksm=bcb34953cee07b5b272af8b190849181a22d91abf4423b9882279789baeeedea440727c6a0f2#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5Mzc2NjczMQ==&mid=2651896459&idx=2&sn=45c3d875b10ac03155ffa27cb0ae30e4&chksm=bcb34953cee07b5b272af8b190849181a22d91abf4423b9882279789baeeedea440727c6a0f2#rd", "authors": ["\u4e2d\u79d1\u9662\u8ba1\u7b97\u6240\u57f9\u8bad\u4e2d\u5fc3"], "title": "\u6bcf\u5468\u4e00\u4e66\u300a<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7cbe\u8981\uff1a\u6838\u5fc3\u7b97\u6cd5\u4e0eTensorFlow\u5b9e\u73b0 pdf\u300b\u5206\u4eab", "comment": "Source: WeChat, Published: 2025-11-07 08:19:28", "summary": "\u4e66\u4e2d\u4ecb\u7ecd\u7684\u4ee3\u7801\u53ef\u4ee5\u5e2e\u52a9\u8bfb\u8005\u5feb\u901f\u5c06\u7b97\u6cd5\u5e94\u7528\u5230\u5b9e\u8df5\u4e2d\u3002\u5f3a\u5316\u5b66\u4e60\u3002\u7cbe\u8981 ui\u3002\u7f16\u8f91\u63a8\u8350\u8be5\u4e66\u7cfb\u7edf\u9610\u8ff0\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u7406\u8bba\u4e0e\u7b97\u6cd5\u5b9e\u73b0\uff0c\u6db5\u76d6\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3001Q-Learning\u3001DQN\u6539\u8fdb\u7b97\u6cd5\u53ca\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u7b49\u5185\u5bb9\uff0c\u7ed3\u5408TensorFlow\u6846\u67b6\u63d0\u4f9b\u4ee3", "AI": {"tldr": "\u4e66\u4e2d\u4ecb\u7ecd\u7684\u4ee3\u7801\u53ef\u4ee5\u5e2e\u52a9\u8bfb\u8005\u5feb\u901f\u5c06\u7b97\u6cd5\u5e94\u7528\u5230\u5b9e\u8df5\u4e2d\u3002\u5f3a\u5316\u5b66\u4e60\u3002\u7cbe\u8981 ui\u3002\u7f16\u8f91\u63a8\u8350\u8be5\u4e66\u7cfb\u7edf\u9610\u8ff0\u5f3a\u5316\u5b66\u4e60\u57fa\u7840\u7406\u8bba\u4e0e\u7b97\u6cd5\u5b9e\u73b0\uff0c\u6db5\u76d6\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3001Q-Learning\u3001DQN\u6539\u8fdb\u7b97\u6cd5\u53ca\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u7b49\u5185\u5bb9\uff0c\u7ed3\u5408TensorFlow\u6846\u67b6\u63d0\u4f9b\u4ee3", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2511.526760b4", "categories": ["wechat.article", "wechat.ai", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2651000503&idx=3&sn=6e1443e4f8c13d3822cd12b731907565&chksm=85883e74e5bde1bde2a663e63ed7f0087076290128c5465bbd8d7d21c37ef39e9af5e6b97c37#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2651000503&idx=3&sn=6e1443e4f8c13d3822cd12b731907565&chksm=85883e74e5bde1bde2a663e63ed7f0087076290128c5465bbd8d7d21c37ef39e9af5e6b97c37#rd", "authors": ["\u673a\u5668\u4e4b\u5fc3"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>+\u5927\u6a21\u578b\u8bb0\u5fc6\uff1aMem-\u03b1\uff0c\u8ba9\u667a\u80fd\u4f53\u7b2c\u4e00\u6b21\u5b66\u4f1a\u201c\u5982\u4f55\u8bb0\u5fc6\u201d", "comment": "Source: WeChat, Published: 2025-11-07 07:14:16", "summary": "\u8fd9\u9879\u5de5\u4f5c\u662f\u9996\u6b21\u5c06\u5f3a\u5316\u5b66\u4e60\u5f15\u5165\u5927\u6a21\u578b\u7684\u8bb0\u5fc6\u7ba1\u7406\u4f53\u7cfb\uff0c\u8ba9\u6a21\u578b\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u5982\u4f55\u4f7f\u7528\u5de5\u5177\u53bb\u5b58\u50a8\u3001\u66f4\u65b0\u548c\u7ec4\u7ec7\u8bb0\u5fc6\u3002Yuanzhe Hu2\uff0c Julian McAuley2\uff0c Xiaojian Wu2 \uff0c", "AI": {"tldr": "\u8fd9\u9879\u5de5\u4f5c\u662f\u9996\u6b21\u5c06\u5f3a\u5316\u5b66\u4e60\u5f15\u5165\u5927\u6a21\u578b\u7684\u8bb0\u5fc6\u7ba1\u7406\u4f53\u7cfb\uff0c\u8ba9\u6a21\u578b\u80fd\u591f\u81ea\u4e3b\u5b66\u4e60\u5982\u4f55\u4f7f\u7528\u5de5\u5177\u53bb\u5b58\u50a8\u3001\u66f4\u65b0\u548c\u7ec4\u7ec7\u8bb0\u5fc6\u3002Yuanzhe Hu2\uff0c Julian McAuley2\uff0c Xiaojian Wu2 \uff0c", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.7ce1fa8c", "categories": ["wechat.article", "wechat.rl", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652642887&idx=3&sn=a249244679bc3ab1be1f79cacbfb839b&chksm=f092569002b095abb47490a2e233b4063725ca1b6fa31af976a6d8c6fd3ac5446a57c4e17e06#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI3MTA0MTk1MA==&mid=2652642887&idx=3&sn=a249244679bc3ab1be1f79cacbfb839b&chksm=f092569002b095abb47490a2e233b4063725ca1b6fa31af976a6d8c6fd3ac5446a57c4e17e06#rd", "authors": ["\u65b0\u667a\u5143"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6559\u7236\u91cd\u51fa\u6c5f\u6e56\uff0c \u751f\u6210\u5f0fAI\u7684\u65f6\u4ee3\u8981\u7ed3\u675f\u4e86\uff1f", "comment": "Source: WeChat, Published: 2025-11-07 04:24:44", "summary": "\u6211\u4eec\u7684\u91cd\u70b9\u662f\u771f\u6b63\u7684\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\uff0c\u5b83\u5c06\u63a8\u52a8\u6301\u7eed\u5b66\u4e60\u3001\u6cdb\u5316\u80fd\u529b\u4ee5\u53ca\u57fa\u4e8e\u6a21\u578b\u7684\u5c42\u7ea7\u89c4\u5212\u3002\u4e0e\u5f53\u4e0b\u4f9d\u8d56\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u8def\u7ebf\u4e0d\u540c\uff0cExperienceFlow\u8ba4\u4e3a\u667a\u80fd\u7684\u6838\u5fc3\u4e0d\u5728\u53c2\u6570\u91cf\uff0c\u800c\u5728\u4e8e\u300c\u5982\u4f55\u901a\u8fc7\u7ecf\u9a8c\u4ea7\u751f\u77e5\u8bc6\u300d\u3002", "AI": {"tldr": "\u6211\u4eec\u7684\u91cd\u70b9\u662f\u771f\u6b63\u7684\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\uff0c\u5b83\u5c06\u63a8\u52a8\u6301\u7eed\u5b66\u4e60\u3001\u6cdb\u5316\u80fd\u529b\u4ee5\u53ca\u57fa\u4e8e\u6a21\u578b\u7684\u5c42\u7ea7\u89c4\u5212\u3002\u4e0e\u5f53\u4e0b\u4f9d\u8d56\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u8def\u7ebf\u4e0d\u540c\uff0cExperienceFlow\u8ba4\u4e3a\u667a\u80fd\u7684\u6838\u5fc3\u4e0d\u5728\u53c2\u6570\u91cf\uff0c\u800c\u5728\u4e8e\u300c\u5982\u4f55\u901a\u8fc7\u7ecf\u9a8c\u4ea7\u751f\u77e5\u8bc6\u300d\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.c0d380d1", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA5MjE0MTI0NQ==&mid=2247534208&idx=1&sn=3c22e2f773b631ec3df81d63acd36e87&chksm=911068c612faede6be041f972677ceeb536d28cc89986c1a5b121f7be36d1854aa2868f023cf#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA5MjE0MTI0NQ==&mid=2247534208&idx=1&sn=3c22e2f773b631ec3df81d63acd36e87&chksm=911068c612faede6be041f972677ceeb536d28cc89986c1a5b121f7be36d1854aa2868f023cf#rd", "authors": ["\u4e2d\u56fd\u8d27\u5e01\u5e02\u573a"], "title": "\u57fa\u4e8e<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7684\u673a\u6784\u884c\u4e3a\u60c5\u7eea\u62d0\u70b9\u9884\u8b66\u7cfb\u7edf\u6784\u5efa", "comment": "Source: WeChat, Published: 2025-11-07 02:33:25", "summary": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u4e00\u7c7b\u901a\u8fc7\u4e0e\u73af\u5883\u4ea4\u4e92\u6765\u4e0d\u65ad\u4f18\u5316\u51b3\u7b56\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u56e0\u5176\u5177\u5907\u5f3a\u5927\u7684\u52a8\u6001\u5b66\u4e60\u80fd\u529b\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u5b9e\u65f6\u51c6\u786e\u8bc6\u522b\u5e02\u573a\u6781\u7aef\u60c5\u7eea\u72b6\u6001\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002", "AI": {"tldr": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5f3a\u5316\u5b66\u4e60\u4f5c\u4e3a\u4e00\u7c7b\u901a\u8fc7\u4e0e\u73af\u5883\u4ea4\u4e92\u6765\u4e0d\u65ad\u4f18\u5316\u51b3\u7b56\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u56e0\u5176\u5177\u5907\u5f3a\u5927\u7684\u52a8\u6001\u5b66\u4e60\u80fd\u529b\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u5b9e\u65f6\u51c6\u786e\u8bc6\u522b\u5e02\u573a\u6781\u7aef\u60c5\u7eea\u72b6\u6001\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2511.55f42821", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU2OTQ3NzUxNQ==&mid=2247485071&idx=1&sn=55062507a0f663eab54c71f5d4c45eaf&chksm=fd800f50ad679297fe42c38b035c39d346908c2504ae23d3811ee6e7cecbb620491bcbc9f6a2#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU2OTQ3NzUxNQ==&mid=2247485071&idx=1&sn=55062507a0f663eab54c71f5d4c45eaf&chksm=fd800f50ad679297fe42c38b035c39d346908c2504ae23d3811ee6e7cecbb620491bcbc9f6a2#rd", "authors": ["PEDynamics"], "title": "\u6587\u732e\u901f\u9012\u2014\u9762\u5411\u57ce\u5e02\u7ed3\u6784\u5316\u7a7a\u57df\u907f\u649e\u7684\u4e09\u7ef4\u4ea4\u4e92\u901f\u5ea6\u969c\u788d\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u6df1\u5ea6<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>", "comment": "Source: WeChat, Published: 2025-11-07 01:41:00", "summary": "\u4f20\u7edf\u65b9\u6cd5\u5728\u8be5\u60c5\u666f\u4e0b\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u901f\u5ea6\u969c\u788d\u6cd5\u5728\u7ea6\u675f\u4e0b\u89e3\u7a7a\u95f4\u788e\u7247\u5316\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u53c8\u5f80\u5f80\u5ffd\u7565\u7a7a\u57df\u89c4\u5219\uff0c\u5b66\u5f97\u7684\u7b56\u7565\u5728\u5b9e\u9645\u4e2d\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\uff0c\u7ed3\u6784\u5316\u7a7a\u57df\u907f\u649e\u95ee\u9898\u5448\u73b0\u51fa\u4e09\u4e2a\u663e\u8457\u7279\u5f81\uff1a\u4e00\u662f\u4f20\u7edf\u7b97\u6cd5\u7684\u53ef\u884c\u89e3\u7a7a\u95f4\u6025\u5267\u6536\u7f29", "AI": {"tldr": "\u4f20\u7edf\u65b9\u6cd5\u5728\u8be5\u60c5\u666f\u4e0b\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u901f\u5ea6\u969c\u788d\u6cd5\u5728\u7ea6\u675f\u4e0b\u89e3\u7a7a\u95f4\u788e\u7247\u5316\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u53c8\u5f80\u5f80\u5ffd\u7565\u7a7a\u57df\u89c4\u5219\uff0c\u5b66\u5f97\u7684\u7b56\u7565\u5728\u5b9e\u9645\u4e2d\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\uff0c\u7ed3\u6784\u5316\u7a7a\u57df\u907f\u649e\u95ee\u9898\u5448\u73b0\u51fa\u4e09\u4e2a\u663e\u8457\u7279\u5f81\uff1a\u4e00\u662f\u4f20\u7edf\u7b97\u6cd5\u7684\u53ef\u884c\u89e3\u7a7a\u95f4\u6025\u5267\u6536\u7f29", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.c1f9b120", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIzODI0MzQ5Mw==&mid=2650906537&idx=1&sn=a543993793aaca741d68566b4ee20a37&chksm=f3ebde47e71b4fcc0842f9932096d5a54d45a5b62b47822ef02225764defcfa33d865885ca50#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIzODI0MzQ5Mw==&mid=2650906537&idx=1&sn=a543993793aaca741d68566b4ee20a37&chksm=f3ebde47e71b4fcc0842f9932096d5a54d45a5b62b47822ef02225764defcfa33d865885ca50#rd", "authors": ["AI Pulse"], "title": "\u5fae\u8f6f\u6700\u65b0\u5f00\u6e90\uff1a\u8ba9\u4efb\u4f55AI Agent\u201c\u81ea\u6211\u8fdb\u5316\u201d\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6846\u67b6", "comment": "Source: WeChat, Published: 2025-11-06 16:03:20", "summary": "\u5f3a\u5316\u5b66\u4e60\uff08Reinforcement Learning\uff0c RL\uff09\u88ab\u8ba4\u4e3a\u662f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u5173\u952e\uff0c\u5b83\u80fd\u57fa\u4e8e\u201c\u4efb\u52a1\u7ed3\u679c\u53cd\u9988\u201d\u76f4\u63a5\u4f18\u5316\u6a21\u578b\u7b56\u7565\uff0c\u800c\u65e0\u9700\u6602\u8d35\u6807\u6ce8\u6570\u636e\u3002\u7136\u800c\uff0c\u5c06 RL \u5e94\u7528\u4e8e Agent \u573a\u666f\u4ecd\u9762\u4e34\u5de8\u5927\u6311\u6218\u2014\u2014", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\uff08Reinforcement Learning\uff0c RL\uff09\u88ab\u8ba4\u4e3a\u662f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u5173\u952e\uff0c\u5b83\u80fd\u57fa\u4e8e\u201c\u4efb\u52a1\u7ed3\u679c\u53cd\u9988\u201d\u76f4\u63a5\u4f18\u5316\u6a21\u578b\u7b56\u7565\uff0c\u800c\u65e0\u9700\u6602\u8d35\u6807\u6ce8\u6570\u636e\u3002\u7136\u800c\uff0c\u5c06 RL \u5e94\u7528\u4e8e Agent \u573a\u666f\u4ecd\u9762\u4e34\u5de8\u5927\u6311\u6218\u2014\u2014", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.834ed4f5", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxMTQwODY1MQ==&mid=2651574369&idx=1&sn=a001bca353bfe6a29b35c2617591e8e2&chksm=81cb0e858869eb2284f1812b84f700c856496f19d09462d2261a60270d46f25c5b203de626a9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxMTQwODY1MQ==&mid=2651574369&idx=1&sn=a001bca353bfe6a29b35c2617591e8e2&chksm=81cb0e858869eb2284f1812b84f700c856496f19d09462d2261a60270d46f25c5b203de626a9#rd", "authors": ["\u4e91\u4e0e\u6570\u5b57\u5316"], "title": "\u4ece\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u5230\u667a\u80fd\u4f53\u5b66\u4e60\u95ed\u73af\uff1aLLM <em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7684\u5de5\u7a0b\u5b9e\u8df5\u5256\u6790", "comment": "Source: WeChat, Published: 2025-11-06 14:00:24", "summary": "\u5f3a\u5316\u5b66\u4e60\uff08ppo\uff09\uff1a\u7528\u5956\u52b1\u4fe1\u53f7\u53cd\u5411\u66f4\u65b0\u7b56\u7565\uff0c\u8ba9\u6a21\u578b\u503e\u5411\u8f93\u51fa\u201c\u66f4\u53d7\u6b22\u8fce\u201d\u7684\u7ed3\u679c\u3002\u5f62\u5f0f\u5316\u5730\u8bf4\uff1a [ \\max_\\theta E_a \\sim \\pi_\\theta\uff08as\uff09[R\uff08s\uff0c a\uff09] ] RLHF \u8ba9\u6a21\u578b\u4e0d\u4ec5\u201c\u4f1a\u8bf4\u201d\uff0c\u8fd8\u8981\u201c\u8bf4\u5f97\u8ba9\u4eba\u6ee1\u610f\u201d\u3002", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\uff08ppo\uff09\uff1a\u7528\u5956\u52b1\u4fe1\u53f7\u53cd\u5411\u66f4\u65b0\u7b56\u7565\uff0c\u8ba9\u6a21\u578b\u503e\u5411\u8f93\u51fa\u201c\u66f4\u53d7\u6b22\u8fce\u201d\u7684\u7ed3\u679c\u3002\u5f62\u5f0f\u5316\u5730\u8bf4\uff1a [ \\max_\\theta E_a \\sim \\pi_\\theta\uff08as\uff09[R\uff08s\uff0c a\uff09] ] RLHF \u8ba9\u6a21\u578b\u4e0d\u4ec5\u201c\u4f1a\u8bf4\u201d\uff0c\u8fd8\u8981\u201c\u8bf4\u5f97\u8ba9\u4eba\u6ee1\u610f\u201d\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.cc62df56", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU1MjcwNTM5OA==&mid=2247486682&idx=8&sn=23aa638b7ca5e29bd2a46a56a30f87e1&chksm=fa50305f68ecdd0d37c5bff77742e51c0d84bcd863ce877bab4ec14ae7e40e3db26975b0554d#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU1MjcwNTM5OA==&mid=2247486682&idx=8&sn=23aa638b7ca5e29bd2a46a56a30f87e1&chksm=fa50305f68ecdd0d37c5bff77742e51c0d84bcd863ce877bab4ec14ae7e40e3db26975b0554d#rd", "authors": ["\u805a\u641c\u8425\u9500"], "title": "\u534e\u4e3a\u4e91<em class=\"highlight\">Agentic</em> AI\u9a71\u52a8\u5b58\u50a8\u67b6\u6784\u53d8\u9769\uff0c\u6570\u636e\u5b58\u50a8\u5411\u201c\u77e5\u8bc6\u5b58\u50a8\u201d\u8dc3\u8fc1", "comment": "Source: WeChat, Published: 2025-11-07 08:14:48", "summary": "Agentic AI \u65f6\u4ee3\u7684\u6838\u5fc3\u7279\u5f81\u662f\u667a\u80fd\u4f53\uff08Agent\uff09\u7684\u5d1b\u8d77\uff0c\u8fd9\u4fc3\u4f7f\u5b58\u50a8\u7684\u4ef7\u503c\u4e0d\u518d\u5c40\u9650\u4e8e\u7b80\u5355\u7684\u201c\u6570\u636e\u5b58\u653e\u201d\uff0c\u800c\u662f\u6b63\u5728\u5411\u300c\u77e5\u8bc6\u5b58\u50a8\u300d\u8dc3\u8fc1\u3002\u672a\u6765\u7684 AI Data Platform \u5fc5\u987b\u5177\u5907\u4ee5\u4e0b\u80fd\u529b\uff1a", "AI": {"tldr": "Agentic AI \u65f6\u4ee3\u7684\u6838\u5fc3\u7279\u5f81\u662f\u667a\u80fd\u4f53\uff08Agent\uff09\u7684\u5d1b\u8d77\uff0c\u8fd9\u4fc3\u4f7f\u5b58\u50a8\u7684\u4ef7\u503c\u4e0d\u518d\u5c40\u9650\u4e8e\u7b80\u5355\u7684\u201c\u6570\u636e\u5b58\u653e\u201d\uff0c\u800c\u662f\u6b63\u5728\u5411\u300c\u77e5\u8bc6\u5b58\u50a8\u300d\u8dc3\u8fc1\u3002\u672a\u6765\u7684 AI Data Platform \u5fc5\u987b\u5177\u5907\u4ee5\u4e0b\u80fd\u529b\uff1a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.be164291", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2651000503&idx=1&sn=6ad854f9744346f407af041a82853024&chksm=85ef0947122cd46cda940d74ff95b016b23c0934324d82c882063a89d7130fe5c1a517d65bc6#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2651000503&idx=1&sn=6ad854f9744346f407af041a82853024&chksm=85ef0947122cd46cda940d74ff95b016b23c0934324d82c882063a89d7130fe5c1a517d65bc6#rd", "authors": ["\u673a\u5668\u4e4b\u5fc3"], "title": "\u534e\u4e3a\u4e91\u7684\u7ec4\u5408\u65b0\u8303\u5f0f\uff0c\u5f15\u7206\u4e86<em class=\"highlight\">Agentic</em> AI\u5e94\u7528\u9769\u547d", "comment": "Source: WeChat, Published: 2025-11-07 07:15:20", "summary": "Agentic AI\uff0c\u4ece\u6765\u6ca1\u6709\u8fd9\u4e48\u7b80\u5355\u8fc7\u3002\u521a\u521a\uff0c\u5728 2025 \u5168\u7403\u8ba1\u7b97\u5927\u4f1a\uff08CGC 2025\uff09\u4e0a\uff0c\u534e\u4e3a\u4e91\u6253\u51fa\u4e86\u4e00\u5957 AI \u65f6\u4ee3\u6280\u672f\u843d\u5730\u7684\u7ec4\u5408\u62f3\u3002\u4eca\u5e74\u662f AI \u5927\u6a21\u578b\u7684\u843d\u5730\u5173\u952e\u5e74\u3002", "AI": {"tldr": "Agentic AI\uff0c\u4ece\u6765\u6ca1\u6709\u8fd9\u4e48\u7b80\u5355\u8fc7\u3002\u521a\u521a\uff0c\u5728 2025 \u5168\u7403\u8ba1\u7b97\u5927\u4f1a\uff08CGC 2025\uff09\u4e0a\uff0c\u534e\u4e3a\u4e91\u6253\u51fa\u4e86\u4e00\u5957 AI \u65f6\u4ee3\u6280\u672f\u843d\u5730\u7684\u7ec4\u5408\u62f3\u3002\u4eca\u5e74\u662f AI \u5927\u6a21\u578b\u7684\u843d\u5730\u5173\u952e\u5e74\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.a220d532", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIzMTIyODMwMA==&mid=2650193517&idx=1&sn=0ff7a9dd8000eb1cb0c2eb48de4ce60b&chksm=f112e08092653dc4325aaa85d54e66ee6cef4b22f64ea23f4d6dbce5d25936f634061144a2b5#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIzMTIyODMwMA==&mid=2650193517&idx=1&sn=0ff7a9dd8000eb1cb0c2eb48de4ce60b&chksm=f112e08092653dc4325aaa85d54e66ee6cef4b22f64ea23f4d6dbce5d25936f634061144a2b5#rd", "authors": ["AGI\u5546\u4e1a\u65b0\u58f0"], "title": "<em class=\"highlight\">Agentic</em> AI\u76845\u79cd\u5e94\u7528\u65b9\u5f0f", "comment": "Source: WeChat, Published: 2025-11-07 03:33:10", "summary": "5 ways to use agentic ai 1 prompt routing agent 2 query writing\u3002\u00b7 expanding keywords into richer search terms\u3002\u00b7 converting natural language into sql\uff0c api calls\uff0c or vector retrieval queries.\u3002", "AI": {"tldr": "5 ways to use agentic ai 1 prompt routing agent 2 query writing\u3002\u00b7 expanding keywords into richer search terms\u3002\u00b7 converting natural language into sql\uff0c api calls\uff0c or vector retrieval queries.\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.b64e0a80", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYzNzE2ODIxMg==&mid=2247483685&idx=1&sn=186ac5b3590472df0f627c3e3166040d&chksm=f1c03c8f3ac82d6a1705416bcf5b7ceea3c96b3af09d34a48a24e8ba70cd4da7e97e710b87f2#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYzNzE2ODIxMg==&mid=2247483685&idx=1&sn=186ac5b3590472df0f627c3e3166040d&chksm=f1c03c8f3ac82d6a1705416bcf5b7ceea3c96b3af09d34a48a24e8ba70cd4da7e97e710b87f2#rd", "authors": ["EasyShip.AI"], "title": "Google\u53d1\u5e03\uff01\u4e00\u6587\u4e86\u89e321\u79cd<em class=\"highlight\">Agentic</em>\u8bbe\u8ba1\u6a21\u5f0f", "comment": "Source: WeChat, Published: 2025-11-07 02:38:25", "summary": "What makes an AI system an \"agent\"\uff1f\uff0c 9 pages [final\uff0c last read done] part three \uff08total\uff1a 34 pages\uff09 12. chapter 12\uff1a exception handling and recovery \uff08code\uff09\uff0c 8 pages [final\uff0c last read done\uff0c code ok] 13. chapter 13\uff1a human-in-the-loop \uff08code\uff09\uff0c 9 pages [final\uff0c last read don", "AI": {"tldr": "What makes an AI system an \"agent\"\uff1f\uff0c 9 pages [final\uff0c last read done] part three \uff08total\uff1a 34 pages\uff09 12. chapter 12\uff1a exception handling and recovery \uff08code\uff09\uff0c 8 pages [final\uff0c last read done\uff0c code ok] 13. c...", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2511.7613e55f", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA4Njc4MzUzOA==&mid=2651569751&idx=1&sn=a9a61245b4291c350bcb31d53426b9a7&chksm=8569a43ea9a3ef74a7e0bdc1789d117d1d6fcf0b1399b765c57b805493bf0a4db8a25592cbd7#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA4Njc4MzUzOA==&mid=2651569751&idx=1&sn=a9a61245b4291c350bcb31d53426b9a7&chksm=8569a43ea9a3ef74a7e0bdc1789d117d1d6fcf0b1399b765c57b805493bf0a4db8a25592cbd7#rd", "authors": ["\u96f7\u8499\u8bf4"], "title": "\u300a<em class=\"highlight\">Agentic</em> AI \u73b0\u72b6\uff1a\u521b\u59cb\u4eba\u7248\u300b\u5206\u4eab\uff1a\u770b\u770b\u521b\u59cb\u4eba\u4eec\u5982\u4f55\u770b\u5f85AI\u6d6a\u6f6e?", "comment": "Source: WeChat, Published: 2025-11-07 01:31:32", "summary": "\u4ee5\u4e0b\u662f\u6839\u636e MMC Ventures \u53d1\u5e03\u7684\u300aState of Agentic AI\uff1a Founder\u2019s Edition\u300b\uff082025\u5e7411\u67083\u65e5\uff09\u5185\u5bb9\u6574\u7406\u7684\u4e2d\u6587\u603b\u7ed3\uff0c\u6db5\u76d6\u6587\u7ae0\u6838\u5fc3\u4e3b\u9898\u3001\u5173\u952e\u53d1\u73b0\u4e0e\u7ec6\u8282\u8981\u70b9\uff1a", "AI": {"tldr": "\u4ee5\u4e0b\u662f\u6839\u636e MMC Ventures \u53d1\u5e03\u7684\u300aState of Agentic AI\uff1a Founder\u2019s Edition\u300b\uff082025\u5e7411\u67083\u65e5\uff09\u5185\u5bb9\u6574\u7406\u7684\u4e2d\u6587\u603b\u7ed3\uff0c\u6db5\u76d6\u6587\u7ae0\u6838\u5fc3\u4e3b\u9898\u3001\u5173\u952e\u53d1\u73b0\u4e0e\u7ec6\u8282\u8981\u70b9\uff1a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.a7078723", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA5NTI1MTcyNw==&mid=2651119725&idx=1&sn=bdce1893dd817dc630eafbad90eed44e&chksm=8a413fcf136a61c43a5ccc761b1addd9a5c741a4063f4cdc2d5de78f38a0f7a3d792cb8da7d7#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA5NTI1MTcyNw==&mid=2651119725&idx=1&sn=bdce1893dd817dc630eafbad90eed44e&chksm=8a413fcf136a61c43a5ccc761b1addd9a5c741a4063f4cdc2d5de78f38a0f7a3d792cb8da7d7#rd", "authors": ["\u79d1\u6280\u9818\u8896Alliance"], "title": "\u9ea6\u80af\u9521\u603b\u7ed3\u7684<em class=\"highlight\">Agentic</em> AI\u843d\u5730\u76846\u6761\u7ecf\u9a8c\u6559\u8bad", "comment": "Source: WeChat, Published: 2025-11-06 14:50:03", "summary": "\u5f52\u7ed3\u4e3a\u516d\u4e2a\u6559\u8bad\uff0c\u4ee5\u5e2e\u52a9\u9886\u5bfc\u8005\u6210\u529f\u5730\u4eceAgentic Al\u4e2d\u83b7\u53d6\u4ef7\u503c\u3002it's not about the agent\uff1b it's about the workflow\u3002\u4f01\u4e1a\u5e38\u8fc7\u5ea6\u5173\u6ce8A1\u667a\u80fd\u4f53\uff08A1 Agent\uff09\u672c\u8eab\u7684\u6280\u672f\uff0c\u5374\u5ffd\u7565\u4e86\u5176\u5e94\u5d4c\u5165\u7684\u4e1a\u52a1\u6d41\u7a0b\u3002", "AI": {"tldr": "\u5f52\u7ed3\u4e3a\u516d\u4e2a\u6559\u8bad\uff0c\u4ee5\u5e2e\u52a9\u9886\u5bfc\u8005\u6210\u529f\u5730\u4eceAgentic Al\u4e2d\u83b7\u53d6\u4ef7\u503c\u3002it's not about the agent\uff1b it's about the workflow\u3002\u4f01\u4e1a\u5e38\u8fc7\u5ea6\u5173\u6ce8A1\u667a\u80fd\u4f53\uff08A1 Agent\uff09\u672c\u8eab\u7684\u6280\u672f\uff0c\u5374\u5ffd\u7565\u4e86\u5176\u5e94\u5d4c\u5165\u7684\u4e1a\u52a1\u6d41\u7a0b\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.557cccc4", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxNTgxMDAxMg==&mid=2247484250&idx=1&sn=6471aa3b8a4c8c2b4f2d376705137221&chksm=c0f51fab7d9ec1ae64ffca3fe8b7d6e4f9c64bf0c158d94504f09339341aa9b4aff169b6ec6f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxNTgxMDAxMg==&mid=2247484250&idx=1&sn=6471aa3b8a4c8c2b4f2d376705137221&chksm=c0f51fab7d9ec1ae64ffca3fe8b7d6e4f9c64bf0c158d94504f09339341aa9b4aff169b6ec6f#rd", "authors": ["AI Lab Dev"], "title": "<em class=\"highlight\">Agentic</em>21\u79cd\u8bbe\u8ba1\u6a21\u5f0f-What makes an AI system an Agent?", "comment": "Source: WeChat, Published: 2025-11-06 14:22:52", "summary": "agentic ai problem-solving process get the mission 02 scan the scene 03 think lt through 04 take action 05 learn & get better\u56fe 1\uff1a\u8fd9\u79cd Agent \u5145\u5f53\u667a\u80fd\u52a9\u624b\u7684\u89d2\u8272\uff0c\u901a\u8fc7\u4e0d\u65ad\u5b66\u4e60\u6765\u63d0\u5347\u81ea\u8eab\u80fd\u529b\u3002", "AI": {"tldr": "agentic ai problem-solving process get the mission 02 scan the scene 03 think lt through 04 take action 05 learn & get better\u56fe 1\uff1a\u8fd9\u79cd Agent \u5145\u5f53\u667a\u80fd\u52a9\u624b\u7684\u89d2\u8272\uff0c\u901a\u8fc7\u4e0d\u65ad\u5b66\u4e60\u6765\u63d0\u5347\u81ea\u8eab\u80fd\u529b\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.fb54496b", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU4ODkyNzcyNA==&mid=2247534619&idx=1&sn=4b7460431dc0932b6bedb7ffde93855c&chksm=fcd6daac40c15f61b218cfef7f8b89998100d1be00f322a31468da04cd3096690a06c9bf0583#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU4ODkyNzcyNA==&mid=2247534619&idx=1&sn=4b7460431dc0932b6bedb7ffde93855c&chksm=fcd6daac40c15f61b218cfef7f8b89998100d1be00f322a31468da04cd3096690a06c9bf0583#rd", "authors": ["RPA\u5168\u7403\u751f\u6001"], "title": "\u300a2025 AI <em class=\"highlight\">\u5927\u6a21\u578b</em>\u5f00\u53d1\u751f\u6001\u767d\u76ae\u4e66\u300b\u6b63\u5f0f\u53d1\u5e03 | \u7b97\u6ce5\u793e\u533a", "comment": "Source: WeChat, Published: 2025-11-07 13:41:22", "summary": "2025\u5e74\uff0cAI\u5927\u6a21\u578b\u7684\u6280\u672f\u8fed\u4ee3\u5448\u73b0\u51fa\u660e\u663e\u7684\u52a0\u901f\u6001\u52bf\uff0c\u5176\u6838\u5fc3\u7279\u5f81\u662f\u4ece\u5355\u7eaf\u8ffd\u6c42\u57fa\u51c6\u6d4b\u8bd5\u5206\u6570\u7684\u201c\u80fd\u529b\u201d\uff08Capability\uff09\u63d0\u5347\uff0c\u8f6c\u5411\u66f4\u52a0\u6ce8\u91cd\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u7684\u201c\u53ef\u7528\u6027\u201d\uff08Usability\uff09\u8fdb\u5316\u3002", "AI": {"tldr": "2025\u5e74\uff0cAI\u5927\u6a21\u578b\u7684\u6280\u672f\u8fed\u4ee3\u5448\u73b0\u51fa\u660e\u663e\u7684\u52a0\u901f\u6001\u52bf\uff0c\u5176\u6838\u5fc3\u7279\u5f81\u662f\u4ece\u5355\u7eaf\u8ffd\u6c42\u57fa\u51c6\u6d4b\u8bd5\u5206\u6570\u7684\u201c\u80fd\u529b\u201d\uff08Capability\uff09\u63d0\u5347\uff0c\u8f6c\u5411\u66f4\u52a0\u6ce8\u91cd\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u5b9e\u7528\u6027\u7684\u201c\u53ef\u7528\u6027\u201d\uff08Usability\uff09\u8fdb\u5316\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe application"}}
{"id": "wechat.2511.c098affe", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA5NzAwNjg4NA==&mid=2650741338&idx=2&sn=d28732de26e86471264b6db8e53225e7&chksm=891baa49aa9009b3ecd3944de7c5ded06cde03ba0396d577d91a18133590adb44e4b8deb46a6#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA5NzAwNjg4NA==&mid=2650741338&idx=2&sn=d28732de26e86471264b6db8e53225e7&chksm=891baa49aa9009b3ecd3944de7c5ded06cde03ba0396d577d91a18133590adb44e4b8deb46a6#rd", "authors": ["\u5b89\u5fbd\u7701\u79d1\u6280\u5385"], "title": "\u6df1\u5ea6\u63a8\u7406<em class=\"highlight\">\u5927\u6a21\u578b</em>\u8baf\u98de\u661f\u706bX1.5\u53d1\u5e03", "comment": "Source: WeChat, Published: 2025-11-07 13:01:27", "summary": "\u53d1\u5e03\u4f1a\u4e0a\uff0c\u6df1\u5ea6\u63a8\u7406\u5927\u6a21\u578b\u8baf\u98de\u661f\u706bX1.5\u6b63\u5f0f\u4eae\u76f8\u3002\u661f\u706bX1.5\u63a8\u7406\u6548\u7387\u76f8\u6bd4\u661f\u706bX1\u63d0\u5347100%\uff0c\u5b83\u7684\u8bed\u8a00\u7406\u89e3\u3001\u6587\u672c\u751f\u6210\u3001\u77e5\u8bc6\u95ee\u7b54\u3001\u903b\u8f91\u63a8\u7406\u3001\u6570\u5b66\u80fd\u529b\u3001\u4ee3\u7801\u80fd\u529b\u7b49\u516d\u5927\u6838\u5fc3\u80fd\u529b\u5168\u9762\u5bf9\u6807\u56fd\u9645\u4e3b\u6d41\uff0c\u5176\u4e2d\u6570\u5b66\u80fd\u529b\u6301\u7eed\u4fdd\u6301\u56fd\u9645\u9886\u5148", "AI": {"tldr": "\u53d1\u5e03\u4f1a\u4e0a\uff0c\u6df1\u5ea6\u63a8\u7406\u5927\u6a21\u578b\u8baf\u98de\u661f\u706bX1.5\u6b63\u5f0f\u4eae\u76f8\u3002\u661f\u706bX1.5\u63a8\u7406\u6548\u7387\u76f8\u6bd4\u661f\u706bX1\u63d0\u5347100%\uff0c\u5b83\u7684\u8bed\u8a00\u7406\u89e3\u3001\u6587\u672c\u751f\u6210\u3001\u77e5\u8bc6\u95ee\u7b54\u3001\u903b\u8f91\u63a8\u7406\u3001\u6570\u5b66\u80fd\u529b\u3001\u4ee3\u7801\u80fd\u529b\u7b49\u516d\u5927\u6838\u5fc3\u80fd\u529b\u5168\u9762\u5bf9\u6807\u56fd\u9645\u4e3b\u6d41\uff0c\u5176\u4e2d\u6570\u5b66\u80fd\u529b\u6301\u7eed\u4fdd\u6301\u56fd\u9645\u9886\u5148", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2511.b00ade80", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYyMTk5MjAxOA==&mid=2247483740&idx=1&sn=8d868ed0d3b6ae4877c28ba9ac2e49bf&chksm=fe67b6ad432597e42ed40ef278d1d64456fcff8ae675ceb267201df27b6aeabb14dcea5b36c1#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYyMTk5MjAxOA==&mid=2247483740&idx=1&sn=8d868ed0d3b6ae4877c28ba9ac2e49bf&chksm=fe67b6ad432597e42ed40ef278d1d64456fcff8ae675ceb267201df27b6aeabb14dcea5b36c1#rd", "authors": ["AIdea\u7a7a\u95f4"], "title": "<em class=\"highlight\">\u5927\u6a21\u578b</em>\u96c6\u4f53\u7ffb\u8f66\uff01\u5b57\u8282 \u00d7 \u65af\u5766\u798f\u65b0\u57fa\u51c6 MIRA \u63ed\u793a\u591a\u6a21\u6001AI\u7684\u201c\u89c6\u89c9\u63a8\u7406\u77ed\u677f\u201d", "comment": "Source: WeChat, Published: 2025-11-07 12:01:46", "summary": "\u5411\u5de6\u6ed1\u52a8\u67e5\u770b\u66f4\u591a\u5927\u6a21\u578b\u7ffb\u8f66\u77ac\u95f4\uff08\u6b63\u786e\u7b54\u6848\uff1a2\uff09\u4e00\u3001\u4ece\u201c\u601d\u7ef4\u94fe\u201d\u5230\u201c\u89c6\u89c9\u65ad\u94fe\u201d\uff1aText-CoT\u7684\u81f4\u547d\u8f6f\u808b\u5728\u8fc7\u53bb\u7684\u51e0\u5e74\u91cc\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u901a\u8fc7\u4e00\u79cd\u540d\u4e3a\u201c\u601d\u7ef4\u94fe\u201d\uff08Chain-of-Thought\uff0c CoT\uff09\u7684\u6280\u672f\u88ab\u6781\u5927\u6fc0\u6d3b\u4e86\u3002", "AI": {"tldr": "\u5411\u5de6\u6ed1\u52a8\u67e5\u770b\u66f4\u591a\u5927\u6a21\u578b\u7ffb\u8f66\u77ac\u95f4\uff08\u6b63\u786e\u7b54\u6848\uff1a2\uff09\u4e00\u3001\u4ece\u201c\u601d\u7ef4\u94fe\u201d\u5230\u201c\u89c6\u89c9\u65ad\u94fe\u201d\uff1aText-CoT\u7684\u81f4\u547d\u8f6f\u808b\u5728\u8fc7\u53bb\u7684\u51e0\u5e74\u91cc\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u901a\u8fc7\u4e00\u79cd\u540d\u4e3a\u201c\u601d\u7ef4\u94fe\u201d\uff08Chain-of-Thought\uff0c CoT\uff09\u7684\u6280\u672f\u88ab\u6781\u5927\u6fc0\u6d3b\u4e86\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2511.fa75c3bf", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg2MjYyNDU3MQ==&mid=2247488191&idx=2&sn=7315e4510654bfee2b055c77504077c1&chksm=cfa24adc93b57341abbc8120d7a3af67e2ea18a07d25eed6985040f40e889c0f1b061000589e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg2MjYyNDU3MQ==&mid=2247488191&idx=2&sn=7315e4510654bfee2b055c77504077c1&chksm=cfa24adc93b57341abbc8120d7a3af67e2ea18a07d25eed6985040f40e889c0f1b061000589e#rd", "authors": ["\u5fae\u98ce\u667a\u9009"], "title": "\u3010\u5fae\u79d1\u666e\u3011\u4eceAI\u5de5\u5177\u770bAI\u65b0\u6d6a\u6f6e\uff1a<em class=\"highlight\">\u5927\u6a21\u578b</em>\u4e0e\u667a\u80fd\u4f53\u5982\u4f55\u91cd\u5851\u672a\u6765\uff1f", "comment": "Source: WeChat, Published: 2025-11-07 11:50:49", "summary": "\u5927\u6a21\u578b\uff08Large Model\uff09\u6307\u7684\u662f\u901a\u8fc7\u5229\u7528\u6d77\u91cf\u6570\u636e\u8bad\u7ec3\u800c\u6210\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u5e38\u5177\u6709\u53c2\u6570\u91cf\u5927\u3001\u8bad\u7ec3\u6570\u636e\u5927\u3001\u8ba1\u7b97\u8d44\u6e90\u5927\u7b49\u663e\u8457\u7279\u70b9\uff0c\u5177\u5907\u5f3a\u5927\u7684\u6570\u636e\u5904\u7406\u548c\u751f\u6210\u80fd\u529b\u3002", "AI": {"tldr": "\u5927\u6a21\u578b\uff08Large Model\uff09\u6307\u7684\u662f\u901a\u8fc7\u5229\u7528\u6d77\u91cf\u6570\u636e\u8bad\u7ec3\u800c\u6210\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u5e38\u5177\u6709\u53c2\u6570\u91cf\u5927\u3001\u8bad\u7ec3\u6570\u636e\u5927\u3001\u8ba1\u7b97\u8d44\u6e90\u5927\u7b49\u663e\u8457\u7279\u70b9\uff0c\u5177\u5907\u5f3a\u5927\u7684\u6570\u636e\u5904\u7406\u548c\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.547ba380", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkzNzg2NTY1MA==&mid=2247485546&idx=1&sn=f337ab2763c6bcfbc2b1134fae5dc291&chksm=c375e32de7a54bf90ea43f551cec3e0addcbd396836e6de6fd5255e3fea2426c4e2d469b29a6#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkzNzg2NTY1MA==&mid=2247485546&idx=1&sn=f337ab2763c6bcfbc2b1134fae5dc291&chksm=c375e32de7a54bf90ea43f551cec3e0addcbd396836e6de6fd5255e3fea2426c4e2d469b29a6#rd", "authors": ["\u63a2\u6570\u901a"], "title": "\u725b\uff01<em class=\"highlight\">\u5927\u6a21\u578b</em>\u76849\u5927\u6838\u5fc3\u6280\u672f\u89e3\u6790\uff01", "comment": "Source: WeChat, Published: 2025-11-07 09:56:33", "summary": "ai\u667a\u80fd\u4f53\u67b6\u6784\u8bbe\u8ba1 1 2 planning 3 4 action 5 llm 8 6 \u5de5\u5177\u96c6 \u5927\u6a21\u578b 7 9 observation 10 10 final answer \u6398\u91d1\u6280\u672f\u793e\u533a@\u805a\u5ba2ai \u4e8c\u3001Agentic AIAgentic AI \u4ee3\u8868\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u7cfb\u7edf\u67b6\u6784\u3002", "AI": {"tldr": "ai\u667a\u80fd\u4f53\u67b6\u6784\u8bbe\u8ba1 1 2 planning 3 4 action 5 llm 8 6 \u5de5\u5177\u96c6 \u5927\u6a21\u578b 7 9 observation 10 10 final answer \u6398\u91d1\u6280\u672f\u793e\u533a@\u805a\u5ba2ai \u4e8c\u3001Agentic AIAgentic AI \u4ee3\u8868\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u7cfb\u7edf\u67b6\u6784\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.508afe1c", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkxNTE5MjIxNQ==&mid=2247531220&idx=1&sn=9082905fd9baf4122a56ee2720337ea0&chksm=c03556b07ee53bd6a4033771f5e06283dfc728c800c8a004b3391c516f4eb527189317e2af48#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkxNTE5MjIxNQ==&mid=2247531220&idx=1&sn=9082905fd9baf4122a56ee2720337ea0&chksm=c03556b07ee53bd6a4033771f5e06283dfc728c800c8a004b3391c516f4eb527189317e2af48#rd", "authors": ["\u9752\u4e91\u79d1\u6280"], "title": "\u5168\u7403\u5f00\u6e90\u699c\u7b2c\u4e00\u7684\u7f16\u7a0b<em class=\"highlight\">\u5927\u6a21\u578b</em>\u6765\u4e86\uff01\u9752\u4e91\u4e0a\u7ebf MiniMax M2", "comment": "Source: WeChat, Published: 2025-11-07 09:35:12", "summary": "\u5e73\u53f0\u63d0\u4f9b\u6a21\u578b\u8be2\u7528\u670d\u52a1\uff0c\u6a21\u5b9e\u5907\u9645\u8c03\u7528\u5907\u8ba1\u518c\uff0c\u53ef\u5148\u521b\u5efaAPI\u5b97\u5219\uff0c\u4f7f\u7528\u5728\u7ebf\u4f53\u9a8c\u529f\u80fd\uff0c\u4e5f\u53ef\u901a\u8fc7openA\u7528\u8c03\u7528\u63a5\u53e3\u670d\u88c5\uff0c\u670d\u4f7f\u7528\u6307\u5357 \u5168\u90e8 \u6587\u751f\u6587 \u6587\u751f\u56fe \u6587\u751f\u89c6\u9891 \u56fe\u751f\u89c6\u9891 \u8bed\u97f3 \u5d4c\u5165 \u91cd\u6392\u5e8f \u591a\u6a21\u5fd7 api\u5bc6\u660e\u7ba1\u7406 \u7528\u91cf\u7edf\u8ba1 minimax-m2 de", "AI": {"tldr": "\u5e73\u53f0\u63d0\u4f9b\u6a21\u578b\u8be2\u7528\u670d\u52a1\uff0c\u6a21\u5b9e\u5907\u9645\u8c03\u7528\u5907\u8ba1\u518c\uff0c\u53ef\u5148\u521b\u5efaAPI\u5b97\u5219\uff0c\u4f7f\u7528\u5728\u7ebf\u4f53\u9a8c\u529f\u80fd\uff0c\u4e5f\u53ef\u901a\u8fc7openA\u7528\u8c03\u7528\u63a5\u53e3\u670d\u88c5\uff0c\u670d\u4f7f\u7528\u6307\u5357 \u5168\u90e8 \u6587\u751f\u6587 \u6587\u751f\u56fe \u6587\u751f\u89c6\u9891 \u56fe\u751f\u89c6\u9891 \u8bed\u97f3 \u5d4c\u5165 \u91cd\u6392\u5e8f \u591a\u6a21\u5fd7 api\u5bc6\u660e\u7ba1\u7406 \u7528\u91cf\u7edf\u8ba1 minimax-m2 de", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2511.bb1f9ab2", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU0ODkwNDc4Mw==&mid=2247498028&idx=1&sn=372bd79f83b5d71b60716293cf693142&chksm=fa68648be81e67e472a99032860071ac8136ed58eb251fcc8e89effaa00c7c7e1cffd051b1fe#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU0ODkwNDc4Mw==&mid=2247498028&idx=1&sn=372bd79f83b5d71b60716293cf693142&chksm=fa68648be81e67e472a99032860071ac8136ed58eb251fcc8e89effaa00c7c7e1cffd051b1fe#rd", "authors": ["CNIS\u56fd\u5bb6\u5de5\u7a0b\u7814\u7a76\u4e2d\u5fc3"], "title": "AI\u6a21\u578b\u7f51\u7edc\u5b89\u5168\u5b9e\u529b\u5927\u6bd4\u62fc\uff1a\u4e2d\u56fd\u7535\u4fe1\u7814\u7a76\u9662\u53d1\u5e03<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7f51\u7edc\u5b89\u5168\u80fd\u529b\u8bc4\u6d4b\u62a5\u544a", "comment": "Source: WeChat, Published: 2025-11-07 07:11:17", "summary": "\u4e5d\u6b3e\u4e3b\u6d41\u5927\u6a21\u578b\u7f51\u7edc\u5b89\u5168\u80fd\u529b\u6392\u540d\u3001\u80fd\u529b\u5206\u5e03\u89c6\u56fe\u5982\u4e0b\uff0c\u8be6\u7ec6\u6d4b\u8bc4\u7ed3\u679c\u53ef\u53c2\u8003\u6587\u672b\u6d4b\u8bc4\u62a5\u544a\u3002\u5404\u4e2aai\u5b89\u5168\u6a21\u578b\u6574\u4f53\u8bc4\u4ef7\u6392\u540d\u3002glm\u30020. 795\u3002gpt-oss\u30020. 782 seed-oss\u3002", "AI": {"tldr": "\u4e5d\u6b3e\u4e3b\u6d41\u5927\u6a21\u578b\u7f51\u7edc\u5b89\u5168\u80fd\u529b\u6392\u540d\u3001\u80fd\u529b\u5206\u5e03\u89c6\u56fe\u5982\u4e0b\uff0c\u8be6\u7ec6\u6d4b\u8bc4\u7ed3\u679c\u53ef\u53c2\u8003\u6587\u672b\u6d4b\u8bc4\u62a5\u544a\u3002\u5404\u4e2aai\u5b89\u5168\u6a21\u578b\u6574\u4f53\u8bc4\u4ef7\u6392\u540d\u3002glm\u30020. 795\u3002gpt-oss\u30020. 782 seed-oss\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2511.0ceea45c", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzUyNTkyNjc4OQ==&mid=2247502698&idx=2&sn=dc56a867d996199ec84b5a882ff35804&chksm=fbd42d5ecb4449222d8b01291be813320d2a1bab4e56198689732237f615c72156a44634dee9#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzUyNTkyNjc4OQ==&mid=2247502698&idx=2&sn=dc56a867d996199ec84b5a882ff35804&chksm=fbd42d5ecb4449222d8b01291be813320d2a1bab4e56198689732237f615c72156a44634dee9#rd", "authors": ["\u5fae\u98ce\u4f01"], "title": "\u3010\u5fae\u79d1\u666e\u3011\u4eceAI\u5de5\u5177\u770bAI\u65b0\u6d6a\u6f6e\uff1a<em class=\"highlight\">\u5927\u6a21\u578b</em>\u4e0e\u667a\u80fd\u4f53\u5982\u4f55\u91cd\u5851\u672a\u6765\uff1f", "comment": "Source: WeChat, Published: 2025-11-07 06:36:14", "summary": "\u5927\u6a21\u578b\uff08Large Model\uff09\u6307\u7684\u662f\u901a\u8fc7\u5229\u7528\u6d77\u91cf\u6570\u636e\u8bad\u7ec3\u800c\u6210\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u5e38\u5177\u6709\u53c2\u6570\u91cf\u5927\u3001\u8bad\u7ec3\u6570\u636e\u5927\u3001\u8ba1\u7b97\u8d44\u6e90\u5927\u7b49\u663e\u8457\u7279\u70b9\uff0c\u5177\u5907\u5f3a\u5927\u7684\u6570\u636e\u5904\u7406\u548c\u751f\u6210\u80fd\u529b\u3002", "AI": {"tldr": "\u5927\u6a21\u578b\uff08Large Model\uff09\u6307\u7684\u662f\u901a\u8fc7\u5229\u7528\u6d77\u91cf\u6570\u636e\u8bad\u7ec3\u800c\u6210\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u5e38\u5177\u6709\u53c2\u6570\u91cf\u5927\u3001\u8bad\u7ec3\u6570\u636e\u5927\u3001\u8ba1\u7b97\u8d44\u6e90\u5927\u7b49\u663e\u8457\u7279\u70b9\uff0c\u5177\u5907\u5f3a\u5927\u7684\u6570\u636e\u5904\u7406\u548c\u751f\u6210\u80fd\u529b\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2511.ebe8e660", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2651000477&idx=1&sn=775ce5bef5782aae46b873d11b788893&chksm=85d0255eb2a600ec8cc446a9f91797edcd319cc4c9b66950a5bc62f9a8f4d75dc3d9f279a4e0#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2651000477&idx=1&sn=775ce5bef5782aae46b873d11b788893&chksm=85d0255eb2a600ec8cc446a9f91797edcd319cc4c9b66950a5bc62f9a8f4d75dc3d9f279a4e0#rd", "authors": ["\u673a\u5668\u4e4b\u5fc3"], "title": "\u56fd\u4ea7<em class=\"highlight\">\u6a21\u578b</em>\u65b0\u76db\u51b5\uff01\u738b\u5ea7\u6613\u4e3b\uff1aKimi K2 Thinking\u5f00\u6e90\u8d85\u95ed\u6e90", "comment": "Source: WeChat, Published: 2025-11-07 04:25:58", "summary": "\u6628\u665a\uff0c\u6708\u4e4b\u6697\u9762\uff08Moonshot AI\uff09\u521a\u521a\u5f00\u6e90\u4e86\u6700\u65b0\u4e00\u4ee3\u5927\u6a21\u578b Kimi K2 Thinking\uff0c\u65b0\u6a21\u578b\u4e00\u53d1\u5e03\uff0c\u5c31\u6380\u8d77\u4e86\u5168\u7f51\u7684\u5927\u8ba8\u8bba\u3002\u4f5c\u4e3a\u4e00\u6b3e\u5f00\u6e90\u6a21\u578b\uff0c\u5b83\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u6beb\u65e0\u4fdd\u7559\uff0c\u591a\u65b9\u9762\u6027\u80fd\u76f4\u63a5\u8d85\u8d8a\u4e86 GPT-5\u3001Claude Sonnet 4.5 \u7b49\u4e1a\u754c\u5148\u8fdb\u95ed\u6e90\u6a21\u578b\u3002", "AI": {"tldr": "\u6628\u665a\uff0c\u6708\u4e4b\u6697\u9762\uff08Moonshot AI\uff09\u521a\u521a\u5f00\u6e90\u4e86\u6700\u65b0\u4e00\u4ee3\u5927\u6a21\u578b Kimi K2 Thinking\uff0c\u65b0\u6a21\u578b\u4e00\u53d1\u5e03\uff0c\u5c31\u6380\u8d77\u4e86\u5168\u7f51\u7684\u5927\u8ba8\u8bba\u3002\u4f5c\u4e3a\u4e00\u6b3e\u5f00\u6e90\u6a21\u578b\uff0c\u5b83\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u6beb\u65e0\u4fdd\u7559\uff0c\u591a\u65b9\u9762\u6027\u80fd\u76f4\u63a5\u8d85\u8d8a\u4e86 GPT-5\u3001Claude Sonnet 4.5 \u7b49\u4e1a\u754c\u5148\u8fdb\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
