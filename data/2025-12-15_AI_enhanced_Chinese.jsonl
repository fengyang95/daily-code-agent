{"id": "2512.10999", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10999", "abs": "https://arxiv.org/abs/2512.10999", "authors": ["Xin Sun", "Zhongqi Chen", "Xing Zheng", "Qiang Liu", "Shu Wu", "Bowen Song", "Zilei Wang", "Weiqiang Wang", "Liang Wang"], "title": "KBQA-R1: Reinforcing Large Language Models for Knowledge Base Question Answering", "comment": null, "summary": "Knowledge Base Question Answering (KBQA) challenges models to bridge the gap between natural language and strict knowledge graph schemas by generating executable logical forms. While Large Language Models (LLMs) have advanced this field, current approaches often struggle with a dichotomy of failure: they either generate hallucinated queries without verifying schema existence or exhibit rigid, template-based reasoning that mimics synthesized traces without true comprehension of the environment. To address these limitations, we present \\textbf{KBQA-R1}, a framework that shifts the paradigm from text imitation to interaction optimization via Reinforcement Learning. Treating KBQA as a multi-turn decision process, our model learns to navigate the knowledge base using a list of actions, leveraging Group Relative Policy Optimization (GRPO) to refine its strategies based on concrete execution feedback rather than static supervision. Furthermore, we introduce \\textbf{Referenced Rejection Sampling (RRS)}, a data synthesis method that resolves cold-start challenges by strictly aligning reasoning traces with ground-truth action sequences. Extensive experiments on WebQSP, GrailQA, and GraphQuestions demonstrate that KBQA-R1 achieves state-of-the-art performance, effectively grounding LLM reasoning in verifiable execution.", "AI": {"tldr": "KBQA-R1\uff1a\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5c06\u77e5\u8bc6\u5e93\u95ee\u7b54\u4ece\u6587\u672c\u6a21\u4eff\u8f6c\u5411\u4ea4\u4e92\u4f18\u5316\uff0c\u5229\u7528Group Relative Policy Optimization\u548cReferenced Rejection Sampling\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230SOTA\u6027\u80fd", "motivation": "\u5f53\u524dKBQA\u65b9\u6cd5\u5b58\u5728\u4e24\u79cd\u5931\u8d25\u6a21\u5f0f\uff1a\u8981\u4e48\u751f\u6210\u5e7b\u89c9\u67e5\u8be2\u800c\u4e0d\u9a8c\u8bc1\u6a21\u5f0f\u5b58\u5728\u6027\uff0c\u8981\u4e48\u91c7\u7528\u50f5\u5316\u7684\u6a21\u677f\u63a8\u7406\u6a21\u4eff\u5408\u6210\u8f68\u8ff9\u800c\u7f3a\u4e4f\u5bf9\u73af\u5883\u771f\u6b63\u7406\u89e3\u3002\u9700\u8981\u89e3\u51b3LLM\u5728KBQA\u4e2d\u4ece\u6587\u672c\u6a21\u4eff\u5230\u4ea4\u4e92\u4f18\u5316\u7684\u8303\u5f0f\u8f6c\u53d8\u3002", "method": "\u63d0\u51faKBQA-R1\u6846\u67b6\uff0c\u5c06KBQA\u89c6\u4e3a\u591a\u8f6e\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5bfc\u822a\u77e5\u8bc6\u5e93\u3002\u91c7\u7528Group Relative Policy Optimization\uff08GRPO\uff09\u57fa\u4e8e\u6267\u884c\u53cd\u9988\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u5f15\u5165Referenced Rejection Sampling\uff08RRS\uff09\u6570\u636e\u5408\u6210\u65b9\u6cd5\u89e3\u51b3\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u4e25\u683c\u5bf9\u9f50\u63a8\u7406\u8f68\u8ff9\u4e0e\u771f\u5b9e\u52a8\u4f5c\u5e8f\u5217\u3002", "result": "\u5728WebQSP\u3001GrailQA\u548cGraphQuestions\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u5b9e\u9a8c\uff0cKBQA-R1\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u6709\u6548\u5c06LLM\u63a8\u7406\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u7684\u6267\u884c\u3002", "conclusion": "KBQA-R1\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4ea4\u4e92\u4f18\u5316\u89e3\u51b3\u4e86\u5f53\u524dKBQA\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u4ece\u6587\u672c\u6a21\u4eff\u5230\u57fa\u4e8e\u6267\u884c\u53cd\u9988\u7684\u7b56\u7565\u4f18\u5316\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u5e93\u95ee\u7b54\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.11223", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11223", "abs": "https://arxiv.org/abs/2512.11223", "authors": ["Sasara Shimizu", "Yoshiki Higo"], "title": "Coverage Isn't Enough: SBFL-Driven Insights into Manually Created vs. Automatically Generated Tests", "comment": null, "summary": "The testing phase is an essential part of software development, but manually creating test cases can be time-consuming. Consequently, there is a growing need for more efficient testing methods. To reduce the burden on developers, various automated test generation tools have been developed, and several studies have been conducted to evaluate the effectiveness of the tests they produce. However, most of these studies focus primarily on coverage metrics, and only a few examine how well the tests support fault localization-particularly using artificial faults introduced through mutation testing. In this study, we compare the SBFL (Spectrum-Based Fault Localization) score and code coverage of automatically generated tests with those of manually created tests. The SBFL score indicates how accurately faults can be localized using SBFL techniques. By employing SBFL score as an evaluation metric-an approach rarely used in prior studies on test generation-we aim to provide new insights into the respective strengths and weaknesses of manually created and automatically generated tests. Our experimental results show that automatically generated tests achieve higher branch coverage than manually created tests, but their SBFL score is lower, especially for code with deeply nested structures. These findings offer guidance on how to effectively combine automatically generated and manually created testing approaches.", "AI": {"tldr": "\u81ea\u52a8\u751f\u6210\u7684\u6d4b\u8bd5\u6bd4\u624b\u52a8\u6d4b\u8bd5\u6709\u66f4\u9ad8\u7684\u5206\u652f\u8986\u76d6\u7387\uff0c\u4f46\u5728\u57fa\u4e8e\u9891\u8c31\u7684\u6545\u969c\u5b9a\u4f4d(SBFL)\u5f97\u5206\u4e0a\u8f83\u4f4e\uff0c\u5c24\u5176\u662f\u5728\u6df1\u5c42\u5d4c\u5957\u4ee3\u7801\u7ed3\u6784\u4e2d\u3002\u7814\u7a76\u5efa\u8bae\u7ed3\u5408\u4e24\u79cd\u6d4b\u8bd5\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u751f\u6210\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u8986\u76d6\u7387\u6307\u6807\uff0c\u5f88\u5c11\u8bc4\u4f30\u6d4b\u8bd5\u5bf9\u6545\u969c\u5b9a\u4f4d\u7684\u652f\u6301\u6548\u679c\uff0c\u7279\u522b\u662f\u4f7f\u7528\u53d8\u5f02\u6d4b\u8bd5\u5f15\u5165\u7684\u4eba\u5de5\u6545\u969c\u3002\u672c\u7814\u7a76\u65e8\u5728\u6bd4\u8f83\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u548c\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u5728SBFL\u5f97\u5206\u548c\u4ee3\u7801\u8986\u76d6\u7387\u4e0a\u7684\u5dee\u5f02\u3002", "method": "\u4f7f\u7528SBFL\uff08\u57fa\u4e8e\u9891\u8c31\u7684\u6545\u969c\u5b9a\u4f4d\uff09\u5f97\u5206\u4f5c\u4e3a\u8bc4\u4f30\u6307\u6807\uff0c\u6bd4\u8f83\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u548c\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u7684SBFL\u5f97\u5206\u548c\u4ee3\u7801\u8986\u76d6\u7387\u3002\u7279\u522b\u5173\u6ce8\u6df1\u5c42\u5d4c\u5957\u4ee3\u7801\u7ed3\u6784\u7684\u60c5\u51b5\u3002", "result": "\u81ea\u52a8\u751f\u6210\u7684\u6d4b\u8bd5\u6bd4\u624b\u52a8\u521b\u5efa\u7684\u6d4b\u8bd5\u83b7\u5f97\u66f4\u9ad8\u7684\u5206\u652f\u8986\u76d6\u7387\uff0c\u4f46SBFL\u5f97\u5206\u8f83\u4f4e\uff0c\u5c24\u5176\u662f\u5728\u6df1\u5c42\u5d4c\u5957\u7ed3\u6784\u7684\u4ee3\u7801\u4e2d\u3002", "conclusion": "\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u548c\u624b\u52a8\u521b\u5efa\u6d4b\u8bd5\u5404\u6709\u4f18\u52bf\uff1a\u81ea\u52a8\u6d4b\u8bd5\u8986\u76d6\u7387\u9ad8\uff0c\u624b\u52a8\u6d4b\u8bd5\u6545\u969c\u5b9a\u4f4d\u6548\u679c\u597d\u3002\u7814\u7a76\u7ed3\u679c\u4e3a\u5982\u4f55\u6709\u6548\u7ed3\u5408\u4e24\u79cd\u6d4b\u8bd5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "topic": "swe benchmark"}}
{"id": "2512.11169", "categories": ["cs.AI", "cs.LG", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.11169", "abs": "https://arxiv.org/abs/2512.11169", "authors": ["Akhil S Anand", "Elias Aarekol", "Martin Mziray Dalseg", "Magnus Stalhane", "Sebastien Gros"], "title": "CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound", "comment": null, "summary": "Combinatorial sequential decision making problems are typically modeled as mixed integer linear programs (MILPs) and solved via branch and bound (B&B) algorithms. The inherent difficulty of modeling MILPs that accurately represent stochastic real world problems leads to suboptimal performance in the real world. Recently, machine learning methods have been applied to build MILP models for decision quality rather than how accurately they model the real world problem. However, these approaches typically rely on supervised learning, assume access to true optimal decisions, and use surrogates for the MILP gradients. In this work, we introduce a proof of concept CORL framework that end to end fine tunes an MILP scheme using reinforcement learning (RL) on real world data to maximize its operational performance. We enable this by casting an MILP solved by B&B as a differentiable stochastic policy compatible with RL. We validate the CORL method in a simple illustrative combinatorial sequential decision making example.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCORL\u6846\u67b6\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7aef\u5230\u7aef\u5fae\u8c03MILP\u65b9\u6848\uff0c\u5c06B&B\u6c42\u89e3\u7684MILP\u8f6c\u5316\u4e3a\u53ef\u5fae\u968f\u673a\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u5316\u5b9e\u9645\u8fd0\u8425\u6027\u80fd\u800c\u975e\u7cbe\u786e\u5efa\u6a21\u3002", "motivation": "\u4f20\u7edfMILP\u5efa\u6a21\u96be\u4ee5\u51c6\u786e\u8868\u793a\u968f\u673a\u73b0\u5b9e\u95ee\u9898\uff0c\u5bfc\u81f4\u5b9e\u9645\u6027\u80fd\u4e0d\u4f73\u3002\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u76d1\u7763\u5b66\u4e60\u3001\u5047\u8bbe\u5df2\u77e5\u6700\u4f18\u51b3\u7b56\u3001\u4f7f\u7528MILP\u68af\u5ea6\u66ff\u4ee3\uff0c\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51faCORL\u6982\u5ff5\u9a8c\u8bc1\u6846\u67b6\uff0c\u5c06B&B\u6c42\u89e3\u7684MILP\u8f6c\u5316\u4e3a\u53ef\u5fae\u968f\u673a\u7b56\u7565\uff0c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u7aef\u5230\u7aef\u5fae\u8c03MILP\u65b9\u6848\uff0c\u6700\u5927\u5316\u8fd0\u8425\u6027\u80fd\u3002", "result": "\u5728\u7b80\u5355\u7684\u7ec4\u5408\u5e8f\u8d2f\u51b3\u7b56\u793a\u4f8b\u4e2d\u9a8c\u8bc1\u4e86CORL\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "CORL\u6846\u67b6\u80fd\u591f\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u76f4\u63a5\u4f18\u5316MILP\u7684\u5b9e\u9645\u8fd0\u8425\u6027\u80fd\uff0c\u4e3a\u7ec4\u5408\u5e8f\u8d2f\u51b3\u7b56\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u7aef\u5230\u7aef\u4f18\u5316\u65b9\u6cd5\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.11398", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.11398", "abs": "https://arxiv.org/abs/2512.11398", "authors": ["Qiuming Luo", "Yanming Lei", "Kunzhong Wu", "Yixuan Cao", "Chengjian Liu"], "title": "AutoFSM: A Multi-agent Framework for FSM Code Generation with IR and SystemC-Based Testing", "comment": "This version corrects a typo in the section title (\"Intruction\" -> \"Introduction\") that appears in the published version", "summary": "With the rapid advancement of large language models (LLMs) in code generation, their applications in hardware design are receiving growing attention. However, existing LLMs face several challenges when generating Verilog code for finite state machine (FSM) control logic, including frequent syntax errors, low debugging efficiency, and heavy reliance on test benchmarks. To address these challenges, this paper proposes AutoFSM, a multi-agent collaborative framework designed for FSM code generation tasks. AutoFSM introduces a structurally clear intermediate representation (IR) to reduce syntax error rate during code generation and provides a supporting toolchain to enable automatic translation from IR to Verilog. Furthermore, AutoFSM is the first to integrate SystemC-based modeling with automatic testbench generation, thereby improving debugging efficiency and feedback quality. To systematically evaluate the framework's performance, we construct SKT-FSM, the first hierarchical FSM benchmark in the field, comprising 67 FSM samples across different complexity levels. Experimental results show that, under the same base LLM, AutoFSM consistently outperforms the open-source framework MAGE on the SKT-FSM benchmark, achieving up to an 11.94% improvement in pass rate and up to a 17.62% reduction in syntax error rate. These results demonstrate the potential of combining LLMs with structured IR and automated testing to improve the reliability and scalability of register-transfer level (RTL) code generation.", "AI": {"tldr": "AutoFSM\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u4e2d\u95f4\u8868\u793a\u548c\u81ea\u52a8\u5316\u6d4b\u8bd5\u5de5\u5177\u94fe\uff0c\u663e\u8457\u63d0\u5347LLM\u751f\u6210Verilog\u6709\u9650\u72b6\u6001\u673a\u4ee3\u7801\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709LLM\u5728\u751f\u6210Verilog\u6709\u9650\u72b6\u6001\u673a\u63a7\u5236\u903b\u8f91\u65f6\u9762\u4e34\u8bed\u6cd5\u9519\u8bef\u9891\u7e41\u3001\u8c03\u8bd5\u6548\u7387\u4f4e\u3001\u8fc7\u5ea6\u4f9d\u8d56\u6d4b\u8bd5\u57fa\u51c6\u7b49\u95ee\u9898\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u786c\u4ef6\u8bbe\u8ba1\u4ee3\u7801\u751f\u6210\u65b9\u6848\u3002", "method": "\u63d0\u51faAutoFSM\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u5f15\u5165\u7ed3\u6784\u5316\u4e2d\u95f4\u8868\u793a\u964d\u4f4e\u8bed\u6cd5\u9519\u8bef\u7387\uff0c\u63d0\u4f9b\u4eceIR\u5230Verilog\u7684\u81ea\u52a8\u8f6c\u6362\u5de5\u5177\u94fe\uff0c\u5e76\u96c6\u6210SystemC\u5efa\u6a21\u548c\u81ea\u52a8\u6d4b\u8bd5\u5e73\u53f0\u751f\u6210\u3002", "result": "\u5728SKT-FSM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAutoFSM\u76f8\u6bd4\u5f00\u6e90\u6846\u67b6MAGE\u5728\u76f8\u540c\u57fa\u7840LLM\u4e0b\uff0c\u901a\u8fc7\u7387\u63d0\u5347\u6700\u9ad811.94%\uff0c\u8bed\u6cd5\u9519\u8bef\u7387\u964d\u4f4e\u6700\u9ad817.62%\u3002", "conclusion": "\u7ed3\u5408LLM\u4e0e\u7ed3\u6784\u5316\u4e2d\u95f4\u8868\u793a\u548c\u81ea\u52a8\u5316\u6d4b\u8bd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8RTL\u4ee3\u7801\u751f\u6210\u7684\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "topic": "code agent"}}
{"id": "2512.11402", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11402", "abs": "https://arxiv.org/abs/2512.11402", "authors": ["Aryan Gupta", "Y. Raghu Reddy"], "title": "REMODEL-LLM: Transforming C code to Java using LLMs", "comment": null, "summary": "The automated translation of C code to Java code is a notoriously difficult task, fraught with challenges stemming from fundamental paradigm shifts (procedural vs. Object Oriented), memory models (manual pointers vs. Garbage Collection), and incompatible data types. This paper investigates the efficacy of 19 small, quantized LLMs (under 20 billion parameters) for the C to Java translation task. We use a novel, hybrid pipeline that leverages Abstract Syntax Trees (ASTs) for semantic decomposition and employs a highly constrained, rule based prompting strategy. The results are stark: a clear multi tiered performance divide emerged. The vast majority of models (Tier 3, e.g., llama3.1, gemma3, starcoder2) failed 100\\% of the tests, proving incapable of generating even basic, runnable Java boilerplate. A small middle tier (Tier 2, e.g., mistral-nemo and mistral) produced runnable code but was plagued by dangerous semantic failures and wrong translations. Only three models (Tier 1: phi4, deepseek-coder-v2, codeqwen) proved viable, passing over 50\\% of the test suite. Even these top models failed on the most complex C concepts, such as function pointers, sizeof, and enum logic, revealing a hard ceiling for the reasoning capabilities of current quantized models.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e8619\u4e2a\u5c0f\u578b\u91cf\u5316LLM\u5728C\u5230Java\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u53ea\u67093\u4e2a\u6a21\u578b\u80fd\u901a\u8fc7\u8d85\u8fc750%\u7684\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u91cf\u5316\u6a21\u578b\u5728\u590d\u6742C\u6982\u5ff5\u7ffb\u8bd1\u4e0a\u7684\u80fd\u529b\u5929\u82b1\u677f\u3002", "motivation": "C\u5230Java\u7684\u81ea\u52a8\u4ee3\u7801\u7ffb\u8bd1\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u5305\u62ec\u7f16\u7a0b\u8303\u5f0f\u5dee\u5f02\uff08\u8fc7\u7a0b\u5f0fvs\u9762\u5411\u5bf9\u8c61\uff09\u3001\u5185\u5b58\u6a21\u578b\u4e0d\u540c\uff08\u624b\u52a8\u6307\u9488vs\u5783\u573e\u56de\u6536\uff09\u4ee5\u53ca\u6570\u636e\u7c7b\u578b\u4e0d\u517c\u5bb9\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5c0f\u578b\u91cf\u5316LLM\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u5b9e\u9645\u6548\u679c\u3002", "method": "\u91c7\u7528\u6df7\u5408\u7ba1\u9053\u65b9\u6cd5\uff1a\u5229\u7528\u62bd\u8c61\u8bed\u6cd5\u6811\uff08AST\uff09\u8fdb\u884c\u8bed\u4e49\u5206\u89e3\uff0c\u5e76\u7ed3\u5408\u9ad8\u5ea6\u7ea6\u675f\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u63d0\u793a\u7b56\u7565\u3002\u8bc4\u4f30\u4e8619\u4e2a\u53c2\u6570\u5c0f\u4e8e200\u4ebf\u7684\u5c0f\u578b\u91cf\u5316LLM\u3002", "result": "\u7ed3\u679c\u5448\u73b0\u660e\u663e\u7684\u4e09\u7ea7\u6027\u80fd\u5206\u5316\uff1aTier 3\u6a21\u578b\uff08\u5982llama3.1\u3001gemma3\u3001starcoder2\uff09100%\u6d4b\u8bd5\u5931\u8d25\uff1bTier 2\u6a21\u578b\uff08\u5982mistral-nemo\u3001mistral\uff09\u80fd\u751f\u6210\u53ef\u8fd0\u884c\u4ee3\u7801\u4f46\u5b58\u5728\u4e25\u91cd\u8bed\u4e49\u9519\u8bef\uff1b\u53ea\u6709Tier 1\u6a21\u578b\uff08phi4\u3001deepseek-coder-v2\u3001codeqwen\uff09\u8868\u73b0\u53ef\u884c\uff0c\u901a\u8fc7\u7387\u8d85\u8fc750%\uff0c\u4f46\u5728\u51fd\u6570\u6307\u9488\u3001sizeof\u3001\u679a\u4e3e\u903b\u8f91\u7b49\u590d\u6742C\u6982\u5ff5\u4e0a\u4ecd\u4f1a\u5931\u8d25\u3002", "conclusion": "\u5f53\u524d\u5c0f\u578b\u91cf\u5316LLM\u5728C\u5230Java\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u80fd\u529b\u6709\u9650\uff0c\u53ea\u6709\u5c11\u6570\u6a21\u578b\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742C\u8bed\u8a00\u7279\u6027\u65f6\u5b58\u5728\u660e\u663e\u7684\u80fd\u529b\u5929\u82b1\u677f\uff0c\u63ed\u793a\u4e86\u91cf\u5316\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\u3002", "topic": "code agent"}}
{"id": "2512.11213", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.11213", "abs": "https://arxiv.org/abs/2512.11213", "authors": ["Dongwon Jung", "Peng Shi", "Yi Zhang"], "title": "FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration", "comment": null, "summary": "Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.", "AI": {"tldr": "FutureWeaver\u662f\u4e00\u4e2a\u5728\u56fa\u5b9a\u9884\u7b97\u4e0b\u89c4\u5212\u548c\u4f18\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u53cc\u7ea7\u89c4\u5212\u67b6\u6784\u63d0\u5347\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u80fd\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u539f\u5219\u6027\u7684\u8ba1\u7b97\u5206\u914d\u673a\u5236\u6765\u4fc3\u8fdb\u534f\u4f5c\u3001\u6269\u5c55\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5230\u534f\u4f5c\u4ea4\u4e92\uff0c\u4ee5\u53ca\u5728\u660e\u786e\u9884\u7b97\u7ea6\u675f\u4e0b\u8de8\u667a\u80fd\u4f53\u5206\u914d\u8ba1\u7b97\u3002", "method": "\u63d0\u51faFutureWeaver\u6846\u67b6\uff1a1) \u5f15\u5165\u6a21\u5757\u5316\u534f\u4f5c\uff0c\u901a\u8fc7\u81ea\u73a9\u53cd\u601d\u4ece\u5386\u53f2\u8f68\u8ff9\u4e2d\u62bd\u8c61\u51fa\u53ef\u590d\u7528\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u4f5c\u4e3a\u53ef\u8c03\u7528\u51fd\u6570\uff1b2) \u91c7\u7528\u53cc\u7ea7\u89c4\u5212\u67b6\u6784\uff0c\u5728\u5f53\u524d\u4efb\u52a1\u72b6\u6001\u63a8\u7406\u7684\u540c\u65f6\u63a8\u6d4b\u672a\u6765\u6b65\u9aa4\uff0c\u4f18\u5316\u8ba1\u7b97\u5206\u914d\u3002", "result": "\u5728\u590d\u6742\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFutureWeaver\u5728\u4e0d\u540c\u9884\u7b97\u8bbe\u7f6e\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u63a8\u7406\u65f6\u4f18\u5316\u4e2d\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u7684\u6709\u6548\u6027\u3002", "conclusion": "FutureWeaver\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u5206\u914d\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u534f\u4f5c\u548c\u524d\u77bb\u6027\u89c4\u5212\u6709\u6548\u89e3\u51b3\u4e86\u9884\u7b97\u7ea6\u675f\u4e0b\u7684\u534f\u4f5c\u4f18\u5316\u95ee\u9898\u3002", "topic": "agent analysis"}}
{"id": "2512.11482", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.11482", "abs": "https://arxiv.org/abs/2512.11482", "authors": ["Melih Catal", "Pooja Rani", "Harald C. Gall"], "title": "Towards Privacy-Preserving Code Generation: Differentially Private Code Language Models", "comment": null, "summary": "Large language models specialized for code (CodeLLMs) have demonstrated remarkable capabilities in generating code snippets, documentation, and test cases. However, despite their promising capabilities, CodeLLMs can inadvertently memorize and reproduce snippets from their training data, which poses risks of privacy breaches and intellectual property violations. These risks restrict the deployment of CodeLLMs in sensitive domains and limit their training datasets to publicly available sources. To mitigate the memorization risk without compromising their task performance, we apply Differential Privacy (DP) to CodeLLMs. To the best of our knowledge, this is the first comprehensive study that systematically evaluates the effectiveness of DP in CodeLLMs. DP adds calibrated noise to the training process to protect individual data points while still allowing the model to learn useful patterns. To this end, we first identify and understand the driving reasons of the memorization behaviour of the CodeLLMs during their fine-tuning. Then, to address this issue, we empirically evaluate the effect of DP on mitigating memorization while preserving code generation capabilities. Our findings show that DP substantially reduces memorization in CodeLLMs across all the tested snippet types. The snippet types most prone to memorization are also the most effectively mitigated by DP. Furthermore, we observe that DP slightly increases perplexity but preserves, and can even enhance, the code generation capabilities of CodeLLMs, which makes it feasible to apply DP in practice without significantly compromising model utility. Finally, we analyze the impact of DP on training efficiency and energy consumption, finding that DP does not significantly affect training time or energy usage, making it a practical choice for privacy-preserving CodeLLMs training.", "AI": {"tldr": "\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u5dee\u5206\u9690\u79c1\u5728\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0DP\u80fd\u663e\u8457\u964d\u4f4e\u8bb0\u5fc6\u98ce\u9669\uff0c\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4e14\u4e0d\u5f71\u54cd\u8bad\u7ec3\u6548\u7387", "motivation": "\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u4ee3\u7801\u65f6\u53ef\u80fd\u65e0\u610f\u4e2d\u8bb0\u5fc6\u5e76\u590d\u73b0\u8bad\u7ec3\u6570\u636e\u7247\u6bb5\uff0c\u5bfc\u81f4\u9690\u79c1\u6cc4\u9732\u548c\u77e5\u8bc6\u4ea7\u6743\u4fb5\u6743\u98ce\u9669\uff0c\u9650\u5236\u4e86\u5728\u654f\u611f\u9886\u57df\u7684\u90e8\u7f72", "method": "\u5e94\u7528\u5dee\u5206\u9690\u79c1\u5230\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\uff0c\u9996\u5148\u5206\u6790\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u8bb0\u5fc6\u884c\u4e3a\u539f\u56e0\uff0c\u7136\u540e\u5b9e\u8bc1\u8bc4\u4f30DP\u5728\u51cf\u5c11\u8bb0\u5fc6\u540c\u65f6\u4fdd\u6301\u4ee3\u7801\u751f\u6210\u80fd\u529b\u7684\u6548\u679c", "result": "DP\u663e\u8457\u964d\u4f4e\u4e86\u6240\u6709\u6d4b\u8bd5\u4ee3\u7801\u7247\u6bb5\u7684\u8bb0\u5fc6\u98ce\u9669\uff0c\u6700\u6613\u8bb0\u5fc6\u7684\u7247\u6bb5\u7c7b\u578b\u4e5f\u662fDP\u6700\u6709\u6548\u7f13\u89e3\u7684\u7c7b\u578b\uff1bDP\u8f7b\u5fae\u589e\u52a0\u56f0\u60d1\u5ea6\u4f46\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u80fd\u529b\uff0c\u4e14\u4e0d\u5f71\u54cd\u8bad\u7ec3\u65f6\u95f4\u548c\u80fd\u8017", "conclusion": "\u5dee\u5206\u9690\u79c1\u662f\u4fdd\u62a4\u9690\u79c1\u7684\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u5b9e\u7528\u9009\u62e9\uff0c\u80fd\u5728\u4e0d\u663e\u8457\u5f71\u54cd\u6a21\u578b\u6548\u7528\u7684\u524d\u63d0\u4e0b\u6709\u6548\u964d\u4f4e\u8bb0\u5fc6\u98ce\u9669", "topic": "code agent"}}
{"id": "2512.11270", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11270", "abs": "https://arxiv.org/abs/2512.11270", "authors": ["Hong Je-Gal", "Chan-Bin Yi", "Hyun-Suk Lee"], "title": "A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation", "comment": "NeurIPS 2025 Workshop: Multi-Turn Interactions in Large Language Models. 26 pages, 8 figures", "summary": "Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.", "AI": {"tldr": "A-LAMP\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u81ea\u52a8\u8f6c\u6362\u4e3aMDP\u6a21\u578b\u5e76\u751f\u6210\u8bad\u7ec3\u597d\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u5206\u89e3\u5efa\u6a21\u3001\u7f16\u7801\u548c\u8bad\u7ec3\u4e3a\u53ef\u9a8c\u8bc1\u9636\u6bb5\u6765\u786e\u4fdd\u8bed\u4e49\u5bf9\u9f50\u3002", "motivation": "\u5c06\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u4e8e\u73b0\u5b9e\u4efb\u52a1\u9700\u8981\u5c06\u975e\u6b63\u5f0f\u63cf\u8ff0\u8f6c\u6362\u4e3a\u6b63\u5f0f\u7684MDP\u3001\u5b9e\u73b0\u53ef\u6267\u884c\u73af\u5883\u5e76\u8bad\u7ec3\u7b56\u7565\u4ee3\u7406\u3002\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\u9762\u4e34\u5efa\u6a21\u9519\u8bef\u3001\u8106\u5f31\u4ee3\u7801\u548c\u76ee\u6807\u4e0d\u5bf9\u9f50\u7b49\u6311\u6218\uff0c\u8fd9\u4e9b\u56e0\u7d20\u5e38\u5e38\u963b\u788d\u7b56\u7565\u8bad\u7ec3\u3002", "method": "\u63d0\u51faA-LAMP\u6846\u67b6\uff0c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u5c06\u81ea\u7531\u5f62\u5f0f\u7684\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u8f6c\u6362\u4e3aMDP\u516c\u5f0f\u548c\u8bad\u7ec3\u7b56\u7565\u3002\u8be5\u6846\u67b6\u5c06\u5efa\u6a21\u3001\u7f16\u7801\u548c\u8bad\u7ec3\u5206\u89e3\u4e3a\u53ef\u9a8c\u8bc1\u9636\u6bb5\uff0c\u786e\u4fdd\u6574\u4e2a\u6d41\u7a0b\u7684\u8bed\u4e49\u5bf9\u9f50\u3002", "result": "\u5728\u7ecf\u5178\u63a7\u5236\u548c\u81ea\u5b9a\u4e49RL\u9886\u57df\u4e2d\uff0cA-LAMP\u59cb\u7ec8\u6bd4\u5355\u4e2a\u6700\u5148\u8fdb\u7684LLM\u6a21\u578b\u5177\u6709\u66f4\u9ad8\u7684\u7b56\u7565\u751f\u6210\u80fd\u529b\u3002\u5176\u8f7b\u91cf\u7ea7\u53d8\u4f53\uff08\u57fa\u4e8e\u8f83\u5c0f\u8bed\u8a00\u6a21\u578b\uff09\u4e5f\u80fd\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\u3002\u6848\u4f8b\u7814\u7a76\u663e\u793aA-LAMP\u751f\u6210\u7684\u73af\u5883\u548c\u7b56\u7565\u80fd\u4fdd\u6301\u4efb\u52a1\u7684\u6700\u4f18\u6027\u3002", "conclusion": "A-LAMP\u6846\u67b6\u901a\u8fc7\u81ea\u52a8\u5316MDP\u5efa\u6a21\u548c\u7b56\u7565\u751f\u6210\uff0c\u89e3\u51b3\u4e86RL\u5e94\u7528\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u9ad8\u4e86\u7b56\u7565\u751f\u6210\u80fd\u529b\u5e76\u786e\u4fdd\u6b63\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u5373\u4f7f\u4f7f\u7528\u8f83\u5c0f\u6a21\u578b\u4e5f\u80fd\u83b7\u5f97\u826f\u597d\u6027\u80fd\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.10975", "categories": ["cs.LG", "cs.AI", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.10975", "abs": "https://arxiv.org/abs/2512.10975", "authors": ["Matvey Nepomnyaschiy", "Oleg Pereziabov", "Anvar Tliamov", "Stanislav Mikhailov", "Ilya Afanasyev"], "title": "Agent-Based Modular Learning for Multimodal Emotion Recognition in Human-Agent Systems", "comment": "14 pages, 4 figures", "summary": "Effective human-agent interaction (HAI) relies on accurate and adaptive perception of human emotional states. While multimodal deep learning models - leveraging facial expressions, speech, and textual cues - offer high accuracy in emotion recognition, their training and maintenance are often computationally intensive and inflexible to modality changes. In this work, we propose a novel multi-agent framework for training multimodal emotion recognition systems, where each modality encoder and the fusion classifier operate as autonomous agents coordinated by a central supervisor. This architecture enables modular integration of new modalities (e.g., audio features via emotion2vec), seamless replacement of outdated components, and reduced computational overhead during training. We demonstrate the feasibility of our approach through a proof-of-concept implementation supporting vision, audio, and text modalities, with the classifier serving as a shared decision-making agent. Our framework not only improves training efficiency but also contributes to the design of more flexible, scalable, and maintainable perception modules for embodied and virtual agents in HAI scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u4e2d\u592e\u534f\u8c03\u5668\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\u548c\u7075\u6d3b\u6269\u5c55", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u6a21\u578b\u867d\u7136\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u8bad\u7ec3\u548c\u7ef4\u62a4\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e14\u96be\u4ee5\u7075\u6d3b\u9002\u5e94\u6a21\u6001\u53d8\u5316\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06\u6bcf\u4e2a\u6a21\u6001\u7f16\u7801\u5668\u548c\u878d\u5408\u5206\u7c7b\u5668\u8bbe\u8ba1\u4e3a\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u7531\u4e2d\u592e\u76d1\u7763\u5668\u534f\u8c03\uff0c\u652f\u6301\u6a21\u5757\u5316\u96c6\u6210\u65b0\u6a21\u6001\u548c\u7ec4\u4ef6\u66ff\u6362", "result": "\u901a\u8fc7\u652f\u6301\u89c6\u89c9\u3001\u97f3\u9891\u548c\u6587\u672c\u6a21\u6001\u7684\u6982\u5ff5\u9a8c\u8bc1\u5b9e\u73b0\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u53ef\u884c\u6027\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\uff0c\u8fd8\u4e3aHAI\u573a\u666f\u4e2d\u7684\u5177\u8eab\u548c\u865a\u62df\u667a\u80fd\u4f53\u8bbe\u8ba1\u4e86\u66f4\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u548c\u53ef\u7ef4\u62a4\u7684\u611f\u77e5\u6a21\u5757", "topic": "agent analysis"}}
{"id": "2512.11589", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11589", "abs": "https://arxiv.org/abs/2512.11589", "authors": ["Lukas Twist"], "title": "A Study of Library Usage in Agent-Authored Pull Requests", "comment": "5 pages, 3 tables", "summary": "Coding agents are becoming increasingly capable of completing end-to-end software engineering workflows that previously required a human developer, including raising pull requests (PRs) to propose their changes. However, we still know little about how these agents use libraries when generating code, a core part of real-world software development. To fill this gap, we study 26,760 agent-authored PRs from the AIDev dataset to examine three questions: how often do agents import libraries, how often do they introduce new dependencies (and with what versioning), and which specific libraries do they choose? We find that agents often import libraries (29.5% of PRs) but rarely add new dependencies (1.3% of PRs); and when they do, they follow strong versioning practices (75.0% specify a version), an improvement on direct LLM usage where versions are rarely mentioned. Generally, agents draw from a surprisingly diverse set of external libraries, contrasting with the limited \"library preferences\" seen in prior non-agentic LLM studies. Our results offer an early empirical view into how AI coding agents interact with today's software ecosystems.", "AI": {"tldr": "AI\u7f16\u7801\u4ee3\u7406\u572829.5%\u7684PR\u4e2d\u5bfc\u5165\u5e93\uff0c\u4f46\u4ec51.3%\u6dfb\u52a0\u65b0\u4f9d\u8d56\uff1b\u6dfb\u52a0\u4f9d\u8d56\u65f675%\u6307\u5b9a\u7248\u672c\uff0c\u4f18\u4e8e\u76f4\u63a5\u4f7f\u7528LLM\uff1b\u4ee3\u7406\u4f7f\u7528\u7684\u5916\u90e8\u5e93\u591a\u6837\u6027\u8fdc\u8d85\u975e\u4ee3\u7406LLM\u7814\u7a76", "motivation": "\u5c3d\u7ba1AI\u7f16\u7801\u4ee3\u7406\u80fd\u591f\u5b8c\u6210\u7aef\u5230\u7aef\u8f6f\u4ef6\u5f00\u53d1\u5de5\u4f5c\u6d41\uff0c\u4f46\u6211\u4eec\u5bf9\u4ee3\u7406\u5982\u4f55\u4f7f\u7528\u5e93\u8fd9\u4e00\u8f6f\u4ef6\u5f00\u53d1\u6838\u5fc3\u73af\u8282\u4e86\u89e3\u751a\u5c11\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63a2\u7a76\u4ee3\u7406\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5982\u4f55\u4f7f\u7528\u5916\u90e8\u5e93\u3002", "method": "\u57fa\u4e8eAIDev\u6570\u636e\u96c6\u768426,760\u4e2a\u4ee3\u7406\u751f\u6210\u7684PR\u8fdb\u884c\u5206\u6790\uff0c\u7814\u7a76\u4e09\u4e2a\u95ee\u9898\uff1a\u4ee3\u7406\u5bfc\u5165\u5e93\u7684\u9891\u7387\u3001\u5f15\u5165\u65b0\u4f9d\u8d56\u7684\u9891\u7387\u53ca\u7248\u672c\u63a7\u5236\u5b9e\u8df5\u3001\u4ee5\u53ca\u5177\u4f53\u9009\u62e9\u7684\u5e93\u7c7b\u578b\u3002", "result": "\u4ee3\u7406\u7ecf\u5e38\u5bfc\u5165\u5e93\uff0829.5%\u7684PR\uff09\uff0c\u4f46\u5f88\u5c11\u6dfb\u52a0\u65b0\u4f9d\u8d56\uff08\u4ec51.3%\uff09\uff1b\u6dfb\u52a0\u4f9d\u8d56\u65f675%\u4f1a\u6307\u5b9a\u7248\u672c\uff0c\u8fd9\u6bd4\u76f4\u63a5\u4f7f\u7528LLM\u65f6\u5f88\u5c11\u63d0\u53ca\u7248\u672c\u7684\u60c5\u51b5\u6709\u663e\u8457\u6539\u8fdb\uff1b\u4ee3\u7406\u4f7f\u7528\u7684\u5916\u90e8\u5e93\u591a\u6837\u6027\u8fdc\u8d85\u5148\u524d\u975e\u4ee3\u7406LLM\u7814\u7a76\u4e2d\u89c2\u5bdf\u5230\u7684\u6709\u9650\"\u5e93\u504f\u597d\"\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86AI\u7f16\u7801\u4ee3\u7406\u4e0e\u5f53\u524d\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u4ea4\u4e92\u7684\u65e9\u671f\u5b9e\u8bc1\u89c6\u89d2\uff0c\u663e\u793a\u4ee3\u7406\u5728\u5e93\u4f7f\u7528\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u6210\u719f\u7684\u5b9e\u8df5\u548c\u66f4\u5e7f\u6cdb\u7684\u5e93\u9009\u62e9\uff0c\u4e3a\u7406\u89e3AI\u7f16\u7801\u4ee3\u7406\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002", "topic": "code agent"}}
{"id": "2512.11421", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11421", "abs": "https://arxiv.org/abs/2512.11421", "authors": ["Gonca G\u00fcrsun"], "title": "Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance", "comment": "Accepted to AAAI 2026 Workshop on Trust and Control in Agentic AI (TrustAgent)", "summary": "Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals.\n  The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2aLLM\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5f62\u5f0f\u5316\u73af\u5883\u4e2d\u7684\u660e\u786e\u884c\u4e3a\u6307\u5bfc\uff0c\u5b9e\u73b0\u53ef\u9760\u3001\u53ef\u9a8c\u8bc1\u7684\u591a\u8f6e\u4efb\u52a1\u5b8c\u6210", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u8f6e\u4efb\u52a1\u4e2d\u7684\u884c\u4e3a\u5f80\u5f80\u7f3a\u4e4f\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u660e\u786e\u884c\u4e3a\u6307\u5bfc\u7684\u6846\u67b6", "method": "\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u7ec4\u4ef6\uff1a\u8f7b\u91cf\u7ea7\u4efb\u52a1\u5206\u6790\u5668\u9009\u62e9\u63a8\u7406\u548c\u751f\u6210\u7b56\u7565\uff1b\u63a8\u7406\u6a21\u5757\u5b66\u4e60\u53ef\u9a8c\u8bc1\u7684\u89c2\u5bdf-\u52a8\u4f5c\u6620\u5c04\uff1b\u751f\u6210\u6a21\u5757\u901a\u8fc7\u9a8c\u8bc1\u6216\u786e\u5b9a\u6027\u5408\u6210\u786e\u4fdd\u7ea6\u675f\u5408\u89c4\u8f93\u51fa", "result": "\u667a\u80fd\u4f53\u4e0e\u73af\u5883\u4ea4\u4e92\u65f6\uff0c\u8fd9\u4e9b\u7ec4\u4ef6\u5171\u540c\u6f14\u5316\uff0c\u4ea7\u751f\u53ef\u4fe1\u8d56\u7684\u884c\u4e3a", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u4f7fLLM\u667a\u80fd\u4f53\u5728\u5f3a\u5316\u5b66\u4e60\u5f62\u5f0f\u5316\u7684\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u660e\u786e\u7684\u6307\u5bfc\u5b9e\u73b0\u53ef\u9760\u3001\u53ef\u9a8c\u8bc1\u7684\u4efb\u52a1\u5b8c\u6210", "topic": "agentic reinforcement learning"}}
{"id": "2512.11426", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11426", "abs": "https://arxiv.org/abs/2512.11426", "authors": ["Shuowei Cai", "Yansong Ning", "Hao Liu"], "title": "AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints", "comment": null, "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance", "AI": {"tldr": "AgentBalance\u662f\u4e00\u4e2a\u5728\u660e\u786etoken\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u7ea6\u675f\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u91c7\u7528\u5148\u9aa8\u5e72\u540e\u62d3\u6251\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5728\u76f8\u540c\u9884\u7b97\u4e0b\u6027\u80fd\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u901a\u5e38\u4f18\u5148\u8003\u8651\u901a\u4fe1\u62d3\u6251\u7ed3\u6784\uff0c\u5f88\u5c11\u5728\u660e\u786e\u7684token\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u7ea6\u675f\u4e0b\u8fdb\u884c\u5efa\u6a21\u548c\u4f18\u5316\uff0c\u5bfc\u81f4\u5728\u9884\u7b97\u7ea6\u675f\u4e0b\u6210\u672c\u6548\u76ca\u4e0d\u4f73\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5927\u89c4\u6a21\u90e8\u7f72\u7684\u5b9e\u9645\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5148\u9aa8\u5e72\u540e\u62d3\u6251\u7684\u4e24\u9636\u6bb5\u8bbe\u8ba1\uff1a1) \u9aa8\u5e72\u5bfc\u5411\u7684\u667a\u80fd\u4f53\u751f\u6210\uff1a\u901a\u8fc7LLM\u6c60\u6784\u5efa\u3001\u6c60\u9009\u62e9\u548c\u89d2\u8272-\u9aa8\u5e72\u5339\u914d\u6784\u5efa\u5f02\u6784\u9aa8\u5e72\u7684\u667a\u80fd\u4f53\uff1b2) \u81ea\u9002\u5e94MAS\u62d3\u6251\u751f\u6210\uff1a\u901a\u8fc7\u667a\u80fd\u4f53\u8868\u793a\u5b66\u4e60\u3001\u95e8\u63a7\u673a\u5236\u548c\u5ef6\u8fdf\u611f\u77e5\u62d3\u6251\u5408\u6210\u6765\u6307\u5bfc\u667a\u80fd\u4f53\u95f4\u901a\u4fe1\u3002", "result": "\u5728\u5305\u542b14\u4e2a\u5019\u9009LLM\u9aa8\u5e72\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentBalance\u5728\u5339\u914d\u7684token\u6210\u672c\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8fbe10%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5339\u914d\u7684\u5ef6\u8fdf\u9884\u7b97\u4e0b\u5b9e\u73b0\u9ad8\u8fbe22%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5728\u6027\u80fd-\u9884\u7b97\u66f2\u7ebf\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684AUC\u3002", "conclusion": "AgentBalance\u80fd\u591f\u5728\u660e\u786e\u7684token\u6210\u672c\u548c\u5ef6\u8fdf\u9884\u7b97\u7ea6\u675f\u4e0b\u6784\u5efa\u6210\u672c\u6548\u76ca\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u53ef\u4f5c\u4e3a\u73b0\u6709MAS\u7684\u63d2\u4ef6\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u80fd\u5f88\u597d\u5730\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684LLM\uff0c\u5b9e\u73b0\u5b9e\u7528\u7684\u9884\u7b97\u611f\u77e5\u90e8\u7f72\u3002", "topic": "agent analysis"}}
{"id": "2512.11277", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11277", "abs": "https://arxiv.org/abs/2512.11277", "authors": ["Mrinal Rawat", "Arkajyoti Chakraborty", "Neha Gupta", "Roberto Pieraccini"], "title": "When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents", "comment": null, "summary": "Supervised fine-tuning (SFT) has emerged as one of the most effective ways to improve the performance of large language models (LLMs) in downstream tasks. However, SFT can have difficulty generalizing when the underlying data distribution changes, even when the new data does not fall completely outside the training domain. Recent reasoning-focused models such as o1 and R1 have demonstrated consistent gains over their non-reasoning counterparts, highlighting the importance of reasoning for improved generalization and reliability. However, collecting high-quality reasoning traces for SFT remains challenging -- annotations are costly, subjective, and difficult to scale. To address this limitation, we leverage Reinforcement Learning (RL) to enable models to learn reasoning strategies directly from task outcomes. We propose a pipeline in which LLMs generate reasoning steps that guide both the invocation of tools (e.g., function calls) and the final answer generation for conversational agents. Our method employs Group Relative Policy Optimization (GRPO) with rewards designed around tool accuracy and answer correctness, allowing the model to iteratively refine its reasoning and actions. Experimental results demonstrate that our approach improves both the quality of reasoning and the precision of tool invocations, achieving a 1.5% relative improvement over the SFT model (trained without explicit thinking) and a 40% gain compared to the base of the vanilla Qwen3-1.7B model. These findings demonstrate the promise of unifying reasoning and action learning through RL to build more capable and generalizable conversational agents.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u8bad\u7ec3LLMs\u63a8\u7406\u7b56\u7565\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7Group Relative Policy Optimization\uff08GRPO\uff09\u7ed3\u5408\u5de5\u5177\u51c6\u786e\u6027\u548c\u7b54\u6848\u6b63\u786e\u6027\u7684\u5956\u52b1\u673a\u5236\uff0c\u63d0\u5347\u5bf9\u8bdd\u4ee3\u7406\u7684\u63a8\u7406\u8d28\u91cf\u548c\u5de5\u5177\u8c03\u7528\u7cbe\u5ea6\u3002", "motivation": "\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5728\u6570\u636e\u5206\u5e03\u53d8\u5316\u65f6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u800c\u9ad8\u8d28\u91cf\u63a8\u7406\u6807\u6ce8\u6210\u672c\u9ad8\u3001\u4e3b\u89c2\u6027\u5f3a\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\u63a8\u7406\u80fd\u529b\u5bf9\u6a21\u578b\u6cdb\u5316\u548c\u53ef\u9760\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7ba1\u9053\uff0c\u8ba9LLMs\u751f\u6210\u63a8\u7406\u6b65\u9aa4\u6765\u6307\u5bfc\u5de5\u5177\u8c03\u7528\uff08\u5982\u51fd\u6570\u8c03\u7528\uff09\u548c\u6700\u7ec8\u7b54\u6848\u751f\u6210\u3002\u4f7f\u7528Group Relative Policy Optimization\uff08GRPO\uff09\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u5de5\u5177\u51c6\u786e\u6027\u548c\u7b54\u6848\u6b63\u786e\u6027\u7684\u5956\u52b1\u673a\u5236\uff0c\u8ba9\u6a21\u578b\u4ece\u4efb\u52a1\u7ed3\u679c\u4e2d\u76f4\u63a5\u5b66\u4e60\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u63a8\u7406\u8d28\u91cf\u548c\u5de5\u5177\u8c03\u7528\u7cbe\u5ea6\u4e0a\u5747\u6709\u63d0\u5347\uff0c\u76f8\u6bd4\u672a\u4f7f\u7528\u663e\u5f0f\u63a8\u7406\u7684SFT\u6a21\u578b\u83b7\u5f971.5%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u76f8\u6bd4\u57fa\u7840Qwen3-1.7B\u6a21\u578b\u83b7\u5f9740%\u7684\u6027\u80fd\u589e\u76ca\u3002", "conclusion": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u7edf\u4e00\u63a8\u7406\u548c\u52a8\u4f5c\u5b66\u4e60\uff0c\u53ef\u4ee5\u6784\u5efa\u66f4\u5f3a\u5927\u548c\u53ef\u6cdb\u5316\u7684\u5bf9\u8bdd\u4ee3\u7406\uff0c\u5c55\u793a\u4e86RL\u5728\u63d0\u5347LLMs\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.11463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11463", "abs": "https://arxiv.org/abs/2512.11463", "authors": ["Junghwan Lim", "Sungmin Lee", "Dongseok Kim", "Taehyun Kim", "Eunhwan Park", "Jeesoo Lee", "Jeongdoo Lee", "Junhyeok Lee", "Wai Ting Cheung", "Dahye Choi", "Minsu Ha", "Jaeheui Her", "Jaeyeon Huh", "Hanbin Jung", "Changjin Kang", "Beomgyu Kim", "Minjae Kim", "Taewhan Kim", "Youngrok Kim", "Hyukjin Kweon", "Haesol Lee", "Kungyu Lee", "Dongpin Oh", "Yeongjae Park", "Bokki Ryu", "Dongjoo Weon"], "title": "Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes", "comment": null, "summary": "We introduce Motif-2-12.7B-Reasoning, a 12.7B parameter language model designed to bridge the gap between open-weight systems and proprietary frontier models in complex reasoning and long-context understanding. Addressing the common challenges of model collapse and training instability in reasoning adaptation, we propose a comprehensive, reproducible training recipe spanning system, data, and algorithmic optimizations. Our approach combines memory-efficient infrastructure for 64K-token contexts using hybrid parallelism and kernel-level optimizations with a two-stage Supervised Fine-Tuning (SFT) curriculum that mitigates distribution mismatch through verified, aligned synthetic data. Furthermore, we detail a robust Reinforcement Learning Fine-Tuning (RLFT) pipeline that stabilizes training via difficulty-aware data filtering and mixed-policy trajectory reuse. Empirical results demonstrate that Motif-2-12.7B-Reasoning achieves performance comparable to models with significantly larger parameter counts across mathematics, coding, and agentic benchmarks, offering the community a competitive open model and a practical blueprint for scaling reasoning capabilities under realistic compute constraints.", "AI": {"tldr": "Motif-2-12.7B-Reasoning\u662f\u4e00\u4e2a12.7B\u53c2\u6570\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u7cfb\u7edf\u3001\u6570\u636e\u548c\u7b97\u6cd5\u4f18\u5316\uff0c\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u8fbe\u5230\u63a5\u8fd1\u524d\u6cbf\u4e13\u6709\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5f00\u6e90\u6a21\u578b\u4e0e\u4e13\u6709\u524d\u6cbf\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u65b9\u9762\u7684\u5dee\u8ddd\uff0c\u540c\u65f6\u89e3\u51b3\u63a8\u7406\u9002\u5e94\u4e2d\u7684\u6a21\u578b\u5d29\u6e83\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7b49\u5e38\u89c1\u6311\u6218\u3002", "method": "\u91c7\u7528\u7efc\u5408\u8bad\u7ec3\u65b9\u6848\uff1a1) \u4f7f\u7528\u6df7\u5408\u5e76\u884c\u548c\u5185\u6838\u7ea7\u4f18\u5316\u7684\u5185\u5b58\u9ad8\u6548\u57fa\u7840\u8bbe\u65bd\u652f\u630164K\u4ee4\u724c\u4e0a\u4e0b\u6587\uff1b2) \u4e24\u9636\u6bb5\u76d1\u7763\u5fae\u8c03\u8bfe\u7a0b\uff0c\u901a\u8fc7\u9a8c\u8bc1\u5bf9\u9f50\u7684\u5408\u6210\u6570\u636e\u7f13\u89e3\u5206\u5e03\u4e0d\u5339\u914d\uff1b3) \u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u7ba1\u9053\uff0c\u901a\u8fc7\u96be\u5ea6\u611f\u77e5\u6570\u636e\u8fc7\u6ee4\u548c\u6df7\u5408\u7b56\u7565\u8f68\u8ff9\u91cd\u7528\u6765\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "Motif-2-12.7B-Reasoning\u5728\u6570\u5b66\u3001\u7f16\u7801\u548c\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6027\u80fd\u53ef\u4e0e\u53c2\u6570\u6570\u91cf\u663e\u8457\u66f4\u5927\u7684\u6a21\u578b\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u793e\u533a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u7ade\u4e89\u529b\u7684\u5f00\u6e90\u6a21\u578b\uff0c\u5e76\u4e3a\u5728\u73b0\u5b9e\u8ba1\u7b97\u7ea6\u675f\u4e0b\u6269\u5c55\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u84dd\u56fe\u3002", "topic": "code agent"}}
{"id": "2512.11303", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.11303", "abs": "https://arxiv.org/abs/2512.11303", "authors": ["Jiarun Liu", "Shiyue Xu", "Yang Li", "Shangkun Liu", "Yongli Yu", "Peng Cao"], "title": "Unifying Dynamic Tool Creation and Cross-Task Experience Sharing through Cognitive Memory Architecture", "comment": null, "summary": "Large Language Model agents face fundamental challenges in adapting to novel tasks due to limitations in tool availability and experience reuse. Existing approaches either rely on predefined tools with limited coverage or build tools from scratch without leveraging past experiences, leading to inefficient exploration and suboptimal performance. We introduce SMITH (Shared Memory Integrated Tool Hub), a unified cognitive architecture that seamlessly integrates dynamic tool creation with cross-task experience sharing through hierarchical memory organization. SMITH organizes agent memory into procedural, semantic, and episodic components, enabling systematic capability expansion while preserving successful execution patterns. Our approach formalizes tool creation as iterative code generation within controlled sandbox environments and experience sharing through episodic memory retrieval with semantic similarity matching. We further propose a curriculum learning strategy based on agent-ensemble difficulty re-estimation. Extensive experiments on the GAIA benchmark demonstrate SMITH's effectiveness, achieving 81.8% Pass@1 accuracy and outperforming state-of-the-art baselines including Alita (75.2%) and Memento (70.9%). Our work establishes a foundation for building truly adaptive agents that continuously evolve their capabilities through principled integration of tool creation and experience accumulation.", "AI": {"tldr": "SMITH\u662f\u4e00\u4e2a\u7edf\u4e00\u8ba4\u77e5\u67b6\u6784\uff0c\u901a\u8fc7\u5206\u5c42\u8bb0\u5fc6\u7ec4\u7ec7\u5c06\u52a8\u6001\u5de5\u5177\u521b\u5efa\u4e0e\u8de8\u4efb\u52a1\u7ecf\u9a8c\u5171\u4eab\u76f8\u7ed3\u5408\uff0c\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523081.8%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u4ee3\u7406\u5728\u9002\u5e94\u65b0\u4efb\u52a1\u65f6\u9762\u4e34\u5de5\u5177\u8986\u76d6\u6709\u9650\u548c\u7ecf\u9a8c\u91cd\u7528\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5de5\u5177\u521b\u5efa\u548c\u7ecf\u9a8c\u5171\u4eab\u673a\u5236\u3002", "method": "\u63d0\u51faSMITH\u67b6\u6784\uff0c\u5c06\u8bb0\u5fc6\u7ec4\u7ec7\u4e3a\u7a0b\u5e8f\u6027\u3001\u8bed\u4e49\u6027\u548c\u60c5\u666f\u6027\u4e09\u4e2a\u5c42\u6b21\uff0c\u901a\u8fc7\u6c99\u76d2\u73af\u5883\u4e2d\u7684\u8fed\u4ee3\u4ee3\u7801\u751f\u6210\u521b\u5efa\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5339\u914d\u5b9e\u73b0\u7ecf\u9a8c\u5171\u4eab\uff0c\u8fd8\u63d0\u51fa\u57fa\u4e8e\u4ee3\u7406\u96c6\u6210\u96be\u5ea6\u91cd\u4f30\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523081.8%\u7684Pass@1\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8eAlita\uff0875.2%\uff09\u548cMemento\uff0870.9%\uff09\u7b49\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "SMITH\u4e3a\u6784\u5efa\u771f\u6b63\u81ea\u9002\u5e94\u4ee3\u7406\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u901a\u8fc7\u5de5\u5177\u521b\u5efa\u548c\u7ecf\u9a8c\u79ef\u7d2f\u7684\u6709\u673a\u7ed3\u5408\u5b9e\u73b0\u80fd\u529b\u7684\u6301\u7eed\u8fdb\u5316\u3002", "topic": "code agent"}}
{"id": "2512.11682", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11682", "abs": "https://arxiv.org/abs/2512.11682", "authors": ["Tim Cofala", "Christian Kalfar", "Jingge Xiao", "Johanna Schrader", "Michelle Tang", "Wolfgang Nejdl"], "title": "MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition", "comment": "7 pages, 3 figures", "summary": "Therapeutic decision-making in clinical medicine constitutes a high-stakes domain in which AI guidance interacts with complex interactions among patient characteristics, disease processes, and pharmacological agents. Tasks such as drug recommendation, treatment planning, and adverse-effect prediction demand robust, multi-step reasoning grounded in reliable biomedical knowledge. Agentic AI methods, exemplified by TxAgent, address these challenges through iterative retrieval-augmented generation (RAG). TxAgent employs a fine-tuned Llama-3.1-8B model that dynamically generates and executes function calls to a unified biomedical tool suite (ToolUniverse), integrating FDA Drug API, OpenTargets, and Monarch resources to ensure access to current therapeutic information. In contrast to general-purpose RAG systems, medical applications impose stringent safety constraints, rendering the accuracy of both the reasoning trace and the sequence of tool invocations critical. These considerations motivate evaluation protocols treating token-level reasoning and tool-usage behaviors as explicit supervision signals. This work presents insights derived from our participation in the CURE-Bench NeurIPS 2025 Challenge, which benchmarks therapeutic-reasoning systems using metrics that assess correctness, tool utilization, and reasoning quality. We analyze how retrieval quality for function (tool) calls influences overall model performance and demonstrate performance gains achieved through improved tool-retrieval strategies. Our work was awarded the Excellence Award in Open Science. Complete information can be found at https://curebench.ai/.", "AI": {"tldr": "TxAgent\u662f\u4e00\u4e2a\u7528\u4e8e\u4e34\u5e8a\u6cbb\u7597\u51b3\u7b56\u7684AI\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fed\u4ee3\u5f0f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u7edf\u4e00\u751f\u7269\u533b\u5b66\u5de5\u5177\u5957\u4ef6\uff0c\u5728CURE-Bench\u6311\u6218\u8d5b\u4e2d\u83b7\u5f97\u5353\u8d8a\u8868\u73b0\u3002", "motivation": "\u4e34\u5e8a\u6cbb\u7597\u51b3\u7b56\u662f\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u9700\u8981AI\u7cfb\u7edf\u8fdb\u884c\u591a\u6b65\u63a8\u7406\u5e76\u57fa\u4e8e\u53ef\u9760\u7684\u751f\u7269\u533b\u5b66\u77e5\u8bc6\u3002\u533b\u7597\u5e94\u7528\u6709\u4e25\u683c\u7684\u5b89\u5168\u7ea6\u675f\uff0c\u8981\u6c42\u63a8\u7406\u8f68\u8ff9\u548c\u5de5\u5177\u8c03\u7528\u5e8f\u5217\u7684\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u5fae\u8c03\u7684Llama-3.1-8B\u6a21\u578b\uff0c\u901a\u8fc7\u52a8\u6001\u751f\u6210\u548c\u6267\u884c\u51fd\u6570\u8c03\u7528\u6765\u8bbf\u95ee\u7edf\u4e00\u751f\u7269\u533b\u5b66\u5de5\u5177\u5957\u4ef6\uff08ToolUniverse\uff09\uff0c\u6574\u5408FDA\u836f\u7269API\u3001OpenTargets\u548cMonarch\u8d44\u6e90\u3002", "result": "\u5728CURE-Bench NeurIPS 2025\u6311\u6218\u8d5b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u83b7\u5f97\u5f00\u653e\u79d1\u5b66\u5353\u8d8a\u5956\u3002\u5206\u6790\u663e\u793a\u5de5\u5177\u68c0\u7d22\u8d28\u91cf\u5bf9\u6574\u4f53\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u6539\u8fdb\u5de5\u5177\u68c0\u7d22\u7b56\u7565\u53ef\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "TxAgent\u5c55\u793a\u4e86\u4ee3\u7406AI\u65b9\u6cd5\u5728\u4e34\u5e8a\u6cbb\u7597\u51b3\u7b56\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5f3a\u8c03\u4e86\u5de5\u5177\u68c0\u7d22\u8d28\u91cf\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u952e\u4f5c\u7528\uff0c\u4e3a\u533b\u7597AI\u7cfb\u7edf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "topic": "agent analysis"}}
{"id": "2512.11573", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11573", "abs": "https://arxiv.org/abs/2512.11573", "authors": ["Paulius Rauba", "Qiyao Wei", "Mihaela van der Schaar"], "title": "Visualizing token importance for black-box language models", "comment": null, "summary": "We consider the problem of auditing black-box large language models (LLMs) to ensure they behave reliably when deployed in production settings, particularly in high-stakes domains such as legal, medical, and regulatory compliance. Existing approaches for LLM auditing often focus on isolated aspects of model behavior, such as detecting specific biases or evaluating fairness. We are interested in a more general question -- can we understand how the outputs of black-box LLMs depend on each input token? There is a critical need to have such tools in real-world applications that rely on inaccessible API endpoints to language models. However, this is a highly non-trivial problem, as LLMs are stochastic functions (i.e. two outputs will be different by chance), while computing prompt-level gradients to approximate input sensitivity is infeasible. To address this, we propose Distribution-Based Sensitivity Analysis (DBSA), a lightweight model-agnostic procedure to evaluate the sensitivity of the output of a language model for each input token, without making any distributional assumptions about the LLM. DBSA is developed as a practical tool for practitioners, enabling quick, plug-and-play visual exploration of LLMs reliance on specific input tokens. Through illustrative examples, we demonstrate how DBSA can enable users to inspect LLM inputs and find sensitivities that may be overlooked by existing LLM interpretability methods.", "AI": {"tldr": "\u63d0\u51faDBSA\u65b9\u6cd5\uff0c\u7528\u4e8e\u5ba1\u8ba1\u9ed1\u76d2\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u6790\u6bcf\u4e2a\u8f93\u5165token\u5bf9\u8f93\u51fa\u7684\u654f\u611f\u6027\uff0c\u65e0\u9700\u6a21\u578b\u5047\u8bbe\uff0c\u652f\u6301\u53ef\u89c6\u5316\u63a2\u7d22", "motivation": "\u73b0\u6709LLM\u5ba1\u8ba1\u65b9\u6cd5\u901a\u5e38\u5173\u6ce8\u7279\u5b9a\u65b9\u9762\uff08\u5982\u504f\u89c1\u68c0\u6d4b\uff09\uff0c\u7f3a\u4e4f\u5bf9\u8f93\u5165token\u4f9d\u8d56\u6027\u7684\u5168\u9762\u7406\u89e3\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u80fd\u591f\u5206\u6790\u9ed1\u76d2API\u6a21\u578b\u8f93\u51fa\u4e0e\u8f93\u5165token\u5173\u7cfb\u7684\u5de5\u5177", "method": "\u63d0\u51faDistribution-Based Sensitivity Analysis (DBSA)\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u3001\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u5bf9LLM\u505a\u5206\u5e03\u5047\u8bbe\uff0c\u901a\u8fc7\u5206\u6790\u8f93\u51fa\u5206\u5e03\u6765\u8bc4\u4f30\u6bcf\u4e2a\u8f93\u5165token\u7684\u654f\u611f\u6027", "result": "\u901a\u8fc7\u793a\u4f8b\u8bc1\u660eDBSA\u80fd\u591f\u5e2e\u52a9\u7528\u6237\u68c0\u67e5LLM\u8f93\u5165\uff0c\u53d1\u73b0\u73b0\u6709\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\u53ef\u80fd\u5ffd\u7565\u7684\u654f\u611f\u6027", "conclusion": "DBSA\u4e3a\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u63d2\u4ef6\u5f0f\u5de5\u5177\uff0c\u652f\u6301\u5feb\u901f\u53ef\u89c6\u5316\u63a2\u7d22LLM\u5bf9\u7279\u5b9a\u8f93\u5165token\u7684\u4f9d\u8d56\u5173\u7cfb", "topic": "agent analysis"}}
{"id": "2512.11315", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11315", "abs": "https://arxiv.org/abs/2512.11315", "authors": ["Pranav Guruprasad", "Sudipta Chowdhury", "Harsh Sikka", "Mridul Sharma", "Helen Lu", "Sean Rivera", "Aryan Khurana", "Hangliang Ren", "Yangyue Wang"], "title": "Benchmarking the Generality of Vision-Language-Action Models", "comment": "23 pages, 7 figures, and 1 table", "summary": "Generalist multimodal agents are expected to unify perception, language, and control - operating robustly across diverse real world domains. However, current evaluation practices remain fragmented across isolated benchmarks, making it difficult to assess whether today's foundation models truly generalize beyond their training distributions. We introduce MultiNet v1.0, a unified benchmark for measuring the cross domain generality of vision language models (VLMs) and vision language action models (VLAs) across six foundational capability regimes. Visual grounding, spatial reasoning, tool use, physical commonsense, multi agent coordination, and continuous robot control. Evaluating GPT 5, Pi0, and Magma, we find that no model demonstrates consistent generality. All exhibit substantial degradation on unseen domains, unfamiliar modalities, or cross domain task shifts despite strong performance within their training distributions.These failures manifest as modality misalignment, output format instability, and catastrophic knowledge degradation under domain transfer.Our findings reveal a persistent gap between the aspiration of generalist intelligence and the actual capabilities of current foundation models.MultiNet v1.0 provides a standardized evaluation substrate for diagnosing these gaps and guiding the development of future generalist agents.Code, data, and leaderboards are publicly available.", "AI": {"tldr": "MultiNet v1.0\u662f\u4e00\u4e2a\u7edf\u4e00\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9\u8bed\u8a00\u52a8\u4f5c\u6a21\u578b\u5728\u516d\u4e2a\u6838\u5fc3\u80fd\u529b\u9886\u57df\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u5728\u672a\u89c1\u9886\u57df\u5b58\u5728\u663e\u8457\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u5f53\u524d\u591a\u6a21\u6001\u667a\u80fd\u4f53\u8bc4\u4f30\u5206\u6563\u5728\u5b64\u7acb\u57fa\u51c6\u4e2d\uff0c\u96be\u4ee5\u5224\u65ad\u57fa\u7840\u6a21\u578b\u662f\u5426\u771f\u6b63\u8d85\u8d8a\u4e86\u8bad\u7ec3\u5206\u5e03\u5b9e\u73b0\u6cdb\u5316\u3002\u9700\u8981\u7edf\u4e00\u57fa\u51c6\u6765\u8861\u91cf\u6a21\u578b\u5728\u8de8\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51faMultiNet v1.0\u57fa\u51c6\uff0c\u6db5\u76d6\u516d\u4e2a\u6838\u5fc3\u80fd\u529b\u9886\u57df\uff1a\u89c6\u89c9\u57fa\u7840\u3001\u7a7a\u95f4\u63a8\u7406\u3001\u5de5\u5177\u4f7f\u7528\u3001\u7269\u7406\u5e38\u8bc6\u3001\u591a\u667a\u80fd\u4f53\u534f\u8c03\u548c\u8fde\u7eed\u673a\u5668\u4eba\u63a7\u5236\u3002\u8bc4\u4f30\u4e86GPT-5\u3001Pi0\u548cMagma\u7b49\u6a21\u578b\u3002", "result": "\u6240\u6709\u6a21\u578b\u90fd\u672a\u5c55\u73b0\u4e00\u81f4\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u672a\u89c1\u9886\u57df\u3001\u964c\u751f\u6a21\u6001\u6216\u8de8\u9886\u57df\u4efb\u52a1\u8f6c\u6362\u4e2d\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u5c3d\u7ba1\u5728\u8bad\u7ec3\u5206\u5e03\u5185\u8868\u73b0\u826f\u597d\u3002\u5931\u8d25\u8868\u73b0\u4e3a\u6a21\u6001\u9519\u4f4d\u3001\u8f93\u51fa\u683c\u5f0f\u4e0d\u7a33\u5b9a\u548c\u9886\u57df\u8f6c\u79fb\u4e0b\u7684\u707e\u96be\u6027\u77e5\u8bc6\u9000\u5316\u3002", "conclusion": "\u5f53\u524d\u57fa\u7840\u6a21\u578b\u5728\u6cdb\u5316\u667a\u80fd\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002MultiNet v1.0\u4e3a\u8bca\u65ad\u8fd9\u4e9b\u5dee\u8ddd\u548c\u6307\u5bfc\u672a\u6765\u901a\u7528\u667a\u80fd\u4f53\u5f00\u53d1\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u7840\u3002", "topic": "agent analysis"}}
{"id": "2512.11470", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.11470", "abs": "https://arxiv.org/abs/2512.11470", "authors": ["Bowen Ding", "Yuhan Chen", "Jiayang Lv", "Jiyao Yuan", "Qi Zhu", "Shuangshuang Tian", "Dantong Zhu", "Futing Wang", "Heyuan Deng", "Fei Mi", "Lifeng Shang", "Tao Lin"], "title": "Rethinking Expert Trajectory Utilization in LLM Post-training", "comment": "24 pages, 5 figures, under review", "summary": "While effective post-training integrates Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), the optimal mechanism for utilizing expert trajectories remains unresolved. We propose the Plasticity-Ceiling Framework to theoretically ground this landscape, decomposing performance into foundational SFT performance and the subsequent RL plasticity. Through extensive benchmarking, we establish the Sequential SFT-then-RL pipeline as the superior standard, overcoming the stability deficits of synchronized approaches. Furthermore, we derive precise scaling guidelines: (1) Transitioning to RL at the SFT Stable or Mild Overfitting Sub-phase maximizes the final ceiling by securing foundational SFT performance without compromising RL plasticity; (2) Refuting ``Less is More'' in the context of SFT-then-RL scaling, we demonstrate that Data Scale determines the primary post-training potential, while Trajectory Difficulty acts as a performance multiplier; and (3) Identifying that the Minimum SFT Validation Loss serves as a robust indicator for selecting the expert trajectories that maximize the final performance ceiling. Our findings provide actionable guidelines for maximizing the value extracted from expert trajectories.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5851\u6027-\u5929\u82b1\u677f\u6846\u67b6\uff0c\u5c06\u540e\u8bad\u7ec3\u6027\u80fd\u5206\u89e3\u4e3a\u57fa\u7840SFT\u6027\u80fd\u548c\u540e\u7eedRL\u5851\u6027\uff0c\u786e\u5b9aSFT-then-RL\u4e3a\u6700\u4f18\u6d41\u7a0b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u6269\u5c55\u6307\u5bfc\u539f\u5219\u3002", "motivation": "\u5f53\u524d\u540e\u8bad\u7ec3\u4e2d\u5982\u4f55\u6709\u6548\u5229\u7528\u4e13\u5bb6\u8f68\u8ff9\u7684\u95ee\u9898\u5c1a\u672a\u89e3\u51b3\uff0c\u9700\u8981\u7406\u8bba\u6846\u67b6\u6765\u6307\u5bfcSFT\u548cRL\u7684\u6700\u4f73\u6574\u5408\u65b9\u5f0f\u3002", "method": "\u63d0\u51fa\u5851\u6027-\u5929\u82b1\u677f\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u5927\u91cf\u57fa\u51c6\u6d4b\u8bd5\u5206\u6790SFT\u548cRL\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u5efa\u7acbSFT-then-RL\u987a\u5e8f\u6d41\u7a0b\uff0c\u5e76\u63a8\u5bfc\u51fa\u5177\u4f53\u7684\u6269\u5c55\u6307\u5bfc\u539f\u5219\u3002", "result": "\u786e\u5b9aSFT-then-RL\u4f18\u4e8e\u540c\u6b65\u65b9\u6cd5\uff1b\u5728SFT\u7a33\u5b9a\u6216\u8f7b\u5ea6\u8fc7\u62df\u5408\u9636\u6bb5\u8f6c\u5411RL\u53ef\u6700\u5927\u5316\u6700\u7ec8\u6027\u80fd\uff1b\u6570\u636e\u89c4\u6a21\u51b3\u5b9a\u540e\u8bad\u7ec3\u6f5c\u529b\uff0c\u8f68\u8ff9\u96be\u5ea6\u4f5c\u4e3a\u6027\u80fd\u4e58\u6570\uff1bSFT\u9a8c\u8bc1\u635f\u5931\u662f\u9009\u62e9\u4e13\u5bb6\u8f68\u8ff9\u7684\u53ef\u9760\u6307\u6807\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u6700\u5927\u5316\u4e13\u5bb6\u8f68\u8ff9\u4ef7\u503c\u7684\u5b9e\u7528\u6307\u5bfc\u539f\u5219\uff0c\u4e3a\u540e\u8bad\u7ec3\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5177\u4f53\u64cd\u4f5c\u6307\u5357\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.11345", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.11345", "abs": "https://arxiv.org/abs/2512.11345", "authors": ["Minwoo Park", "Junwoo Chang", "Jongeun Choi", "Roberto Horowitz"], "title": "Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits", "comment": null, "summary": "Equivariant diffusion policies (EDPs) combine the generative expressivity of diffusion models with the strong generalization and sample efficiency afforded by geometric symmetries. While steering these policies with reinforcement learning (RL) offers a promising mechanism for fine-tuning beyond demonstration data, directly applying standard (non-equivariant) RL can be sample-inefficient and unstable, as it ignores the symmetries that EDPs are designed to exploit. In this paper, we theoretically establish that the diffusion process of an EDP is equivariant, which in turn induces a group-invariant latent-noise MDP that is well-suited for equivariant diffusion steering. Building on this theory, we introduce a principled symmetry-aware steering framework and compare standard, equivariant, and approximately equivariant RL strategies through comprehensive experiments across tasks with varying degrees of symmetry. While we identify the practical boundaries of strict equivariance under symmetry breaking, we show that exploiting symmetry during the steering process yields substantial benefits-enhancing sample efficiency, preventing value divergence, and achieving strong policy improvements even when EDPs are trained from extremely limited demonstrations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5bf9\u79f0\u611f\u77e5\u7684\u6269\u6563\u7b56\u7565\u5f15\u5bfc\u6846\u67b6\uff0c\u5c06\u7b49\u53d8\u6269\u6563\u7b56\u7565\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\uff0c\u5229\u7528\u51e0\u4f55\u5bf9\u79f0\u6027\u63d0\u9ad8\u6837\u672c\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u7b49\u53d8\u6269\u6563\u7b56\u7565\u7ed3\u5408\u4e86\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\u548c\u51e0\u4f55\u5bf9\u79f0\u6027\u7684\u6cdb\u5316\u4f18\u52bf\uff0c\u4f46\u76f4\u63a5\u7528\u6807\u51c6\u5f3a\u5316\u5b66\u4e60\u5f15\u5bfc\u4f1a\u5ffd\u7565\u5bf9\u79f0\u6027\uff0c\u5bfc\u81f4\u6837\u672c\u6548\u7387\u4f4e\u548c\u4e0d\u7a33\u5b9a\u3002\u9700\u8981\u5f00\u53d1\u80fd\u5229\u7528\u5bf9\u79f0\u6027\u7684\u5f15\u5bfc\u6846\u67b6\u3002", "method": "\u7406\u8bba\u8bc1\u660e\u7b49\u53d8\u6269\u6563\u8fc7\u7a0b\u7684\u7b49\u53d8\u6027\uff0c\u6784\u5efa\u7fa4\u4e0d\u53d8\u6f5c\u5728\u566a\u58f0MDP\uff0c\u63d0\u51fa\u5bf9\u79f0\u611f\u77e5\u5f15\u5bfc\u6846\u67b6\uff0c\u6bd4\u8f83\u6807\u51c6\u3001\u7b49\u53d8\u548c\u8fd1\u4f3c\u7b49\u53d8\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5229\u7528\u5bf9\u79f0\u6027\u8fdb\u884c\u5f15\u5bfc\u80fd\u663e\u8457\u63d0\u9ad8\u6837\u672c\u6548\u7387\uff0c\u9632\u6b62\u4ef7\u503c\u53d1\u6563\uff0c\u5373\u4f7f\u5728\u6781\u6709\u9650\u6f14\u793a\u6570\u636e\u8bad\u7ec3\u4e0b\u4e5f\u80fd\u5b9e\u73b0\u5f3a\u7b56\u7565\u6539\u8fdb\u3002", "conclusion": "\u5bf9\u79f0\u6027\u5728\u6269\u6563\u7b56\u7565\u5f15\u5bfc\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u5bf9\u79f0\u611f\u77e5\u6846\u67b6\u80fd\u6709\u6548\u5229\u7528\u51e0\u4f55\u5bf9\u79f0\u6027\u63d0\u5347\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u540c\u65f6\u8bc6\u522b\u4e86\u4e25\u683c\u7b49\u53d8\u6027\u5728\u5bf9\u79f0\u6027\u7834\u574f\u60c5\u51b5\u4e0b\u7684\u5b9e\u9645\u8fb9\u754c\u3002", "topic": "agentic reinforcement learning"}}
{"id": "2512.11391", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11391", "abs": "https://arxiv.org/abs/2512.11391", "authors": ["Yifan Niu", "Han Xiao", "Dongyi Liu", "Nuo Chen", "Jia Li"], "title": "Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization", "comment": null, "summary": "As Large Language Models (LLMs) are increasingly deployed in real-world applications, it is important to ensure their behaviors align with human values, societal norms, and ethical principles. However, safety alignment under Reinforcement Learning (RL) often suffers from forgetting learned general abilities, which is also known as the alignment tax. To address this issue, we introduce Null-Space constrained Policy Optimization (NSPO), a novel RL framework for LLM safety alignment while preserving their core abilities. The safety policy gradients are geometrically projected into the null space of general tasks, thereby mitigating the safety alignment tax. In addition, we theoretically prove that NSPO preserves the model's original core capabilities, while still guaranteeing a descent direction for effective safety alignment. Extensive experiments demonstrate that NSPO outperforms existing methods by a large margin, achieving state-of-the-art safety performance without sacrificing accuracy on general tasks, including math, code, and instruction-following tasks. Notably, NSPO is data-efficient and only requires 40% of public human-annotated safety data from PKU-SafeRLHF to achieve promising safety performance, without a large amount of mixed general tasks data in existing alignment methods.", "AI": {"tldr": "NSPO\u662f\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5b89\u5168\u7b56\u7565\u68af\u5ea6\u6295\u5f71\u5230\u901a\u7528\u4efb\u52a1\u7684\u96f6\u7a7a\u95f4\uff0c\u5728\u4fdd\u8bc1LLM\u5b89\u5168\u5bf9\u9f50\u7684\u540c\u65f6\u907f\u514d\u9057\u5fd8\u6838\u5fc3\u80fd\u529b\uff0c\u663e\u8457\u51cf\u5c11\u5bf9\u9f50\u7a0e\u3002", "motivation": "LLM\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u9700\u8981\u786e\u4fdd\u5176\u884c\u4e3a\u7b26\u5408\u4eba\u7c7b\u4ef7\u503c\u89c2\u3001\u793e\u4f1a\u89c4\u8303\u548c\u4f26\u7406\u539f\u5219\uff0c\u4f46\u4f20\u7edf\u7684RL\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u6a21\u578b\u9057\u5fd8\u5df2\u5b66\u4e60\u7684\u901a\u7528\u80fd\u529b\uff08\u5bf9\u9f50\u7a0e\u95ee\u9898\uff09\u3002", "method": "\u63d0\u51fa\u96f6\u7a7a\u95f4\u7ea6\u675f\u7b56\u7565\u4f18\u5316\uff08NSPO\uff09\uff0c\u5c06\u5b89\u5168\u7b56\u7565\u68af\u5ea6\u51e0\u4f55\u6295\u5f71\u5230\u901a\u7528\u4efb\u52a1\u7684\u96f6\u7a7a\u95f4\u4e2d\uff0c\u7406\u8bba\u4e0a\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u4fdd\u6301\u6a21\u578b\u539f\u59cb\u6838\u5fc3\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u8bc1\u5b89\u5168\u5bf9\u9f50\u7684\u6709\u6548\u4e0b\u964d\u65b9\u5411\u3002", "result": "NSPO\u5927\u5e45\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u6570\u5b66\u3001\u4ee3\u7801\u548c\u6307\u4ee4\u8ddf\u968f\u7b49\u901a\u7528\u4efb\u52a1\u4e0a\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5b89\u5168\u6027\u80fd\u3002\u6570\u636e\u6548\u7387\u9ad8\uff0c\u4ec5\u9700PKU-SafeRLHF\u4e2d40%\u7684\u5b89\u5168\u6570\u636e\u5373\u53ef\u8fbe\u5230\u826f\u597d\u6548\u679c\u3002", "conclusion": "NSPO\u6709\u6548\u89e3\u51b3\u4e86LLM\u5b89\u5168\u5bf9\u9f50\u4e2d\u7684\u5bf9\u9f50\u7a0e\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6838\u5fc3\u80fd\u529b\u7684\u540c\u65f6\u5b9e\u73b0\u5b89\u5168\u5bf9\u9f50\uff0c\u4e3aLLM\u7684\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "topic": "agentic reinforcement learning"}}
{"id": "tldr.2512.821494a8", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2F8G92Jp/1/0100019b0dbe0109-d67dc7e1-4e16-4764-a274-f694a9b38c76-000000/GeembiumrTb272fyaR0VecNBXTuGGKqosprUOy7mBqo=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2F8G92Jp/1/0100019b0dbe0109-d67dc7e1-4e16-4764-a274-f694a9b38c76-000000/GeembiumrTb272fyaR0VecNBXTuGGKqosprUOy7mBqo=435", "authors": ["TLDR Newsletter"], "title": "Agentic Commerce Is Here: Why PSPs Must Act Now to Stay Relevant", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: 5 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Flinks.tldrnewsletter.com%2F8G92Jp/1/0100019b0dbe0109-d67dc7e1-4e16-4764-a274-f694a9b38c76-000000/GeembiumrTb272fyaR0VecNBXTuGGKqosprUOy7mBqo=435", "summary": "Agentic Commerce Is Here: Why PSPs Must Act Now to Stay Relevant (5 minute read) Agentic commerce is moving from concept to reality faster than the industry expected. AI agents are increasingly steering how consumers discover products, compare options, build carts, and initiate purchases. While the long-term vision is fully autonomous payments, the near-term reality looks quite different. We are entering a semi-autonomous era: AI agents do the heavy lifting, but the user remains the final dec...", "source": "tldr", "AI": {"tldr": "AI\u4ee3\u7406\u6b63\u5728\u91cd\u5851\u7535\u5546\uff0c\u4ece\u4ea7\u54c1\u53d1\u73b0\u5230\u8d2d\u7269\u8f66\u6784\u5efa\uff0c\u4f46\u5f53\u524d\u5904\u4e8e\u534a\u81ea\u4e3b\u9636\u6bb5\uff0c\u7528\u6237\u4ecd\u662f\u6700\u7ec8\u51b3\u7b56\u8005", "motivation": "AI\u4ee3\u7406\u5728\u7535\u5546\u4e2d\u7684\u5e94\u7528\u6b63\u4ece\u6982\u5ff5\u5feb\u901f\u53d8\u4e3a\u73b0\u5b9e\uff0c\u652f\u4ed8\u670d\u52a1\u63d0\u4f9b\u5546\u9700\u8981\u7acb\u5373\u884c\u52a8\u4ee5\u4fdd\u6301\u76f8\u5173\u6027", "method": "\u5206\u6790AI\u4ee3\u7406\u5728\u7535\u5546\u5404\u73af\u8282\u7684\u5e94\u7528\u73b0\u72b6\uff0c\u9884\u6d4b\u4ece\u534a\u81ea\u4e3b\u5230\u5168\u81ea\u4e3b\u652f\u4ed8\u7684\u53d1\u5c55\u8def\u5f84", "result": "AI\u4ee3\u7406\u6b63\u5728\u6539\u53d8\u6d88\u8d39\u8005\u7684\u8d2d\u7269\u884c\u4e3a\u6a21\u5f0f\uff0c\u7535\u5546\u884c\u4e1a\u6b63\u5728\u8fdb\u5165\u534a\u81ea\u4e3b\u65f6\u4ee3", "conclusion": "\u652f\u4ed8\u670d\u52a1\u63d0\u4f9b\u5546\u5fc5\u987b\u7acb\u5373\u9002\u5e94AI\u4ee3\u7406\u9a71\u52a8\u7684\u7535\u5546\u53d8\u9769\uff0c\u5426\u5219\u5c06\u5931\u53bb\u5e02\u573a\u76f8\u5173\u6027", "topic": "agent analysis"}}
{"id": "tldr.2512.475949d0", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsemgrep.dev%2Fblog%2F2025%2Fcan-llms-detect-idors-understanding-the-boundaries-of-ai-reasoning%2F%3Futm_source=tldrinfosec/1/0100019b0dd3ac53-588fc471-6a71-4818-88c7-edb4d013fa47-000000/Xg4hXoxCCz4cRFrZKJ0wYR6MiA5JZYpOWqEOz-Q4Cn0=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsemgrep.dev%2Fblog%2F2025%2Fcan-llms-detect-idors-understanding-the-boundaries-of-ai-reasoning%2F%3Futm_source=tldrinfosec/1/0100019b0dd3ac53-588fc471-6a71-4818-88c7-edb4d013fa47-000000/Xg4hXoxCCz4cRFrZKJ0wYR6MiA5JZYpOWqEOz-Q4Cn0=435", "authors": ["TLDR Newsletter"], "title": "Can LLMs Detect IDORs? Understanding the Boundaries of AI Reasoning", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: 10 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fsemgrep.dev%2Fblog%2F2025%2Fcan-llms-detect-idors-understanding-the-boundaries-of-ai-reasoning%2F%3Futm_source=tldrinfosec/1/0100019b0dd3ac53-588fc471-6a71-4818-88c7-edb4d013fa47-000000/Xg4hXoxCCz4cRFrZKJ0wYR6MiA5JZYpOWqEOz-Q4Cn0=435", "summary": "Can LLMs Detect IDORs? Understanding the Boundaries of AI Reasoning (10 minute read) Semgrep tested Claude Code with Sonnet 4 and OpenAI Codex with GPT5's ability to detect IDOR vulnerabilities in code with four levels of increasing difficulty, from no authorization to implicit authorization through middleware. In total, the models identified 15 real, previously unknown vulnerabilities and 93 false positives, with Sonnet 4 performing best. In its test with a generic prompt, Semgrep found that...", "source": "tldr", "AI": {"tldr": "Semgrep\u6d4b\u8bd5\u4e86Claude Code Sonnet 4\u548cOpenAI Codex GPT5\u68c0\u6d4bIDOR\u6f0f\u6d1e\u7684\u80fd\u529b\uff0c\u5728\u56db\u4e2a\u96be\u5ea6\u7ea7\u522b\u4e0a\u53d1\u73b0\u4e8615\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u548c93\u4e2a\u8bef\u62a5\uff0cSonnet 4\u8868\u73b0\u6700\u4f73\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4bIDOR\uff08\u4e0d\u5b89\u5168\u7684\u76f4\u63a5\u5bf9\u8c61\u5f15\u7528\uff09\u6f0f\u6d1e\u65b9\u9762\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u4e86\u89e3AI\u63a8\u7406\u7684\u8fb9\u754c\u3002", "method": "\u4f7f\u7528Semgrep\u5e73\u53f0\u6d4b\u8bd5Claude Code Sonnet 4\u548cOpenAI Codex GPT5\uff0c\u8bbe\u8ba1\u4e86\u56db\u4e2a\u96be\u5ea6\u7ea7\u522b\u7684\u6d4b\u8bd5\u573a\u666f\uff1a\u65e0\u6388\u6743\u3001\u663e\u5f0f\u6388\u6743\u3001\u9690\u5f0f\u6388\u6743\u548c\u4e2d\u95f4\u4ef6\u9690\u5f0f\u6388\u6743\u3002", "result": "\u603b\u5171\u53d1\u73b0\u4e8615\u4e2a\u771f\u5b9e\u4e14\u4e4b\u524d\u672a\u77e5\u7684\u6f0f\u6d1e\u548c93\u4e2a\u8bef\u62a5\u3002Sonnet 4\u5728\u68c0\u6d4bIDOR\u6f0f\u6d1e\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u7279\u522b\u662f\u5728\u901a\u7528\u63d0\u793a\u6d4b\u8bd5\u4e2d\u3002", "conclusion": "LLMs\u5728\u68c0\u6d4bIDOR\u6f0f\u6d1e\u65b9\u9762\u5177\u6709\u4e00\u5b9a\u80fd\u529b\uff0c\u4f46\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u968f\u7740\u6388\u6743\u673a\u5236\u590d\u6742\u5ea6\u7684\u589e\u52a0\uff0c\u68c0\u6d4b\u96be\u5ea6\u4f1a\u663e\u8457\u63d0\u9ad8\u3002", "topic": "code agent"}}
{"id": "tldr.2512.d657d810", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcursor.com%2Fblog%2Fdebug-mode%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/cC-IBRAcCkyQjmeTW0fbp6dtJk49kO3DTE7MuRQ5Fho=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcursor.com%2Fblog%2Fdebug-mode%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/cC-IBRAcCkyQjmeTW0fbp6dtJk49kO3DTE7MuRQ5Fho=435", "authors": ["TLDR Newsletter"], "title": "Cursor Debug Mode", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: 3 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fcursor.com%2Fblog%2Fdebug-mode%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/cC-IBRAcCkyQjmeTW0fbp6dtJk49kO3DTE7MuRQ5Fho=435", "summary": "Cursor Debug Mode (3 minute read) Cursor has introduced Debug Mode, a new agent loop that incorporates runtime logs and human interaction to fix stubborn bugs. Inspired by expert debugging workflows, the mode generates multiple failure hypotheses, instruments code with logs, and loops in the user to reproduce errors and verify fixes.", "source": "tldr", "AI": {"tldr": "Cursor\u63a8\u51faDebug Mode\uff0c\u8fd9\u662f\u4e00\u79cd\u7ed3\u5408\u8fd0\u884c\u65f6\u65e5\u5fd7\u548c\u4eba\u5de5\u4ea4\u4e92\u7684\u65b0\u4ee3\u7406\u5faa\u73af\uff0c\u7528\u4e8e\u4fee\u590d\u987d\u56fabug", "motivation": "\u53d7\u4e13\u5bb6\u8c03\u8bd5\u5de5\u4f5c\u6d41\u7a0b\u542f\u53d1\uff0c\u65e8\u5728\u89e3\u51b3\u4f20\u7edf\u4ee3\u7801\u4ee3\u7406\u5728\u4fee\u590d\u590d\u6742bug\u65f6\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7ed3\u5408\u4eba\u7c7b\u4ea4\u4e92\u63d0\u9ad8\u8c03\u8bd5\u6548\u7387", "method": "\u91c7\u7528\u65b0\u7684\u4ee3\u7406\u5faa\u73af\uff1a1) \u751f\u6210\u591a\u4e2a\u5931\u8d25\u5047\u8bbe 2) \u7528\u65e5\u5fd7\u68c0\u6d4b\u4ee3\u7801 3) \u8ba9\u7528\u6237\u91cd\u73b0\u9519\u8bef 4) \u9a8c\u8bc1\u4fee\u590d\u65b9\u6848", "result": "\u5f00\u53d1\u4e86Debug Mode\u529f\u80fd\uff0c\u5c06\u8fd0\u884c\u65f6\u65e5\u5fd7\u548c\u4eba\u5de5\u4ea4\u4e92\u6574\u5408\u5230\u8c03\u8bd5\u8fc7\u7a0b\u4e2d\uff0c\u63d0\u9ad8\u4e86\u987d\u56fabug\u7684\u4fee\u590d\u80fd\u529b", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u4eba\u7c7b\u4ea4\u4e92\u548c\u81ea\u52a8\u5316\u8c03\u8bd5\uff0cCursor\u7684Debug Mode\u4e3a\u4ee3\u7801\u4ee3\u7406\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684bug\u4fee\u590d\u5de5\u4f5c\u6d41\u7a0b", "topic": "code agent"}}
{"id": "tldr.2512.885f5b44", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fthreadreaderapp.com%2Fthread%2F1998830338735485239.html%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/OksxsjNYyeRadZ6X5xbtIPVGY0g5Rr2UqvRtAdXMXAA=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fthreadreaderapp.com%2Fthread%2F1998830338735485239.html%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/OksxsjNYyeRadZ6X5xbtIPVGY0g5Rr2UqvRtAdXMXAA=435", "authors": ["TLDR Newsletter"], "title": "Upgrades to Claude Code CLI", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: 2 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fthreadreaderapp.com%2Fthread%2F1998830338735485239.html%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/OksxsjNYyeRadZ6X5xbtIPVGY0g5Rr2UqvRtAdXMXAA=435", "summary": "Upgrades to Claude Code CLI (2 minute read) Claude Code CLI now has async subagents, instant compact, customer session names, and usage stats. There are also new keyboard shortcuts on the /resume screen. Run 'claude update' to get all of the new features.", "source": "tldr", "AI": {"tldr": "Claude Code CLI \u65b0\u589e\u5f02\u6b65\u5b50\u4ee3\u7406\u3001\u5373\u65f6\u538b\u7f29\u3001\u5ba2\u6237\u4f1a\u8bdd\u540d\u79f0\u548c\u7528\u91cf\u7edf\u8ba1\u529f\u80fd\uff0c/resume \u754c\u9762\u65b0\u589e\u952e\u76d8\u5feb\u6377\u952e", "motivation": "\u63d0\u5347 Claude Code CLI \u7684\u5f00\u53d1\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u901a\u8fc7\u65b0\u589e\u529f\u80fd\u589e\u5f3a\u5de5\u5177\u7684\u751f\u4ea7\u529b", "method": "\u53d1\u5e03 Claude Code CLI \u66f4\u65b0\u7248\u672c\uff0c\u6dfb\u52a0\u5f02\u6b65\u5b50\u4ee3\u7406\u3001\u5373\u65f6\u538b\u7f29\u3001\u5ba2\u6237\u4f1a\u8bdd\u540d\u79f0\u3001\u7528\u91cf\u7edf\u8ba1\u7b49\u529f\u80fd\uff0c\u5e76\u5728 /resume \u754c\u9762\u589e\u52a0\u952e\u76d8\u5feb\u6377\u952e", "result": "\u7528\u6237\u53ef\u901a\u8fc7\u8fd0\u884c 'claude update' \u547d\u4ee4\u83b7\u53d6\u6240\u6709\u65b0\u529f\u80fd\uff0c\u63d0\u5347\u4ee3\u7801\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u7684\u6548\u7387", "conclusion": "Claude Code CLI \u6301\u7eed\u6539\u8fdb\uff0c\u901a\u8fc7\u529f\u80fd\u589e\u5f3a\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u652f\u6301", "topic": "code agent"}}
{"id": "tldr.2512.86119e9b", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Farxiv.org%2Fabs%2F2512.08296%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/OoMuS1yGA30gbGLaK-sOfrsExxMmCGRzpq6QiKTu7rs=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Farxiv.org%2Fabs%2F2512.08296%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/OoMuS1yGA30gbGLaK-sOfrsExxMmCGRzpq6QiKTu7rs=435", "authors": ["TLDR Newsletter"], "title": "Towards a Science of Scaling Agent Systems", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: 2 minute read, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Farxiv.org%2Fabs%2F2512.08296%3Futm_source=tldrai/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/OoMuS1yGA30gbGLaK-sOfrsExxMmCGRzpq6QiKTu7rs=435", "summary": "Towards a Science of Scaling Agent Systems (2 minute read) Agents are becoming the dominant paradigm for real-world AI applications. However, practitioners still rely on heuristics rather than principled design choices. This study attempts to derive quantitative scaling principles for agent systems.", "source": "tldr", "AI": {"tldr": "\u672c\u6587\u5c1d\u8bd5\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u5efa\u7acb\u5b9a\u91cf\u6269\u5c55\u539f\u5219\uff0c\u4ee5\u66ff\u4ee3\u5f53\u524d\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u7684\u8bbe\u8ba1\u5b9e\u8df5\u3002", "motivation": "\u667a\u80fd\u4f53\u6b63\u5728\u6210\u4e3a\u73b0\u5b9e\u4e16\u754cAI\u5e94\u7528\u7684\u4e3b\u5bfc\u8303\u5f0f\uff0c\u4f46\u4ece\u4e1a\u8005\u4ecd\u7136\u4f9d\u8d56\u542f\u53d1\u5f0f\u65b9\u6cd5\u800c\u975e\u539f\u5219\u6027\u8bbe\u8ba1\u9009\u62e9\uff0c\u9700\u8981\u5efa\u7acb\u79d1\u5b66\u7684\u6269\u5c55\u539f\u5219\u3002", "method": "\u7814\u7a76\u5c1d\u8bd5\u63a8\u5bfc\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5b9a\u91cf\u6269\u5c55\u539f\u5219\uff0c\u5efa\u7acb\u79d1\u5b66\u7684\u6269\u5c55\u65b9\u6cd5\u5b66\u3002", "result": "\u8bba\u6587\u63d0\u51fa\u4e86\u5efa\u7acb\u667a\u80fd\u4f53\u7cfb\u7edf\u6269\u5c55\u79d1\u5b66\u7684\u521d\u6b65\u5c1d\u8bd5\uff0c\u65e8\u5728\u4e3a\u5b9e\u8df5\u63d0\u4f9b\u5b9a\u91cf\u6307\u5bfc\u539f\u5219\u3002", "conclusion": "\u9700\u8981\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u5efa\u7acb\u79d1\u5b66\u7684\u6269\u5c55\u539f\u5219\uff0c\u4ee5\u66ff\u4ee3\u5f53\u524d\u4f9d\u8d56\u542f\u53d1\u5f0f\u7684\u8bbe\u8ba1\u5b9e\u8df5\u3002", "topic": "agent analysis"}}
{"id": "tldr.2512.1cefdf7e", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2Fnews%2Famp-inc%3F%26utm_medium=paid%2520sponsored%26utm_source=tldrnewsletter%26utm_campaign=amp_split/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/mHNGb8xT-VFf2cxG3PMfSLLEZXm1FT89gnUNHELgrgw=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2Fnews%2Famp-inc%3F%26utm_medium=paid%2520sponsored%26utm_source=tldrnewsletter%26utm_campaign=amp_split/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/mHNGb8xT-VFf2cxG3PMfSLLEZXm1FT89gnUNHELgrgw=435", "authors": ["TLDR Newsletter"], "title": "Frontier coding agent Amp spins out of Sourcegraph as a separate company", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Reading time: Sponsor, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2Fnews%2Famp-inc%3F%26utm_medium=paid%2520sponsored%26utm_source=tldrnewsletter%26utm_campaign=amp_split/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/mHNGb8xT-VFf2cxG3PMfSLLEZXm1FT89gnUNHELgrgw=435", "summary": "Frontier coding agent Amp spins out of Sourcegraph as a separate company (Sponsor) Sourcegraph launched Amp 9 months ago as an experimental coding agent. It quickly grew to become one of the leading coding agents. Now, Amp is its own company operating at the frontier of software development.Read more on the new Amp website >", "source": "tldr", "AI": {"tldr": "Sourcegraph\u7684\u7f16\u7801\u4ee3\u7406Amp\u57289\u4e2a\u6708\u5b9e\u9a8c\u540e\u6210\u4e3a\u9886\u5148\u7f16\u7801\u4ee3\u7406\uff0c\u73b0\u5df2\u5206\u62c6\u4e3a\u72ec\u7acb\u516c\u53f8\uff0c\u4e13\u6ce8\u4e8e\u524d\u6cbf\u8f6f\u4ef6\u5f00\u53d1", "motivation": "Sourcegraph\u6700\u521d\u5c06Amp\u4f5c\u4e3a\u5b9e\u9a8c\u6027\u7f16\u7801\u4ee3\u7406\u63a8\u51fa\uff0c\u65e8\u5728\u63a2\u7d22AI\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\uff0c\u968f\u7740\u5176\u5feb\u901f\u53d1\u5c55\u6210\u4e3a\u9886\u5148\u7f16\u7801\u4ee3\u7406\uff0c\u9700\u8981\u72ec\u7acb\u8fd0\u8425\u4ee5\u66f4\u597d\u5730\u4e13\u6ce8\u4e8e\u524d\u6cbf\u6280\u672f\u5f00\u53d1", "method": "\u901a\u8fc7\u5c06Amp\u4eceSourcegraph\u5206\u62c6\u4e3a\u72ec\u7acb\u516c\u53f8\uff0c\u4f7f\u5176\u80fd\u591f\u4e13\u6ce8\u4e8e\u7f16\u7801\u4ee3\u7406\u6280\u672f\u7684\u7814\u53d1\u548c\u521b\u65b0\uff0c\u72ec\u7acb\u8fd0\u8425\u4ee5\u52a0\u901f\u53d1\u5c55", "result": "Amp\u57289\u4e2a\u6708\u5185\u4ece\u5b9e\u9a8c\u9879\u76ee\u6210\u957f\u4e3a\u9886\u5148\u7f16\u7801\u4ee3\u7406\uff0c\u6210\u529f\u5b8c\u6210\u516c\u53f8\u5206\u62c6\uff0c\u73b0\u5728\u4f5c\u4e3a\u72ec\u7acb\u516c\u53f8\u8fd0\u8425\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u524d\u6cbf", "conclusion": "\u7f16\u7801\u4ee3\u7406Amp\u7684\u6210\u529f\u5206\u62c6\u6807\u5fd7\u7740\u5176\u5728\u8f6f\u4ef6\u5f00\u53d1\u9886\u57df\u7684\u91cd\u8981\u5730\u4f4d\uff0c\u72ec\u7acb\u8fd0\u8425\u5c06\u6709\u52a9\u4e8e\u5176\u5728\u524d\u6cbf\u6280\u672f\u9886\u57df\u53d6\u5f97\u66f4\u5927\u7a81\u7834", "topic": "code agent"}}
{"id": "tldr.2512.7ce8e8ca", "categories": ["tldr.article"], "pdf": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2Fnews%2Famp-inc%3F%26utm_medium=paid%2520sponsored%26utm_source=tldrnewsletter%26utm_campaign=amp_split/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/mHNGb8xT-VFf2cxG3PMfSLLEZXm1FT89gnUNHELgrgw=435", "abs": "https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2Fnews%2Famp-inc%3F%26utm_medium=paid%2520sponsored%26utm_source=tldrnewsletter%26utm_campaign=amp_split/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/mHNGb8xT-VFf2cxG3PMfSLLEZXm1FT89gnUNHELgrgw=435", "authors": ["TLDR Newsletter"], "title": "Read more on the new Amp website >", "comment": "Source: TLDR Newsletter, Date: 2025-12-11, Links: https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fampcode.com%2Fnews%2Famp-inc%3F%26utm_medium=paid%2520sponsored%26utm_source=tldrnewsletter%26utm_campaign=amp_split/1/0100019b0de2e5a4-ecea8ec4-4b82-4da4-8b49-a2b541c02ce3-000000/mHNGb8xT-VFf2cxG3PMfSLLEZXm1FT89gnUNHELgrgw=435", "summary": "Frontier coding agent Amp spins out of Sourcegraph as a separate company (Sponsor) Sourcegraph launched Amp 9 months ago as an experimental coding agent. It quickly grew to become one of the leading coding agents. Now, Amp is its own company operating at the frontier of software development.Read more on the new Amp website >", "source": "tldr", "AI": {"tldr": "Sourcegraph\u5c06\u5176\u5b9e\u9a8c\u6027\u7f16\u7801\u4ee3\u7406Amp\u5206\u62c6\u4e3a\u72ec\u7acb\u516c\u53f8\uff0c\u8be5\u4ee3\u7406\u57289\u4e2a\u6708\u5185\u6210\u957f\u4e3a\u9886\u5148\u7684\u7f16\u7801\u4ee3\u7406\u4e4b\u4e00", "motivation": "Amp\u4f5c\u4e3a\u5b9e\u9a8c\u6027\u7f16\u7801\u4ee3\u7406\u5728Sourcegraph\u5185\u90e8\u5feb\u901f\u6210\u957f\u4e3a\u9886\u5148\u4ea7\u54c1\uff0c\u5206\u62c6\u4e3a\u72ec\u7acb\u516c\u53f8\u4ee5\u4fbf\u66f4\u597d\u5730\u4e13\u6ce8\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u7684\u5c16\u7aef\u9886\u57df", "method": "\u5c06\u539f\u672c\u4f5c\u4e3aSourcegraph\u5185\u90e8\u5b9e\u9a8c\u9879\u76ee\u7684\u7f16\u7801\u4ee3\u7406Amp\u5206\u62c6\u4e3a\u72ec\u7acb\u8fd0\u8425\u7684\u516c\u53f8", "result": "Amp\u57289\u4e2a\u6708\u5185\u6210\u957f\u4e3a\u9886\u5148\u7684\u7f16\u7801\u4ee3\u7406\u4e4b\u4e00\uff0c\u73b0\u5728\u4f5c\u4e3a\u72ec\u7acb\u516c\u53f8\u8fd0\u8425\u4e8e\u8f6f\u4ef6\u5f00\u53d1\u524d\u6cbf", "conclusion": "\u7f16\u7801\u4ee3\u7406Amp\u7684\u6210\u529f\u5206\u62c6\u663e\u793a\u4e86\u8be5\u6280\u672f\u5728\u8f6f\u4ef6\u5f00\u53d1\u9886\u57df\u7684\u5de8\u5927\u6f5c\u529b\u548c\u5e02\u573a\u4ef7\u503c", "topic": "code agent"}}
{"id": "wechat.2512.9a7418f5", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4MzAxOTEzNQ==&mid=2247483776&idx=1&sn=40efe628faf10b1866365381aab38517&chksm=ce1ca00381455030072fb28d24d776a1e5e051b472ebf4553dc0ff42157e95137aa174eb5abf#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4MzAxOTEzNQ==&mid=2247483776&idx=1&sn=40efe628faf10b1866365381aab38517&chksm=ce1ca00381455030072fb28d24d776a1e5e051b472ebf4553dc0ff42157e95137aa174eb5abf#rd", "authors": ["\u5c0f\u718a\u732b\u8bfb\u8bba\u6587"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7b2c\u4e00\u7bc7 \uff1a google SRL \u5f53\u201c\u6b7b\u8bb0\u786c\u80cc\u201d\u9047\u4e0a\u201c\u6b65\u6b65\u60ca\u5fc3\u201d", "comment": "Source: WeChat, Published: 2025-12-15 13:52:04", "summary": "\u5b83\u4e0d\u518d\u662f\u76f2\u76ee\u5730\u8499\u7b54\u6848\uff0c\u800c\u662f\u5728\u5b66\u4e60**\u201c\u4ec0\u4e48\u6837\u7684\u903b\u8f91\u63a8\u6f14\u662f\u7b26\u5408\u5ba2\u89c2\u89c4\u5f8b\u7684\u201d**\u300205 \u7ed3\u5c40\u8fd9\u4e2a\u6545\u4e8b\u7684\u7ed3\u5c40\u662f\u4ec0\u4e48\uff1f\u8bba\u6587\u7684\u6570\u636e\u544a\u8bc9\u6211\u4eec\uff0cSRL \u8fd9\u79cd\u201c\u5148\u5b66\u62db\u5f0f\uff0c\u518d\u609f\u5fc3\u6cd5\uff0c\u4e14\u6b65\u6b65\u4e3a\u8425\u201d\u7684\u65b9\u6cd5\uff0c\u5728\u590d\u6742\u7684\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u628a\u90a3\u4e9b", "AI": {"tldr": "\u5b83\u4e0d\u518d\u662f\u76f2\u76ee\u5730\u8499\u7b54\u6848\uff0c\u800c\u662f\u5728\u5b66\u4e60**\u201c\u4ec0\u4e48\u6837\u7684\u903b\u8f91\u63a8\u6f14\u662f\u7b26\u5408\u5ba2\u89c2\u89c4\u5f8b\u7684\u201d**\u300205 \u7ed3\u5c40\u8fd9\u4e2a\u6545\u4e8b\u7684\u7ed3\u5c40\u662f\u4ec0\u4e48\uff1f\u8bba\u6587\u7684\u6570\u636e\u544a\u8bc9\u6211\u4eec\uff0cSRL \u8fd9\u79cd\u201c\u5148\u5b66\u62db\u5f0f\uff0c\u518d\u609f\u5fc3\u6cd5\uff0c\u4e14\u6b65\u6b65\u4e3a\u8425\u201d\u7684\u65b9\u6cd5\uff0c\u5728\u590d\u6742\u7684\u903b\u8f91\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u628a\u90a3\u4e9b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.70a3d0c3", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYzMzIxMDc2Mw==&mid=2247483880&idx=1&sn=a6d71c5e38bdc3dd8f6535d61058113b&chksm=f19909ae552f672a1d875aeda278d22e32638e3d750cfb36e9f3d0833dc30cb80142a48e89ed#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYzMzIxMDc2Mw==&mid=2247483880&idx=1&sn=a6d71c5e38bdc3dd8f6535d61058113b&chksm=f19909ae552f672a1d875aeda278d22e32638e3d750cfb36e9f3d0833dc30cb80142a48e89ed#rd", "authors": ["AI\u8bba\u6587\u5feb\u8bfb\u7ad9"], "title": "Nature|\u8c37\u6b4c\u56e2\u961f\uff1a\u6700\u5148\u8fdb\u7684<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7b97\u6cd5", "comment": "Source: WeChat, Published: 2025-12-15 11:30:00", "summary": "\u300c\u7b97\u6cd5\u57fa\u56e0\u300d\u53cc\u5c42\u6f14\u5316\u6d41\u7a0b\u56fe\uff1a\u4ece\u4f2a\u4ee3\u7801\u5411\u91cf\u5230 SOTA \u5f3a\u5316\u5b66\u4e60\u672c\u56fe\u6574\u4e2a\u7814\u7a76\u6d41\u7a0b\u6700\u5de6\u4fa7\u662f\u628a RL \u66f4\u65b0\u89c4\u5219\u62c6\u6210 50 \u4f59\u4e2a\u53ef\u5fae\u7b97\u5b50\u5e76\u7f16\u7801\u6210\u4e00\u6761\u201c\u7b97\u6cd5\u57fa\u56e0\u201d\u5411\u91cf\uff1b", "AI": {"tldr": "\u300c\u7b97\u6cd5\u57fa\u56e0\u300d\u53cc\u5c42\u6f14\u5316\u6d41\u7a0b\u56fe\uff1a\u4ece\u4f2a\u4ee3\u7801\u5411\u91cf\u5230 SOTA \u5f3a\u5316\u5b66\u4e60\u672c\u56fe\u6574\u4e2a\u7814\u7a76\u6d41\u7a0b\u6700\u5de6\u4fa7\u662f\u628a RL \u66f4\u65b0\u89c4\u5219\u62c6\u6210 50 \u4f59\u4e2a\u53ef\u5fae\u7b97\u5b50\u5e76\u7f16\u7801\u6210\u4e00\u6761\u201c\u7b97\u6cd5\u57fa\u56e0\u201d\u5411\u91cf\uff1b", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.fe0b8eb9", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzU2NjU3OTc5NA==&mid=2247605333&idx=2&sn=019b34e93d16c723a9065ff1b6c503a7&chksm=fdafddc79b30e5b1716b99a9fdbdb63e06dc088d498e092f8f617c3e246940c3e6a0fb25bc6a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzU2NjU3OTc5NA==&mid=2247605333&idx=2&sn=019b34e93d16c723a9065ff1b6c503a7&chksm=fdafddc79b30e5b1716b99a9fdbdb63e06dc088d498e092f8f617c3e246940c3e6a0fb25bc6a#rd", "authors": ["\u6df1\u84ddAI"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u5e94\u7528\u5728\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684\u4e00\u4e9b\u601d\u8003", "comment": "Source: WeChat, Published: 2025-12-15 09:33:11", "summary": "\u5f3a\u5316\u5b66\u4e60\u7684\u6838\u5fc3\u4ef7\u503c\u5c31\u662f\u95ed\u73af\u5b66\u4e60\uff0c\u4f7f\u7528\u4e00\u4e9b\u6bd4\u8f83\u56f0\u96be\u7684\u5c0f\u6570\u636e\u96c6\u6765\u505a RL\uff0c\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u63d0\u5347\u662f\u7acb\u7aff\u89c1\u5f71\u7684\u3002\u5f53\u7136\u8fd9\u4e5f\u662f\u53c2\u8003\u4e86\u5927\u6a21\u578b\u4e2d RL \u5fae\u8c03\u7684\u4e2d\u95f4\u5f62\u6001\uff0c\u5982\u679c\u60f3\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u80fd\u529b\uff0c\u8ddf\u7740 tesla \u8d70\u5c31\u884c\u4e86\u3002", "AI": {"tldr": "\u5f3a\u5316\u5b66\u4e60\u7684\u6838\u5fc3\u4ef7\u503c\u5c31\u662f\u95ed\u73af\u5b66\u4e60\uff0c\u4f7f\u7528\u4e00\u4e9b\u6bd4\u8f83\u56f0\u96be\u7684\u5c0f\u6570\u636e\u96c6\u6765\u505a RL\uff0c\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u63d0\u5347\u662f\u7acb\u7aff\u89c1\u5f71\u7684\u3002\u5f53\u7136\u8fd9\u4e5f\u662f\u53c2\u8003\u4e86\u5927\u6a21\u578b\u4e2d RL \u5fae\u8c03\u7684\u4e2d\u95f4\u5f62\u6001\uff0c\u5982\u679c\u60f3\u8981\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u80fd\u529b\uff0c\u8ddf\u7740 tesla \u8d70\u5c31\u884c\u4e86\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.cd891d0d", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYzNTE3Mzk3Mw==&mid=2247484371&idx=1&sn=20c70ba0ca59a18ecc0c3de58636713b&chksm=f1e8fabfcd3c6f15acc5e9b013fac9afc4afb45b8453c49139d3437e86c62c27c0890c2e40cf#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYzNTE3Mzk3Mw==&mid=2247484371&idx=1&sn=20c70ba0ca59a18ecc0c3de58636713b&chksm=f1e8fabfcd3c6f15acc5e9b013fac9afc4afb45b8453c49139d3437e86c62c27c0890c2e40cf#rd", "authors": ["tNature"], "title": "AI\u5f00\u59cb\"\u81ea\u6211\u8fdb\u5316\"\uff1aDeepMind\u8ba9\u673a\u5668\u81ea\u4e3b\u8bbe\u8ba1<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u7b97\u6cd5\uff0c\u6027\u80fd\u78be\u538b\u4eba\u7c7b\u667a\u6167\u7ed3\u6676", "comment": "Source: WeChat, Published: 2025-12-15 09:30:00", "summary": "\u4e00\u3001\u5f3a\u5316\u5b66\u4e60\u7684\"\u5929\u82b1\u677f\"\uff1a\u5f53\u4eba\u7c7b\u667a\u6167\u9047\u5230\u74f6\u9888\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4f5c\u4e3aAI\u7684\u6838\u5fc3\u8303\u5f0f\u4e4b\u4e00\uff0c\u66fe\u5728\u56f4\u68cb\u3001\u661f\u9645\u4e89\u9738\u3001\u673a\u5668\u4eba\u63a7\u5236\u7b49\u9886\u57df\u521b\u9020\u4f20\u5947\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u8f89\u714c\u6210\u5c31\u80cc\u540e\u9690\u85cf\u7740\u4e00\u4e2a\u5c34\u5c2c\u73b0\u5b9e\uff1a\u6240\u6709\u7b97\u6cd5\u90fd\u4f9d\u8d56\u4eba\u7c7b\u4e13\u5bb6\u6570\u5e74\u751a\u81f3\u6570\u5341\u5e74", "AI": {"tldr": "\u4e00\u3001\u5f3a\u5316\u5b66\u4e60\u7684\"\u5929\u82b1\u677f\"\uff1a\u5f53\u4eba\u7c7b\u667a\u6167\u9047\u5230\u74f6\u9888\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4f5c\u4e3aAI\u7684\u6838\u5fc3\u8303\u5f0f\u4e4b\u4e00\uff0c\u66fe\u5728\u56f4\u68cb\u3001\u661f\u9645\u4e89\u9738\u3001\u673a\u5668\u4eba\u63a7\u5236\u7b49\u9886\u57df\u521b\u9020\u4f20\u5947\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u8f89\u714c\u6210\u5c31\u80cc\u540e\u9690\u85cf\u7740\u4e00\u4e2a\u5c34\u5c2c\u73b0\u5b9e\uff1a\u6240\u6709\u7b97\u6cd5\u90fd\u4f9d\u8d56\u4eba\u7c7b\u4e13\u5bb6\u6570\u5e74\u751a\u81f3\u6570\u5341\u5e74", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.f815e097", "categories": ["wechat.article", "wechat.ai", "wechat.rl", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&mid=2247663026&idx=1&sn=85e7d452b276c33b62f79500473a18cf&chksm=e89deab7db406d94d22404620f632d6a1c245f43ca35860e7cbdeffea15e54188fb82a7eecf5#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI1MjQ2OTQ3Ng==&mid=2247663026&idx=1&sn=85e7d452b276c33b62f79500473a18cf&chksm=e89deab7db406d94d22404620f632d6a1c245f43ca35860e7cbdeffea15e54188fb82a7eecf5#rd", "authors": ["\u6570\u636e\u6d3eTHU"], "title": "LLM<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u4e0d\u7a33\u5b9a\u4e4b\u8c1c\uff0c\u88abQwen\u56e2\u961f\u4ece\u300c\u4e00\u9636\u8fd1\u4f3c\u300d\u89c6\u89d2\u89e3\u5f00", "comment": "Source: WeChat, Published: 2025-12-15 09:02:15", "summary": "\u5982\u4eca\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5df2\u6210\u4e3a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u590d\u6742\u63a8\u7406\u4e0e\u89e3\u9898\u80fd\u529b\u7684\u5173\u952e\u6280\u672f\u8303\u5f0f\uff0c\u800c\u7a33\u5b9a\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5bf9\u4e8e\u6210\u529f\u6269\u5c55 RL \u81f3\u5173\u91cd\u8981\u3002\u7531\u4e8e\u8bed\u8a00\u5177\u6709\u5f3a\u70c8\u7684\u4e0a\u4e0b\u6587\u5c5e\u6027\uff0cLLM \u7684 RL \u901a\u5e38\u4f9d\u8d56\u5e8f\u5217\u7ea7\u5956\u52b1 \u2014\u2014 \u5373\u6839\u636e\u5b8c\u6574\u751f\u6210\u5e8f\u5217", "AI": {"tldr": "\u5982\u4eca\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u5df2\u6210\u4e3a\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u590d\u6742\u63a8\u7406\u4e0e\u89e3\u9898\u80fd\u529b\u7684\u5173\u952e\u6280\u672f\u8303\u5f0f\uff0c\u800c\u7a33\u5b9a\u7684\u8bad\u7ec3\u8fc7\u7a0b\u5bf9\u4e8e\u6210\u529f\u6269\u5c55 RL \u81f3\u5173\u91cd\u8981\u3002\u7531\u4e8e\u8bed\u8a00\u5177\u6709\u5f3a\u70c8\u7684\u4e0a\u4e0b\u6587\u5c5e\u6027\uff0cLLM \u7684 RL \u901a\u5e38\u4f9d\u8d56\u5e8f\u5217\u7ea7\u5956\u52b1 \u2014\u2014 \u5373\u6839\u636e\u5b8c\u6574\u751f\u6210\u5e8f\u5217", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.e6063cf1", "categories": ["wechat.article", "wechat.rl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg2Nzg5ODQyMA==&mid=2247503805&idx=1&sn=9cd108579337b378a7db831665a25889&chksm=cf8487c7f59ede56c4c4ee00e7f6d464af869959763a7e4e59da4cafebe50d17c940b6f5c25b#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg2Nzg5ODQyMA==&mid=2247503805&idx=1&sn=9cd108579337b378a7db831665a25889&chksm=cf8487c7f59ede56c4c4ee00e7f6d464af869959763a7e4e59da4cafebe50d17c940b6f5c25b#rd", "authors": ["\u667a\u6167\u8f66\u8f86\u4e0e\u4ea4\u901a"], "title": "COMMTR | MARL-OD-DA\uff1a\u9762\u5411\u5927\u89c4\u6a21\u4ea4\u901a\u5206\u914d\u7684\u53ef\u6269\u5c55\u591a\u667a\u80fd\u4f53<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u6846\u67b6", "comment": "Source: WeChat, Published: 2025-12-15 09:00:00", "summary": "MARL-OD-DA\u4e0d\u4ec5\u7a81\u7834\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u4ea4\u901a\u5206\u914d\u9886\u57df\u957f\u671f\u5b58\u5728\u7684\u53ef\u6269\u5c55\u6027\u74f6\u9888\uff0c\u66f4\u901a\u8fc7\u521b\u65b0\u7684\u52a8\u4f5c\u5efa\u6a21\u4e0e\u5956\u52b1\u8bbe\u8ba1\uff0c\u4f7f\u5176\u5728\u771f\u5b9e\u57ce\u5e02\u7ea7\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5177\u5907\u53ef\u90e8\u7f72\u6027\u3002", "AI": {"tldr": "MARL-OD-DA\u4e0d\u4ec5\u7a81\u7834\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u4ea4\u901a\u5206\u914d\u9886\u57df\u957f\u671f\u5b58\u5728\u7684\u53ef\u6269\u5c55\u6027\u74f6\u9888\uff0c\u66f4\u901a\u8fc7\u521b\u65b0\u7684\u52a8\u4f5c\u5efa\u6a21\u4e0e\u5956\u52b1\u8bbe\u8ba1\uff0c\u4f7f\u5176\u5728\u771f\u5b9e\u57ce\u5e02\u7ea7\u4ea4\u901a\u7cfb\u7edf\u4e2d\u5177\u5907\u53ef\u90e8\u7f72\u6027\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.af4779bb", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzIxNDgzNDg3NQ==&mid=2247573366&idx=2&sn=0478bca5a3ff3c2db69cbc163e3986f6&chksm=96e1dd9d27ad5d61264b199d9808cf42e76c9c5d1979093f4a677cbb22d6d2a95816fadd6614#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzIxNDgzNDg3NQ==&mid=2247573366&idx=2&sn=0478bca5a3ff3c2db69cbc163e3986f6&chksm=96e1dd9d27ad5d61264b199d9808cf42e76c9c5d1979093f4a677cbb22d6d2a95816fadd6614#rd", "authors": ["\u6df1\u5ea6\u5b66\u4e60\u4e0eNLP"], "title": "DRL\u5723\u7ecf2025\u6700\u65b0\u7248-\u300a<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>:\u5bfc\u8bba\u7b2c\u4e8c\u7248\u300b\u514d\u8d39pdf\u5206\u4eab", "comment": "Source: WeChat, Published: 2025-12-15 05:00:00", "summary": "\u6211\u4eec\u7b2c\u4e8c\u7248\u7684\u76ee\u6807\u548c\u7b2c\u4e00\u7248\u7684\u76ee\u6807\u662f\u4e00\u6837\u7684\uff1a\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u601d\u60f3\u548c\u7b97\u6cd5\u63d0\u4f9b\u4e00\u4e2a\u6e05\u6670\u800c\u7b80\u5355\u7684\u63cf\u8ff0\uff0c\u4f9b\u6240\u6709\u76f8\u5173\u5b66\u79d1\u7684\u8bfb\u8005\u9605\u8bfb\u3002\u8be5\u7248\u672c\u4ecd\u7136\u662f\u4e00\u4e2a\u4ecb\u7ecd\uff0c\u6211\u4eec\u4fdd\u7559\u4e86\u6838\u5fc3\uff0c\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u7684\u91cd\u70b9\u3002", "AI": {"tldr": "\u6211\u4eec\u7b2c\u4e8c\u7248\u7684\u76ee\u6807\u548c\u7b2c\u4e00\u7248\u7684\u76ee\u6807\u662f\u4e00\u6837\u7684\uff1a\u4e3a\u5f3a\u5316\u5b66\u4e60\u7684\u5173\u952e\u601d\u60f3\u548c\u7b97\u6cd5\u63d0\u4f9b\u4e00\u4e2a\u6e05\u6670\u800c\u7b80\u5355\u7684\u63cf\u8ff0\uff0c\u4f9b\u6240\u6709\u76f8\u5173\u5b66\u79d1\u7684\u8bfb\u8005\u9605\u8bfb\u3002\u8be5\u7248\u672c\u4ecd\u7136\u662f\u4e00\u4e2a\u4ecb\u7ecd\uff0c\u6211\u4eec\u4fdd\u7559\u4e86\u6838\u5fc3\uff0c\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u7684\u91cd\u70b9\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.86885209", "categories": ["wechat.article", "wechat.ai", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk0NDYxNDQxOQ==&mid=2247484844&idx=1&sn=6d4dbe4528a9b6273014619bbe320582&chksm=c2b6bbc1b64c6557bd92112a1f6d28b006281587858af764d2ee9cea553168e1ade4b03b46ed#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk0NDYxNDQxOQ==&mid=2247484844&idx=1&sn=6d4dbe4528a9b6273014619bbe320582&chksm=c2b6bbc1b64c6557bd92112a1f6d28b006281587858af764d2ee9cea553168e1ade4b03b46ed#rd", "authors": ["\u7fcc\u4e1c\u5bf0\u7403"], "title": "AI\u5982\u4f55\u201c\u65e0\u5e08\u81ea\u901a\u201d\uff1a<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u8bad\u7ec3\u5965\u79d8", "comment": "Source: WeChat, Published: 2025-12-15 02:00:00", "summary": "04\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u5904\u7406\u7535\u5b50\u6e38\u620f\u6216\u81ea\u52a8\u9a7e\u9a76\u7b49\u590d\u6742\u573a\u666f\u65f6\u663e\u5f97\u529b\u4e0d\u4ece\u5fc3\uff0c\u8fd9\u662f\u56e0\u4e3a\u72b6\u6001\u7a7a\u95f4\u592a\u8fc7\u5e9e\u5927\uff0c\u6bd4\u5982Dota 2\u7684\u72b6\u6001\u7a7a\u95f4\u51e0\u4e4e\u65e0\u9650\u3002", "AI": {"tldr": "04\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u5904\u7406\u7535\u5b50\u6e38\u620f\u6216\u81ea\u52a8\u9a7e\u9a76\u7b49\u590d\u6742\u573a\u666f\u65f6\u663e\u5f97\u529b\u4e0d\u4ece\u5fc3\uff0c\u8fd9\u662f\u56e0\u4e3a\u72b6\u6001\u7a7a\u95f4\u592a\u8fc7\u5e9e\u5927\uff0c\u6bd4\u5982Dota 2\u7684\u72b6\u6001\u7a7a\u95f4\u51e0\u4e4e\u65e0\u9650\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.2c662cda", "categories": ["wechat.article", "wechat.rl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkwODY3ODc0MQ==&mid=2247483753&idx=1&sn=dba52b0d9da931430fd5628eef49112d&chksm=c1140b209b7d1ba8cb83d04bb18f6fd86320dae332d7389a55c5384b2402d4387a9180591f99#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkwODY3ODc0MQ==&mid=2247483753&idx=1&sn=dba52b0d9da931430fd5628eef49112d&chksm=c1140b209b7d1ba8cb83d04bb18f6fd86320dae332d7389a55c5384b2402d4387a9180591f99#rd", "authors": ["\u667a\u80fd\u539f\u59cb\u4eba"], "title": "<em class=\"highlight\">\u5f3a\u5316\u5b66\u4e60</em>\u4e2d\u7684\u9a6c\u5c14\u53ef\u592b", "comment": "Source: WeChat, Published: 2025-12-14 16:22:11", "summary": "#\u7b97\u6cd5 #\u5f3a\u5316\u5b66\u4e60", "AI": {"tldr": "#\u7b97\u6cd5 #\u5f3a\u5316\u5b66\u4e60", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agentic reinforcement learning"}}
{"id": "wechat.2512.c7b93bcd", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzk1NzMyNDQxNg==&mid=2247488111&idx=1&sn=e7d27457aeafb4420db3262627491fcb&chksm=c20d1c0f83b42b72675645971cd1c555aec08aadf17782f01174d59eaf72ef4a00d82f5ebe98#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzk1NzMyNDQxNg==&mid=2247488111&idx=1&sn=e7d27457aeafb4420db3262627491fcb&chksm=c20d1c0f83b42b72675645971cd1c555aec08aadf17782f01174d59eaf72ef4a00d82f5ebe98#rd", "authors": ["AcademicDaily"], "title": "\u5f00\u6e90 AI \u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5c01\u795e\uff01Meta + \u54c8\u4f5b\u63a8\u51fa CCA\uff0c\u5de5\u4e1a\u7ea7<em class=\"highlight\">\u4ee3\u7801</em>\u4efb\u52a1\u901a\u8fc7\u7387 54.3% \u7834\u7eaa\u5f55", "comment": "Source: WeChat, Published: 2025-12-15 04:08:00", "summary": "\u8fd1\u65e5\uff0cMeta \u4e0e\u54c8\u4f5b\u5927\u5b66\u56e2\u961f\u5f00\u6e90\u4e86\u5de5\u4e1a\u7ea7 AI \u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5b54\u5b50\u7f16\u7801\u667a\u80fd\u4f53\uff08Confucius Code Agent\uff08CCA\uff09\uff09\uff0c\u57fa\u4e8e\u5168\u65b0 Confucius SDK \u6784\u5efa\uff0c\u4e0d\u4ec5\u5728 SWE-Bench-Pro \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u521b\u4e0b 54.3% \u7684 Resole@1 \u6210\u7ee9\uff0c\u66f4\u5b9e\u73b0\u4e86 \u201c\u900f\u660e\u53ef\u6269\u5c55 + \u5de5\u4e1a\u7ea7\u6027\u80fd\u201d \u7684\u53cc", "AI": {"tldr": "\u8fd1\u65e5\uff0cMeta \u4e0e\u54c8\u4f5b\u5927\u5b66\u56e2\u961f\u5f00\u6e90\u4e86\u5de5\u4e1a\u7ea7 AI \u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5b54\u5b50\u7f16\u7801\u667a\u80fd\u4f53\uff08Confucius Code Agent\uff08CCA\uff09\uff09\uff0c\u57fa\u4e8e\u5168\u65b0 Confucius SDK \u6784\u5efa\uff0c\u4e0d\u4ec5\u5728 SWE-Bench-Pro \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u521b\u4e0b 54.3% \u7684 Resole@1 \u6210\u7ee9\uff0c\u66f4\u5b9e\u73b0\u4e86 \u201c\u900f\u660e\u53ef\u6269\u5c55 + \u5de5\u4e1a\u7ea7\u6027\u80fd\u201d \u7684\u53cc", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
{"id": "wechat.2512.f13a4553", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzYyMTQzNzY2OA==&mid=2247484177&idx=1&sn=4d7560a5c2f447a295426948755abccc&chksm=fe2a934ae871d30c0179c4efc38c3b8dfa38da048e089215a61574214d4063409d2157c7f48b#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzYyMTQzNzY2OA==&mid=2247484177&idx=1&sn=4d7560a5c2f447a295426948755abccc&chksm=fe2a934ae871d30c0179c4efc38c3b8dfa38da048e089215a61574214d4063409d2157c7f48b#rd", "authors": ["\u9f99\u5927\u804aAI"], "title": "\u4e09\u5206\u949f\u770b\u61c2\u751f\u6210\u5f0fAI\u3001AI Agent\u548c<em class=\"highlight\">Agentic</em> AI\u7684\u672c\u8d28\u533a\u522b", "comment": "Source: WeChat, Published: 2025-12-15 05:50:31", "summary": "\u672c\u8d28\u533a\u522b\uff1aAI Agent\uff1a\u4e00\u4e2a\u80fd\u5e72\u7684\u5458\u5de5Agentic AI\uff1a\u4e00\u4e2a\u80fd\u81ea\u6211\u534f\u8c03\u7684\u56e2\u961f\u4e09\u8005\u80fd\u529b\u5bf9\u6bd4\uff1a\u4ece\"\u804a\u5929\"\u5230\"\u529e\u4e8b\"\u8ba9\u6211\u4eec\u7528\u4e00\u5f20\u8868\u683c\u770b\u6e05\u695a\u5b83\u4eec\u7684\u533a\u522b\uff1a\u80fd\u529b\u7ef4\u5ea6\u751f\u6210\u5f0fAI", "AI": {"tldr": "\u672c\u8d28\u533a\u522b\uff1aAI Agent\uff1a\u4e00\u4e2a\u80fd\u5e72\u7684\u5458\u5de5Agentic AI\uff1a\u4e00\u4e2a\u80fd\u81ea\u6211\u534f\u8c03\u7684\u56e2\u961f\u4e09\u8005\u80fd\u529b\u5bf9\u6bd4\uff1a\u4ece\"\u804a\u5929\"\u5230\"\u529e\u4e8b\"\u8ba9\u6211\u4eec\u7528\u4e00\u5f20\u8868\u683c\u770b\u6e05\u695a\u5b83\u4eec\u7684\u533a\u522b\uff1a\u80fd\u529b\u7ef4\u5ea6\u751f\u6210\u5f0fAI", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.48288bbf", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4Mjg4NTQxMQ==&mid=2247549601&idx=1&sn=5a02779b3a75f5dbe65f4f2e188b2937&chksm=cea58402e25f9acd1241a364f6886c73ed64a13a03fe64155c1d16f9b40cf6eb265446f3013a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4Mjg4NTQxMQ==&mid=2247549601&idx=1&sn=5a02779b3a75f5dbe65f4f2e188b2937&chksm=cea58402e25f9acd1241a364f6886c73ed64a13a03fe64155c1d16f9b40cf6eb265446f3013a#rd", "authors": ["\u5927\u6a21\u578b\u4e4b\u5fc3Tech"], "title": "\u804a\u804a\u5173\u4e8e <em class=\"highlight\">Agentic</em> RL \u8bad\u63a8\u6846\u67b6\u7684\u4e00\u70b9\u770b\u6cd5\u548c\u601d\u8003", "comment": "Source: WeChat, Published: 2025-12-15 03:51:34", "summary": "\u76ee\u524d\u6ca1\u6709\u4e00\u6b3e\u53ef\u4ee5\u5f88\u597d\u9002\u914d\u591a\u6a21\u6001\u6a21\u578b\u53bb\u505a\u6211\u7684\u9700\u6c42\u4e1a\u52a1\u7684 agentic rl \u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u5f53\u7136\u8fd9\u4e5f\u4e0d\u662f\u6846\u67b6\u7684\u539f\u56e0\uff0c\u4e3b\u8981\u5728\u4e8e agentic \u73af\u5883\u4e0e\u5177\u4f53\u4e1a\u52a1\u76f8\u5173\uff0c\u6ca1\u6709\u529e\u6cd5\u4ece\u6846\u67b6\u5c42\u9762\u62bd\u8c61\u51fa\u6765\u4e00\u4e2a\u51fd\u6570\u6216\u8005\u7c7b\u6765\u9002\u914d\u6240\u6709\u7684 agentic \u73af\u5883\uff0c\u8fd9\u4e5f\u662f", "AI": {"tldr": "\u76ee\u524d\u6ca1\u6709\u4e00\u6b3e\u53ef\u4ee5\u5f88\u597d\u9002\u914d\u591a\u6a21\u6001\u6a21\u578b\u53bb\u505a\u6211\u7684\u9700\u6c42\u4e1a\u52a1\u7684 agentic rl \u8bad\u7ec3\u7684\u6846\u67b6\uff0c\u5f53\u7136\u8fd9\u4e5f\u4e0d\u662f\u6846\u67b6\u7684\u539f\u56e0\uff0c\u4e3b\u8981\u5728\u4e8e agentic \u73af\u5883\u4e0e\u5177\u4f53\u4e1a\u52a1\u76f8\u5173\uff0c\u6ca1\u6709\u529e\u6cd5\u4ece\u6846\u67b6\u5c42\u9762\u62bd\u8c61\u51fa\u6765\u4e00\u4e2a\u51fd\u6570\u6216\u8005\u7c7b\u6765\u9002\u914d\u6240\u6709\u7684 agentic \u73af\u5883\uff0c\u8fd9\u4e5f\u662f", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.43887a76", "categories": ["wechat.article", "wechat.ai", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg4MjkwMDkxMQ==&mid=2247488946&idx=2&sn=f9c995f5aa6317c90daa664e38a1fe20&chksm=ce4cccde5c9cf3ba8316d538e1bab154a4f532660e09816808257e0fe98e0aa0ec69dfe35b1a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg4MjkwMDkxMQ==&mid=2247488946&idx=2&sn=f9c995f5aa6317c90daa664e38a1fe20&chksm=ce4cccde5c9cf3ba8316d538e1bab154a4f532660e09816808257e0fe98e0aa0ec69dfe35b1a#rd", "authors": ["AIGC\u63a2\u7d22"], "title": "AI <em class=\"highlight\">\u667a\u80fd\u4f53</em>\u6838\u5fc3\u539f\u7406\u7efc\u8ff0\uff1a\u4ece <em class=\"highlight\">Agentic</em> AI \u5230 AI Agent", "comment": "Source: WeChat, Published: 2025-12-15 02:16:23", "summary": "agentic ai \u7684\u80cc\u666f LLM \u6700\u521d\u7684\u4ea7\u54c1\u5f62\u6001\u662f\u7531 OpenAI \u9886\u8854\u7684 ChatBot\uff08\u804a\u5929\u673a\u5668\u4eba\uff09\uff0c\u5e95\u5c42\u652f\u6491\u6280\u672f\u662f Transformer \u67b6\u6784\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6700\u521d\u4e13\u6ce8\u4e8e\u8bed\u8a00\u6587\u672c\u9886\u57df\u7684\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u573a\u666f\u3002", "AI": {"tldr": "agentic ai \u7684\u80cc\u666f LLM \u6700\u521d\u7684\u4ea7\u54c1\u5f62\u6001\u662f\u7531 OpenAI \u9886\u8854\u7684 ChatBot\uff08\u804a\u5929\u673a\u5668\u4eba\uff09\uff0c\u5e95\u5c42\u652f\u6491\u6280\u672f\u662f Transformer \u67b6\u6784\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u6700\u521d\u4e13\u6ce8\u4e8e\u8bed\u8a00\u6587\u672c\u9886\u57df\u7684\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u573a\u666f\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.6435fe3a", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&mid=2247504821&idx=1&sn=2452ca9c378c9d24035aa0a5850233f8&chksm=fbb1b98070188f100d387bec5f564a9f1a8b33aade18bbd99482a5ccb44404bec1a4e529723c#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzUzOTgwNDMzOQ==&mid=2247504821&idx=1&sn=2452ca9c378c9d24035aa0a5850233f8&chksm=fbb1b98070188f100d387bec5f564a9f1a8b33aade18bbd99482a5ccb44404bec1a4e529723c#rd", "authors": ["AINLPer"], "title": "Google\u53d1\u5e03\uff01\u4e00\u6587\u4e86\u89e321\u79cd<em class=\"highlight\">Agentic</em>\u8bbe\u8ba1\u6a21\u5f0f", "comment": "Source: WeChat, Published: 2025-12-15 02:01:14", "summary": "\u626b\u7801\u56de\u590d\u201c\u667a\u80fd\u4f53\u8bbe\u8ba1\u201d\u514d\u8d39\u9886\u53d6\u539f\u8457&\u4e2d\u6587\u7248PDF\u5982\u679c\u4f60\u60f3\u5199\u5927\u6a21\u578b\u8bba\u6587\uff0c\u4f46\u5374\u6ca1\u6709\u5408\u9002\u7684idea\uff0c\u6211\u6536\u96c6\u6574\u7406\u4e86\u6765\u81eaQS\u524d50\u540d\u6821\u5927\u4f6c\u7684\u5927\u6a21\u578b\u7814\u7a76\u601d\u8def\uff01", "AI": {"tldr": "\u626b\u7801\u56de\u590d\u201c\u667a\u80fd\u4f53\u8bbe\u8ba1\u201d\u514d\u8d39\u9886\u53d6\u539f\u8457&\u4e2d\u6587\u7248PDF\u5982\u679c\u4f60\u60f3\u5199\u5927\u6a21\u578b\u8bba\u6587\uff0c\u4f46\u5374\u6ca1\u6709\u5408\u9002\u7684idea\uff0c\u6211\u6536\u96c6\u6574\u7406\u4e86\u6765\u81eaQS\u524d50\u540d\u6821\u5927\u4f6c\u7684\u5927\u6a21\u578b\u7814\u7a76\u601d\u8def\uff01", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.0d2e0471", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg5MTkzMzQ5Ng==&mid=2247485462&idx=1&sn=8aeed61bcb4cacd0c546c85a542c46bf&chksm=ceee8010bc7d5d495f6016c1fb4b64d9692ecb7bf2d9446a4d1bbbb01c1cbe8e53f51456670e#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg5MTkzMzQ5Ng==&mid=2247485462&idx=1&sn=8aeed61bcb4cacd0c546c85a542c46bf&chksm=ceee8010bc7d5d495f6016c1fb4b64d9692ecb7bf2d9446a4d1bbbb01c1cbe8e53f51456670e#rd", "authors": ["\u51ef\u54e5\u63a2\u6570"], "title": "\u667a\u80fd<em class=\"highlight\">\u4ee3\u7406</em>\u5f0f\u6570\u636e\u7f16\u7ec7 <em class=\"highlight\">Agentic</em> Data Fabric", "comment": "Source: WeChat, Published: 2025-12-15 01:00:10", "summary": "\u5c06 Foundry \u6bd4\u4f5c\u201c\u8ba1\u5212\u7ecf\u6d4e\u4e0b\u7684\u91cd\u5de5\u4e1a\u5de5\u5382\u201d\uff0c\u90a3\u4e48 Agentic Data Fabric \u5c31\u662f\u201c\u5e02\u573a\u7ecf\u6d4e\u4e0b\u7684\u6309\u9700\uff08Just-in-Time\uff09\u5236\u9020\u7f51\u7edc\u201d\u3002\u4e00\u3001 \u901f\u5ea6\u7ef4\u5ea6\u7684\u78be\u538b\uff1a\u4ece \"\u9884\u5148\u5efa\u6a21\" \u5230 \"\u5373\u65f6\u63a8\u7406\"", "AI": {"tldr": "\u5c06 Foundry \u6bd4\u4f5c\u201c\u8ba1\u5212\u7ecf\u6d4e\u4e0b\u7684\u91cd\u5de5\u4e1a\u5de5\u5382\u201d\uff0c\u90a3\u4e48 Agentic Data Fabric \u5c31\u662f\u201c\u5e02\u573a\u7ecf\u6d4e\u4e0b\u7684\u6309\u9700\uff08Just-in-Time\uff09\u5236\u9020\u7f51\u7edc\u201d\u3002\u4e00\u3001 \u901f\u5ea6\u7ef4\u5ea6\u7684\u78be\u538b\uff1a\u4ece \"\u9884\u5148\u5efa\u6a21\" \u5230 \"\u5373\u65f6\u63a8\u7406\"", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.92ecadfa", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA4NjAzMjEyOA==&mid=2654576523&idx=1&sn=61f14d75497483862ed90b6111e33dda&chksm=8592e53b92531058e0ab8a0fbe625d3418217f70f15059d1f87aabcedcc763575eb8a093e0aa#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA4NjAzMjEyOA==&mid=2654576523&idx=1&sn=61f14d75497483862ed90b6111e33dda&chksm=8592e53b92531058e0ab8a0fbe625d3418217f70f15059d1f87aabcedcc763575eb8a093e0aa#rd", "authors": ["AI\u8fd0\u7ef4\u4eba\u673a\u65b0\u8303\u5f0f"], "title": "<em class=\"highlight\">Agentic</em> \u7ec4\u7ec7\u4e0b\u7684\u7ec8\u6781\u62f7\u95ee\uff1a\u5eb7\u5a01\u5b9a\u5f8b\u662f\u5426\u5df2\u5931\u6548\uff1f", "comment": "Source: WeChat, Published: 2025-12-15 00:05:56", "summary": "Agentic \u7ec4\u7ec7\uff1a\u4f19\u4f34\u5171\u751f\u4e0e\u201c\u4e09\u4eba\u884c\u201dAI Native \u65f6\u4ee3\u6700\u5927\u7684\u53d8\u9769\u5728\u4e8e\uff0cAgent \u6210\u4e3a\u4e86\u7ec4\u7ec7\u4e2d\u65b0\u7684\u3001\u9ad8\u6548\u7387\u7684\u3001\u65e0\u75b2\u52b3\u7684\u201c\u667a\u80fd\u4f19\u4f34\u201d\u3002\u5728\u60a8\u7684\u201c\u4e09\u4eba\u884c\u201d\u56e2\u961f\u6a21\u5f0f\u4e2d\uff08\u4e1a\u52a1\u4e13\u5bb6\u3001\u4ea7\u54c1\u7ecf\u7406\u3001\u6280\u672f\u7ecf\u7406\uff09\uff0cAgent \u7684\u4f5c\u7528\u662f\uff1a", "AI": {"tldr": "Agentic \u7ec4\u7ec7\uff1a\u4f19\u4f34\u5171\u751f\u4e0e\u201c\u4e09\u4eba\u884c\u201dAI Native \u65f6\u4ee3\u6700\u5927\u7684\u53d8\u9769\u5728\u4e8e\uff0cAgent \u6210\u4e3a\u4e86\u7ec4\u7ec7\u4e2d\u65b0\u7684\u3001\u9ad8\u6548\u7387\u7684\u3001\u65e0\u75b2\u52b3\u7684\u201c\u667a\u80fd\u4f19\u4f34\u201d\u3002\u5728\u60a8\u7684\u201c\u4e09\u4eba\u884c\u201d\u56e2\u961f\u6a21\u5f0f\u4e2d\uff08\u4e1a\u52a1\u4e13\u5bb6\u3001\u4ea7\u54c1\u7ecf\u7406\u3001\u6280\u672f\u7ecf\u7406\uff09\uff0cAgent \u7684\u4f5c\u7528\u662f\uff1a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.fd57e3ef", "categories": ["wechat.article", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg3MDY0OTQ0NA==&mid=2247507645&idx=1&sn=7a232eef2b9f44a4d21862bc244851cf&chksm=cf0bc1a01e96ae358c501dd83065bc4522a56558f2526fb0b3a832d26d6b2dce36169797158a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg3MDY0OTQ0NA==&mid=2247507645&idx=1&sn=7a232eef2b9f44a4d21862bc244851cf&chksm=cf0bc1a01e96ae358c501dd83065bc4522a56558f2526fb0b3a832d26d6b2dce36169797158a#rd", "authors": ["Andy730"], "title": "<em class=\"highlight\">\u667a\u80fd\u4f53</em>\uff08<em class=\"highlight\">Agentic</em> AI\uff09\u7684\u8fdb\u5316\u4e4b\u9053\uff1a\u6df1\u5ea6\u89e3\u8bfb\u81ea\u9002\u5e94\u6846\u67b6\u4e0e\u672a\u6765\u8d8b\u52bf", "comment": "Source: WeChat, Published: 2025-12-14 23:30:00", "summary": "\u672c\u6b21\u6df1\u5ea6\u89e3\u8bfb\u4ee5\u4e00\u7bc7\u524d\u6cbf\u7814\u7a76\u8bba\u6587\u4e3a\u6838\u5fc3\uff1a\u300aAdaptation of Agentic AI\u300b\u3002\u8be5\u8bba\u6587\u7531Pengcheng Jiang\uff0c Jiacheng Lin\uff0c Zhiyi Shi\u7b49\u4eba\u9886\u8854\uff0c\u6c47\u805a\u4e86\u6765\u81ea UIUC\u3001\u65af\u5766\u798f\u3001\u666e\u6797\u65af\u987f\u3001\u54c8\u4f5b\u3001UW \u7b49\u9876\u5c16\u673a\u6784\u7684\u7814\u7a76\u529b\u91cf\u3002", "AI": {"tldr": "\u672c\u6b21\u6df1\u5ea6\u89e3\u8bfb\u4ee5\u4e00\u7bc7\u524d\u6cbf\u7814\u7a76\u8bba\u6587\u4e3a\u6838\u5fc3\uff1a\u300aAdaptation of Agentic AI\u300b\u3002\u8be5\u8bba\u6587\u7531Pengcheng Jiang\uff0c Jiacheng Lin\uff0c Zhiyi Shi\u7b49\u4eba\u9886\u8854\uff0c\u6c47\u805a\u4e86\u6765\u81ea UIUC\u3001\u65af\u5766\u798f\u3001\u666e\u6797\u65af\u987f\u3001\u54c8\u4f5b\u3001UW \u7b49\u9876\u5c16\u673a\u6784\u7684\u7814\u7a76\u529b\u91cf\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.4b54dcb7", "categories": ["wechat.article"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzkwMjQwMTQ0Mw==&mid=2247483899&idx=1&sn=2f55f857ab794c1da0caadf9f4382eaf&chksm=c1aa905c1809da497bf93bc0f836c1da162e225afa1034bf79d132d02b678cf5150e8712a36f#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzkwMjQwMTQ0Mw==&mid=2247483899&idx=1&sn=2f55f857ab794c1da0caadf9f4382eaf&chksm=c1aa905c1809da497bf93bc0f836c1da162e225afa1034bf79d132d02b678cf5150e8712a36f#rd", "authors": ["\u6c34\u8c5a\u6570\u667a\u793e"], "title": "\u5434\u6069\u8fbe\u6700\u65b0\u8bfe\u7a0b\uff1a\u522b\u518d\u53ea\u5199Prompt\u4e86\uff01\u638c\u63e1<em class=\"highlight\">Agentic</em> AI\uff0c\u8ba9AI\u81ea\u4e3b\u5de5\u4f5c\uff01", "comment": "Source: WeChat, Published: 2025-12-14 14:49:42", "summary": "\u8fd9\u6b21\u4ed6\u5e26\u6765\u7684\u65b0\u8bfe\u7a0b\u540d\u5b57\u975e\u5e38\u76f4\u63a5\uff0c\u5c31\u53eb\u505a\"Agentic AI\"\u3002\u5982\u679c\u4f60\u8fd8\u5728\u5199\u63d0\u793a\u8bcd\uff08Prompt\uff09\uff0c\u5e76\u671f\u671bAI\u80fd\u5b8c\u6210\u590d\u6742\u7684\u9879\u76ee\uff0c\u90a3\u4f60\u4e00\u5b9a\u4e5f\u4f53\u4f1a\u8fc7\u5404\u79cd\u65e0\u5948\uff01\u672a\u6765\u8c01\u80fd\u7528\u597dAI\uff0c\u4e0d\u5728\u4e8e\u63d0\u793a\u8bcd\u5de5\u7a0b \uff08Prompt Engineering\uff09\uff0c\u800c\u5728\u4e8e\u5982\u4f55\u66f4\u597d\u5730\u7f16\u6392\u667a", "AI": {"tldr": "\u8fd9\u6b21\u4ed6\u5e26\u6765\u7684\u65b0\u8bfe\u7a0b\u540d\u5b57\u975e\u5e38\u76f4\u63a5\uff0c\u5c31\u53eb\u505a\"Agentic AI\"\u3002\u5982\u679c\u4f60\u8fd8\u5728\u5199\u63d0\u793a\u8bcd\uff08Prompt\uff09\uff0c\u5e76\u671f\u671bAI\u80fd\u5b8c\u6210\u590d\u6742\u7684\u9879\u76ee\uff0c\u90a3\u4f60\u4e00\u5b9a\u4e5f\u4f53\u4f1a\u8fc7\u5404\u79cd\u65e0\u5948\uff01\u672a\u6765\u8c01\u80fd\u7528\u597dAI\uff0c\u4e0d\u5728\u4e8e\u63d0\u793a\u8bcd\u5de5\u7a0b \uff08Prompt Engineering\uff09\uff0c\u800c\u5728\u4e8e\u5982\u4f55\u66f4\u597d\u5730\u7f16\u6392\u667a", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.f87e2985", "categories": ["wechat.article", "wechat.ai", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzI0NzA3MTk2NQ==&mid=2662951542&idx=1&sn=35ada390ee621218c44170781c74bba2&chksm=f35f93206edc5c3af8ee1e7ab53ce8ece78763a3174f8af1c30ce10b8e150f602ca06e4802c8#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzI0NzA3MTk2NQ==&mid=2662951542&idx=1&sn=35ada390ee621218c44170781c74bba2&chksm=f35f93206edc5c3af8ee1e7ab53ce8ece78763a3174f8af1c30ce10b8e150f602ca06e4802c8#rd", "authors": ["\u751f\u7269\u4fe1\u606f\u4e0e\u80b2\u79cd"], "title": "\u6211\u5bf9\u80b2\u79cd<em class=\"highlight\">\u5927\u6a21\u578b</em>\u7684\u4e00\u4e9b\u7c97\u6d45\u770b\u6cd5", "comment": "Source: WeChat, Published: 2025-12-15 09:55:30", "summary": "\u4e94\u3001\u603b\u7ed3 \u80b2\u79cd\u5927\u6a21\u578b\u4e0d\u5e94\u662f\u6280\u672f\u70ab\u6280\uff0c\u800c\u5e94\u662f\u52a1\u5b9e\u589e\u6548\u7684\u5de5\u5177\u3002\u5b83\u7684\u7406\u60f3\u5f62\u6001\u662f\u4e00\u4e2a \u201c\u4e09\u5c42\u67b6\u6784\u201d\uff1a\u5e95\u5c42\u662f\u9886\u57df\u9002\u5e94\u7684\u57fa\u7840\u6a21\u578b\uff08\u5b89\u5168\u53ef\u63a7\uff09\uff0c\u4e2d\u5c42\u662f\u6301\u7eed\u79ef\u7d2f\u7684\u79c1\u6709\u6570\u636e\u98de\u8f6e\uff08\u8d8a\u7528\u8d8a\u806a\u660e\uff09\uff0c\u4e0a\u5c42\u662f\u89e3\u51b3\u5177\u4f53\u573a\u666f\u7684\u667a\u80fd\u4f53\uff08", "AI": {"tldr": "\u4e94\u3001\u603b\u7ed3 \u80b2\u79cd\u5927\u6a21\u578b\u4e0d\u5e94\u662f\u6280\u672f\u70ab\u6280\uff0c\u800c\u5e94\u662f\u52a1\u5b9e\u589e\u6548\u7684\u5de5\u5177\u3002\u5b83\u7684\u7406\u60f3\u5f62\u6001\u662f\u4e00\u4e2a \u201c\u4e09\u5c42\u67b6\u6784\u201d\uff1a\u5e95\u5c42\u662f\u9886\u57df\u9002\u5e94\u7684\u57fa\u7840\u6a21\u578b\uff08\u5b89\u5168\u53ef\u63a7\uff09\uff0c\u4e2d\u5c42\u662f\u6301\u7eed\u79ef\u7d2f\u7684\u79c1\u6709\u6570\u636e\u98de\u8f6e\uff08\u8d8a\u7528\u8d8a\u806a\u660e\uff09\uff0c\u4e0a\u5c42\u662f\u89e3\u51b3\u5177\u4f53\u573a\u666f\u7684\u667a\u80fd\u4f53\uff08", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.07a5edde", "categories": ["wechat.article", "wechat.ai", "wechat.cl", "wechat.agent"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzA3OTM0NTQwMw==&mid=2649939974&idx=1&sn=dcb6c7a2de8059ba508d3f7ea1a9bfae&chksm=8684120d9457146f7172c76fa43d4591365bc19f5fc254049323271ac0465da537b8a051ebbb#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzA3OTM0NTQwMw==&mid=2649939974&idx=1&sn=dcb6c7a2de8059ba508d3f7ea1a9bfae&chksm=8684120d9457146f7172c76fa43d4591365bc19f5fc254049323271ac0465da537b8a051ebbb#rd", "authors": ["\u65b0\u8f6f\u4ef6"], "title": "<em class=\"highlight\">\u5927\u6a21\u578b</em>\u4e3a\u4f55\u4f1a\u72af\u4f4e\u7ea7\u903b\u8f91\u9519\u8bef\uff1f", "comment": "Source: WeChat, Published: 2025-12-15 09:00:18", "summary": "\u5317\u4eac\u5927\u5b66\u52a9\u7406\u7814\u7a76\u5458\u3001\u725b\u6d25\u5927\u5b66\u9879\u76ee\u4e2d\u5fc3\u7814\u7a76\u5458\u674e\u660a\u8f69\u53ca\u5176\u56e2\u961f\uff0c\u5728\u8fc7\u53bb\u534a\u5e74\u6df1\u8015\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u903b\u8f91\u63a8\u7406\u4e0e\u56e0\u679c\u6027\u7814\u7a76\uff0c\u4e0d\u4ec5\u63ed\u793a\u4e86\u5927\u6a21\u578b\u201c\u72af\u7cca\u6d82\u201d\u7684\u5e95\u5c42\u539f\u56e0\uff0c\u8fd8\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u534f\u540c\u7b49\u521b\u65b0\u65b9\u6848\uff0c\u4e3aAI\u4ece\u201c\u51ed\u76f8\u5173\u6027\u5224\u65ad", "AI": {"tldr": "\u5317\u4eac\u5927\u5b66\u52a9\u7406\u7814\u7a76\u5458\u3001\u725b\u6d25\u5927\u5b66\u9879\u76ee\u4e2d\u5fc3\u7814\u7a76\u5458\u674e\u660a\u8f69\u53ca\u5176\u56e2\u961f\uff0c\u5728\u8fc7\u53bb\u534a\u5e74\u6df1\u8015\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u903b\u8f91\u63a8\u7406\u4e0e\u56e0\u679c\u6027\u7814\u7a76\uff0c\u4e0d\u4ec5\u63ed\u793a\u4e86\u5927\u6a21\u578b\u201c\u72af\u7cca\u6d82\u201d\u7684\u5e95\u5c42\u539f\u56e0\uff0c\u8fd8\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u534f\u540c\u7b49\u521b\u65b0\u65b9\u6848\uff0c\u4e3aAI\u4ece\u201c\u51ed\u76f8\u5173\u6027\u5224\u65ad", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.1d1dea1c", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzE5MTIyNzIzOQ==&mid=2247484970&idx=2&sn=e06c0faca5fa39eea05988e49d225f76&chksm=97d7865f11e4e74b8cbcca7fc5eefcb98e4a6581712bbfd12fbcd5e5408b11269bc3aa730da7#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzE5MTIyNzIzOQ==&mid=2247484970&idx=2&sn=e06c0faca5fa39eea05988e49d225f76&chksm=97d7865f11e4e74b8cbcca7fc5eefcb98e4a6581712bbfd12fbcd5e5408b11269bc3aa730da7#rd", "authors": ["MIC\u6a21\u521b\u793e\u533a"], "title": "\u6a21\u521b\u89c2\u5bdf\uff5cMIIT/TC1\u91cd\u70b9\u6807\u51c6\u5ba3\u4ecb\uff1a\u4eba\u5de5\u667a\u80fd<em class=\"highlight\">\u5927\u6a21\u578b</em>\u8bc4\u6d4b\u7cfb\u5217\u6807\u51c6", "comment": "Source: WeChat, Published: 2025-12-15 08:53:43", "summary": "\u76ee\u524d\uff0c\u5927\u6a21\u578b\u8bc4\u6d4b\u7cfb\u5217\u6807\u51c6\u5df2\u5728\u963f\u91cc\u3001\u767e\u5ea6\u3001\u534e\u4e3a\u3001\u767e\u5ea6\u3001\u817e\u8baf\u3001\u79d1\u5927\u8baf\u98de\u3001\u4e2d\u79d1\u9662\u7b49100\u4f59\u5bb6\u5355\u4f4d\u5e94\u7528\uff0c\u5168\u9762\u652f\u6491\u5927\u6a21\u578b\u7684\u7814\u53d1\u3001\u4f18\u5316\u4e0e\u8bc4\u4f30\u7b49\u5173\u952e\u73af\u8282\uff0c\u4e3a\u5927\u6a21\u578b\u6280\u672f\u7814\u53d1\u65b9\u548c\u884c\u4e1a\u5e94\u7528\u65b9\u63d0\u4f9b\u79d1\u5b66\u3001\u53ef\u9760\u7684\u9009\u578b\u4f9d\u636e\u4e0e\u6027\u80fd\u4f18\u5316", "AI": {"tldr": "\u76ee\u524d\uff0c\u5927\u6a21\u578b\u8bc4\u6d4b\u7cfb\u5217\u6807\u51c6\u5df2\u5728\u963f\u91cc\u3001\u767e\u5ea6\u3001\u534e\u4e3a\u3001\u767e\u5ea6\u3001\u817e\u8baf\u3001\u79d1\u5927\u8baf\u98de\u3001\u4e2d\u79d1\u9662\u7b49100\u4f59\u5bb6\u5355\u4f4d\u5e94\u7528\uff0c\u5168\u9762\u652f\u6491\u5927\u6a21\u578b\u7684\u7814\u53d1\u3001\u4f18\u5316\u4e0e\u8bc4\u4f30\u7b49\u5173\u952e\u73af\u8282\uff0c\u4e3a\u5927\u6a21\u578b\u6280\u672f\u7814\u53d1\u65b9\u548c\u884c\u4e1a\u5e94\u7528\u65b9\u63d0\u4f9b\u79d1\u5b66\u3001\u53ef\u9760\u7684\u9009\u578b\u4f9d\u636e\u4e0e\u6027\u80fd\u4f18\u5316", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.73a97d8b", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=MzAxNjYxOTY3NQ==&mid=2455622945&idx=1&sn=51d51f3fad593cf0f83d4d3464502b44&chksm=8d25a43619788d85d9eb6b57c0ca75f67653814f3893a6b8e44ab494d8257f93ebc90dd10832#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MzAxNjYxOTY3NQ==&mid=2455622945&idx=1&sn=51d51f3fad593cf0f83d4d3464502b44&chksm=8d25a43619788d85d9eb6b57c0ca75f67653814f3893a6b8e44ab494d8257f93ebc90dd10832#rd", "authors": ["\u5927\u6a21\u578b\u8bc4\u6d4b\u53ca\u4f18\u5316NoneLinear"], "title": "\u6bcf\u5468AI<em class=\"highlight\">\u5927\u6a21\u578b</em>\u66f4\u65b0\u901f\u901212.08~12.14", "comment": "Source: WeChat, Published: 2025-12-15 04:30:47", "summary": "\u5927\u6a21\u578b/agent\u8bc4\u6d4b\u6280\u672f\u4ea4\u6d41\uff1a\u5173\u6ce8\u516c\u4f17\u53f7\uff0c\u53d1\u9001\u6d88\u606f\"\u8fdb\u7fa4\"", "AI": {"tldr": "\u5927\u6a21\u578b/agent\u8bc4\u6d4b\u6280\u672f\u4ea4\u6d41\uff1a\u5173\u6ce8\u516c\u4f17\u53f7\uff0c\u53d1\u9001\u6d88\u606f\"\u8fdb\u7fa4\"", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "agent analysis"}}
{"id": "wechat.2512.c0a1ea98", "categories": ["wechat.article", "wechat.ai"], "pdf": "http://mp.weixin.qq.com/s?__biz=Mzg3ODU5NDI0MQ==&mid=2247499714&idx=1&sn=9c11ad87d3454ae85b4892f115001281&chksm=ced7b62f1608d16b4fcfadd262d0af3472b71ad79c13138c306d36f49cf37a13e9dd3eca8aa2#rd", "abs": "http://mp.weixin.qq.com/s?__biz=Mzg3ODU5NDI0MQ==&mid=2247499714&idx=1&sn=9c11ad87d3454ae85b4892f115001281&chksm=ced7b62f1608d16b4fcfadd262d0af3472b71ad79c13138c306d36f49cf37a13e9dd3eca8aa2#rd", "authors": ["\u53ef\u4fe1AI\u8bc4\u6d4b"], "title": "MIIT/TC1\u91cd\u70b9\u6807\u51c6\u5ba3\u4ecb | \u4eba\u5de5\u667a\u80fd<em class=\"highlight\">\u5927\u6a21\u578b</em>\u8bc4\u6d4b\u7cfb\u5217\u6807\u51c6", "comment": "Source: WeChat, Published: 2025-12-15 03:00:00", "summary": "\u76ee\u524d\uff0c\u5927\u6a21\u578b\u8bc4\u6d4b\u7cfb\u5217\u6807\u51c6\u5df2\u5728\u963f\u91cc\u3001\u767e\u5ea6\u3001\u534e\u4e3a\u3001\u767e\u5ea6\u3001\u817e\u8baf\u3001\u79d1\u5927\u8baf\u98de\u3001\u4e2d\u79d1\u9662\u7b49100\u4f59\u5bb6\u5355\u4f4d\u5e94\u7528\uff0c\u5168\u9762\u652f\u6491\u5927\u6a21\u578b\u7684\u7814\u53d1\u3001\u4f18\u5316\u4e0e\u8bc4\u4f30\u7b49\u5173\u952e\u73af\u8282\uff0c\u4e3a\u5927\u6a21\u578b\u6280\u672f\u7814\u53d1\u65b9\u548c\u884c\u4e1a\u5e94\u7528\u65b9\u63d0\u4f9b\u79d1\u5b66\u3001\u53ef\u9760\u7684\u9009\u578b\u4f9d\u636e\u4e0e\u6027\u80fd\u4f18\u5316", "AI": {"tldr": "\u76ee\u524d\uff0c\u5927\u6a21\u578b\u8bc4\u6d4b\u7cfb\u5217\u6807\u51c6\u5df2\u5728\u963f\u91cc\u3001\u767e\u5ea6\u3001\u534e\u4e3a\u3001\u767e\u5ea6\u3001\u817e\u8baf\u3001\u79d1\u5927\u8baf\u98de\u3001\u4e2d\u79d1\u9662\u7b49100\u4f59\u5bb6\u5355\u4f4d\u5e94\u7528\uff0c\u5168\u9762\u652f\u6491\u5927\u6a21\u578b\u7684\u7814\u53d1\u3001\u4f18\u5316\u4e0e\u8bc4\u4f30\u7b49\u5173\u952e\u73af\u8282\uff0c\u4e3a\u5927\u6a21\u578b\u6280\u672f\u7814\u53d1\u65b9\u548c\u884c\u4e1a\u5e94\u7528\u65b9\u63d0\u4f9b\u79d1\u5b66\u3001\u53ef\u9760\u7684\u9009\u578b\u4f9d\u636e\u4e0e\u6027\u80fd\u4f18\u5316", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "swe benchmark"}}
{"id": "wechat.2512.bee84866", "categories": ["wechat.article", "wechat.ai", "wechat.cl"], "pdf": "http://mp.weixin.qq.com/s?__biz=MjM5ODE3OTkxMQ==&mid=2650575313&idx=1&sn=82c4667c12f87f3b4fe87f2c331cf1aa&chksm=bf5d00340960d6b43bbd06f0de2a8911a447039f151e4211980d4e1df7df15eb9b6f5b855d0a#rd", "abs": "http://mp.weixin.qq.com/s?__biz=MjM5ODE3OTkxMQ==&mid=2650575313&idx=1&sn=82c4667c12f87f3b4fe87f2c331cf1aa&chksm=bf5d00340960d6b43bbd06f0de2a8911a447039f151e4211980d4e1df7df15eb9b6f5b855d0a#rd", "authors": ["\u81ea\u52a8\u5316\u8f6f\u4ef6\u6d4b\u8bd5"], "title": "<em class=\"highlight\">\u5927\u6a21\u578b</em>\u5728\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\uff1a\u5f00\u542f\u667a\u80fd\u5316\u6d4b\u8bd5\u65b0\u65f6\u4ee3", "comment": "Source: WeChat, Published: 2025-12-15 00:00:37", "summary": "\u89e3\u6790\uff1a \u5927\u6a21\u578b\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u7406\u89e3\uff0c\u5c06\u9700\u6c42\u63cf\u8ff0\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u811a\u672c\u7684\u5f00\u53d1\u6548\u7387\u30023. \u7f3a\u9677\u9884\u6d4b\u4e0e\u9759\u6001\u4ee3\u7801\u5206\u6790 \u5927\u6a21\u578b\u901a\u8fc7\u5b66\u4e60\u5386\u53f2\u4ee3\u7801\u548c\u7f3a\u9677\u6570\u636e\uff0c\u80fd\u591f\u9884\u6d4b\u53ef\u80fd\u7684\u7f3a\u9677\u4f4d\u7f6e\uff0c\u5e76\u7ed9\u51fa\u4f18\u5316\u5efa\u8bae\u3002", "AI": {"tldr": "\u89e3\u6790\uff1a \u5927\u6a21\u578b\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u7406\u89e3\uff0c\u5c06\u9700\u6c42\u63cf\u8ff0\u8f6c\u5316\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u6781\u5927\u5730\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u811a\u672c\u7684\u5f00\u53d1\u6548\u7387\u30023. \u7f3a\u9677\u9884\u6d4b\u4e0e\u9759\u6001\u4ee3\u7801\u5206\u6790 \u5927\u6a21\u578b\u901a\u8fc7\u5b66\u4e60\u5386\u53f2\u4ee3\u7801\u548c\u7f3a\u9677\u6570\u636e\uff0c\u80fd\u591f\u9884\u6d4b\u53ef\u80fd\u7684\u7f3a\u9677\u4f4d\u7f6e\uff0c\u5e76\u7ed9\u51fa\u4f18\u5316\u5efa\u8bae\u3002", "motivation": "\u5fae\u4fe1\u516c\u4f17\u53f7\u6587\u7ae0\uff0c\u5206\u4eabAI\u76f8\u5173\u6280\u672f\u5185\u5bb9", "method": "\u57fa\u4e8e\u5b9e\u9645\u5e94\u7528\u7ecf\u9a8c\u7684\u6280\u672f\u5206\u4eab", "result": "\u63d0\u4f9b\u5b9e\u7528\u7684AI\u6280\u672f\u89c1\u89e3\u548c\u6848\u4f8b\u5206\u6790", "conclusion": "\u9002\u5408\u4e86\u89e3AI\u6280\u672f\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528", "topic": "code agent"}}
