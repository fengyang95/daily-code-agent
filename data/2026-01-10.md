<div id=toc></div>

# Table of Contents

- [tldr.article](#tldr.article) [Total: 2]


<div id='tldr.article'></div>

# tldr.article [[Back]](#toc)

### [1] [Recursive Language Models and Context Folding](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fwww.primeintellect.ai%2Fblog%2Frlm%3Futm_source=tldrai/1/0100019b9e169e42-0780e18a-91e7-487b-b08f-7364d8885d51-000000/-O1FhO1xRYcWcLNCA9Uobgcf74J2zKgmQ3u4qWNSjmQ=439)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: 递归语言模型（RLM）通过脚本和子模型管理记忆，解决LLM智能体长上下文限制问题，避免信息摘要损失


<details>
  <summary>Details</summary>
Motivation: 传统语言模型在处理长上下文时存在限制，通常需要摘要来压缩信息，但摘要会丢失细节。RLM旨在通过递归结构和记忆管理来解决这一问题，使智能体能够处理更长的交互序列

Method: 提出递归语言模型（RLM）架构，使用脚本和子模型来管理记忆，通过递归调用和上下文折叠技术，避免传统的信息摘要方法，保持原始信息的完整性

Result: RLM能够有效处理长上下文任务，相比传统方法减少了信息损失，提高了智能体在复杂任务中的表现和记忆管理能力

Conclusion: 递归语言模型为LLM智能体的长上下文处理提供了灵活有效的解决方案，通过避免摘要和采用记忆管理策略，显著提升了智能体的长期记忆和任务执行能力

Abstract: Recursive Language Models and Context Folding (28 minute read) Recursive Language Model (RLM) is a flexible solution to long-context limitations in LLM agents. RLMs avoid summarization by delegating memory management to scripts and sub-models.

</details>


### [2] [Open Gaming Foundation Model](https://tracking.tldrnewsletter.com/CL0/https:%2F%2Fgithub.com%2FMineDojo%2FNitroGen%3Futm_source=tldrai/1/0100019b9e169e42-0780e18a-91e7-487b-b08f-7364d8885d51-000000/YYtTTf4_ZebEaQkYe0-Fn6soSuxJR1gjzQE-VLKT5Rc=439)
*TLDR Newsletter*

Main category: tldr.article

TL;DR: NitroGen是一个通用游戏智能体，通过互联网游戏视频训练，能够从像素预测控制器动作，并通过后训练适应未见过的游戏


<details>
  <summary>Details</summary>
Motivation: 开发一个通用的游戏智能体，能够从视觉输入直接学习游戏控制，并具备跨游戏的适应能力，减少对特定游戏专门训练的需求

Method: 使用互联网游戏视频进行训练，学习从像素到控制器动作的映射，采用后训练技术使模型能够适应新的未见过的游戏

Result: 创建了NitroGen模型，这是一个能够从像素预测控制器动作的通用游戏智能体，具备跨游戏适应能力

Conclusion: NitroGen展示了通过大规模互联网游戏视频训练通用游戏智能体的可行性，为开发能够适应多种游戏的AI系统提供了新途径

Abstract: Open Gaming Foundation Model (GitHub Repo) NitroGen is a generalist gaming agent trained on internet gameplay videos capable of predicting controller actions from pixels and adapting to unseen games through post-training.

</details>
